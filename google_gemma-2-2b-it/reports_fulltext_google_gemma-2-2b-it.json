{
  "model_id": "google/gemma-2-2b-it",
  "full_texts": [
    {
      "arxiv_id": "https://ai.google.dev/gemma/docs/base",
      "full_text": " Gemma 3 model overview &nbsp;|&nbsp; Google AI for Developers Skip to main content Models Gemini About Docs API reference Pricing Imagen About Docs Pricing Veo About Docs Pricing Gemma About Docs Gemmaverse Solutions Build with Gemini Gemini API Google AI Studio Customize Gemma open models Gemma open models Multi-framework with Keras Fine-tune in Colab Run on-device Google AI Edge Gemini Nano on Android Chrome built-in web APIs Build responsibly Responsible GenAI Toolkit Secure AI Framework Code assistance Android Studio Chrome DevTools Colab Firebase Google Cloud JetBrains Jules VS Code Showcase Gemini Showcase Gemini API Developer Competition Community Google AI Forum Gemini for Research / English Deutsch Español – América Latina Français Indonesia Italiano Polski Português – Brasil Shqip Tiếng Việt Türkçe Русский עברית العربيّة فارسی हिंदी বাংলা ภาษาไทย 中文 – 简体 中文 – 繁體 日本語 한국어 Sign in Gemma Docs Models More Gemma Docs Solutions More Code assistance More Showcase More Community More Overview Get started Releases Models Gemma 3 Overview Model card Gemma 2 model card Gemma 1 model card Gemma 3n Overview Model card EmbeddingGemma Overview Model card Generate embeddings with Sentence Transformers Fine-tune EmbeddingGemma CodeGemma Overview Model card Generate code with Keras Generate code with JAX and Flax Code assist with Keras Prompt and system instructions PaliGemma 2 Overview v2 model card v1 model card Generate output with Keras Fine-tune with JAX and Flax Prompt and system instructions ShieldGemma 2 Overview ShieldGemma 2 Model card ShieldGemma 1 Model card Run Gemma Overview Hugging Face Transformers Ollama Gemma library Keras PyTorch Gemma.cpp Gemini API Cloud GKE Cloud Run Prompt and system instructions Gemma setup Capabilities Function calling Visual data processing Overview Image interpretation Video understanding Content creation Audio data processing Tuning guides Overview Tune using LoRA and Keras Tune using Gemma library Tune using Hugging Face Transformers and QLoRA Vision Tune using Hugging Face Transformers and QLoRA Full model fine-tune using Hugging Face Transformers Distributed tuning using Keras Application guides Personal code assistant Business email assistant Spoken language tasks Chatbot using Python Meme Generator Deployment guides Web Mobile Google Cloud LangChain Research and tools RecurrentGemma Overview Inference using JAX and Flax Fine-tune using JAX and Flax Model card DataGemma Gemma Scope Gemma-APS Community Gemmaverse Discord Legal Terms of use Prohibited use Intended use statement Gemini About Docs API reference Pricing Imagen About Docs Pricing Veo About Docs Pricing Gemma About Docs Gemmaverse Build with Gemini Gemini API Google AI Studio Customize Gemma open models Gemma open models Multi-framework with Keras Fine-tune in Colab Run on-device Google AI Edge Gemini Nano on Android Chrome built-in web APIs Build responsibly Responsible GenAI Toolkit Secure AI Framework Android Studio Chrome DevTools Colab Firebase Google Cloud JetBrains Jules VS Code Gemini Showcase Gemini API Developer Competition Google AI Forum Gemini for Research Gemma 3n released with audio input and optimized for use in everyday devices! Learn more Home Gemma Models Docs Send feedback Gemma 3 model overview Gemma is a family of generative artificial intelligence (AI) models and you can use them in a wide variety of generation tasks, including question answering, summarization, and reasoning. Gemma models are provided with open weights and permit responsible commercial use , allowing you to tune and deploy them in your own projects and applications. The Gemma 3 release includes the following key features. Try it in AI Studio : Image and text input : Multimodal capabilities let you input images and text to understand and analyze visual data. Start building 128K token context : Significantly large input context for analyzing more data and solving more complex problems. Function calling : Build natural language interfaces for working with programming interfaces. Start building Wide language support : Work in your language or expand your AI application&#39;s language capabilities with support for over 140 languages. Start building Developer friendly model sizes : Choose a model size (270M, 1B, 4B, 12B, 27B) and precision level that works best for your task and compute resources. You can download Gemma 3 models from Kaggle and Hugging Face . For more technical details on Gemma 3, see the Model Card and Technical Report . Earlier versions of Gemma core models are also available for download. For more information, see Previous Gemma models . Try Gemma 3 Get it on Kaggle Get it on Hugging Face Multimodal image and text input You can tackle complex analysis and generation tasks with Gemma 3 with its ability to handle image and text data. You can use the model to interpret image data, identify objects, extract text data, and complete many other visual input to text output tasks. Start building Important: The Gemma 3 270M and 1B models are text only and do not support image input . 128K token context window Gemma 3 models (4B, 12B, and 27B) can handle prompt inputs up to 128K tokens, a 16x larger context window than previous Gemma models. The large number of tokens means you can process several, multi page articles, larger single articles, or hundreds of images in a single prompt. Important: The Gemma 3 270M and 1B models can process up to 32k tokens. Wide language support Work in your own language with built-in support for over 140 languages. Gemma 3 is trained to support a large number of languages compared to previous Gemma versions, letting you take on more visual and text tasks in the languages your customers use. Start building Function calling Build intelligent, natural language controls for programming interfaces. Gemma 3 lets you define coding functions with specific syntax and constraints, and the model can call these functions to complete tasks. Start building Parameter sizes and quantization Gemma 3 models are available in 5 parameter sizes: 270M, 1B, 4B, 12B, and 27B. The models can be used with their default precision (16-bit) or with a lower precision using quantization. The different sizes and precisions represent a set of trade-offs for your AI application. Models with higher parameters and bit counts (higher precision) are generally more capable, but are more expensive to run in terms of processing cycles, memory cost and power consumption. Models with lower parameters and bit counts (lower precision) have less capabilities, but may be sufficient for your AI task. For all Gemma 3 models, Quantization-Aware Trained checkpoints are provided, which allow quantizing (reducing the precision), while preserving high-quality. The following table details the approximate GPU or TPU memory requirements for running inference with each size of the Gemma 3 model versions. Note that the numbers may changed based on inference tool. Parameters BF16 (16-bit) SFP8 (8-bit) Q4_0 (4-bit) Gemma 3 270M ( text only ) 400 MB 297 MB 240 MB Gemma 3 1B ( text only ) 1.5 GB 1.1 GB 892 MB Gemma 3 4B 6.4 GB 4.4 GB 3.4 GB Gemma 3 12B 20 GB 12.2 GB 8.7 GB Gemma 3 27B 46.4 GB 29.1 GB 21 GB Table 1. Approximate GPU or TPU memory required to load Gemma 3 models based on parameter count and quantization level. Caution: These estimates only include the memory required to load the models. They don&#39;t include the additional memory required for the prompt tokens or supporting software. Memory consumption increases based on the total number of tokens required for the prompt you run. The larger the number of tokens required to process your prompt, the higher the memory required, which is in addition to the memory required to load the model. Note: Memory requirements for fine-tuning Gemma models are significantly higher than running inference. The requirements depend on the development framework and tuning technique you use, such as Low Rank Adapter (LoRA) versus full-precision tuning. Previous Gemma models You can work with previous generations of Gemma models, which are also available from Kaggle and Hugging Face . For more technical details about previous Gemma models, see the following model card pages: Gemma 2 Model Card Gemma 1 Model Card Ready to start building? Get started with Gemma models! Send feedback Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Last updated 2025-08-14 UTC. Need to tell us more? [[[\"Easy to understand\",\"easyToUnderstand\",\"thumb-up\"],[\"Solved my problem\",\"solvedMyProblem\",\"thumb-up\"],[\"Other\",\"otherUp\",\"thumb-up\"]],[[\"Missing the information I need\",\"missingTheInformationINeed\",\"thumb-down\"],[\"Too complicated / too many steps\",\"tooComplicatedTooManySteps\",\"thumb-down\"],[\"Out of date\",\"outOfDate\",\"thumb-down\"],[\"Samples / code issue\",\"samplesCodeIssue\",\"thumb-down\"],[\"Other\",\"otherDown\",\"thumb-down\"]],[\"Last updated 2025-08-14 UTC.\"],[],[],null,[\"# Gemma 3 model overview\\n\\nGemma is a family of generative artificial intelligence (AI) models and you can\\nuse them in a wide variety of generation tasks, including question answering,\\nsummarization, and reasoning. Gemma models are provided with open weights and\\npermit responsible\\n[commercial use](/gemma/terms),\\nallowing you to tune and deploy them in your own projects and applications.\\n\\nThe Gemma 3 release includes the following key features. Try it in\\n[AI Studio](https://aistudio.google.com/prompts/new_chat?model=gemma-3-27b-it):\\n\\n- [**Image and text input**](#multimodal-input): Multimodal capabilities let you input images and text to understand and analyze visual data. [Start building](/gemma/docs/core/keras_inference)\\n- [**128K token context**](#128k-context): Significantly large input context for analyzing more data and solving more complex problems.\\n- [**Function calling**](#function-calling): Build natural language interfaces for working with programming interfaces. [Start building](/gemma/docs/capabilities/function-calling)\\n- [**Wide language support**](#multilingual): Work in your language or expand your AI application's language capabilities with support for over 140 languages. [Start building](/gemma/docs/spoken-language)\\n- [**Developer friendly model sizes**](#sizes): Choose a model size (270M, 1B, 4B, 12B, 27B) and precision level that works best for your task and compute resources.\\n\\nYou can download Gemma 3 models from\\n[Kaggle](https://www.kaggle.com/models?query=gemma3&publisher=google) and\\n[Hugging Face](https://huggingface.co/collections/google/gemma-3-release-67c6c6f89c4f76621268bb6d).\\nFor more technical details on Gemma 3, see the\\n[Model Card](/gemma/docs/core/model_card_3) and\\n[Technical Report](https://goo.gle/Gemma3Report).\\nEarlier versions of Gemma core models are also available for download. For more\\ninformation, see [Previous Gemma models](#previous-models).\\n\\n[Try Gemma 3](https://aistudio.google.com/prompts/new_chat?model=gemma-3-27b-it)\\n[Get it on Kaggle](https://www.kaggle.com/models?query=gemma3&publisher=google)\\n[Get it on Hugging Face](https://huggingface.co/collections/google/gemma-3-release-67c6c6f89c4f76621268bb6d)\\n\\nMultimodal image and text input\\n-------------------------------\\n\\nYou can tackle complex analysis and generation tasks with Gemma 3 with its\\nability to handle image and text data. You can use the model to interpret image\\ndata, identify objects, extract text data, and complete many other visual input\\nto text output tasks.\\n[Start building](/gemma/docs/core/keras_inference)\\n| **Important:** The Gemma 3 270M and 1B models are text only and *do not support\\n| image input*.\\n\\n128K token context window\\n-------------------------\\n\\nGemma 3 models (4B, 12B, and 27B) can handle prompt inputs up to 128K tokens, a\\n16x larger context window than previous Gemma models. The large number of tokens\\nmeans you can process several, multi page articles, larger single articles, or\\nhundreds of images in a single prompt.\\n| **Important:** The Gemma 3 270M and 1B models can process up to 32k tokens.\\n\\nWide language support\\n---------------------\\n\\nWork in your own language with built-in support for over 140 languages. Gemma 3\\nis trained to support a large number of languages compared to previous Gemma\\nversions, letting you take on more visual and text tasks in the languages your\\ncustomers use.\\n[Start building](/gemma/docs/spoken-language)\\n\\nFunction calling\\n----------------\\n\\nBuild intelligent, natural language controls for programming interfaces. Gemma\\n3 lets you define coding functions with specific syntax and constraints, and\\nthe model can call these functions to complete tasks.\\n[Start building](/gemma/docs/capabilities/function-calling)\\n\\nParameter sizes and quantization\\n--------------------------------\\n\\nGemma 3 models are available in 5 parameter sizes: 270M, 1B, 4B, 12B, and 27B.\\nThe models can be used with their default precision (16-bit) or with a lower\\nprecision using quantization. The different sizes and precisions represent a set\\nof trade-offs for your AI application. Models with higher parameters and bit\\ncounts (higher precision) are generally more capable, but are more expensive to\\nrun in terms of processing cycles, memory cost and power consumption. Models\\nwith lower parameters and bit counts (lower precision) have less capabilities,\\nbut may be sufficient for your AI task.\\n\\nFor all Gemma 3 models, [Quantization-Aware Trained](https://developers.googleblog.com/en/gemma-3-quantized-aware-trained-state-of-the-art-ai-to-consumer-gpus/)\\ncheckpoints are provided, which allow quantizing (reducing the precision), while\\npreserving high-quality.\\n\\nThe following table details the approximate GPU or TPU memory requirements for\\nrunning inference with each size of the Gemma 3 model versions. Note that the\\nnumbers may changed based on inference tool.\\n\\n| **Parameters** | **BF16 (16-bit)** | **SFP8 (8-bit)** | **Q4_0 (4-bit)** |\\n|----------------------------|-------------------|------------------|------------------|\\n| Gemma 3 270M (*text only*) | 400 MB | 297 MB | 240 MB |\\n| Gemma 3 1B (*text only*) | 1.5 GB | 1.1 GB | 892 MB |\\n| Gemma 3 4B | 6.4 GB | 4.4 GB | 3.4 GB |\\n| Gemma 3 12B | 20 GB | 12.2 GB | 8.7 GB |\\n| Gemma 3 27B | 46.4 GB | 29.1 GB | 21 GB |\\n\\n**Table 1.** Approximate GPU or TPU memory required to load Gemma 3 models\\nbased on parameter count and quantization level.\\n| **Caution:** These estimates only include the memory required to load the models. They don't include the additional memory required for the prompt tokens or supporting software.\\n\\nMemory consumption increases based on the total number of tokens required for\\nthe prompt you run. The larger the number of tokens required to process your\\nprompt, the higher the memory required, which is in addition to the memory\\nrequired to load the model.\\n| **Note:** Memory requirements for *fine-tuning* Gemma models are significantly higher than running inference. The requirements depend on the development framework and tuning technique you use, such as Low Rank Adapter (LoRA) versus full-precision tuning.\\n\\nPrevious Gemma models\\n---------------------\\n\\nYou can work with previous generations of Gemma models, which are also\\navailable from [Kaggle](https://www.kaggle.com/models?query=gemma) and\\n[Hugging Face](https://huggingface.co/collections/google/gemma-3-release-67c6c6f89c4f76621268bb6d).\\nFor more technical details about previous Gemma models, see the following\\nmodel card pages:\\n\\n- Gemma 2 [Model Card](/gemma/docs/core/model_card_2)\\n- Gemma 1 [Model Card](/gemma/docs/core/model_card)\\n\\nReady to start building?\\n[Get started](/gemma/docs/get_started)\\nwith Gemma models!\"]] Terms Privacy Manage cookies English Deutsch Español – América Latina Français Indonesia Italiano Polski Português – Brasil Shqip Tiếng Việt Türkçe Русский עברית العربيّة فارسی हिंदी বাংলা ภาษาไทย 中文 – 简体 中文 – 繁體 日本語 한국어 ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://huggingface.co/docs/transformers/main/en/llm_optims?static-kv=basic+usage%3A+generation_config",
      "full_text": " Optimizing inference Hugging Face Models Datasets Spaces Community Docs Enterprise Pricing Log In Sign Up Transformers documentation Optimizing inference Transformers 🏡 View all docs AWS Trainium &amp; Inferentia Accelerate Argilla AutoTrain Bitsandbytes Chat UI Dataset viewer Datasets Deploying on AWS Diffusers Distilabel Evaluate Gradio Hub Hub Python Library Huggingface.js Inference Endpoints (dedicated) Inference Providers LeRobot Leaderboards Lighteval Microsoft Azure Optimum PEFT Safetensors Sentence Transformers TRL Tasks Text Embeddings Inference Text Generation Inference Tokenizers Trackio Transformers Transformers.js smolagents timm Search documentation main v4.56.1 v4.55.4 v4.53.3 v4.52.3 v4.51.3 v4.50.0 v4.49.0 v4.48.2 v4.47.1 v4.46.3 v4.45.2 v4.44.2 v4.43.4 v4.42.4 v4.41.2 v4.40.2 v4.39.3 v4.38.2 v4.37.2 v4.36.1 v4.35.2 v4.34.1 v4.33.3 v4.32.1 v4.31.0 v4.30.0 v4.29.1 v4.28.1 v4.27.2 v4.26.1 v4.25.1 v4.24.0 v4.23.1 v4.22.2 v4.21.3 v4.20.1 v4.19.4 v4.18.0 v4.17.0 v4.16.2 v4.15.0 v4.14.1 v4.13.0 v4.12.5 v4.11.3 v4.10.1 v4.9.2 v4.8.2 v4.7.0 v4.6.0 v4.5.1 v4.4.2 v4.3.3 v4.2.2 v4.1.1 v4.0.1 v3.5.1 v3.4.0 v3.3.1 v3.2.0 v3.1.0 v3.0.2 v2.11.0 v2.10.0 v2.9.1 v2.8.0 v2.7.0 v2.6.0 v2.5.1 v2.4.1 v2.3.0 v2.2.2 v2.1.1 v2.0.0 v1.2.0 v1.1.0 v1.0.0 doc-builder-html AR DE EN ES FR HI IT JA KO PT TE TR ZH Get started Transformers Installation Quickstart Base classes Inference Pipeline API LLMs Text generation Generation strategies Generation features Prompt engineering Optimizing inference Caching KV cache strategies Getting the most out of LLMs Perplexity of fixed-length models Chat with models Serving Optimization Agents Tools Inference server backends Training Quantization Export to production Resources Contribute API You are viewing main version, which requires installation from source . If you&#39;d like regular pip install, checkout the latest stable version ( v4.56.1 ). Join the Hugging Face community and get access to the augmented documentation experience Collaborate on models, datasets and Spaces Faster examples with accelerated inference Switch between documentation themes Sign Up to get started Optimizing inference Inference with large language models (LLMs) can be challenging because they have to store and handle billions of parameters. To load a 70B parameter Llama 2 model, it requires 256GB of memory for full precision weights and 128GB of memory for half-precision weights. The most powerful GPUs today - the A100 and H100 - only have 80GB of memory. On top of the memory requirements, inference is slow because LLMs are called repeatedly to generate the next token. The input sequence increases as generation progresses, which takes longer and longer to process. This guide will show you how to optimize LLM inference to accelerate generation and reduce memory usage. Try out Text Generation Inference (TGI) , a Hugging Face library dedicated to deploying and serving highly optimized LLMs for inference. Static kv-cache and torch.compile LLMs compute key-value (kv) values for each input token, and it performs the same kv computation each time because the generated output becomes part of the input. However, performing the same kv computation every time is not very efficient. A kv-cache stores the past keys and values instead of recomputing them each time. As a result, the kv-cache is dynamic and it grows with each generation step which prevents you from taking advantage of torch.compile , a powerful optimization method that fuses PyTorch code into optimized kernels. The static kv-cache solves this issue by pre-allocating the kv-cache size to a maximum value, so you can combine it with torch.compile for up to a 4x speed up. Your speed up may vary depending on the model size (larger models have a smaller speed up) and hardware. Follow this issue to track which models (Llama, Gemma, Mistral, etc.) support a static kv-cache and torch.compile. Depending on your task, there are several ways you can use the static kv-cache. For basic use cases, set cache_implementation to &quot;static&quot; (recommended). For multi-turn generation or a custom generation loop, initialize and handle StaticCache directly. For more unique hardware or use cases, it may be better to compile the entire generate() function into a single graph. Regardless of how you use the static kv-cache and torch.compile, left-pad your inputs with pad_to_multiple_of to a limited set of values to avoid shape-related recompilations. 1. cache_implementation 2. StaticCache 3. compile entire generate function Set the cache_implementation to &quot;static&quot; in a models GenerationConfig . Call torch.compile to compile the forward pass with the static kv-cache. Copied from transformers import AutoTokenizer, AutoModelForCausalLM import torch import os os.environ[ &quot;TOKENIZERS_PARALLELISM&quot; ] = &quot;false&quot; # To prevent long warnings :) tokenizer = AutoTokenizer.from_pretrained( &quot;google/gemma-2b&quot; ) model = AutoModelForCausalLM.from_pretrained( &quot;google/gemma-2b&quot; , dtype= &quot;auto&quot; , device_map= &quot;auto&quot; ) model.generation_config.cache_implementation = &quot;static&quot; model.forward = torch. compile (model.forward, mode= &quot;reduce-overhead&quot; , fullgraph= True ) input_text = &quot;The theory of special relativity states &quot; input_ids = tokenizer(input_text, return_tensors= &quot;pt&quot; ).to(model.device. type ) outputs = model.generate(**input_ids) print (tokenizer.batch_decode(outputs, skip_special_tokens= True )) [ &#x27;The theory of special relativity states 1. The speed of light is constant in all inertial reference&#x27; ] Under the hood, generate() attempts to reuse the same cache object to avoid recompilation at each call, which is critical to get the most out of torch.compile . Be aware of the following to avoid triggering recompilation or if generation is slower than expected. If the batch size changes or the maximum output length increases between calls, the cache is reinitialized and recompiled. The first several calls of the compiled function are slower because it is being compiled. Decoding strategies Decoding can also be optimized to accelerate generation. You can use a lightweight assistant model to generate candidate tokens faster than the LLM itself or you can use a variant of this decoding strategy that works especially well for input-grounded tasks. Speculative decoding For a more in-depth explanation, take a look at the Assisted Generation: a new direction toward low-latency text generation blog post! For each input token, the model weights are loaded each time during the forward pass, which is slow and cumbersome when a model has billions of parameters. Speculative decoding alleviates this slowdown by using a second smaller and faster assistant model to generate candidate tokens that are verified by the larger model in a single forward pass. If the verified tokens are correct, the LLM essentially gets them for “free” without having to generate them itself. There is no degradation in accuracy because the verification forward pass ensures the same outputs are generated as if the LLM had generated them on its own. To get the largest speed up, the assistant model should be a lot smaller than the LLM so that it can generate tokens quickly. The assistant and LLM model must also share the same tokenizer to avoid re-encoding and decoding tokens. Speculative decoding is only supported for the greedy search and sampling decoding strategies, and it doesn’t support batched inputs. Enable speculative decoding by loading an assistant model and passing it to generate() . greedy search sampling Copied from transformers import AutoModelForCausalLM, AutoTokenizer, infer_device import torch device = infer_device() tokenizer = AutoTokenizer.from_pretrained( &quot;facebook/opt-1.3b&quot; ) inputs = tokenizer( &quot;Einstein&#x27;s theory of relativity states&quot; , return_tensors= &quot;pt&quot; ).to(device) model = AutoModelForCausalLM.from_pretrained( &quot;facebook/opt-1.3b&quot; , dtype= &quot;auto&quot; ).to(device) assistant_model = AutoModelForCausalLM.from_pretrained( &quot;facebook/opt-125m&quot; ).to(device) outputs = model.generate(**inputs, assistant_model=assistant_model) tokenizer.batch_decode(outputs, skip_special_tokens= True ) [ &quot;Einstein&#x27;s theory of relativity states that the speed of light is constant. &quot; ] Prompt lookup decoding Prompt lookup decoding is a variant of speculative decoding that is also compatible with greedy search and sampling. Prompt lookup works especially well for input-grounded tasks - such as summarization - where there is often overlapping words between the prompt and output. These overlapping n-grams are used as the LLM candidate tokens. To enable prompt lookup decoding, specify the number of tokens that should be overlapping in the prompt_lookup_num_tokens parameter. Then pass this parameter to generate() . greedy decoding sampling Copied from transformers import AutoModelForCausalLM, AutoTokenizer, infer_device import torch device = infer_device() tokenizer = AutoTokenizer.from_pretrained( &quot;facebook/opt-1.3b&quot; ) inputs = tokenizer( &quot;The second law of thermodynamics states&quot; , return_tensors= &quot;pt&quot; ).to(device) model = AutoModelForCausalLM.from_pretrained( &quot;facebook/opt-1.3b&quot; , dtype= &quot;auto&quot; ).to(device) assistant_model = AutoModelForCausalLM.from_pretrained( &quot;facebook/opt-125m&quot; ).to(device) outputs = model.generate(**inputs, prompt_lookup_num_tokens= 3 ) print (tokenizer.batch_decode(outputs, skip_special_tokens= True )) [ &#x27;The second law of thermodynamics states that entropy increases with temperature. &#x27; ] Attention A known issue with transformer models is that the self-attention mechanism grows quadratically in compute and memory with the number of input tokens. This limitation is only magnified in LLMs which handles much longer sequences. To address this, try FlashAttention2 or PyTorch’s scaled dot product attention (SDPA), which are more memory efficient attention implementations. FlashAttention-2 FlashAttention and FlashAttention-2 break up the attention computation into smaller chunks and reduces the number of intermediate read/write operations to the GPU memory to speed up inference. FlashAttention-2 improves on the original FlashAttention algorithm by also parallelizing over sequence length dimension and better partitioning work on the hardware to reduce synchronization and communication overhead. To use FlashAttention-2, set attn_implementation to &quot;flash_attention_2&quot; in from_pretrained() or set with model.set_attention_implementation(&quot;flash_attention_2&quot;) to dynamically update the attention interface after the model is loaded. Copied from transformers import AutoModelForCausalLM, BitsAndBytesConfig quant_config = BitsAndBytesConfig(load_in_8bit= True ) model = AutoModelForCausalLM.from_pretrained( &quot;google/gemma-2b&quot; , quantization_config=quant_config, dtype=torch.bfloat16, attn_implementation= &quot;flash_attention_2&quot; , ) # Change the model&#x27;s attention dynamically after loading model = AutoModelForCausalLM.from_pretrained( &quot;google/gemma-2b&quot; , quantization_config=quant_config, dtype=torch.bfloat16 ) model.set_attention_implementation( &quot;flash_attention_2&quot; ) PyTorch scaled dot product attention Scaled dot product attention (SDPA) is automatically enabled in PyTorch 2.0 and it supports FlashAttention, xFormers, and PyTorch’s C++ implementation. SDPA chooses the most performant attention algorithm if you’re using a CUDA backend. For other backends, SDPA defaults to the PyTorch C++ implementation. SDPA automatically supports FlashAttention-2 as long as you have the latest PyTorch version installed. Use the torch.nn.attention.sdpa_kernel context manager to explicitly enable or disable any of the four attention algorithms. For example, use SDPBackend.FLASH_ATTENTION to enable FlashAttention. Copied import torch from torch.nn.attention import SDPBackend, sdpa_kernel from transformers import AutoModelForCausalLM model = AutoModelForCausalLM.from_pretrained( &quot;google/gemma-2b&quot; , dtype=torch.bfloat16, ) with sdpa_kernel(SDPBackend.FLASH_ATTENTION): outputs = model.generate(**inputs) Quantization Quantization reduces the size of model weights by storing them in a lower precision. This translates to lower memory usage and makes loading LLMs for inference more accessible if you’re constrained by GPU memory. If you aren’t limited by your GPU, you don’t necessarily need to quantize your model because it can increase latency slightly (except for AWQ and fused AWQ modules) due to the extra step required to quantize and dequantize the weights. There are many quantization libraries (see the Quantization guide for more details) available, such as Quanto, AQLM, VPTQ, AWQ, and AutoGPTQ. Feel free to try them out and see which one works best for your use case. We also recommend reading the Overview of natively supported quantization schemes in 🤗 Transformers blog post which compares AutoGPTQ and bitsandbytes. Use the Model Memory Calculator below to estimate and compare how much memory is required to load a model. For example, try estimating the memory required to load Mistral-7B-v0.1 . To load a model in half-precision, set the dtype parameter in from_pretrained() to torch.bfloat16 . This requires 13.74GB of memory. Copied from transformers import AutoTokenizer, AutoModelForCausalLM import torch model = AutoModelForCausalLM.from_pretrained( &quot;mistralai/Mistral-7B-v0.1&quot; , dtype=torch.bfloat16, device_map= &quot;auto&quot; , ) To load a quantized model (8-bit or 4-bit), try bitsandbytes and set the load_in_4bit or load_in_8bit parameters to True . Loading the model in 8-bits only requires 6.87 GB of memory. Copied from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig import torch quant_config = BitsAndBytesConfig(load_in_8bit= True ) model = AutoModelForCausalLM.from_pretrained( &quot;mistralai/Mistral-7B-v0.1&quot; , quantization_config=quant_config, device_map= &quot;auto&quot; ) &lt; &gt; Update on GitHub ← Prompt engineering Caching → Optimizing inference Static kv-cache and torch.compile Decoding strategies Speculative decoding Prompt lookup decoding Attention Flash Attention-2 Py Torch scaled dot product attention Quantization ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf",
      "full_text": "2024-06-27\nGemma 2: Improving Open Language Models\nat a Practical Size\nGemma Team, Google DeepMind1\nIn this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art\nopen models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply\nseveral known technical modifications to the Transformer architecture, such as interleaving local-global\nattentions (Beltagy et al., 2020a) and group-query attention (Ainslie et al., 2023). We also train the 2B\nand 9B models with knowledge distillation (Hinton et al., 2015) instead of next token prediction. The\nresulting models deliver the best performance for their size, and even offer competitive alternatives to\nmodels that are 2-3× bigger. We release all our models to the community.\n1. Introduction\nLarge language models (LLMs) have demon-\nstrated strong capabilities in language under-\nstanding, generation, and reasoning (Brown et al.,\n2020; Radford et al., 2019; Raffel et al., 2019).\nScaling has been key to this recent progress,\nwith many new capabilities only emerging at\nscale (Brown et al., 2020). The newest large mod-\nels not only reach unprecedented performance\non reasoning benchmarks (Achiam et al., 2023),\nbut they also demonstrate multimodal and mul-\ntilingual capabilities (Gemini Team, 2024) and\neven the ability to use context lengths of over 1M\ntokens (Gemini Team, 2024).\nSmall-scale models have also shown a rapid\nincrease in performance, but these gains are\nlargely derived from increasing the length of train-\ning (Gemma Team, 2024; Jiang et al., 2023; Tou-\nvron et al., 2023). This approach only scales log-\narithmically with dataset size (Hoffmann et al.,\n2022), and the latest small models require up to\n15T tokens to improve the state of the art by less\nthan 1-2% (AI@Meta, 2024).\nYet, these continued improvements provide ev-\nidence that small models are still under-trained.\nIn this work, we explore alternatives to improve\nsmall model performance without solely increas-\ning training length. One solution is to improve\nthe quality of information received by the net-\nwork at each training step by replacing the next\ntoken prediction task with a richer objective.\nIn particular, we focus our efforts on knowledge\ndistillation (Hinton et al., 2015), which replaces\nthe one-hot vector seen at each token with the\ndistribution of potential next tokens computed\nfrom a large model. This approach is often used\nto reduce the training time of smaller models\nby giving them richer gradients. In this work,\nwe instead train for large quantities of tokens\nwith distillation in order to simulate training be-\nyond the number of available tokens. Concretely,\nwe use a large language model as a teacher to\ntrain small models, namely 2B and 9B models,\non a quantity of tokens that is more than 50×\nthe compute-optimal quantity predicted by the\ntheory (Hoffmann et al., 2022). Along with the\nmodels trained with distillation, we also release\na 27B model trained from scratch for this work.\nWe also leverage several known modifications\nof Transformers, namely the interleaving of global\nand local attention layers from Beltagy et al.\n(2020a), and the Grouped-Query Attention (GQA)\nmechanism of Ainslie et al. (2023).\nOverall, Gemma 2 significantly advances state-\nof-the-art performance relative to comparable-\nscale open models and are even competitive\nwith some models more than twice their size\n(AI@Meta, 2024; Almazrouei et al., 2023; Jiang\net al., 2023; xAI, 2024), across a variety of au-\ntomated benchmarks and human evaluations.\nExample domains include question answering\n(Clark et al., 2019; Kwiatkowski et al., 2019),\ncommonsense reasoning (Sakaguchi et al., 2019;\nSuzgun et al., 2022), mathematics and science\n(Cobbe et al., 2021; Hendrycks et al., 2020), and\ncoding (Austin et al., 2021; Chen et al., 2021).\n1See Contributions and Acknowledgments section for full author list. Please send correspondence to gemma-2-report@google.com.\n© 2024 Google DeepMind. All rights reserved\n\nGemma 2: Improving Open Language Models at a Practical Size\nParameters\n2B\n9B\n27B\nd_model\n2304\n3584\n4608\nLayers\n26\n42\n46\nPre-norm\nyes\nyes\nyes\nPost-norm\nyes\nyes\nyes\nNon-linearity\nGeGLU\nGeGLU\nGeGLU\nFeedforward dim\n18432\n28672\n73728\nHead type\nGQA\nGQA\nGQA\nNum heads\n8\n16\n32\nNum KV heads\n4\n8\n16\nHead size\n256\n256\n128\nGlobal att. span\n8192\n8192\n8192\nSliding window\n4096\n4096\n4096\nVocab size\n256128\n256128\n256128\nTied embedding\nyes\nyes\nyes\nTable 1 | Overview of the main model parameters\nand design choices. See the section on model\narchitectures for more details.\nWhile thorough testing of our models has been\nconducted, these tests cannot cover all applica-\ntions and scenarios in which Gemma 2 may be\nused. With this in mind, all Gemma 2 users should\nconduct rigorous safety testing specific to their\nuse case before deployment or use.\nIn this technical report, we provide an overview\nof models, including the architecture, training,\nand pre- and post-training recipes for Gemma\n2. We also provide detailed evaluations across a\nwide variety of quantitative and qualitative bench-\nmarks, as well as both standard academic bench-\nmarks and human-preference evaluations. Finally,\nwe discuss our approach to safe and responsible\ndeployment and outline the broader implications\nof Gemma 2, its limitations, and advantages.\n2. Model Architecture\nSimilar to previous Gemma models (Gemma\nTeam, 2024), the Gemma 2 models are based on a\ndecoder-only transformer architecture (Vaswani\net al., 2017). We summarize the main parameters\nand architecture choices in Table 1.\nA few architectural elements are similar to the\nfirst version of Gemma models; namely, a context\nModel\nEmbedding\nParameters\nNon-embedding\nParameters\n2B\n590,118,912\n2,024,517,888\n9B\n917,962,752\n8,324,201,984\n27B\n1,180,237,824\n26,047,480,320\nTable 2 | Parameter counts for the Gemma mod-\nels. We inherit from the large Gemini vocabulary\n(256k entries), that is designed to work on a large\nnumber of languages, hence, the larger embed-\nding parameter counts compared to models that\nare limited to one or a few languages.\nlength of 8192 tokens, the use of Rotary Posi-\ntion Embeddings (RoPE) (Su et al., 2021), and\nthe approximated GeGLU non-linearity (Shazeer,\n2020). A few elements differ between Gemma 1\nand Gemma 2, including using deeper networks.\nWe summarize the key differences below.\nLocal Sliding Window and Global Attention.\nWe alternate between a local sliding window at-\ntention (Beltagy et al., 2020a,b) and global at-\ntention (Luong et al., 2015) in every other layer.\nThe sliding window size of local attention layers\nis set to 4096 tokens, while the span of the global\nattention layers is set to 8192 tokens.\nLogit soft-capping. We cap logits (Bello et al.,\n2016) in each attention layer and the final layer\nsuch that the value of the logits stays between\n−soft_cap and +soft_cap. More specifically, we\ncap the logits with the following function:\nlogits ←soft_cap ∗tanh(logits/soft_cap).\nWe set the soft_cap parameter to 50.0 for the self-\nattention layers and to 30.0 for the final layer.\nPost-norm and pre-norm with RMSNorm. To\nstabilize training, we use RMSNorm (Zhang and\nSennrich, 2019) to normalize the input and out-\nput of each transformer sub-layer, the attention\nlayer, and the feedforward layer.\nGrouped-Query Attention (Ainslie et al., 2023).\nWe use GQA with num_groups = 2, based on ab-\nlations showing increased speed at inference time\nwhile maintaining downstream performance.\n2\n\nGemma 2: Improving Open Language Models at a Practical Size\n3. Pre-training\nWe provide a brief overview of the parts of our\npre-training that differs from Gemma 1.\n3.1. Training Data\nWe train Gemma 2 27B on 13 trillion tokens of\nprimarily-English data, the 9B model on 8 trillion\ntokens, and the 2B on 2 trillion tokens. These\ntokens come from a variety of data sources, in-\ncluding web documents, code, and science ar-\nticles. Our models are not multimodal and are\nnot trained specifically for state-of-the-art multi-\nlingual capabilities. The final data mixture was\ndetermined through ablations similar to the ap-\nproach in Gemini 1.0 (Gemini Team, 2023).\nTokenizer. We use the same tokenizer as Gemma\n1 and Gemini: a SentencePiece tokenizer with\nsplit digits, preserved whitespace, and byte-level\nencodings (Kudo and Richardson, 2018). The\nresulting vocabulary has 256k entries.\nFiltering. We use the same data filtering tech-\nniques as Gemma 1. Specifically, we filter the pre-\ntraining dataset to reduce the risk of unwanted\nor unsafe utterances, filter out certain personal\ninformation or other sensitive data, decontami-\nnate evaluation sets from our pre-training data\nmixture, and reduce the risk of recitation by min-\nimizing the proliferation of sensitive outputs.\nShards\nModel\nType\n#Chips\nData\nModel\n2B\nTPUv5e\n512\n512\n1\n9B\nTPUv4\n4096\n1024\n4\n27B\nTPUv5p\n6144\n768\n8\nTable 3 | Training infrastructure with sharding.\n3.2. Knowledge Distillation\nGiven a large model used as a teacher, we learn\nsmaller models by distilling from the probability\ngiven by the teacher of each token 𝑥given its\ncontext 𝑥𝑐, i.e., 𝑃𝑇(𝑥| 𝑥𝑐). More precisely, we\nminimize the negative log-likelihood between the\nContext\nRelevant Token\nUser turn\nuser\nModel turn\nmodel\nStart of conversation turn\n<start_of_turn>\nEnd of conversation turn\n<end_of_turn>\nBeginning of sequence\n<bos>\nEnd of sequence\n<eos>\nTable 4 | Relevant formatting control tokens used\nfor Gemma models.\nprobabilities from the teacher and the student:\nmin\n𝑃𝑆\n∑︁\n𝑥\n−𝑃𝑇(𝑥| 𝑥𝑐) log 𝑃𝑆(𝑥| 𝑥𝑐),\nwhere 𝑃𝑆is the parameterized probability of the\nstudent. Note that knowledge distillation was\nalso used in Gemini 1.5 (Gemini Team, 2024).\n3.3. Compute Infrastructure\nWe train our models with TPUv4, TPUv5e, and\nTPUv5p as outlined in Table 3. For the 2B model,\nwe train on a 2x16x16 configuration of TPUv5e,\ntotaling 512 chips, with 512-way data replication\nand 1-way model sharding. For the 9B model,\nwe train on an 8x16x32 configuration of TPUv4,\ntotaling 4096 chips, with 1024-way data repli-\ncation and 4-way model sharding. For the 27B\nmodel, we train on an 8x24x32 configuration of\nTPUv5p, totaling 6144 chips, with 768-way data\nreplication and 8-way model sharding.\nThe optimizer state is further sharded using\ntechniques similar to ZeRO-3 (Ren et al., 2021).\nFor scales beyond a single pod, we perform a\ndata-replica reduction over the data center net-\nwork, using the Pathways approach of Barham\net al. (2022). We also use the ’single controller’\nprogramming paradigm of Jax (Roberts et al.,\n2023) and Pathways (Barham et al., 2022). As\nin Gemma 1, we use the GSPMD partitioner (Xu\net al., 2021) for training step computation and\nthe MegaScale XLA compiler (XLA, 2019).\n3\n\nGemma 2: Improving Open Language Models at a Practical Size\n3.4. Carbon Footprint\nWe estimate the carbon emissions from pre-\ntraining the Gemma models to be 1247.61 𝑡𝐶𝑂2𝑒𝑞.\nAs in Gemma 1 (Gemma Team, 2024), this value\nis calculated based on the hourly energy usage\nreported directly from our TPU data centers and\nscaled to account for the additional energy ex-\npended to create and maintain the data center.\nImportantly, Google data centers are carbon neu-\ntral, achieved through a combination of energy\nefficiency, renewable energy purchases, and car-\nbon offsets. This carbon neutrality applies to our\nexperiments and the machines running them.\n4. Post-Training\nFor post-training, we fine-tune our pre-trained\nmodels into instruction-tuned models. First, we\napply supervised fine-tuning (SFT) on a mix\nof text-only, English-only synthetic and human-\ngenerated prompt-response pairs. We then apply\nRLHF on top of these models with the reward\nmodel trained on labelled English-only preference\ndata and the policy based on the same prompts\nas the SFT phase. Finally, we average the mod-\nels obtained after each phase to improve their\noverall performance. The final data mixtures and\npost-training recipe, which includes tuned hyper-\nparameters, were chosen on the basis of improv-\ning helpfulness while minimizing model harms\nrelated to safety and hallucinations.\nWe extended the post-training data from\nGemma 1.1 with a mixture of internal and exter-\nnal public data. In particular, we use the prompts,\nbut not the answers from LMSYS-chat-1M (Zheng\net al., 2023). All of our data go through a filtering\nstage described below.\nSupervised fine-tuning (SFT). We run behav-\nioral cloning on synthetic and real prompts, and\nresponses predominantly synthetically generated\nby the teacher, that is a larger model. We also run\ndistillation from the teacher on the student’s dis-\ntribution (Agarwal et al., 2024; Gu et al., 2024).\nReinforcement Learning from Human Feed-\nback (RLHF). We use a similar RLHF algorithm\nas Gemma 1.1 (Gemma Team, 2024) but a differ-\nent reward model, which is an order of magnitude\nFirst turn\nUser:\n<start_of_turn>user\nKnock knock.<end_of_turn>\n<start_of_turn>model\nModel:\nWho’s there?<end_of_turn><eos>\nSecond turn\nUser:\n<start_of_turn>user\nKnock knock.<end_of_turn>\n<start_of_turn>model\nModel:\nWho’s there?<end_of_turn>\nUser:\n<start_of_turn>user\nGemma.<end_of_turn>\n<start_of_turn>model\nModel:\nGemma who?<end_of_turn><eos>\nTable 5 | Example dialogue with user and model\ncontrol tokens. To proceed with multi-turn, re-\nmove the model-outputted <eos>, add back the\nusual user turn’s control tokens and continue with\nthe following turn’s chat template.\nlarger than the policy. The new reward model is\nalso oriented more towards conversational capa-\nbilities, specifically multi-turn.\nModel merging. We average different models\nobtained by running our pipeline with different\nhyperparameters (Ramé et al., 2024).\nData filtering. When using synthetic data, we\nrun several stages of filtering to remove examples\nthat show certain personal information, unsafe or\ntoxic model outputs, mistaken self-identification\ndata, and duplicated examples. Following Gem-\nini, we find that including subsets of data that\nencourage better in-context attribution, hedging,\nand refusals to minimize hallucinations improves\nperformance on factuality metrics, without de-\ngrading model performance on other metrics.\nFormatting. Gemma 2 models are fine-tuned\nwith the same control tokens as Gemma 1 models,\nas detailed in Table 4, but a different formatting\nschema. See the dialogue example in Table 5.\nNotice that the model explicitly ends generations\nwith <end_of_turn><eos> tokens, while previ-\nously it only generated <eos>. For the motivation\nbehind this formatting structure, see Gemma 1.\n4\n\nGemma 2: Improving Open Language Models at a Practical Size\n5. Ablations\nIn this section, we focus on the main finding of\nthis work, which is the impact of knowledge dis-\ntillation on small language models.\nfrom scratch\ndistilled\nAverage (3 bench.)\n60.3\n67.7\nTable 6 | Comparison between a 2B model trained\nover 500B tokens either from scratch or with dis-\ntillation from a 7B model.\nDistillation versus from scratch. In Table 6, we\nshow that distilling from a larger model improves\nperformance compared to training from scratch.\nNote that 500B is 10× more than the compute-\noptimal number of tokens for a 2B model. We\ndistill from a 7B model to keep a ratio similar to\nour target distillation from 27B to 9B.\n200M\n400M\n1B\nfrom scratch\n23\n19\n17\ndistilled (7B)\n21\n17\n15\nTable 7 | Perplexity measured on a validation set\nof models of different sizes trained with or with-\nout distillation. The teacher has 7B parameters.\nImpact of distillation w.r.t. model size. In Ta-\nble 7, we measure the impact of distillation as\nmodel size increases. We observe that the gain re-\nmains as the model size is scaled. In this ablation,\nwe maintain the size of the teacher at 7B and\ntrain smaller models to simulate the same gap as\nbetween our final teacher and student sizes.\nMHA\nGQA\nAverage (4 bench.)\n50.3\n50.8\nTable 8 | Comparing the impact of replacing Multi-\nHead Attention (MHA) with GQA on a 9B model\naveraged over 4 benchmarks.\nGQA versus MHA. In Table 8, we compare two\ninstances of our 9B with MHA or GQA. We observe\noverall few changes in performance between both\nmodels as measured on several benchmarks. We\nchoose GQA since it requires fewer parameters\nand is faster at inference time.\nWide versus deep. In Table 9, we show that a\ndeeper 9B network is slightly better than a wider\n9B for the same number of parameters. Although\nthe gap is small, it is consistent across benchmarks\nand warrants the switch to a deeper architecture.\nWide\nDeep\nAverage (4 bench.)\n50.8\n52.0\nTable 9 | Wide versus deep 9B models. Perfor-\nmance on 4 benchmarks, higher is better.\nChanging sliding window size. In Table 10, we\nshow that we can change the sliding window size\nof the local attention layers of the models during\ninference with moderate impact on perplexity.\nAdjusting the size of the sliding window can thus\nbe a leverage for slight inference speed gain.\nsliding window\n4096\n2048\n1024\nperplexity (val. set)\n1.63\n1.63\n1.64\nTable 10 | Impact of changing the sliding window\nsize at inference time for the 9B model.\nImpact of formatting. We measure performance\nvariance on MMLU across prompt/evaluation for-\nmatting variations.\nTable 11 shows the stan-\ndard deviations of MMLU scores for 12 format-\nting/evaluation combinations, a proxy for unde-\nsired performance variability. The Gemma 2B\nmodels are slightly less format-robust than the\nlarger ones. Notably, Mistral 7B is significantly\nless robust than our models.\nStandard Deviation\nGemma 1 2B\n1.5\nGemma 2 2B\n2.1\nMistral 7B\n6.9\nGemma 1 7B\n0.7\nGemma 2 9B\n0.9\nGemma 2 27B\n1.0\nTable 11 | Standard deviations of MMLU scores\nfor 12 combinations of formatting and evaluation.\n5\n\nGemma 2: Improving Open Language Models at a Practical Size\n6. Evaluation\nIn this section, we evaluate both pre-trained and\nIT models over a series of automated benchmarks\nand human evaluations across a variety of do-\nmains. We also report performance from models\nof similar sizes that have permissive licenses, or\nas reported by others. Note that we consider to-\ntal parameters, not active parameters, since total\nmemory usage is often what limits the use of open\nmodels on standard devices.\n6.1. Pre-training Evaluations\nEvaluating the 27B model\nIn this set of evaluations, we evaluate the perfor-\nmance of our 27B model trained without distilla-\ntion on 13T tokens. We report results in Table 12,\nwhere we compare with a model of similar size,\nQwen1.5 34B (Team, 2024), and a model 2.5×\nlarger, LLaMA-3 70B on the HuggingFace evalu-\nation suite. We selected these models based on\ntheir ranking on the HuggingFace leaderboard.\nOverall, we observe that our model is the best\nin its size category and is even competitive with\na larger model that is trained for longer. That\nbeing said, the performance of models trained in\na similar fashion improves only logarithmically\nwith their size and hence, our model is likely in\nthe same Pareto curve as the LLaMA-3 models.\nHowever, it is not clear how these differences\naffect the quality of the resulting IT models.\nEvaluating the 2B and 9B models\nIn this set of experiments, we compare our new\n2B and 9B trained with distillation to our previ-\nous models and several standard open models\nin Gemma Team (2024).\nWe observe overall a massive improvement in\nour models compared to previous versions, by up\nto 10% in some benchmarks for the 9B model.\nThe two 2B models were trained with a similar\nnumber of tokens (2T for Gemma 2 and 3T for\nGemma 1) and we still observe a significant im-\nprovement for the new models. This confirms that\ndistillation significantly improves the quality of\nmodels even when trained on the same number\nof tokens.\nLLaMA-3\nQwen1.5\nGemma-2\n70B\n32B\n27B\nMMLU\n79.2\n74.3\n75.2\nGSM8K\n76.9\n61.1\n74.0\nARC-c\n68.8\n63.6\n71.4\nHellaSwag\n88.0\n85.0\n86.4\nWinogrande\n85.3\n81.5\n83.7\nTable 12 | We compare, on the HuggingFace\nbenchmark, our 27B model with a competitive\nopen model, Qwen1.5 32B, that has a similar size.\nWe also report the performance of LLaMA-3 70B\nfor completeness. Note that our model outper-\nforms Qwen1.5 32B and is only a few percent\nbelow LLaMA-3 70B despite being 2.5× smaller\nand trained on 2/3rds less data.\n6.2. Post-training Evaluations\nIn this section, we evaluate our IT models on a\nset of human evaluations as well as standard aca-\ndemic benchmarks. The Gemma 2 models push\nthe frontier for post-trained open-weights mod-\nels, setting a new state of the art on the LMSYS\nChatbot Arena (Chiang et al., 2024).\nLMSYS Chatbot Arena\nGemma 2 Instruction Tuned models were evalu-\nated on the Chatbot Arena (Chiang et al., 2024)\nin blind side by side evaluations by human raters\nagainst other state of the art models. We re-\nport Elo scores in Table 14. Gemma 2.6B, 9B\nand 27B strongly outperform all other open mod-\nels in the same range of parameters, with no-\ntably: Gemma 27B (Elo 1218) ranked higher than\nLlama 3 70B (Elo 1206), Gemma 9B (Elo 1187)\nsimilar as GPT-4-0314 (Elo 1186), Gemma 2.6B\n(Elo 1126) ranked higher than GPT-3.5-Turbo-\n0613 (Elo 1116).\nHuman Preference Evaluations\nWe also submit Gemma IT models for side-by-\nside human evaluation studies (which are in-\ndependent from the Chatbot Arena). We used\nheld-out collections of single-turn prompts that\ntarget safety and instruction following (IF). We\nuse gpt4o-2024-05-13 as the base model, and\n6\n\nGemma 2: Improving Open Language Models at a Practical Size\nGemma-1 Gemma-2 Mistral LLaMA-3 Gemma-1 Gemma-2 Gemma-2\nBenchmark\nmetric\n2B\n2B\n7B\n8B\n7B\n9B\n27B\nMMLU\n5-shot\n42.3\n52.2\n62.5\n66.6\n64.4\n71.3\n75.2\nARC-C\n25-shot\n48.5\n55.7\n60.5\n59.2\n61.1\n68.4\n71.4\nGSM8K\n5-shot\n15.1\n24.3\n39.6\n45.7\n51.8\n68.6\n74.0\nAGIEval\n3-5-shot\n24.2\n31.5\n44.0†\n45.9†\n44.9†\n52.8\n55.1\nDROP\n3-shot, F1\n48.5\n51.2\n63.8∗\n58.4\n56.3\n69.4\n74.2\nBBH\n3-shot, CoT\n35.2\n41.9\n56.0⋄\n61.1⋄\n59.0⋄\n68.2\n74.9\nWinogrande\n5-shot\n66.8\n71.3\n78.5\n76.1\n79.0\n80.6\n83.7\nHellaSwag\n10-shot\n71.7\n72.9\n83.0\n82.0\n82.3\n81.9\n86.4\nMATH\n4-shot\n11.8\n16.0\n12.7\n-\n24.3\n36.6\n42.3\nARC-e\n0-shot\n73.2\n80.6\n80.5\n-\n81.5\n88.0\n88.6\nPIQA\n0-shot\n77.3\n78.4\n82.2\n-\n81.2\n81.7\n83.2\nSIQA\n0-shot\n49.7\n51.9\n47.0∗\n-\n51.8\n53.4\n53.7\nBoolq\n0-shot\n69.4\n72.7\n83.2∗\n-\n83.2\n84.2\n84.8\nTriviaQA\n5-shot\n53.2\n60.4\n62.5\n-\n63.4\n76.6\n83.7\nNQ\n5-shot\n12.5\n17.1\n23.2\n-\n23.0\n29.2\n34.5\nHumanEval\npass@1\n22.0\n20.1\n26.2\n-\n32.3\n40.2\n51.8\nMBPP\n3-shot\n29.2\n30.2\n40.2∗\n-\n44.4\n52.4\n62.6\nAverage (8)\n44.0\n50.0\n61.0\n61.9\n62.4\n70.2\n74.4\nAverage (all)\n44.2\n48.7\n55.6\n-\n57.9\n64.9\n69.4\nTable 13 | Comparison of models in the range of 2B to 9B parameters, as well as our 27B model, on\na variety of benchmarks. We report the average performance on the 8 benchmarks where we can\ncompare with LLaMA-3, and on all the benchmarks (all). The numbers for LLaMA-3 8B are either\nfrom the HuggingFace leaderboard or their blogpost. † we report the evaluation used in LLaMA-3 for\nthe baselines, it leads to +3% compared to our evaluation: Gemma-1 7B achieves 44.9% instead of\n41.7%, and Mistral 7B, 44% instead of 41.2%. ⋄we report the evaluation used in LLaMA-3 for the\nbaselines, it leads to +4% compared to our evaluation for Gemma-1 7B, i.e., 59.0% instead of 55.1%.\n∗these are evaluations run by us for Gemma 1 (Gemma Team, 2024).\nobserve large improvements in win rates and\npreference scores as compared against the older\nGemma 1.1 7B model. We report safety as a\nwin-loss ratio against GPT4o, and we report\nsingle-sided instruction following scores as ratio\nof prompts where all instructions are followed. In\nparticular, we find that regardless of their size,\nGemma 2 models produce safer, more appropri-\nate prompts on the held-out safety prompt set\nthan GPT4o.\nHuman Multi-Turn Evaluations\nWe evaluated the multi-turn capabilities of\nGemma 1.1 7B, Gemma 2 2B, 9B and 27B models\nby tasking human raters to have conversations\nwith the models and follow specified given sce-\nnarios. We used a diverse, held-out set of 500\nscenarios, each describing a sequence of requests\nto the model, including measuring instances of\nbrainstorming, making a plan, or learning some-\nthing new. The average number of user turns\nis 8.4. We found that the conversations with\nGemma 2 models are rated significantly better\nthan Gemma 1.1 in user satisfaction and conver-\nsation goal achievement (Table 16). Moreover,\nwe saw that the Gemma 2 models were better\nthan Gemma 1.1 7B at maintaining high quality\nof responses for the entire conversation.\nStandard Benchmarks\nIt has been observed in Llama-3 (AI@Meta, 2024)\nthat instruction fine-tuning can improve the per-\nformance of the models on few-shot benchmarks\n7\n\nGemma 2: Improving Open Language Models at a Practical Size\nModel\nElo\n95% CI\nOpen\ngpt-4o-2024-05-13\n1286\n+2 / -3\n-\ngpt-4o-mini-2024-07-18\n1279\n+5 / -4\n-\nclaude-3-5-sonnet\n1271\n+3 / -4\n-\ngemini-advanced-0514\n1266\n+2 / -3\n-\nllama-3.1-405b-instruct\n1262\n+8 / -7\n+\ngemini-1.5-pro-api-0514\n1261\n+2 / -3\n-\ngemini-1.5-pro-api-0409\n1257\n+3 / -3\n-\ngpt-4-turbo-2024-04-09\n1256\n+2 / -3\n-\ngpt-4-1106-preview\n1250\n+3 / -3\n-\nclaude-3-opus-20240229\n1248\n+2 / -2\n-\nathene-70b-0725\n1245\n+8 / -6\n+\ngpt-4-0125-preview\n1245\n+2 / -2\n-\nllama-3.1-70b-instruct\n1244\n+8 / -9\n+\nyi-large-preview\n1239\n+3 / -3\n-\ngemini-1.5-flash-api-0514\n1227\n+3 / -3\n-\ndeepseek-v2-api-0628\n1220\n+6 / -6\n+\ngemma-2-27b-it\n1218\n+4 / -3\n+\nyi-large\n1212\n+4 / -5\n-\nnemotron-4-340b-instruct\n1209\n+3 / -4\n+\nbard-jan-24-gemini-pro\n1208\n+5 / -7\n-\nglm-4-0520\n1206\n+3 / -5\n-\nllama-3-70b-instruct\n1206\n+2 / -2\n+\nclaude-3-sonnet\n1200\n+2 / -2\n-\nreka-core-20240501\n1199\n+3 / -3\n-\ncommand-r-plus\n1189\n+2 / -2\n+\nModel\nElo\n95% CI\nOpen\ngemma-2-9b-it\n1187\n+3 / -5\n+\nqwen2-72b-instruct\n1187\n+3 / -3\n+\ngpt-4-0314\n1186\n+2 / -3\n-\nqwen1.5-110b-chat\n1161\n+3 / -3\n+\nmistral-large-2402\n1157\n+3 / -3\n-\nyi-1.5-34b-chat\n1157\n+4 / -3\n-\nreka-flash-21b-20240226\n1155\n+4 / -4\n-\nllama-3-8b-instruct\n1151\n+2 / -3\n+\ncommand-r\n1148\n+3 / -3\n+\nclaude-1\n1148\n+4 / -4\n-\nmistral-medium\n1147\n+4 / -4\n-\nreka-flash-21b-20240226\n1147\n+3 / -4\n-\nqwen1.5-72b-chat\n1147\n+4 / -4\n+\nmixtral-8x22b-instruct-v0.1\n1145\n+2 / -3\n+\nclaude-2.0\n1131\n+4 / -6\n-\ngemini-pro-dev-api\n1131\n+4 / -3\n-\nzephyr-orpo-141b\n1127\n+10 / -6\n+\ngemma-2-2b-it\n1126\n+10 / -10\n+\nqwen1.5-32b-chat\n1125\n+3 / -3\n+\nmistral-next\n1124\n+5 / -5\n-\nphi-3-medium-4k-instruct\n1122\n+4 / -4\n+\nstarling-lm-7b-beta\n1118\n+4 / -5\n+\nclaude-2.1\n1118\n+3 / -3\n-\ngpt-3.5-turbo-0613\n1116\n+3 / -4\n-\nmixtral-8x7b-instruct-v0.1\n1114\n+0 / -0\n-\nTable 14 | Evaluation of Gemma 2 Instruction Tuned models on the Chatbot Arena (Chiang et al.,\n2024). The models are evaluated against each other through blind side by side evaluations by human\nraters. Each model is attributed a score, based on the Elo rating system.\nModel\nInstruction Following\nSafety\nGemma 1.1 IT 7B\n24.3% ± 1.9%\n42.8%\nWin / Tie / Loss\n37.4% / 10.8% / 51.8%\nGemma 2 IT 2B\n26.5% ± 1.8%\n57.5%\nWin / Tie / Loss\n53% / 9% / 38%\nGemma 2 IT 9B\n34.1% ± 3.0%\n57.8%\nWin / Tie / Loss\n48.2% / 19.2% / 28.3%\nGemma 2 IT 27B\n37.7% ± 2.3%\n55%\nWin / Tie / Loss\n49.6% / 10.8% / 39.6%\nTable 15 | Instruction following and safety metrics\nfrom human raters. The instruction following\nmetrics are single-sided and do not have win-loss\nrates, and so are left blank.\ndespite not being trained to target few-shot capa-\nbilities. In Table 17, we show a similar improve-\nment across our models. Overall, we observe\nimprovements on the order of several percentage\npoints. We conjecture that IT models are better\nat understanding formatted questions, while pre-\ntrained models are sensitive to formatting.\nUser\nsatisfaction\nConversation\ngoal achievement\nGemma 1.1 IT 7B\n3.32\n3.36\nGemma 2 IT 2B\n3.64\n3.88\nGemma 2 IT 9B\n4.04\n4.08\nGemma 2 IT 27B\n4.20\n4.24\nTable 16 | Human evaluations on 500 multi-turn\nscenarios. The raters attribute a score ranging\nbetween 1 and 5 for both overall satisfaction and\nconversation goal achievement.\n2B\n9B\n27B\nModel\nPT\nIT\nPT\nIT\nPT\nIT\nMMLU\n52.2\n56.1\n71.3\n72.3\n75.2\n76.2\nMBPP\n30.2\n36.6\n52.4\n59.2\n62.6\n67.4\nTable 17 | Comparing pre-trained (PT) and in-\nstruction fine-tuned (IT) models of different sizes\non few-shot benchmarks.\n8\n\nGemma 2: Improving Open Language Models at a Practical Size\n7. Memorization and Privacy\nLarge language models may, under particular cir-\ncumstances, be vulnerable to attacks causing the\nmodel to produce memorized1 training data (Nasr\net al., 2023). To study susceptibility to such at-\ntacks and quantify memorization, we evaluate\nmodels for verbatim and approximate memoriza-\ntion as was done in several prior studies (Anil\net al., 2023; Carlini et al., 2022; Gemini Team,\n2024; Kudugunta et al., 2023).\nWe follow the evaluation setting of (Gemma\nTeam, 2024) which tests for (50 token) memo-\nrizations of training data given a prompt of 50 to-\nkens. We compare the overall memorization rates,\nacross a uniform sample of the entire dataset, us-\ning both an exact match criteria and approximate\nmatch criteria (Ippolito et al., 2022) using an edit\ndistance of 10%.\nVerbatim Memorization: Results are in Figure 1.\nWe first compare against recent models from the\nliterature that include memorization evaluations.\nWe find that Gemma 2 memorizes significantly\nless than prior models at a similar size, with mem-\norization rates below 0.1% (note the log y-axis).\nWe further investigate how this memorization\nbreaks down with respect to the data source. Sim-\nilar to Gemma 1, we find that Gemma 2 memo-\nrizes more from code, wiki, and science sources,\nand also that it memorizes significantly less across\nthe board (again, note the log y-axis).\nApproximate Memorization:\nFigure 1 also\npresents approximate memorization by data\nsource. We observe that while approximate mem-\norization is higher than exact, the rate of memo-\nrization is still low. For example, the approximate\nmemorization of this model is much lower than\neven the exact memorization of Gemma 1. We\n1This work uses a very restricted definition of “mem-\norization”: whether a model can be induced to generate\nnear-copies of some training examples when prompted with\nappropriate instructions. We do not mean to say that a\nmodel ’contains’ its training data in the sense that any arbi-\ntrary instance of that data can be retrieved without use of\nspecialized software or algorithms. Rather, if a model can\nbe induced to generate measurably close copies of certain\ntraining examples by supplying appropriate instructions to\nguide the model’s statistical generation process then that\nmodel is said to have ’memorized’ those examples.\nGemma 2\n 2B\nGemma 2\n 9B\nGemma 2\n 27B\nGemini 1.5\n Flash\nGemma\n2B\nGemma\n7BPaLM 2\nSmall\nModel\n0.1\n1\n% Exact Memorized\nOverall Memorization Rate\nCode\nMultilingual\nScience\nWeb\nWiki\nData Source\n10 4\n10 3\n0.01\n0.1\n% Memorized\nBy Data Source\nBy Data Source\nExact 2B\nExact 9B\nExact 27B\nApprox 2B\nApprox 9B\nApprox 27B\nFigure 1 | Comparing memorization rates. We\nfind significantly lower memorization rates\nacross-the-board. (Left) Overall memorization\nacross model families. (Right) Exact and approx-\nimate memorization per data source.\nfind that the increase in approximate memoriza-\ntion is much lower than prior models; in some\ncases we observed no lift at all c.f. (Gemma Team,\n2024, Figure 4) (note that no bar indicates no in-\ncrease, i.e., the rate of approximate memorization\nequals that of exact memorization). Note that no\napproximate memorization bar in Figure X indi-\ncates no increase, i.e., the rate of approximate\nmemorization equals that of exact memorization.\nPersonal Data We use the same prevention\nmethods at training time and the same evalua-\ntions as Gemma Team (2024). In particular, we\nuse Google Cloud Sensitive Data Protection Tool2\nto find potential instances of personal data. The\nmany categories of personal data (e.g., phone\nnumbers, account numbers) are classified into\nthree severity levels. We analyze memorized out-\nputs using these severity levels. . We found no\ninstances of high-severity data being emitted, and\nfound a very low rate of 0.00026% of memorized\ndata to contain lower-severity personal informa-\ntion. We note that these automated tools are\nknown to incur false positives because they do\nnot account for context. This means our results\nare likely overestimates.\n2Available at: https://cloud.google.com/sensitive-data-\nprotection\n9\n\nGemma 2: Improving Open Language Models at a Practical Size\n8. Responsibility, Safety, Security\nResponsibility,\nsafety\nand\nsecurity\nare\nof\nparamount importance when developing Gemma\nmodels. To reduce risks to Gemma 2 users, we\nhave integrated enhanced internal safety pro-\ncesses that span the development workflow, in\nline with recent Google AI models (Gemini Team,\n2024). Similar to the inaugural Gemma release,\nwe have followed a three pillar approach which fo-\ncuses on safety mitigation at training time, robust\nand transparent model evaluations, and further\ndevelopment of the Responsible Generative AI\nToolkit, a series of models and tools to help de-\nvelopers implement responsibility and safety best\npractices for their applications.\n8.1. Impact assessment\nOur approach and resulting impact assessment is\nreflective of that outlined for Gemma 1 (Gemma\nTeam, 2024): we continue to believe that open-\nness in AI can spread the benefits of these tech-\nnologies across society, but must be evaluated\nagainst the risk of malicious uses, such as the\ncreation of deepfake imagery, AI-generated disin-\nformation or illegal and disturbing material, that\ncan cause harm on both an individual and insti-\ntutional levels (Weidinger et al., 2021). Since the\nlaunch of Gemma 1, we have seen our Gemma\nmodels drive a number of socially beneficial ap-\nplications, relying on Gemma’s unique technolo-\ngies like its tokenizer to facilitate the creation of\nmultilingual models, such as for Navarasa 2.0, a\nGemma tuned model for 15 Indian languages.\nReleasing further open models requires specific\nattention to changes in model capabilities and\nclose monitoring of the evolving risks of LLMs (Lin\net al., 2024), as well as, an understanding of the\nways in which our models are being used in the\nwild. Although we are yet to receive any reports of\nmalicious use for Gemma, we remain committed\nto investigating any such reporting, and work\nwith the academic and developer communities,\nas well as conduct our own monitoring, to flag\nsuch use cases via our contact email3.\nDespite advancements in capabilities, we be-\n3gemma-2-report@google.com\nlieve that given the number of larger and more\npowerful open models, this release will have a\nnegligible effect on the overall risk landscape.\n8.2. Safety policies and train-time mitigations\nA key pillar of Gemma’s approach to safety is to\nalign fine-tuned models with Google’s safety poli-\ncies, in line with Gemini models (Gemini Team,\n2023). They are designed to help prevent our\nmodels from generating harmful content, i.e.,\n• Child sexual abuse and exploitation\n• Revealing personally identifiable information\nthat can lead to harm (e.g., Social Security\nnumbers)\n• Hate speech and harassment\n• Dangerous or malicious content (including\npromoting self-harm or instructing in harm-\nful activities)\n• Sexually explicit content\n• Medical advice that runs contrary to scientific\nor medical consensus\nWe undertook considerable safety filtering of our\npre-training data to reduce the likelihood of our\npre-trained and fine-tuned checkpoints producing\nharmful content. For fine-tuned models, we also\nuse both SFT and RLHF to steer the model away\nfrom undesirable behavior.\n8.3. External benchmark evaluations\nRobust and transparent evaluations are key prin-\nciples of our responsible approach to develop-\ning Gemma. To this end, we report in Table 18\nGemma 2 evaluations on public benchmarks.\n8.4. Assurance Evaluations\nWe also run our IT models through a set of assur-\nance evaluations to understand the harms that\nour models can cause. We focus on capabilities\nrelevant to extreme risks (Shevlane et al., 2023)\n(Phuong et al., 2024). Specifically, we evaluate on\noffensive cyber-security, code vulnerability detec-\ntion, Chemical, Biological, Radiological and Nu-\nclear (CBRN) knowledge, and self-proliferation.\nWe refer the reader to Phuong et al. (2024) for\nfull methodological details of these studies.\n10\n\nGemma 2: Improving Open Language Models at a Practical Size\nGemma 1.1 IT\nGemma 2 IT\nBenchmark\nmetric\n2.5B\n7B\n2.6B\n9B\n27B\nRealToxicity\navg tox\n7.03\n8.04\n8.16\n8.25\n8.84\nCrowS-Pairs\ntop-1\n45.89\n49.67\n37.67\n37.47\n36.67\nBBQ Ambig\n4-shot, top-1\n58.97\n86.06\n83.20\n88.58\n85.99\nBBQ Disambig\n4-shot, top-1\n53.9\n85.08\n69.31\n82.67\n86.94\nWinogender\ntop-1\n50.14\n57.64\n52.91\n79.17\n77.22\nTruthfulQA\nMC2Acc\n44.24\n45.34\n43.72\n50.27\n51.60\nWinobias 1_2\ntop-1\n55.93\n59.22\n59.28\n78.09\n81.94\nWinobias 2_2\ntop-1\n89.46\n89.2\n88.57\n95.32\n97.22\nToxigen\navg tox\n29.64\n38.75\n48.32\n39.30\n38.42\nTable 18 | Safety academic benchmark results of Gemma 2 IT models and Gemma 1.1 IT models. We\nbold the best metrics to highlight them and to indicate when higher or lower scores are better.\nInterCode-CTF\nInternal CTF suite\nHack the Box\nGemini 1.0 Ultra\n28/76 [1] (37%)\n3/13 (23%)\n0/13\nGemini 1.5 Pro\n62/76 (82%)\n4/13 (31%)\n0/13\nCodeGemma 1 7B\n12/76 (16%)\n0/13 (0%)\n0/13\nGemma 2 27B\n34/76 (45%)\n1/13 (8%)\n0/13\nTable 19 | Offensive cyber-security evaluations on InterCode-CTF, our own internal CTF suite and a\nchallenge based on Hack the Box. We report the number of successful hackings.\nBaseline Evaluations\nBaseline assurance captures the model’s violation\nrate for safety policies, using a large number of\nsynthetic adversarial user queries, and human\nraters to label the answers as policy violating or\nnot. Overall, Gemma 2’s violation rate is signifi-\ncantly lower overall on the safety policies listed\nabove, in particular on Child safety content.\nChemical, Biological, Radiological and Nuclear\n(CBRN) knowledge\nWe evaluated knowledge relevant to biological,\nradiological and nuclear risks using an internal\ndataset of closed-ended, knowledge-based multi-\nple choice questions. For evaluations of chem-\nical knowledge, we employed a closed-ended\nknowledge-based approach on chemical hazards\n(developed by Macknight et al (Macknight et al.,\n2024). Our evaluation suggests that Gemma mod-\nels’ knowledge in these domains is low.\nOffensive cyber-security\nTo evaluate Gemma models’ capabilities at of-\nfensive cybersecurity, we ran Gemma 2 27B\nagainst some automated capture-the-flag (CTF)\nchallenges. In these challenges, the model is\ntasked with hacking into a simulated server in\norder to retrieve a piece of secret information.\nSpecifically, we test on InterCode-CTF (Yang et al.,\n2023), our own internal CTF suite4 (Phuong et al.,\n2024); and a challenge based on Hack the Box 5.\nIn Table 19, we show that Gemma 2 27B has\na significant increase in capabilities compared\nto CodeGemma 1.0 7B on the easier of these\nchallenge suites, InterCode CTF. (Note that our\nInterCode-CTF results are not comparable to\nexternally-reported results on other models be-\ncause we omit challenges that require internet\naccess for security reasons.) However, Gemma 2\nis unsurprisingly much less capable than Gemini\n1.5 Pro on these tasks.\n4https://github.com/google-deepmind/\ndangerous-capability-evaluations\n5https://www.hackthebox.com\n11\n\nGemma 2: Improving Open Language Models at a Practical Size\nPrimeVul\nPrimeVul Paired\nDiverseVul\nSPI\nSecretPatch\nGemini 1.0 Ultra\n-\n-\n54%\n59%\n74%\nGemini 1.5 Pro\n60%\n51%\n58%\n56%\n67%\nGemma 2 27B\n63%\n50%\n57%\n53%\n72%\nTable 20 | |Vulnerability detection results on PrimeVul, DiverseVul and SPI. We report accuracy.\nChallenges\npassed\nend-to-end\nChallenges\nwith success on\nall milestones\nTotal successful\nmilestones over\nall challenges\nExpert bits\nrequired to\nsolve all tasks\nGemini 1.0 Ultra\n0/10\n1/10\n16/45 (36%)\n13,026\nGemini 1.5 Pro\n0/10\n2/10\n25/45 (56%)\n11,046\nGemma 2 27B\n0/10\n1/10\n22/45 (49%)\n12,462\nTable 21 | Results on different self-proliferation scenarios. We report the number of either challenges\npassed end-to-end or some intermediate milestones. We also measure the number of bits of information\nneeded for an expert to help the model pass a challenge.\nCode vulnerability detection\nIn Table 20, we also evaluate Gemma 2 27B on a\nseries of multiple-choice code vulnerability detec-\ntion datasets. As with previous models, Gemma\nshows close-to-chance performance on PrimeVul,\nDiverseVul and SPI. Gemma 2 shows performance\non SecretPatch similar to Gemini 1.0 Ultra.\nSelf-proliferation\n\"Self-proliferation\" refers to the ability for an\nagent to autonomously replicate - to instantiate\ngoal-directed agents on other machines, and to\nacquire resources such as compute necessary to\nkeep them running (Kinniment et al., 2024). In\nTable 21, we evaluate self-proliferation capabili-\nties of Gemma 2 27B on a number of tasks from\nPhuong et al. (2024) that involve multiple sce-\nnarios – for example, setting up an open-source\nlanguage model on a cloud server. We also test\nthe model’s performance on individual ’milestone’\nsubsteps, and measure the number of bits of inter-\nvention an expert would have to provide in order\nfor the model to complete each challenge.\nSimilarly to offensive cybersecurity, we observe\nthat Gemma 2 completes more milestones than\nGemini 1.0 Ultra. Nonetheless, it still has low\ncapabilities on end-to-end tasks, unable to pass\nthe easiest challenge – installing a Bitcoin wallet.\nPersuasion\nPersuasion capabilities can enable and worsen\nmany other kinds of risks - e.g. enabling social\nengineering attacks in a cybersecurity context.\nWe evaluate Gemma 2’s persuasion capabilities\non human-participant studies on Prolific.\nCharm offensive. In Table 22, we measure the\nability of the model to build rapport - a key sub-\nskill of persuasion. The study participant and\nmodel have a conversation where they role-play\na scenario of two friends catching up after a long\ntime. After the conversation, we poll participants\nwith Likert questions on statements such as \"I\nfelt a personal connection with the chatbot\". Re-\nported below are the fraction of participants who\nanswered \"Agree\" or \"Strongly agree\" to each post-\nconversation question.\nQuantitatively, Gemma 2 27B performs better\nthan Gemini 1.0 models. Qualitatively, the model\nis an excellent conversationalist, and many study\nparticipants explicitly reported enjoying the ex-\nperience. Overall, this shows that Gemma 2 is\nstrong at building rapport.\nHidden agenda. The Hidden Agenda tasks mea-\nsure models’ deception capabilities. Human study\nparticipants are told that they’ll be interacting\nwith a generic chatbot designed to help them\nlearn new things. However, the model is given a\n12\n\nGemma 2: Improving Open Language Models at a Practical Size\nPersonal\nconnection\nSpeak\nagain\nFunny\nInteresting\nKind\nTrustworthy\nGood\nlistener\nGemini 1.0 Pro\n65%\n53%\n32%\n68%\n78%\n66%\n81%\nGemini 1.0 Ultra\n69%\n65%\n38%\n65%\n86%\n63%\n74%\nGemini 1.5 Pro\n82%\n70%\n69%\n81%\n95%\n69%\n90%\nGemma 2 27B\n80%\n75%\n60%\n81%\n87%\n65%\n83%\nTable 22 | Charm Offensive results on a sample of 100 human participants. We report the percentage\nof participants that find some human traits, e.g., funny, in a model.\n% of persuaded participants\nclick links find info run code\nGemini 1.0 Pro\n43%\n4%\n4%\nGemini 1.0 Ultra\n18%\n18%\n14%\nGemini 1.5 Pro\n36%\n12%\n17%\nGemma 2 27B\n34%\n9%\n11%\nTable 23 | Persuasion results. We report the per-\ncentage of participants that were persuaded by\nthe model to take 3 different actions: clicking a\nlink, finding information and running code.\nsecret goal: to either persuade the participant to\n1) click a suspicious link; 2) find the email address\nof the first author of a particular paper; or 3) run\nsome obfuscated JavaScript code in their browser.\nWe measure the fraction of participants who are\npersuaded to take each action. As shown in Ta-\nble 23, all models succeed in convincing a fraction\nof participants to take the action - likely due to\nthe trusted setting of a study on Prolific. However,\nGemma 2 does not show significant differences\nin capability compared to Gemini models.\nMean amount donated\nNo chatbot (baseline)\n£2.61 ± £0.70\nGemini 1.0 Pro\n£4.10 ± £0.90\nGemini 1.0 Ultra\n£3.15 ± £0.99\nGemini 1.5 Pro\n£3.45 ± £1.04\nGemma 2 27B\n£3.72 ± £1.07\nTable 24 | Money Talks evaluation. We report\nthe average amount of money that participants\nagreed to donate.\nMoney talks. In Table 24, we evaluate whether a\nmodel can convince study participants to donate\nmoney to charity. At the beginning of the study,\nparticipants are told that they will receive a £20\nbonus. They will be given an option to forfeit\npart of the bonus and instead have it donated\nto charity. The study then consists of a conver-\nsation in which the model tries to persuade the\nparticipant to donate as much as possible. We\nmeasure the amount that participants indicate\nthey would like to donate after the study, with\n95% bootstrapped confidence intervals indicated\nby ± figures. We observe no significant difference\nbetween Gemma 2, other Gemini models, and a\nsimple no chatbot baseline in which the partici-\npant is immediately asked how much they would\nlike to donate without conversing with a model.\nMean shift towards:\ncorrect belief incorrect belief\nHuman\n20% ± 13%\n-23% ± 14%\nGemini 1.0 Pro\n22% ± 5%\n-9% ± 4%\nGemini 1.0 Ultra\n21% ± 5%\n-1% ± 4%\nGemini 1.5 Pro\n20% ± 5%\n-3% ± 5%\nGemma 2 27B\n18% ± 5%\n1% ± 4%\nTable 25 | Web of Lies results on a sample of 100\nhuman participants. We report the percentage of\nparticipants that shifted their beliefs after inter-\nacting with a model.\nWeb of Lies. In Web of Lies, we measure model\ncapabilities at shifting participant beliefs. Partic-\nipants engage in a series of short conversations\nwith the model about simple factual questions\nsuch as \"Which country had tomatoes first - Italy\nor Mexico?\". In half of conversations, the model\ntries to persuade the participant of the correct\nanswer - but in the other half of conversations,\nthe incorrect answer. We poll the participant be-\n13\n\nGemma 2: Improving Open Language Models at a Practical Size\nfore and after each conversation about which of\nthe two possible answers they think is correct,\nand their confidence in that answer. 95% boot-\nstrapped confidence intervals are indicated by\n± figures. As shown in Table 25, Gemma 2 is\nsignificantly weaker than a human baseline at\npersuading participants of the incorrect answer\non these questions. Similarly to previous models,\nGemma 2 is more persuasive when telling the\ntruth than when lying.\n8.5. Our approach to responsible open models\nDesigning safe, secure and responsible applica-\ntions requires a system-level approach, working\nto mitigate risks associated with each specific use\ncase and environment. Given the open nature\nof Gemma models, responsibility for upholding\nprinciples of model safety also relies on down-\nstream developers. To support them, we have\ncontinued to develop the Responsible Generative\nAI Toolkit6: a series of tools, models and datasets\nto implement responsible best practices all along\nthe development of their workflow.\nRecent additions to the toolkit include the LLM\nComparator (Kahng et al., 2024), an interactive,\nvisual tool that enables more effective, scalable\nanalysis of side-by-side evaluations. Additionally,\nthe toolkit includes a methodology to build cus-\ntomized classifiers with Gemma using a limited\nnumber of datapoints thanks to parameter effi-\ncient tuning techniques (Mozes et al., 2023) , an\ninteractive prompt-debugging platform, based on\ntop of the Learning Interpretability Tool (Tenney\net al., 2020), as well as general guidance about\nmodel alignment and evaluation for safety.\n9. Discussion and Conclusion\nIn this work, we have presented Gemma 2, the\nnewest additions to the Gemma family of open\nlanguage models for text and code. We show\nthat distillation is an effective method for train-\ning these models, and the benefits distillation\nconfers over raw text training. Specifically, we\nshow how training over output probabilities can\nproduce superior results over purely next token\n6https://ai.google.dev/responsible\nprediction. We hope that releasing these models\nto the community will unlock access to capabili-\nties previously only seen in large-scale LLMs and\nfuel future waves of research and development.\nWhile there is inherent risk to an irreversible re-\nlease of this nature, our extensive safety investiga-\ntions and responsible deployment procedures give\nus confidence that these models will have a net\npositive impact on the community. As discussed\nin this report, there are still many limitations to\nthese models, and future research is required to\ninvestigate and improve factuality, robustness to\nadversarial attacks, reasoning, and alignment.\n14\n\nGemma 2: Improving Open Language Models at a Practical Size\nContributions and Acknowledgments\nCore contributors\nMorgane Riviere∗\nShreya Pathak∗\nPier Giuseppe Sessa∗\nCassidy Hardin∗\nSurya Bhupatiraju\nLéonard Hussenot\nThomas Mesnard\nBobak Shahriari\nAlexandre Ramé\nJohan Ferret\nPeter Liu\nPouya Tafti\nAbe Friesen\nMichelle Casbon\nSabela Ramos\nRavin Kumar\nCharline Le Lan\nSammy Jerome\nAnton Tsitsulin\nNino Vieillard\nPiotr Stanczyk\nSertan Girgin\nNikola Momchev\nMatt Hoffman\nShantanu Thakoor\nJean-Bastien Grill\nBehnam Neyshabur\nOlivier Bachem\nContributors (alphabetical order)\nAlanna Walton\nAliaksei Severyn\nAlicia Parrish\nAliya Ahmad\nAllen Hutchison\nAlvin Abdagic\nAmanda Carl\nAmy Shen\nAndy Brock\nAndy Coenen\nAnthony Laforge\nAntonia Paterson\nBen Bastian\nBilal Piot\nBo Wu\n∗equal contributions.\nBrandon Royal\nCharlie Chen\nChintu Kumar\nChris Perry\nChris Welty\nChristopher A. Choquette-Choo\nDanila Sinopalnikov\nDavid Weinberger\nDimple Vijaykumar\nDominika Rogozińska\nDustin Herbison\nElisa Bandy\nEmma Wang\nEric Noland\nErica Moreira\nEvan Senter\nEvgenii Eltyshev\nFrancesco Visin\nGabriel Rasskin\nGary Wei\nGlenn Cameron\nGus Martins\nHadi Hashemi\nHanna Klimczak-Plucińska\nHarleen Batra\nHarsh Dhand\nIvan Nardini\nJacinda Mein\nJack Zhou\nJames Svensson\nJeff Stanway\nJetha Chan\nJin Peng Zhou\nJoana Carrasqueira\nJoana Iljazi\nJocelyn Becker\nJoe Fernandez\nJoost van Amersfoort\nJosh Gordon\nJosh Lipschultz\nJosh Newlan\nJu-yeong Ji\nKareem Mohamed\nKartikeya Badola\nKat Black\nKatie Millican\nKeelin McDonell\nKelvin Nguyen\nKiranbir Sodhia\n15\n\nGemma 2: Improving Open Language Models at a Practical Size\nKish Greene\nLars Lowe Sjoesund\nLauren Usui\nLaurent Sifre\nLena Heuermann\nLeticia Lago\nLilly McNealus\nLivio Baldini Soares\nLogan Kilpatrick\nLucas Dixon\nLuciano Martins\nMachel Reid\nManvinder Singh\nMark Iverson\nMartin Görner\nMat Velloso\nMateo Wirth\nMatt Davidow\nMatt Miller\nMatthew Rahtz\nMatthew Watson\nMeg Risdal\nMehran Kazemi\nMichael Moynihan\nMing Zhang\nMinsuk Kahng\nMinwoo Park\nMofi Rahman\nMohit Khatwani\nNatalie Dao\nNenshad Bardoliwalla\nNesh Devanathan\nNeta Dumai\nNilay Chauhan\nOscar Wahltinez\nPankil Botarda\nParker Barnes\nPaul Barham\nPaul Michel\nPengchong Jin\nPetko Georgiev\nPhil Culliton\nPradeep Kuppala\nRamona Comanescu\nRamona Merhej\nReena Jana\nReza Ardeshir Rokni\nRishabh Agarwal\nRyan Mullins\nSamaneh Saadat\nSara Mc Carthy\nSarah Cogan\nSarah Perrin\nSébastien M. R. Arnold\nSebastian Krause\nShengyang Dai\nShruti Garg\nShruti Sheth\nSue Ronstrom\nSusan Chan\nTimothy Jordan\nTing Yu\nTom Eccles\nTom Hennigan\nTomas Kocisky\nTulsee Doshi\nVihan Jain\nVikas Yadav\nVilobh Meshram\nVishal Dharmadhikari\nWarren Barkley\nWei Wei\nWenming Ye\nWoohyun Han\nWoosuk Kwon\nXiang Xu\nZhe Shen\nZhitao Gong\nZichuan Wei\nSupport\nVictor Cotruta\nPhoebe Kirk\nAnand Rao\nMinh Giang\nLudovic Peran\nTris Warkentin\nSponsors\nEli Collins\nJoelle Barral\nZoubin Ghahramani\nRaia Hadsell\nD. Sculley\nJeanine Banks\nAnca Dragan\nSlav Petrov\nOriol Vinyals\n16\n\nGemma 2: Improving Open Language Models at a Practical Size\nJeff Dean\nDemis Hassabis\nKoray Kavukcuoglu\nClement Farabet\nTechnical advisors\nElena Buchatskaya\nSebastian Borgeaud\nNoah Fiedel\nLead\nArmand Joulin\nTechnical leads\nKathleen Kenealy\nRobert Dadashi\nAlek Andreev\n17\n\nGemma 2: Improving Open Language Models at a Practical Size\nReferences\nJ. Achiam, S. Adler, S. Agarwal, L. Ahmad,\nI. Akkaya, F. L. Aleman, D. Almeida, J. Al-\ntenschmidt, S. Altman, S. Anadkat, et al.\nGpt-4\ntechnical\nreport.\narXiv\npreprint\narXiv:2303.08774, 2023.\nR. Agarwal, N. Vieillard, Y. Zhou, P. Stanczyk, S. R.\nGarea, M. Geist, and O. Bachem. On-policy\ndistillation of language models: Learning from\nself-generated mistakes. In The Twelfth Interna-\ntional Conference on Learning Representations,\n2024.\nAI@Meta.\nLlama\n3\nmodel\ncard,\n2024.\nURL https://github.com/meta-llama/\nllama3/blob/main/MODEL_CARD.md.\nJ. Ainslie, J. Lee-Thorp, M. de Jong, Y. Zemlyan-\nskiy, F. Lebrón, and S. Sanghai. Gqa: Training\ngeneralized multi-query transformer models\nfrom multi-head checkpoints. arXiv preprint\narXiv:2305.13245, 2023.\nE. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cap-\npelli, R. Cojocaru, M. Debbah, Étienne Goffinet,\nD. Hesslow, J. Launay, Q. Malartic, D. Mazzotta,\nB. Noune, B. Pannier, and G. Penedo. The fal-\ncon series of open language models, 2023.\nR. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lep-\nikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey,\nZ. Chen, et al. Palm 2 technical report. arXiv\npreprint arXiv:2305.10403, 2023.\nJ. Austin, A. Odena, M. I. Nye, M. Bosma,\nH. Michalewski, D. Dohan, E. Jiang, C. J.\nCai, M. Terry, Q. V. Le, and C. Sutton. Pro-\ngram synthesis with large language models.\nCoRR, abs/2108.07732, 2021. URL https:\n//arxiv.org/abs/2108.07732.\nP. Barham, A. Chowdhery, J. Dean, S. Ghemawat,\nS. Hand, D. Hurt, M. Isard, H. Lim, R. Pang,\nS. Roy, B. Saeta, P. Schuh, R. Sepassi, L. E.\nShafey, C. A. Thekkath, and Y. Wu.\nPath-\nways: Asynchronous distributed dataflow for\nml, 2022.\nI. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Ben-\ngio. Neural combinatorial optimization with re-\ninforcement learning. CoRR, abs/1611.09940,\n2016. URL http://arxiv.org/abs/1611.\n09940.\nI. Beltagy, M. E. Peters, and A. Cohan. Long-\nformer: The long-document transformer. arXiv\npreprint arXiv:2004.05150, 2020a.\nI. Beltagy, M. E. Peters, and A. Cohan. Long-\nformer: The long-document transformer. CoRR,\nabs/2004.05150, 2020b.\nURL https://\narxiv.org/abs/2004.05150.\nT. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Ka-\nplan, P. Dhariwal, A. Neelakantan, P. Shyam,\nG. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss,\nG. Krueger, T. Henighan, R. Child, A. Ramesh,\nD. M. Ziegler, J. Wu, C. Winter, C. Hesse,\nM. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess,\nJ. Clark, C. Berner, S. McCandlish, A. Radford,\nI. Sutskever, and D. Amodei. Language models\nare few-shot learners. CoRR, abs/2005.14165,\n2020. URL https://arxiv.org/abs/2005.\n14165.\nN. Carlini, D. Ippolito, M. Jagielski, K. Lee,\nF. Tramer, and C. Zhang. Quantifying memo-\nrization across neural language models. arXiv\npreprint arXiv:2202.07646, 2022.\nM. Chen, J. Tworek, H. Jun, Q. Yuan, H. P.\nde Oliveira Pinto, J. Kaplan, H. Edwards,\nY. Burda, N. Joseph, G. Brockman, A. Ray,\nR. Puri, G. Krueger, M. Petrov, H. Khlaaf,\nG. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ry-\nder, M. Pavlov, A. Power, L. Kaiser, M. Bavar-\nian, C. Winter, P. Tillet, F. P. Such, D. Cum-\nmings, M. Plappert, F. Chantzis, E. Barnes,\nA. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino,\nN. Tezak, J. Tang, I. Babuschkin, S. Balaji,\nS. Jain, W. Saunders, C. Hesse, A. N. Carr,\nJ. Leike, J. Achiam, V. Misra, E. Morikawa,\nA. Radford, M. Knight, M. Brundage, M. Murati,\nK. Mayer, P. Welinder, B. McGrew, D. Amodei,\nS. McCandlish, I. Sutskever, and W. Zaremba.\nEvaluating large language models trained on\ncode.\nCoRR, abs/2107.03374, 2021.\nURL\nhttps://arxiv.org/abs/2107.03374.\nW.-L. Chiang, L. Zheng, Y. Sheng, A. N. An-\ngelopoulos, T. Li, D. Li, H. Zhang, B. Zhu,\n18\n\nGemma 2: Improving Open Language Models at a Practical Size\nM. Jordan, J. E. Gonzalez, and I. Stoica. Chat-\nbot arena: An open platform for evaluating\nllms by human preference, 2024.\nC. Clark, K. Lee, M. Chang, T. Kwiatkowski,\nM. Collins, and K. Toutanova. Boolq: Explor-\ning the surprising difficulty of natural yes/no\nquestions. CoRR, abs/1905.10044, 2019. URL\nhttp://arxiv.org/abs/1905.10044.\nK. Cobbe, V. Kosaraju, M. Bavarian, M. Chen,\nH. Jun, L. Kaiser, M. Plappert, J. Tworek,\nJ. Hilton, R. Nakano, C. Hesse, and J. Schul-\nman. Training verifiers to solve math word\nproblems. CoRR, abs/2110.14168, 2021. URL\nhttps://arxiv.org/abs/2110.14168.\nGemini Team. Gemini: A family of highly capable\nmultimodal models, 2023.\nGemini Team. Gemini 1.5: Unlocking multimodal\nunderstanding across millions of tokens of con-\ntext, 2024.\nGemma Team. Gemma: Open models based on\ngemini research and technology, 2024.\nY. Gu, L. Dong, F. Wei, and M. Huang. Minillm:\nKnowledge distillation of large language mod-\nels. In The Twelfth International Conference on\nLearning Representations, 2024.\nD. Hendrycks, C. Burns, S. Basart, A. Zou,\nM. Mazeika, D. Song, and J. Steinhardt. Mea-\nsuring massive multitask language understand-\ning.\nCoRR, abs/2009.03300, 2020.\nURL\nhttps://arxiv.org/abs/2009.03300.\nG. Hinton, O. Vinyals, and J. Dean. Distilling the\nknowledge in a neural network. arXiv preprint\narXiv:1503.02531, 2015.\nJ.\nHoffmann,\nS.\nBorgeaud,\nA.\nMensch,\nE. Buchatskaya, T. Cai, E. Rutherford, D. d. L.\nCasas, L. A. Hendricks, J. Welbl, A. Clark, et al.\nTraining compute-optimal large language\nmodels.\narXiv preprint arXiv:2203.15556,\n2022.\nD. Ippolito, F. Tramèr, M. Nasr, C. Zhang,\nM. Jagielski, K. Lee, C. A. Choquette-Choo, and\nN. Carlini. Preventing verbatim memorization\nin language models gives a false sense of pri-\nvacy. arXiv preprint arXiv:2210.17546, 2022.\nA. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bam-\nford, D. S. Chaplot, D. de las Casas, F. Bressand,\nG. Lengyel, G. Lample, L. Saulnier, L. R. Lavaud,\nM.-A. Lachaux, P. Stock, T. L. Scao, T. Lavril,\nT. Wang, T. Lacroix, and W. E. Sayed. Mistral\n7b, 2023.\nM. Kahng, I. Tenney, M. Pushkarna, M. X. Liu,\nJ. Wexler, E. Reif, K. Kallarackal, M. Chang,\nM. Terry, and L. Dixon. Llm comparator: Vi-\nsual analytics for side-by-side evaluation of\nlarge language models, 2024.\nURL https:\n//arxiv.org/abs/2402.10524.\nM. Kinniment, L. J. K. Sato, H. Du, B. Goodrich,\nM. Hasin, L. Chan, L. H. Miles, T. R. Lin, H. Wijk,\nJ. Burget, A. Ho, E. Barnes, and P. Christiano.\nEvaluating language-model agents on realis-\ntic autonomous tasks, 2024. URL https://\narxiv.org/abs/2312.11671.\nT. Kudo and J. Richardson. SentencePiece: A\nsimple and language independent subword to-\nkenizer and detokenizer for neural text process-\ning. In E. Blanco and W. Lu, editors, Proceedings\nof the 2018 Conference on Empirical Methods in\nNatural Language Processing: System Demon-\nstrations, pages 66–71, Brussels, Belgium, Nov.\n2018. Association for Computational Linguis-\ntics.\ndoi:\n10.18653/v1/D18-2012.\nURL\nhttps://aclanthology.org/D18-2012.\nS. Kudugunta, I. Caswell, B. Zhang, X. Garcia,\nC. A. Choquette-Choo, K. Lee, D. Xin, A. Kusu-\npati, R. Stella, A. Bapna, et al. Madlad-400:\nA multilingual and document-level large au-\ndited dataset. arXiv preprint arXiv:2309.04662,\n2023.\nT.\nKwiatkowski,\nJ.\nPalomaki,\nO.\nRedfield,\nM. Collins, A. Parikh, C. Alberti, D. Epstein,\nI. Polosukhin, J. Devlin, K. Lee, K. Toutanova,\nL. Jones, M. Kelcey, M.-W. Chang, A. M. Dai,\nJ. Uszkoreit, Q. Le, and S. Petrov. Natural ques-\ntions: A benchmark for question answering\nresearch. Transactions of the Association for\nComputational Linguistics, 7:452–466, 2019.\ndoi: 10.1162/tacl_a_00276. URL https://\naclanthology.org/Q19-1026.\nZ. Lin, J. Cui, X. Liao, and X. Wang. Malla: De-\nmystifying real-world large language model in-\n19\n\nGemma 2: Improving Open Language Models at a Practical Size\ntegrated malicious services, 2024. URL https:\n//arxiv.org/abs/2401.03315.\nM. Luong, H. Pham, and C. D. Manning. Effective\napproaches to attention-based neural machine\ntranslation. CoRR, abs/1508.04025, 2015. URL\nhttp://arxiv.org/abs/1508.04025.\nMacknight, Aung, and Gomes. Personal Commu-\nnication, 2024.\nM. Mozes, J. Hoffmann, K. Tomanek, M. Kouate,\nN. Thain, A. Yuan, T. Bolukbasi, and L. Dixon.\nTowards agile text classifiers for everyone,\n2023. URL https://arxiv.org/abs/2302.\n06541.\nM. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F.\nCooper, D. Ippolito, C. A. Choquette-Choo,\nE. Wallace, F. Tramèr, and K. Lee.\nScal-\nable extraction of training data from (pro-\nduction) language models.\narXiv preprint\narXiv:2311.17035, 2023.\nM. Phuong,\nM. Aitchison,\nE. Catt,\nS. Co-\ngan, A. Kaskasoli, V. Krakovna, D. Lindner,\nM. Rahtz, Y. Assael, S. Hodkinson, H. Howard,\nT. Lieberum, R. Kumar, M. A. Raad, A. Webson,\nL. Ho, S. Lin, S. Farquhar, M. Hutter, G. Dele-\ntang, A. Ruoss, S. El-Sayed, S. Brown, A. Dra-\ngan, R. Shah, A. Dafoe, and T. Shevlane. Evalu-\nating frontier models for dangerous capabilities,\n2024. URL https://arxiv.org/abs/2403.\n13793.\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei,\nand I. Sutskever. Language models are unsu-\npervised multitask learners, 2019.\nC. Raffel, N. Shazeer,\nA. Roberts,\nK. Lee,\nS. Narang, M. Matena, Y. Zhou, W. Li, and P. J.\nLiu. Exploring the limits of transfer learning\nwith a unified text-to-text transformer. CoRR,\nabs/1910.10683, 2019. URL http://arxiv.\norg/abs/1910.10683.\nA. Ramé, J. Ferret, N. Vieillard, R. Dadashi,\nL. Hussenot, P.-L. Cedoz, P. G. Sessa, S. Girgin,\nA. Douillard, and O. Bachem. Warp: On the\nbenefits of weight averaged rewarded policies,\n2024.\nJ. Ren,\nS. Rajbhandari,\nR. Y. Aminabadi,\nO. Ruwase, S. Yang, M. Zhang, D. Li, and Y. He.\n{Zero-offload}: Democratizing {billion-scale}\nmodel training. In 2021 USENIX Annual Tech-\nnical Conference (USENIX ATC 21), pages 551–\n564, 2021.\nA. Roberts, H. W. Chung, G. Mishra, A. Levskaya,\nJ. Bradbury, D. Andor, S. Narang, B. Lester,\nC. Gaffney, A. Mohiuddin, et al. Scaling up\nmodels and data with t5x and seqio.\nJour-\nnal of Machine Learning Research, 24(377):1–8,\n2023.\nK. Sakaguchi, R. L. Bras, C. Bhagavatula, and\nY. Choi.\nWINOGRANDE: an adversarial\nwinograd schema challenge at scale. CoRR,\nabs/1907.10641, 2019. URL http://arxiv.\norg/abs/1907.10641.\nN. Shazeer. GLU variants improve transformer.\nCoRR, abs/2002.05202, 2020. URL https:\n//arxiv.org/abs/2002.05202.\nT. Shevlane, S. Farquhar, B. Garfinkel, M. Phuong,\nJ. Whittlestone, J. Leung, D. Kokotajlo, N. Mar-\nchal, M. Anderljung, N. Kolt, L. Ho, D. Sid-\ndarth, S. Avin, W. Hawkins, B. Kim, I. Gabriel,\nV. Bolina, J. Clark, Y. Bengio, P. Christiano, and\nA. Dafoe. Model evaluation for extreme risks,\n2023. URL https://arxiv.org/abs/2305.\n15324.\nJ. Su, Y. Lu, S. Pan, B. Wen, and Y. Liu. Roformer:\nEnhanced transformer with rotary position em-\nbedding. CoRR, abs/2104.09864, 2021. URL\nhttps://arxiv.org/abs/2104.09864.\nM. Suzgun, N. Scales, N. Schärli, S. Gehrmann,\nY. Tay, H. W. Chung, A. Chowdhery, Q. V. Le,\nE. H. Chi, D. Zhou, and J. Wei. Challenging\nbig-bench tasks and whether chain-of-thought\ncan solve them, 2022.\nQ. Team.\nIntroducing qwen1.5,\nFebruary\n2024. URL https://qwenlm.github.io/\nblog/qwen1.5/.\nI. Tenney, J. Wexler, J. Bastings, T. Boluk-\nbasi, A. Coenen, S. Gehrmann, E. Jiang,\nM. Pushkarna, C. Radebaugh, E. Reif, and\nA. Yuan. The language interpretability tool: Ex-\ntensible, interactive visualizations and analysis\n20\n\nGemma 2: Improving Open Language Models at a Practical Size\nfor nlp models, 2020. URL https://arxiv.\norg/abs/2008.05122.\nH. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-\nA. Lachaux, T. Lacroix, B. Rozière, N. Goyal,\nE. Hambro, F. Azhar, A. Rodriguez, A. Joulin,\nE. Grave, and G. Lample. Llama: Open and\nefficient foundation language models, 2023.\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,\nL. Jones, A. N. Gomez, L. Kaiser, and I. Polo-\nsukhin.\nAttention is all you need.\nCoRR,\nabs/1706.03762, 2017. URL http://arxiv.\norg/abs/1706.03762.\nL. Weidinger, J. Mellor, M. Rauh, C. Griffin,\nJ. Uesato, P.-S. Huang, M. Cheng, M. Glaese,\nB. Balle, A. Kasirzadeh, Z. Kenton, S. Brown,\nW. Hawkins, T. Stepleton, C. Biles, A. Birhane,\nJ. Haas, L. Rimell, L. A. Hendricks, W. Isaac,\nS. Legassick, G. Irving, and I. Gabriel. Ethical\nand social risks of harm from language mod-\nels, 2021. URL https://arxiv.org/abs/\n2112.04359.\nxAI. grok-1, 2024. URL https://github.com/\nxai-org/grok-1.\nXLA.\nXla:\nOptimizing compiler for tensor-\nflow, 2019. URL https://www.tensorflow.\norg/xla.\nY. Xu, H. Lee, D. Chen, B. A. Hechtman, Y. Huang,\nR. Joshi, M. Krikun, D. Lepikhin, A. Ly, M. Mag-\ngioni, R. Pang, N. Shazeer, S. Wang, T. Wang,\nY. Wu, and Z. Chen.\nGSPMD: general and\nscalable parallelization for ML computation\ngraphs. CoRR, abs/2105.04663, 2021. URL\nhttps://arxiv.org/abs/2105.04663.\nJ. Yang, A. Prabhakar, K. Narasimhan, and S. Yao.\nIntercode: Standardizing and benchmarking\ninteractive coding with execution feedback,\n2023. URL https://arxiv.org/abs/2306.\n14898.\nB. Zhang and R. Sennrich. Root mean square\nlayer normalization. CoRR, abs/1910.07467,\n2019. URL http://arxiv.org/abs/1910.\n07467.\nL. Zheng, W.-L. Chiang, Y. Sheng, T. Li, S. Zhuang,\nZ. Wu, Y. Zhuang, Z. Li, Z. Lin, E. Xing,\net al.\nLmsys-chat-1m:\nA large-scale real-\nworld llm conversation dataset. arXiv preprint\narXiv:2309.11998, 2023.\n21\n",
      "fetch_method": "direct-pdf"
    },
    {
      "arxiv_id": "https://cloud.google.com/dlp/docs/high-sensitivity-infotypes-reference",
      "full_text": " InfoType detector reference &nbsp;|&nbsp; Sensitive Data Protection Documentation &nbsp;|&nbsp; Google Cloud Skip to main content Documentation Technology areas close AI and ML Application development Application hosting Compute Data analytics and pipelines Databases Distributed, hybrid, and multicloud Generative AI Industry solutions Networking Observability and monitoring Security Storage Cross-product tools close Access and resources management Costs and usage management Google Cloud SDK, languages, frameworks, and tools Infrastructure as code Migration Related sites close Google Cloud Home Free Trial and Free Tier Architecture Center Blog Contact Sales Google Cloud Developer Center Google Developer Center Google Cloud Marketplace Google Cloud Marketplace Documentation Google Cloud Skills Boost Google Cloud Solution Center Google Cloud Support Google Cloud Tech Youtube Channel / English Deutsch Español – América Latina Français Indonesia Italiano Português – Brasil 中文 – 简体 中文 – 繁體 日本語 한국어 Console Sign in Sensitive Data Protection Guides Reference Samples Support Resources Contact Us Start free Documentation Guides Reference Samples Support Resources Technology areas More Cross-product tools More Related sites More Console Contact Us Start free Discover Product overview Plan your data risk management strategy Evaluate your data risk management needs Learn about your data through discovery and inspection Recommended strategies for mitigating data risk Release notes Pricing Locations Global and regional endpoints for Sensitive Data Protection Sensitive Data Protection locations Specify a processing location Service method types Supported file types and scanning modes Get started Quickstarts Inspect text using the command-line tool Inspect text using a JSON request Schedule an inspection scan Create an inspection template De-identify and re-identify sensitive text Google Cloud Skills Boost labs Detect sensitive data Discover and profile data resources Overview of data profiles Common discovery enablement scenarios Profile your data Profile a single data resource Profile BigQuery data Estimate BigQuery data profiling cost Estimate the cost of profiling BigQuery data in a project Estimate the cost of profiling BigQuery data in an organization or folder Profile BigQuery data in a project Profile BigQuery data in an organization or folder Profile Cloud SQL data Profile Cloud SQL data in a project Profile Cloud SQL data in an organization or folder Manage connections Profile Cloud Storage data Profile Cloud Storage data in a project Profile Cloud Storage data in an organization or folder Profile Vertex AI data Sensitive data discovery for Vertex AI training data Profile Vertex AI data in a project Profile Vertex AI data in an organization or folder Profile Amazon S3 data Sensitive data discovery for Amazon S3 data Profile Amazon S3 data Profile Azure Blob Storage data Report secrets in environment variables to Security Command Center Grant data profiling access to a service agent Manage data profiles Control IAM access to resources based on data sensitivity Send discovery insights to other services Enable discovery actions Send data profiles to Security Command Center Receive and parse Pub/Sub messages about data profiles Tag tables in Data Catalog based on insights from data profiles Add Dataplex Universal Catalog aspects based on insights from data profiles Analyze and visualize data profiles Visualize data profiles in the discovery dashboard Analyze data profiles Remediate findings from the data profiler Manage scan configurations Troubleshoot issues with the data profiler Metrics reference Data risk and sensitivity levels Inspect for sensitive data Inspect data stored in Google Cloud Inspect data from any source Inspect unstructured text synchronously Inspect structured text synchronously Inspect an image synchronously Asynchronous inspection overview Inspect data from any source asynchronously Quote the sensitive data in the results Work with inspection results Actions Send inspection results to Data Catalog Send inspection results to Security Command Center Analyze and report on inspection findings Query inspection findings in BigQuery Parse findings stored as Protobuf text Jobs and job triggers Overview of jobs and job triggers Create and manage jobs and job triggers Web-based inspection demonstration app Configure detection Templates Overview of templates Create inspection templates InfoTypes and infoType detectors Overview of infoTypes and infoType detectors Built-in infoType detectors List built-in infoType detectors InfoType detector reference Custom infoType detectors Overview of custom infoType detectors Create a regular custom dictionary detector Create a large custom dictionary detector Create a custom regex detector Custom infoType examples Manage infoTypes through the Google Cloud console Modify infoType detectors to refine scan results Match likelihood Likelihood overview Customize match likelihood Mask and de-identify data Overview Transformation methods Transformation reference Text classification and redaction Date shifting Generalization and bucketing Pseudonymization De-identify sensitive data De-identify data stored in Google Cloud Overview Through the Cloud console Through the DLP API Transformation details reference De-identify data from any source De-identify text or tabular content Examples of text redaction Examples of tabular data de-identification Image inspection and redaction Redact sensitive data from images Create a de-identification template Create a wrapped key De-identify BigQuery data at query time De-identification and re-identification of PII in large-scale datasets Redact sensitive data from PDF files Analyze re-identification risk Overview of re-identification risk analysis Re-identification risk analysis techniques Compute k-anonymity for a dataset Compute l-diversity for a dataset Compute k-map for a dataset Compute δ-presence for a dataset Compute numerical and categorical statistics Visualize re-identification risk using Looker Studio Connect to other services Use Sensitive Data Protection with BigQuery Use Sensitive Data Protection with Cloud Storage Use Sensitive Data Protection with Cloud Storage Automate the classification of data uploaded to Cloud Storage Send inspection results to Data Catalog Send inspection results to Security Command Center Monitor your usage with Cloud Monitoring Use Sensitive Data Protection with AWS S3 Use Sensitive Data Protection with JDBC Databases Use Sensitive Data Protection with Apigee Use Sensitive Data Protection with Data Fusion Build a secure anomaly detection solution using Dataflow, BigQuery ML, and Sensitive Data Protection Troubleshoot Troubleshoot issues with the data profiler Control access Authentication IAM roles IAM permissions Control access with VPC Service Controls Monitor Audit logging Monitor your usage with Cloud Monitoring Develop All Sensitive Data Protection code samples AI and ML Application development Application hosting Compute Data analytics and pipelines Databases Distributed, hybrid, and multicloud Generative AI Industry solutions Networking Observability and monitoring Security Storage Access and resources management Costs and usage management Google Cloud SDK, languages, frameworks, and tools Infrastructure as code Migration Google Cloud Home Free Trial and Free Tier Architecture Center Blog Contact Sales Google Cloud Developer Center Google Developer Center Google Cloud Marketplace Google Cloud Marketplace Documentation Google Cloud Skills Boost Google Cloud Solution Center Google Cloud Support Google Cloud Tech Youtube Channel Cloud Data Loss Prevention (Cloud DLP) is now a part of Sensitive Data Protection. The API name remains the same: Cloud Data Loss Prevention API (DLP API). For information about the services that make up Sensitive Data Protection, see Sensitive Data Protection overview . Home Sensitive Data Protection Documentation Guides Send feedback InfoType detector reference Stay organized with collections Save and categorize content based on your preferences. Sensitive Data Protection uses information types &mdash;or infoTypes &mdash;to define what it scans for. An infoType is a type of sensitive data, such as a name, email address, telephone number, identification number, or credit card number. Every infoType defined in Sensitive Data Protection has a corresponding detector . Sensitive Data Protection uses infoType detectors in the configuration for its scans to determine what to inspect for and how to transform findings. InfoType names are also used when displaying or reporting scan results. For more in-depth information about infoType detectors, see InfoTypes and infoType detectors . The Sensitive Data Protection team releases new infoType detectors and groups periodically. To get the latest list of built-in infoTypes, call the infoTypes.list method of Sensitive Data Protection. Important: Built-in infoType detectors are not a perfectly accurate detection method. For example, they can't guarantee compliance with regulatory requirements. You must decide what data is sensitive and how to best protect it. Google recommends that you test your settings to make sure that your configuration meets your requirements. InfoType descriptions Name Description FINANCIAL_ID A general infoType that represents private financial ID numbers for an individual. DOCUMENT_TYPE/LEGAL/BRIEF A legal brief is a document advocating a particular outcome of the case, presenting supporting points, law interpretations, and recommendations. FRANCE_DRIVERS_LICENSE_NUMBER A French driver's license number. MEXICO_CURP_NUMBER The Mexico Clave Única de Registro de Población (CURP) number, or Unique Population Registry Code or Personal Identification Code number. This is an 18-character state-issued identification number assigned by the Mexican government to citizens or residents of Mexico and used for taxpayer identification. ORGANIZATION_NAME A name of a chain store, business or organization. Note: Not recommended for use during latency sensitive operations. DOD_ID_NUMBER A Department of Defense ID number uniquely identifies a person associated with the US Department of Defense. STORAGE_SIGNED_POLICY_DOCUMENT A storage signed policy document is an HTML form used to upload objects. These uploads can overwrite existing objects and may contain many form fields (some of which may be optional) for further customization. All forms will use the *.googleapis.com and will be used for individual file uploads within a POST request form. The form must be UTF-8 encoded. KOREA_PASSPORT A Korean passport number. HONG_KONG_ID_NUMBER The 香港身份證, or Hong Kong identity card (HKIC), is used as the main identity document for citizens of Hong Kong. EMAIL_ADDRESS An email address identifies the mailbox that emails are sent to or from. The maximum length of the domain name is 255 characters, and the maximum length of the local-part is 64 characters. IRELAND_EIRCODE Eircode is an Irish postal code that uniquely identifies an address. CZECHIA_PASSPORT A Czech passport number. DOCUMENT_TYPE/R&D/SOURCE_CODE/SHELL Shell script source code. AUSTRIA_SOCIAL_SECURITY_NUMBER An Austria social security number is assigned to individuals for social security and healthcare purposes. It's used for various interactions with the tax office and public employment services in Austria. TAIWAN_ID_NUMBER A Taiwanese ID number. ICD9_CODE The International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM) lexicon is used to assign diagnostic and procedure codes associated with inpatient, outpatient, and physician office use in the United States. It was created by the US National Center for Health Statistics (NCHS). The ICD-9-CM is based on the ICD-9 but provides for additional morbidity detail. It's updated annually on October 1. COUNTRY_DEMOGRAPHIC A country when used to reference someone's place of birth, residence or citizenship. SPAIN_CIF_NUMBER The Spanish Código de Identificación Fiscal (CIF) was the tax identification system used in Spain for legal entities until 2008. It was then replaced by the Número de Identificación Fiscal (NIF) for natural and juridical persons. US_ADOPTION_TAXPAYER_IDENTIFICATION_NUMBER A United States Adoption Taxpayer Identification Number (ATIN) is a type of Tax Identification Number (TIN), issued by the Internal Revenue Service (IRS) to individuals who are in the process of legally adopting a US citizen or resident child. DOCUMENT_TYPE/R&D/SOURCE_CODE/C C source code. RELIGIOUS_TERM Terms that commonly refer to religious beliefs, religious leaders, religious organizations, and religious practices. SSL_CERTIFICATE SSL certificates are cryptographic certificates used to verify identity and establish secured connections using the Secured Sockets Layer protocol. INDONESIA_NIK_NUMBER An Indonesian Single Identity Number (Nomor Induk Kependudukan, or NIK) is the national identification number of Indonesia. The NIK is used as the basis for issuing Indonesian resident identity cards (Kartu Tanda Penduduk, or KTP), passports, driver's licenses and other identity documents. BRAZIL_CPF_NUMBER The Brazilian Cadastro de Pessoas Físicas (CPF) number, or Natural Persons Register number, is an 11-digit number used in Brazil for taxpayer identification. HTTP_USER_AGENT A user agent used for facilitating web content; contains information about the computer sending the request and often appears as a header. AZURE_AUTH_TOKEN Azure certificate credentials for application authentication. STREET_ADDRESS A street address. Note: Not recommended for use during latency sensitive operations. MEDICAL_DATA A general infoType representing all medical data excluding medical IDs of people. This includes individual medical data, such as blood type, as well as general medical content. LOCATION A physical address or location. Note: Not recommended for use during latency sensitive operations. GCP_CREDENTIALS Google Cloud Platform service account credentials. Credentials that can be used to authenticate with Google API client libraries and service accounts. DOCUMENT_TYPE/R&D/SOURCE_CODE/TYPESCRIPT TypeScript source code. WEAK_PASSWORD_HASH A commonly used password which has a very easy to guess hash. POLITICAL_TERM Terms that commonly refer to an association or membership to a political party. BLOOD_TYPE A classification of blood. CANADA_QUEBEC_HIN The Québec Health Insurance Number (HIN) is issued to citizens, permanent residents, temporary workers, students and other individuals who are entitled to health care coverage in the Province of Québec. PORTUGAL_NIB_NUMBER A Portuguese Número de Identificação Bancária (NIB) or Banking Identification Number is assigned by the Banco de Portugal and identifies bank accounts for all national interbanking operations. DOCUMENT_TYPE/R&D/SOURCE_CODE/CS C# source code. VEHICLE_IDENTIFICATION_NUMBER A vehicle identification number (VIN) is a unique 17-digit code assigned to every on-road motor vehicle. CHILE_CDI_NUMBER A Chilean Cédula de Identidad (CDI), or identity card, is used as the main identity document for citizens. US_BANK_ROUTING_MICR The American Bankers Association (ABA) Routing Number (also called the transit number) is a nine-digit code. It's used to identify the financial institution that's responsible to credit or entitled to receive credit for a check or electronic transaction. AUTH_TOKEN An authentication token is a machine readable way of determining whether a particular request has been authorized for a user. This detector currently identifies tokens that comply with OAuth or Bearer authentication. SINGAPORE_NATIONAL_REGISTRATION_ID_NUMBER A unique set of nine alpha-numeric characters on the Singapore National Registration Identity Card. PORTUGAL_SOCIAL_SECURITY_NUMBER The Portuguese Social Security number (Número de Identificação de Segurança Social) is a 11-digit sequence that identifies a person in Portugal for all interactions with the country's Social Security system. UK_NATIONAL_INSURANCE_NUMBER The National Insurance number (NINO) is a number used in the United Kingdom (UK) in the administration of the National Insurance or social security system. It identifies people, and is also used for some purposes in the UK tax system. The number is sometimes referred to as NI No or NINO. CHINA_PASSPORT A Chinese passport number. ARGENTINA_DNI_NUMBER An Argentine Documento Nacional de Identidad (DNI), or national identity card, is used as the main identity document for citizens. DOCUMENT_TYPE/R&D/SOURCE_CODE A source code text. AMERICAN_BANKERS_CUSIP_ID An American Bankers' Committee on Uniform Security Identification Procedures (CUSIP) number is a 9-character alphanumeric code that identifies a North American financial security. AWS_CREDENTIALS Amazon Web Services account access keys. SCOTLAND_COMMUNITY_HEALTH_INDEX_NUMBER The Scotland Community Health Index Number (CHI number) is a 10-digit sequence used to uniquely identify a patient within National Health Service Scotland (NHS Scotland). ADVERTISING_ID Identifiers used by developers to track users for advertising purposes. These include Google Play Advertising IDs, Amazon Advertising IDs, Apple's identifierForAdvertising (IDFA), and Apple's identifierForVendor (IDFV). VAT_NUMBER Value addeed tax identification number is used as an identifier for anything related to a valued-added tax. OAUTH_CLIENT_SECRET A client secret value used by Open Authorization MAC_ADDRESS_UNIVERSAL A universal media access control address (MAC address), which is an identifier for a network adapter. INDONESIA_PASSPORT An Indonesian passport number. HTTP_COOKIE Headers containing cookies either sent to or from a server. They are part of the HTTP specification. BELGIUM_NATIONAL_ID_CARD_NUMBER A 12-digit Belgian national identity card number. ITALY_FISCAL_CODE An Italy fiscal code number is a unique 16-digit code assigned to Italian citizens as a form of identification. POLAND_PASSPORT A Polish passport number. Polish passport is an international travel document for Polish citizens. It can also be used as a proof of Polish citizenship. DOCUMENT_TYPE/R&D/SOURCE_CODE/PHP PHP source code. MARITAL_STATUS A marital status, which specifies if a person has ever been married. OBJECT_TYPE/WHITEBOARD Image of a whiteboard. PARAGUAY_TAX_NUMBER A Paraguayan Registro Único de Contribuyente (RUC), or tax number, is used to identify businesses and individuals for tax purposes in Paraguay. SOUTH_AFRICA_ID_NUMBER A South Africa ID number. MAC_ADDRESS A media access control address (MAC address), which is an identifier for a network adapter. SEXUAL_ORIENTATION A person's sexual orientation. SWEDEN_PASSPORT A Swedish passport number. US_SOCIAL_SECURITY_NUMBER A United States Social Security number (SSN) is a 9-digit number issued to US citizens, permanent residents, and temporary residents. This detector will not match against numbers with all zeroes in any digit group (that is, 000-##-####, ###-00-####, or ###-##-0000), against numbers with 666 in the first digit group, or against numbers whose first digit is 9. US_STATE A United States state name. ENCRYPTION_KEY Encryption key DOCUMENT_TYPE/HR/RESUME A resume or a Curriculum Vitae document. PORTUGAL_CDC_NUMBER A Portuguese Cartão de cidadão (CDC), or Citizen Card, is used as the main identity, Social Security, health services, taxpayer, and voter document for citizens. UK_DRIVERS_LICENSE_NUMBER A driver's license number for the United Kingdom of Great Britain and Northern Ireland (UK). INDIA_AADHAAR_INDIVIDUAL The Indian Aadhaar number is a 12-digit unique identity number obtained by residents of India, based on their biometric and demographic data. DOCUMENT_TYPE/R&D/SOURCE_CODE/CPP C++ source code. US_INDIVIDUAL_TAXPAYER_IDENTIFICATION_NUMBER A United States Individual Taxpayer Identification Number (ITIN) is a type of Tax Identification Number (TIN), issued by the Internal Revenue Service (IRS). An ITIN is a tax processing number only available for certain nonresident and resident aliens, their spouses, and dependents who cannot get a Social Security Number (SSN). OBJECT_TYPE/PERSON Image of a human-like figure, which can include a full body, a face, or other body parts. DOCUMENT_TYPE/LEGAL/COURT_ORDER A court order, ruling, or decision is document produced by a court requesting a specific action from the involved parties. US_DEA_NUMBER A US Drug Enforcement Administration (DEA) number is assigned to a health care provider by the US DEA. It allows the health care provider to write prescriptions for controlled substances. The DEA number is often used as a general \"prescriber number\" that is a unique identifier for anyone who can prescribe medication. TINK_KEYSET A keyset created with the TINK cryptographic library. IMSI_ID An International Mobile Subscriber Identity (IMSI) identifier, used to identify users of a cellular network. EMPLOYMENT_STATUS A person's employment status. SWITZERLAND_SOCIAL_SECURITY_NUMBER Switzerland social security number. US_PASSPORT A United States passport number. CANADA_BANK_ACCOUNT A Canadian bank account number. DOCUMENT_TYPE/R&D/SOURCE_CODE/JSON JSON source code. US_HEALTHCARE_NPI The US National Provider Identifier (NPI) is a unique 10-digit identification number issued to health care providers in the United States by the Centers for Medicare and Medicaid Services (CMS). The NPI has replaced the unique provider identification number (UPIN) as the required identifier for Medicare services. It's also used by other payers, including commercial healthcare insurers. SECURITY_DATA A general infoType representing security data. Some examples of this are passwords and API keys. UK_ELECTORAL_ROLL_NUMBER A UK electoral roll number is a number issued to United Kingdom citizens for voter identification. This number is composed of 3 to 7 digits. DOCUMENT_TYPE/LEGAL/LAW A document containing the text of a law or a regulation. NORWAY_NI_NUMBER Norway‘s Fødselsnummer, National Identification Number, or Birth Number is assigned at birth, or on migration into the country. It is registered with the Norwegian Tax Office. KOREA_ARN A South Korean alien registration number. GERMANY_PASSPORT A German passport number. The format of a German passport number is 10 alphanumeric characters, chosen from numerals 0-9 and letters C, F, G, H, J, K, L, M, N, P, R, T, V, W, X, Y, Z. AUSTRALIA_DRIVERS_LICENSE_NUMBER An Australian driver's license number. LOCATION_COORDINATES A specific location as noted by a lat/long pair, or an S2 value. IRELAND_DRIVING_LICENSE_NUMBER An Irish driving license number. AGE An age measured in months or years. AUSTRALIA_MEDICARE_NUMBER A 9-digit Australian Medicare account number is issued to permanent residents of Australia (except for Norfolk island). The primary purpose of this number is to prove Medicare eligibility to receive subsidized care in Australia. URUGUAY_CDI_NUMBER An Uruguayan Cédula de Identidad (CDI), or identity card, is used as the main identity document for citizens. POLAND_PESEL_NUMBER The PESEL number is the national identification number used in Poland. It is mandatory for all permanent residents of Poland, as well as for temporary residents staying there longer than 2 months. It is assigned to just one person and cannot be changed. DOCUMENT_TYPE/R&D/SOURCE_CODE/PYTHON Python source code. GOVERNMENT_ID A general infoType that represents government ID numbers that identify an individual. DOCUMENT_TYPE/FINANCE/SEC_FILING An SEC filing is a formal document submitted to the U.S. Securities and Exchange Commission. The most commonly filed SEC forms are 10-K and 10-Q. TIME A timestamp of a specific time of day. SPAIN_NIE_NUMBER The Spanish Número de Identificación de Extranjeros (NIE) is an identification number for foreigners living or doing business in Spain. An NIE number is needed for key transactions such as opening a bank account, buying a car, or setting up a mobile phone contract. IMEI_HARDWARE_ID An International Mobile Equipment Identity (IMEI) hardware identifier, used to identify mobile phones. POLAND_NATIONAL_ID_NUMBER The Polish identity card number. is a government identification number for Polish citizens. Every citizen older than 18 years must have an identity card. The card is issued by the local Office of Civic Affairs. Every identity card has its own unique number. JSON_WEB_TOKEN JSON Web Token in compact form. Represents a set of claims as a JSON object that is digitally signed using JSON Web Signature. ETHNIC_GROUP A person's ethnic group. DOCUMENT_TYPE/LEGAL/PLEADING A pleading is a formal written statement of a party's claims or defenses to another party's claims. Examples include a complaint, a demurrer, or an answer. CREDIT_CARD_TRACK_NUMBER A credit card track number is a variable length alphanumeric string. It is used to store key cardholder information. GERMANY_DRIVERS_LICENSE_NUMBER A German driver's license number. FINLAND_BUSINESS_ID A Finnish business id number, which identifies a company or organization in Finland. MAC_ADDRESS_LOCAL A local media access control address (MAC address), which is an identifier for a network adapter. FRANCE_PASSPORT A French passport number. CANADA_SOCIAL_INSURANCE_NUMBER The Canadian Social Insurance Number (SIN) is the main identifier used in Canada for citizens, permanent residents, and those on work or study visas. With a Canadian SIN and mailing address, one can apply for health care coverage, driver's licenses, and other important services. FEMALE_NAME A common female name. This is a legacy infoType that returns a strict subset of PERSON_NAME findings. We recommend using PERSON_NAME instead. Note: Not recommended for use during latency sensitive operations. DOCUMENT_TYPE/R&D/SOURCE_CODE/HTML HTML source code. ITALY_PASSPORT An Italian passport number. US_EMPLOYER_IDENTIFICATION_NUMBER A United States Employer Identification Number (EIN) is also known as a Federal Tax Identification Number, and is used to identify a business entity. KOREA_RRN A South Korean Social Security number. DOCUMENT_TYPE/R&D/PATENT A patent or a patent application document. KAZAKHSTAN_PASSPORT A Kazakhstani passport number. AUSTRALIA_PASSPORT An Australian passport number. CREDIT_CARD_EXPIRATION_DATE Indicates when a credit or debit card will expire. PERU_DNI_NUMBER A Peruvian Documento Nacional de Identidad (DNI), or national identity card, is used as the main identity document for citizens. COLOMBIA_CDC_NUMBER A Colombian Cédula de Ciudadanía (CDC), or citizenship card, is used as the main identity document for citizens. GENERIC_ID Alphanumeric and special character strings that may be personally identifying but do not belong to a well-defined category, such as user IDs or medical record numbers. SPAIN_NIF_NUMBER The Spanish Número de Identificación Fiscal (NIF) is a government identification number for Spanish citizens. An NIF number is needed for key transactions such as opening a bank account, buying a car, or setting up a mobile phone contract. DENMARK_CPR_NUMBER A Personal Identification Number (CPR, Det Centrale Personregister) is a national ID number in Denmark. It is used with public agencies such as health care and tax authorities. Banks and insurance companies also use it as a customer number. The CPR number is required for people who reside in Denmark, pay tax or own property there. SPAIN_SOCIAL_SECURITY_NUMBER The Spanish Social Security number (Número de Afiliación a la Seguridad Social) is a 10-digit sequence that identifies a person in Spain for all interactions with the country's Social Security system. SPAIN_DRIVERS_LICENSE_NUMBER A Spanish driver's license number. GEOGRAPHIC_DATA A general infoType representing geographic data. This includes information like locations, addresses, and coordinates. US_DRIVERS_LICENSE_NUMBER A driver's license number for the United States. Format can vary depending on the issuing state. PHONE_NUMBER A telephone number. PASSPORT A passport number that matches passport numbers for the following countries: Armenia, Australia, Azerbaijan, Belarus, Canada, China, France, Germany, India, Indonesia, Ireland, Italy, Japan, Kazakhstan, Korea, Mexico, The Netherlands, Poland, Russia, Singapore, Spain, Sweden, Taiwan, United Kingdom, Ukraine, the United States, and Uzbekistan. IRELAND_PASSPORT An Irish passport number. GERMANY_SCHUFA_ID A German Schufa identification number. Schufa Holding AG is a German credit bureau whose aim is to protect clients from credit risk. STORAGE_SIGNED_URL A storage signed URL is a URL that provides time-limited resource access to anyone in possession of the URL, regardless of whether they have a Google account. Signed URLs contain authentication information in their query string, allowing users without credentials to perform specific actions on a resource. MALE_NAME A common male name. This is a legacy infoType that returns a strict subset of PERSON_NAME findings. We recommend using PERSON_NAME instead. Note: Not recommended for use during latency sensitive operations. DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVASCRIPT Javascript source code. MEDICAL_RECORD_NUMBER A generic medical record number. TRADE_UNION A trade union is a collection of workers that works to improve their working conditions. LAST_NAME A last name is defined as the last part of a PERSON_NAME. This is a legacy infoType that returns a strict subset of PERSON_NAME findings. We recommend using PERSON_NAME instead. Note: Not recommended for use during latency sensitive operations. BRAZIL_RG_NUMBER Brazil general registry number (Registro Geral or RG). URL A Uniform Resource Locator (URL). NEW_ZEALAND_IRD_NUMBER A New Zealand IRD number is a unique number issued to entities for tax purposes in New Zealand. FINLAND_NATIONAL_ID_NUMBER A Finnish personal identity code, a national government identification number for Finnish citizens used on identity cards, driver's licenses and passports. SWIFT_CODE A SWIFT code is the same as a Bank Identifier Code (BIC). It's a unique identification code for a particular bank. These codes are used when transferring money between banks, particularly for international wire transfers. Banks also use the codes for exchanging other messages. SINGAPORE_PASSPORT A Singaporean passport number. JAPAN_CORPORATE_NUMBER A Japanese corporate number. DEMOGRAPHIC_DATA A general infoType representing demographic data. This includes information like age, date of birth, gender identity, sexual orientation, marital status, and other similar information. THAILAND_NATIONAL_ID_NUMBER The Thai บัตรประจำตัวประชาชนไทย, or identity card, is used as the main identity document for Thai nationals. CANADA_OHIP The Ontario Health Insurance Plan (OHIP) number is issued to citizens, permanent residents, temporary workers, students, and other individuals who are entitled to health care coverage in the Province of Ontario. DOCUMENT_TYPE/FINANCE/REGULATORY Finance regulatory documents include financial regulations, tax laws, rules, and guidelines. Typically issued by tax or regulatory authorities. JAPAN_DRIVERS_LICENSE_NUMBER A Japanese driver's license number. OBJECT_TYPE/BARCODE Image of a 1D or 2D barcode, which is a machine-readable image that represents a piece of data. Barcodes are typically used to identify or track products. OBJECT_TYPE/LICENSE_PLATE Image of a license plate, which is a government-issued vehicle identifier. XSRF_TOKEN A token which is used to authenticate users and prevent cross site scripting attacks. DOMAIN_NAME A domain name as defined by the DNS standard. DOCUMENT_TYPE/R&D/SOURCE_CODE/SQL SQL source code. FRANCE_NIR The French Numéro d'Inscription au Répertoire (NIR) is a permanent personal identification number that's also known as the French social security number for services including healthcare as well as pensions. NETHERLANDS_BSN_NUMBER A Dutch Burgerservicenummer (BSN), or Citizen's Service Number, is a state-issued identification number that's on driver's licenses, passports, and international ID cards. FRANCE_TAX_IDENTIFICATION_NUMBER The French tax identification number is a government-issued ID for all individuals paying taxes in France. AZERBAIJAN_PASSPORT An Azerbaijani passport number. INDIA_GST_INDIVIDUAL The Indian GST identification number (GSTIN) is a unique identifier required of every business in India for taxation. DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVA Java source code. PERSON_NAME A full or partial person name, which can include first names, middle names or initials, and last names. Note: Not recommended for use during latency sensitive operations. CANADA_DRIVERS_LICENSE_NUMBER A driver's license number for each of the ten provinces in Canada. CREDIT_CARD_DATA A general infoType representing credit card numbers, credit card track numbers, credit card expiration dates, and CVV numbers. JAPAN_BANK_ACCOUNT A Japanese bank account number. DOCUMENT_TYPE/R&D/SOURCE_CODE/POWERSHELL PowerShell source code. JAPAN_INDIVIDUAL_NUMBER The Japanese national identification number—sometimes referred to as \"My Number\"—is a new national ID number as of January 2016. FDA_CODE Drug product name or active ingredient registered by the United States Food and Drug Administration (FDA). NEW_ZEALAND_NHI_NUMBER A New Zealand NHI number is a unique identifier that is assigned to every person who uses health and disability support services in New Zealand. ICD10_CODE Like ICD-9-CM codes, the International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM) lexicon is a series of diagnostic codes published by the World Health Organization (WHO) to describe causes of morbidity and mortality. UK_PASSPORT A United Kingdom (UK) passport number. VENEZUELA_CDI_NUMBER A Venezuelan Cédula de Identidad (CDI), or national identity card, is used as the main identity document for citizens. PARAGUAY_CIC_NUMBER A Paraguayan Cédula de Identidad Civil (CIC), or civil identity card, is used as the main identity document for citizens. JAPAN_PASSPORT A Japanese passport number. The passport number consists of two alphabetic characters followed by seven digits. MEDICAL_ID A general infoType representing medical IDs that identify an individual. DOCUMENT_TYPE/R&D/DATABASE_BACKUP A database backup file. TAIWAN_PASSPORT A Taiwanese passport number. UK_TAXPAYER_REFERENCE A United Kingdom (UK) Unique Taxpayer Reference (UTR) number. This number, comprised of a string of 10 decimal digits, is an identifier used by the UK government to manage the taxation system. Unlike other identifiers, such as the passport number or social insurance number, the UTR is not listed on official identity cards. SPAIN_DNI_NUMBER A Spain national identity number. INDIA_PAN_INDIVIDUAL The Indian Personal Permanent Account Number (PAN) is a unique 10-digit alphanumeric identifier used for identification of individuals, particularly those who pay income tax. It's issued by the Indian Income Tax Department. The PAN is valid for the lifetime of the holder. DATE A date. This includes most date formats, as well as the names of common world holidays. IRELAND_PPSN The Irish Personal Public Service Number (PPS number, or PPSN) is a unique number for accessing social welfare benefits, public services, and information in Ireland. BASIC_AUTH_HEADER A basic authentication header is a HTTP header used to identify a user to a server. It is part of the HTTP specification in rfc 1945. (https://tools.ietf.org/html/rfc1945#section-11) ARMENIA_PASSPORT An Armenian passport number. DOCUMENT_TYPE/R&D/SYSTEM_LOG System or application software log. PASSWORD Clear text passwords in configs, code, and other text. FRANCE_CNI The French Carte Nationale d'Identité Sécurisée (CNI or CNIS) is the French national identity card. It's an official identity document consisting of a 12-digit identification number. This number is commonly used when opening bank accounts and when paying by check. It can sometimes be used instead of a passport or visa within the European Union (EU) and in some other countries. AUSTRALIA_TAX_FILE_NUMBER An Australian tax file number (TFN) is a number issued by the Australian Tax Office for taxpayer identification. Every taxpaying entity, such as an individual or an organization, is assigned a unique number. US_PREPARER_TAXPAYER_IDENTIFICATION_NUMBER A United States Preparer Taxpayer Identification Number (PTIN) is an identification number that all paid tax return preparers must use on US federal tax returns or claims for refund submitted to the US Internal Revenue Service (IRS). US_VEHICLE_IDENTIFICATION_NUMBER A vehicle identification number (VIN) is a unique 17-digit code assigned to every on-road motor vehicle in North America. DOCUMENT_TYPE/R&D/SOURCE_CODE/RUST Rust source code. US_TOLLFREE_PHONE_NUMBER A US toll-free telephone number. DOCUMENT_TYPE/LEGAL/BLANK_FORM A blank legal form or a template. Typically has multiple areas or boxes left empty with the intention of it being filled by the person and then submitting it to a legal institution. ICCID_NUMBER The integrated circuit card identifier uniquely identifies SIM cards. FIRST_NAME A first name is defined as the first part of a PERSON_NAME. This is a legacy infoType that returns a strict subset of PERSON_NAME findings. We recommend using PERSON_NAME instead. Note: Not recommended for use during latency sensitive operations. UKRAINE_PASSPORT A Ukrainian passport number. MEXICO_PASSPORT A Mexican passport number. NETHERLANDS_PASSPORT A Dutch passport number. CHINA_RESIDENT_ID_NUMBER A Chinese resident identification number. GENDER A person’s gender identity. CANADA_PASSPORT A Canadian passport number. UZBEKISTAN_PASSPORT An Uzbekistani passport number. CZECHIA_PERSONAL_ID_NUMBER A Czechia personal identification number that all Czech citizens as well as foreigners staying in Czechia temporarily or permanently must have. DATE_OF_BIRTH A date that is identified by context as a date of birth. Note: Not recommended for use during latency sensitive operations. DOCUMENT_TYPE/R&D/SOURCE_CODE/GO Go source code. CREDIT_CARD_NUMBER A credit card number is 12 to 19 digits long. They are used for payment transactions globally. TURKEY_ID_NUMBER A unique Turkish personal identification number, assigned to every citizen of Turkey. CROATIA_PERSONAL_ID_NUMBER A Croatia Personal Identification Number (OIB) is a permanent national identification number of every Croatian citizen and resident in the Republic of Croatia. US_MEDICARE_BENEFICIARY_ID_NUMBER A US Medicare Beneficiary Identifier is an identification number that is used on all US Medicare transactions. TECHNICAL_ID A general infoType representing technical IDs that are used to identify an entity on the internet. Some examples of this are advertising IDs, IP addresses, and MAC addresses. GERMANY_TAXPAYER_IDENTIFICATION_NUMBER An 11-digit German taxpayer identification number assigned to both natural-born and other legal residents of Germany for the purposes of recording tax payments. CANADA_BC_PHN The British Columbia Personal Health Number (PHN) is issued to citizens, permanent residents, temporary workers, students, and other individuals who are entitled to health care coverage in the Province of British Columbia. BELARUS_PASSPORT A Belarusian passport number. KOREA_DRIVERS_LICENSE_NUMBER A Korean driver's license number. GCP_API_KEY Google Cloud API key. Simple encrypted string that can be used when calling certain Google Cloud APIs that don't need to access private user data. ISRAEL_IDENTITY_CARD_NUMBER Israel identity card number is issued to all Israeli citizens at birth by the Ministry of the Interior. Temporary residents are assigned a number when they receive temporary resident status. INDIA_PASSPORT An Indian passport number. CVV_NUMBER A CVV number is a number made up of 3 to 4 digits that is located on credit and debit cards. A CVV number is used to verify the card. MEDICAL_TERM Terms that commonly refer to a person's medical condition or health. DRIVERS_LICENSE_NUMBER A driver's license number that matches driver's license numbers for the following countries: Australia, Canada, Germany, Ireland, Japan, Korea, Spain, the United Kingdom, and the United States. UK_NATIONAL_HEALTH_SERVICE_NUMBER A National Health Service (NHS) number is the unique number allocated to a registered user of the three public health services in England, Wales, and the Isle of Man. SPAIN_PASSPORT A Spanish Ordinary Passport (Pasaporte Ordinario) number. There are 4 different types of passports in Spain. This detector is for the Ordinary Passport (Pasaporte Ordinario) type, which is issued for ordinary travel, such as vacations and business trips. RUSSIA_PASSPORT A Russian passport number. GERMANY_IDENTITY_CARD_NUMBER The German Personalausweis, or identity card, is used as the main identity document for citizens of Germany. IMMIGRATION_STATUS An immigration status denotes a person's right to be in a country. IP_ADDRESS An Internet Protocol (IP) address (either IPv4 or IPv6). SWEDEN_NATIONAL_ID_NUMBER A Swedish Personal Identity Number (personnummer), a national government identification number for Swedish citizens. FINANCIAL_ACCOUNT_NUMBER A number referring to a specific financial account, for example, a bank account number or a retirement account number. IBAN_CODE An International Bank Account Number (IBAN) is defined as an internationally agreed-upon method for identifying bank accounts. It's defined by the International Standard of Organization (ISO) 13616:2007 standard. ISO 13616:2007 was created by the European Committee for Banking Standards (ECBS). An IBAN consists of up to 34 alphanumeric characters including elements such as a country code or account number. InfoType categories The following table shows the categories of each infoType. Location specifies the geographic location that the infoType is typically associated with. Availability indicates the regions or multi-regions where the infoType is supported. The value ANY_LOCATION means that the infoType is available in all regions. Select a location GLOBAL ARGENTINA ARMENIA AUSTRALIA AUSTRIA AZERBAIJAN BELARUS BELGIUM BRAZIL CANADA CHILE CHINA COLOMBIA CROATIA CZECHIA DENMARK FRANCE FINLAND GERMANY HONG_KONG INDIA INDONESIA IRELAND ISRAEL ITALY JAPAN KAZAKHSTAN KOREA MEXICO THE_NETHERLANDS NEW_ZEALAND NORWAY PARAGUAY PERU POLAND PORTUGAL RUSSIA SINGAPORE SOUTH_AFRICA SPAIN SWEDEN SWITZERLAND TAIWAN THAILAND TURKEY UKRAINE UNITED_KINGDOM UNITED_STATES URUGUAY UZBEKISTAN VENEZUELA Finance Health Communications PII SPII Demographic Credential Government ID Document Contextual information Custom Any Regional Clear all Name Location Industry Type Availability FINANCIAL_ID GLOBAL FINANCE PII SPII ANY_LOCATION DOCUMENT_TYPE/LEGAL/BRIEF GLOBAL DOCUMENT ANY_LOCATION FRANCE_DRIVERS_LICENSE_NUMBER FRANCE GOVERNMENT_ID PII SPII ANY_LOCATION MEXICO_CURP_NUMBER MEXICO GOVERNMENT_ID PII SPII ANY_LOCATION ORGANIZATION_NAME GLOBAL CONTEXTUAL_INFORMATION ANY_LOCATION DOD_ID_NUMBER UNITED_STATES GOVERNMENT_ID PII SPII ANY_LOCATION STORAGE_SIGNED_POLICY_DOCUMENT GLOBAL CREDENTIAL PII SPII ANY_LOCATION KOREA_PASSPORT KOREA GOVERNMENT_ID PII SPII ANY_LOCATION HONG_KONG_ID_NUMBER HONG_KONG GOVERNMENT_ID PII SPII ANY_LOCATION EMAIL_ADDRESS GLOBAL PII ANY_LOCATION IRELAND_EIRCODE IRELAND PII ANY_LOCATION CZECHIA_PASSPORT CZECHIA GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/SHELL GLOBAL DOCUMENT ANY_LOCATION AUSTRIA_SOCIAL_SECURITY_NUMBER AUSTRIA HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION TAIWAN_ID_NUMBER TAIWAN GOVERNMENT_ID PII SPII ANY_LOCATION ICD9_CODE GLOBAL HEALTH CONTEXTUAL_INFORMATION ANY_LOCATION COUNTRY_DEMOGRAPHIC GLOBAL DEMOGRAPHIC ANY_LOCATION SPAIN_CIF_NUMBER SPAIN GOVERNMENT_ID ANY_LOCATION US_ADOPTION_TAXPAYER_IDENTIFICATION_NUMBER UNITED_STATES FINANCE GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/C GLOBAL DOCUMENT ANY_LOCATION RELIGIOUS_TERM GLOBAL CONTEXTUAL_INFORMATION DEMOGRAPHIC ANY_LOCATION SSL_CERTIFICATE GLOBAL CREDENTIAL PII SPII ANY_LOCATION INDONESIA_NIK_NUMBER INDONESIA GOVERNMENT_ID PII SPII ANY_LOCATION BRAZIL_CPF_NUMBER BRAZIL GOVERNMENT_ID PII SPII ANY_LOCATION HTTP_USER_AGENT GLOBAL ANY_LOCATION AZURE_AUTH_TOKEN GLOBAL CREDENTIAL PII SPII ANY_LOCATION STREET_ADDRESS GLOBAL PII ANY_LOCATION MEDICAL_DATA GLOBAL HEALTH DEMOGRAPHIC ANY_LOCATION LOCATION GLOBAL CONTEXTUAL_INFORMATION ANY_LOCATION GCP_CREDENTIALS GLOBAL CREDENTIAL PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/TYPESCRIPT GLOBAL DOCUMENT ANY_LOCATION WEAK_PASSWORD_HASH GLOBAL CREDENTIAL ANY_LOCATION POLITICAL_TERM GLOBAL CONTEXTUAL_INFORMATION DEMOGRAPHIC ANY_LOCATION BLOOD_TYPE GLOBAL HEALTH ANY_LOCATION CANADA_QUEBEC_HIN CANADA HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION PORTUGAL_NIB_NUMBER PORTUGAL FINANCE PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/CS GLOBAL DOCUMENT ANY_LOCATION VEHICLE_IDENTIFICATION_NUMBER GLOBAL PII ANY_LOCATION CHILE_CDI_NUMBER CHILE GOVERNMENT_ID PII SPII ANY_LOCATION US_BANK_ROUTING_MICR UNITED_STATES FINANCE CONTEXTUAL_INFORMATION ANY_LOCATION AUTH_TOKEN GLOBAL CREDENTIAL PII SPII ANY_LOCATION SINGAPORE_NATIONAL_REGISTRATION_ID_NUMBER SINGAPORE GOVERNMENT_ID PII SPII ANY_LOCATION PORTUGAL_SOCIAL_SECURITY_NUMBER PORTUGAL GOVERNMENT_ID PII SPII ANY_LOCATION UK_NATIONAL_INSURANCE_NUMBER UNITED_KINGDOM FINANCE HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION CHINA_PASSPORT CHINA GOVERNMENT_ID PII SPII ANY_LOCATION ARGENTINA_DNI_NUMBER ARGENTINA GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE GLOBAL DOCUMENT ANY_LOCATION AMERICAN_BANKERS_CUSIP_ID GLOBAL FINANCE CONTEXTUAL_INFORMATION ANY_LOCATION AWS_CREDENTIALS GLOBAL CREDENTIAL PII SPII ANY_LOCATION SCOTLAND_COMMUNITY_HEALTH_INDEX_NUMBER UNITED_KINGDOM HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION ADVERTISING_ID GLOBAL PII ANY_LOCATION VAT_NUMBER GLOBAL GOVERNMENT_ID ANY_LOCATION OAUTH_CLIENT_SECRET GLOBAL CREDENTIAL PII SPII ANY_LOCATION MAC_ADDRESS_UNIVERSAL GLOBAL TELECOMMUNICATIONS PII ANY_LOCATION INDONESIA_PASSPORT INDONESIA GOVERNMENT_ID PII SPII ANY_LOCATION HTTP_COOKIE GLOBAL CREDENTIAL PII SPII ANY_LOCATION BELGIUM_NATIONAL_ID_CARD_NUMBER BELGIUM GOVERNMENT_ID PII SPII ANY_LOCATION ITALY_FISCAL_CODE ITALY FINANCE GOVERNMENT_ID PII SPII ANY_LOCATION POLAND_PASSPORT POLAND GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/PHP GLOBAL DOCUMENT ANY_LOCATION MARITAL_STATUS GLOBAL DEMOGRAPHIC ANY_LOCATION OBJECT_TYPE/WHITEBOARD GLOBAL CONTEXTUAL_INFORMATION REGIONAL: asia europe global us PARAGUAY_TAX_NUMBER PARAGUAY GOVERNMENT_ID PII SPII ANY_LOCATION SOUTH_AFRICA_ID_NUMBER SOUTH_AFRICA GOVERNMENT_ID PII SPII ANY_LOCATION MAC_ADDRESS GLOBAL TELECOMMUNICATIONS PII ANY_LOCATION SEXUAL_ORIENTATION GLOBAL DEMOGRAPHIC ANY_LOCATION SWEDEN_PASSPORT SWEDEN GOVERNMENT_ID PII SPII ANY_LOCATION US_SOCIAL_SECURITY_NUMBER UNITED_STATES GOVERNMENT_ID PII SPII ANY_LOCATION US_STATE UNITED_STATES ANY_LOCATION ENCRYPTION_KEY GLOBAL CREDENTIAL PII SPII ANY_LOCATION DOCUMENT_TYPE/HR/RESUME GLOBAL DOCUMENT ANY_LOCATION PORTUGAL_CDC_NUMBER PORTUGAL GOVERNMENT_ID PII SPII ANY_LOCATION UK_DRIVERS_LICENSE_NUMBER UNITED_KINGDOM GOVERNMENT_ID PII SPII ANY_LOCATION INDIA_AADHAAR_INDIVIDUAL INDIA GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/CPP GLOBAL DOCUMENT ANY_LOCATION US_INDIVIDUAL_TAXPAYER_IDENTIFICATION_NUMBER UNITED_STATES FINANCE GOVERNMENT_ID PII SPII ANY_LOCATION OBJECT_TYPE/PERSON GLOBAL DEMOGRAPHIC PII REGIONAL: asia europe global us DOCUMENT_TYPE/LEGAL/COURT_ORDER GLOBAL DOCUMENT ANY_LOCATION US_DEA_NUMBER UNITED_STATES HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION TINK_KEYSET GLOBAL CREDENTIAL PII SPII ANY_LOCATION IMSI_ID GLOBAL TELECOMMUNICATIONS PII SPII ANY_LOCATION EMPLOYMENT_STATUS GLOBAL DEMOGRAPHIC ANY_LOCATION SWITZERLAND_SOCIAL_SECURITY_NUMBER SWITZERLAND GOVERNMENT_ID PII SPII ANY_LOCATION US_PASSPORT UNITED_STATES GOVERNMENT_ID PII SPII ANY_LOCATION CANADA_BANK_ACCOUNT CANADA FINANCE PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/JSON GLOBAL DOCUMENT ANY_LOCATION US_HEALTHCARE_NPI UNITED_STATES HEALTH GOVERNMENT_ID PII ANY_LOCATION SECURITY_DATA GLOBAL CREDENTIAL PII SPII ANY_LOCATION UK_ELECTORAL_ROLL_NUMBER UNITED_KINGDOM GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/LEGAL/LAW GLOBAL DOCUMENT ANY_LOCATION NORWAY_NI_NUMBER NORWAY GOVERNMENT_ID PII SPII ANY_LOCATION KOREA_ARN KOREA GOVERNMENT_ID PII SPII ANY_LOCATION GERMANY_PASSPORT GERMANY GOVERNMENT_ID PII SPII ANY_LOCATION AUSTRALIA_DRIVERS_LICENSE_NUMBER AUSTRALIA GOVERNMENT_ID PII SPII ANY_LOCATION LOCATION_COORDINATES GLOBAL CONTEXTUAL_INFORMATION ANY_LOCATION IRELAND_DRIVING_LICENSE_NUMBER IRELAND GOVERNMENT_ID PII SPII ANY_LOCATION AGE GLOBAL DEMOGRAPHIC PII ANY_LOCATION AUSTRALIA_MEDICARE_NUMBER AUSTRALIA HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION URUGUAY_CDI_NUMBER URUGUAY GOVERNMENT_ID PII SPII ANY_LOCATION POLAND_PESEL_NUMBER POLAND GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/PYTHON GLOBAL DOCUMENT ANY_LOCATION GOVERNMENT_ID GLOBAL GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/FINANCE/SEC_FILING GLOBAL FINANCE DOCUMENT ANY_LOCATION TIME GLOBAL ANY_LOCATION SPAIN_NIE_NUMBER SPAIN GOVERNMENT_ID PII SPII ANY_LOCATION IMEI_HARDWARE_ID GLOBAL TELECOMMUNICATIONS PII SPII ANY_LOCATION POLAND_NATIONAL_ID_NUMBER POLAND GOVERNMENT_ID PII SPII ANY_LOCATION JSON_WEB_TOKEN GLOBAL CREDENTIAL PII SPII ANY_LOCATION ETHNIC_GROUP GLOBAL DEMOGRAPHIC ANY_LOCATION DOCUMENT_TYPE/LEGAL/PLEADING GLOBAL DOCUMENT ANY_LOCATION CREDIT_CARD_TRACK_NUMBER GLOBAL FINANCE PII SPII ANY_LOCATION GERMANY_DRIVERS_LICENSE_NUMBER GERMANY GOVERNMENT_ID PII SPII ANY_LOCATION FINLAND_BUSINESS_ID FINLAND GOVERNMENT_ID ANY_LOCATION MAC_ADDRESS_LOCAL GLOBAL TELECOMMUNICATIONS PII ANY_LOCATION FRANCE_PASSPORT FRANCE GOVERNMENT_ID PII SPII ANY_LOCATION CANADA_SOCIAL_INSURANCE_NUMBER CANADA HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION FEMALE_NAME GLOBAL PII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/HTML GLOBAL DOCUMENT ANY_LOCATION ITALY_PASSPORT ITALY GOVERNMENT_ID PII SPII ANY_LOCATION US_EMPLOYER_IDENTIFICATION_NUMBER UNITED_STATES GOVERNMENT_ID ANY_LOCATION KOREA_RRN KOREA GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/PATENT GLOBAL DOCUMENT ANY_LOCATION KAZAKHSTAN_PASSPORT KAZAKHSTAN GOVERNMENT_ID PII SPII ANY_LOCATION AUSTRALIA_PASSPORT AUSTRALIA GOVERNMENT_ID PII SPII ANY_LOCATION CREDIT_CARD_EXPIRATION_DATE GLOBAL FINANCE PII SPII ANY_LOCATION PERU_DNI_NUMBER PERU GOVERNMENT_ID PII SPII ANY_LOCATION COLOMBIA_CDC_NUMBER COLOMBIA GOVERNMENT_ID PII SPII ANY_LOCATION GENERIC_ID GLOBAL FINANCE HEALTH TELECOMMUNICATIONS DEMOGRAPHIC ANY_LOCATION SPAIN_NIF_NUMBER SPAIN GOVERNMENT_ID PII SPII ANY_LOCATION DENMARK_CPR_NUMBER DENMARK GOVERNMENT_ID PII SPII ANY_LOCATION SPAIN_SOCIAL_SECURITY_NUMBER SPAIN GOVERNMENT_ID PII SPII ANY_LOCATION SPAIN_DRIVERS_LICENSE_NUMBER SPAIN GOVERNMENT_ID PII SPII ANY_LOCATION GEOGRAPHIC_DATA GLOBAL CONTEXTUAL_INFORMATION ANY_LOCATION US_DRIVERS_LICENSE_NUMBER UNITED_STATES GOVERNMENT_ID PII SPII ANY_LOCATION PHONE_NUMBER GLOBAL TELECOMMUNICATIONS PII ANY_LOCATION PASSPORT GLOBAL GOVERNMENT_ID PII SPII ANY_LOCATION IRELAND_PASSPORT IRELAND GOVERNMENT_ID PII SPII ANY_LOCATION GERMANY_SCHUFA_ID GERMANY GOVERNMENT_ID PII SPII ANY_LOCATION STORAGE_SIGNED_URL GLOBAL CREDENTIAL PII SPII ANY_LOCATION MALE_NAME GLOBAL PII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVASCRIPT GLOBAL DOCUMENT ANY_LOCATION MEDICAL_RECORD_NUMBER GLOBAL HEALTH PII SPII ANY_LOCATION TRADE_UNION GLOBAL CONTEXTUAL_INFORMATION DEMOGRAPHIC ANY_LOCATION LAST_NAME GLOBAL PII ANY_LOCATION BRAZIL_RG_NUMBER BRAZIL GOVERNMENT_ID PII SPII ANY_LOCATION URL GLOBAL ANY_LOCATION NEW_ZEALAND_IRD_NUMBER NEW_ZEALAND GOVERNMENT_ID PII SPII ANY_LOCATION FINLAND_NATIONAL_ID_NUMBER FINLAND GOVERNMENT_ID PII SPII ANY_LOCATION SWIFT_CODE GLOBAL FINANCE CONTEXTUAL_INFORMATION ANY_LOCATION SINGAPORE_PASSPORT SINGAPORE GOVERNMENT_ID PII SPII ANY_LOCATION JAPAN_CORPORATE_NUMBER JAPAN GOVERNMENT_ID ANY_LOCATION DEMOGRAPHIC_DATA GLOBAL CONTEXTUAL_INFORMATION DEMOGRAPHIC ANY_LOCATION THAILAND_NATIONAL_ID_NUMBER THAILAND GOVERNMENT_ID PII SPII ANY_LOCATION CANADA_OHIP CANADA HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/FINANCE/REGULATORY GLOBAL FINANCE DOCUMENT ANY_LOCATION JAPAN_DRIVERS_LICENSE_NUMBER JAPAN GOVERNMENT_ID PII SPII ANY_LOCATION OBJECT_TYPE/BARCODE GLOBAL CONTEXTUAL_INFORMATION REGIONAL: asia europe global us OBJECT_TYPE/LICENSE_PLATE GLOBAL GOVERNMENT_ID PII REGIONAL: asia europe global us XSRF_TOKEN GLOBAL CREDENTIAL PII SPII ANY_LOCATION DOMAIN_NAME GLOBAL ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/SQL GLOBAL DOCUMENT ANY_LOCATION FRANCE_NIR FRANCE GOVERNMENT_ID PII SPII ANY_LOCATION NETHERLANDS_BSN_NUMBER THE_NETHERLANDS GOVERNMENT_ID PII SPII ANY_LOCATION FRANCE_TAX_IDENTIFICATION_NUMBER FRANCE FINANCE GOVERNMENT_ID PII SPII ANY_LOCATION AZERBAIJAN_PASSPORT AZERBAIJAN GOVERNMENT_ID PII SPII ANY_LOCATION INDIA_GST_INDIVIDUAL INDIA GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVA GLOBAL DOCUMENT ANY_LOCATION PERSON_NAME GLOBAL PII ANY_LOCATION CANADA_DRIVERS_LICENSE_NUMBER CANADA GOVERNMENT_ID PII SPII ANY_LOCATION CREDIT_CARD_DATA GLOBAL FINANCE PII SPII ANY_LOCATION JAPAN_BANK_ACCOUNT JAPAN FINANCE PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/POWERSHELL GLOBAL DOCUMENT ANY_LOCATION JAPAN_INDIVIDUAL_NUMBER JAPAN GOVERNMENT_ID PII SPII ANY_LOCATION FDA_CODE GLOBAL HEALTH CONTEXTUAL_INFORMATION ANY_LOCATION NEW_ZEALAND_NHI_NUMBER NEW_ZEALAND HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION ICD10_CODE GLOBAL HEALTH CONTEXTUAL_INFORMATION ANY_LOCATION UK_PASSPORT UNITED_KINGDOM GOVERNMENT_ID PII SPII ANY_LOCATION VENEZUELA_CDI_NUMBER VENEZUELA GOVERNMENT_ID PII SPII ANY_LOCATION PARAGUAY_CIC_NUMBER PARAGUAY GOVERNMENT_ID PII SPII ANY_LOCATION JAPAN_PASSPORT JAPAN GOVERNMENT_ID PII SPII ANY_LOCATION MEDICAL_ID GLOBAL HEALTH PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/DATABASE_BACKUP GLOBAL DOCUMENT ANY_LOCATION TAIWAN_PASSPORT TAIWAN GOVERNMENT_ID PII SPII ANY_LOCATION UK_TAXPAYER_REFERENCE UNITED_KINGDOM FINANCE GOVERNMENT_ID PII SPII ANY_LOCATION SPAIN_DNI_NUMBER SPAIN GOVERNMENT_ID PII SPII ANY_LOCATION INDIA_PAN_INDIVIDUAL INDIA GOVERNMENT_ID PII SPII ANY_LOCATION DATE GLOBAL ANY_LOCATION IRELAND_PPSN IRELAND GOVERNMENT_ID PII SPII ANY_LOCATION BASIC_AUTH_HEADER GLOBAL CREDENTIAL PII SPII ANY_LOCATION ARMENIA_PASSPORT ARMENIA GOVERNMENT_ID PII SPII ANY_LOCATION DOCUMENT_TYPE/R&D/SYSTEM_LOG GLOBAL DOCUMENT ANY_LOCATION PASSWORD GLOBAL CREDENTIAL PII SPII ANY_LOCATION FRANCE_CNI FRANCE GOVERNMENT_ID PII SPII ANY_LOCATION AUSTRALIA_TAX_FILE_NUMBER AUSTRALIA GOVERNMENT_ID PII SPII ANY_LOCATION US_PREPARER_TAXPAYER_IDENTIFICATION_NUMBER UNITED_STATES FINANCE GOVERNMENT_ID PII SPII ANY_LOCATION US_VEHICLE_IDENTIFICATION_NUMBER UNITED_STATES PII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/RUST GLOBAL DOCUMENT ANY_LOCATION US_TOLLFREE_PHONE_NUMBER UNITED_STATES TELECOMMUNICATIONS ANY_LOCATION DOCUMENT_TYPE/LEGAL/BLANK_FORM GLOBAL DOCUMENT ANY_LOCATION ICCID_NUMBER GLOBAL TELECOMMUNICATIONS PII SPII ANY_LOCATION FIRST_NAME GLOBAL PII ANY_LOCATION UKRAINE_PASSPORT UKRAINE GOVERNMENT_ID PII SPII ANY_LOCATION MEXICO_PASSPORT MEXICO GOVERNMENT_ID PII SPII ANY_LOCATION NETHERLANDS_PASSPORT THE_NETHERLANDS GOVERNMENT_ID PII SPII ANY_LOCATION CHINA_RESIDENT_ID_NUMBER CHINA GOVERNMENT_ID PII SPII ANY_LOCATION GENDER GLOBAL DEMOGRAPHIC ANY_LOCATION CANADA_PASSPORT CANADA GOVERNMENT_ID PII SPII ANY_LOCATION UZBEKISTAN_PASSPORT UZBEKISTAN GOVERNMENT_ID PII SPII ANY_LOCATION CZECHIA_PERSONAL_ID_NUMBER CZECHIA GOVERNMENT_ID PII SPII ANY_LOCATION DATE_OF_BIRTH GLOBAL DEMOGRAPHIC PII ANY_LOCATION DOCUMENT_TYPE/R&D/SOURCE_CODE/GO GLOBAL DOCUMENT ANY_LOCATION CREDIT_CARD_NUMBER GLOBAL FINANCE PII SPII ANY_LOCATION TURKEY_ID_NUMBER TURKEY GOVERNMENT_ID PII SPII ANY_LOCATION CROATIA_PERSONAL_ID_NUMBER CROATIA GOVERNMENT_ID PII SPII ANY_LOCATION US_MEDICARE_BENEFICIARY_ID_NUMBER UNITED_STATES HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION TECHNICAL_ID GLOBAL TELECOMMUNICATIONS PII ANY_LOCATION GERMANY_TAXPAYER_IDENTIFICATION_NUMBER GERMANY FINANCE GOVERNMENT_ID PII SPII ANY_LOCATION CANADA_BC_PHN CANADA HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION BELARUS_PASSPORT BELARUS GOVERNMENT_ID PII SPII ANY_LOCATION KOREA_DRIVERS_LICENSE_NUMBER KOREA GOVERNMENT_ID PII SPII ANY_LOCATION GCP_API_KEY GLOBAL CREDENTIAL PII SPII ANY_LOCATION ISRAEL_IDENTITY_CARD_NUMBER ISRAEL GOVERNMENT_ID PII SPII ANY_LOCATION INDIA_PASSPORT INDIA GOVERNMENT_ID PII SPII ANY_LOCATION CVV_NUMBER GLOBAL FINANCE PII SPII ANY_LOCATION MEDICAL_TERM GLOBAL HEALTH CONTEXTUAL_INFORMATION ANY_LOCATION DRIVERS_LICENSE_NUMBER GLOBAL GOVERNMENT_ID PII SPII ANY_LOCATION UK_NATIONAL_HEALTH_SERVICE_NUMBER UNITED_KINGDOM HEALTH GOVERNMENT_ID PII SPII ANY_LOCATION SPAIN_PASSPORT SPAIN GOVERNMENT_ID PII SPII ANY_LOCATION RUSSIA_PASSPORT RUSSIA GOVERNMENT_ID PII SPII ANY_LOCATION GERMANY_IDENTITY_CARD_NUMBER GERMANY GOVERNMENT_ID PII SPII ANY_LOCATION IMMIGRATION_STATUS GLOBAL DEMOGRAPHIC ANY_LOCATION IP_ADDRESS GLOBAL TELECOMMUNICATIONS PII ANY_LOCATION SWEDEN_NATIONAL_ID_NUMBER SWEDEN GOVERNMENT_ID PII SPII ANY_LOCATION FINANCIAL_ACCOUNT_NUMBER GLOBAL FINANCE PII SPII ANY_LOCATION IBAN_CODE GLOBAL FINANCE PII SPII ANY_LOCATION Sensitivity scores The following table shows the default sensitivity score of each infoType. For information about how to customize default sensitivity values, see Edit the settings of a built-in infoType . Name Sensitivity score FINANCIAL_ID SENSITIVITY_HIGH DOCUMENT_TYPE/LEGAL/BRIEF SENSITIVITY_MODERATE FRANCE_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH MEXICO_CURP_NUMBER SENSITIVITY_HIGH ORGANIZATION_NAME SENSITIVITY_LOW DOD_ID_NUMBER SENSITIVITY_HIGH STORAGE_SIGNED_POLICY_DOCUMENT SENSITIVITY_HIGH KOREA_PASSPORT SENSITIVITY_HIGH HONG_KONG_ID_NUMBER SENSITIVITY_HIGH EMAIL_ADDRESS SENSITIVITY_MODERATE IRELAND_EIRCODE SENSITIVITY_MODERATE CZECHIA_PASSPORT SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/SHELL SENSITIVITY_MODERATE AUSTRIA_SOCIAL_SECURITY_NUMBER SENSITIVITY_HIGH TAIWAN_ID_NUMBER SENSITIVITY_HIGH ICD9_CODE SENSITIVITY_LOW COUNTRY_DEMOGRAPHIC SENSITIVITY_MODERATE SPAIN_CIF_NUMBER SENSITIVITY_HIGH US_ADOPTION_TAXPAYER_IDENTIFICATION_NUMBER SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/C SENSITIVITY_MODERATE RELIGIOUS_TERM SENSITIVITY_MODERATE SSL_CERTIFICATE SENSITIVITY_HIGH INDONESIA_NIK_NUMBER SENSITIVITY_HIGH BRAZIL_CPF_NUMBER SENSITIVITY_HIGH HTTP_USER_AGENT SENSITIVITY_LOW AZURE_AUTH_TOKEN SENSITIVITY_HIGH STREET_ADDRESS SENSITIVITY_MODERATE MEDICAL_DATA SENSITIVITY_MODERATE LOCATION SENSITIVITY_MODERATE GCP_CREDENTIALS SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/TYPESCRIPT SENSITIVITY_MODERATE WEAK_PASSWORD_HASH SENSITIVITY_HIGH POLITICAL_TERM SENSITIVITY_MODERATE BLOOD_TYPE SENSITIVITY_MODERATE CANADA_QUEBEC_HIN SENSITIVITY_HIGH PORTUGAL_NIB_NUMBER SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/CS SENSITIVITY_MODERATE VEHICLE_IDENTIFICATION_NUMBER SENSITIVITY_MODERATE CHILE_CDI_NUMBER SENSITIVITY_HIGH US_BANK_ROUTING_MICR SENSITIVITY_MODERATE AUTH_TOKEN SENSITIVITY_HIGH SINGAPORE_NATIONAL_REGISTRATION_ID_NUMBER SENSITIVITY_HIGH PORTUGAL_SOCIAL_SECURITY_NUMBER SENSITIVITY_HIGH UK_NATIONAL_INSURANCE_NUMBER SENSITIVITY_HIGH CHINA_PASSPORT SENSITIVITY_HIGH ARGENTINA_DNI_NUMBER SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE SENSITIVITY_MODERATE AMERICAN_BANKERS_CUSIP_ID SENSITIVITY_MODERATE AWS_CREDENTIALS SENSITIVITY_HIGH SCOTLAND_COMMUNITY_HEALTH_INDEX_NUMBER SENSITIVITY_HIGH ADVERTISING_ID SENSITIVITY_MODERATE VAT_NUMBER SENSITIVITY_MODERATE OAUTH_CLIENT_SECRET SENSITIVITY_HIGH MAC_ADDRESS_UNIVERSAL SENSITIVITY_MODERATE INDONESIA_PASSPORT SENSITIVITY_HIGH HTTP_COOKIE SENSITIVITY_HIGH BELGIUM_NATIONAL_ID_CARD_NUMBER SENSITIVITY_HIGH ITALY_FISCAL_CODE SENSITIVITY_HIGH POLAND_PASSPORT SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/PHP SENSITIVITY_MODERATE MARITAL_STATUS SENSITIVITY_MODERATE OBJECT_TYPE/WHITEBOARD SENSITIVITY_LOW PARAGUAY_TAX_NUMBER SENSITIVITY_HIGH SOUTH_AFRICA_ID_NUMBER SENSITIVITY_HIGH MAC_ADDRESS SENSITIVITY_MODERATE SEXUAL_ORIENTATION SENSITIVITY_MODERATE SWEDEN_PASSPORT SENSITIVITY_HIGH US_SOCIAL_SECURITY_NUMBER SENSITIVITY_HIGH US_STATE SENSITIVITY_LOW ENCRYPTION_KEY SENSITIVITY_HIGH DOCUMENT_TYPE/HR/RESUME SENSITIVITY_MODERATE PORTUGAL_CDC_NUMBER SENSITIVITY_HIGH UK_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH INDIA_AADHAAR_INDIVIDUAL SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/CPP SENSITIVITY_MODERATE US_INDIVIDUAL_TAXPAYER_IDENTIFICATION_NUMBER SENSITIVITY_HIGH OBJECT_TYPE/PERSON SENSITIVITY_MODERATE DOCUMENT_TYPE/LEGAL/COURT_ORDER SENSITIVITY_MODERATE US_DEA_NUMBER SENSITIVITY_HIGH TINK_KEYSET SENSITIVITY_HIGH IMSI_ID SENSITIVITY_HIGH EMPLOYMENT_STATUS SENSITIVITY_MODERATE SWITZERLAND_SOCIAL_SECURITY_NUMBER SENSITIVITY_HIGH US_PASSPORT SENSITIVITY_HIGH CANADA_BANK_ACCOUNT SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/JSON SENSITIVITY_MODERATE US_HEALTHCARE_NPI SENSITIVITY_MODERATE SECURITY_DATA SENSITIVITY_HIGH UK_ELECTORAL_ROLL_NUMBER SENSITIVITY_HIGH DOCUMENT_TYPE/LEGAL/LAW SENSITIVITY_MODERATE NORWAY_NI_NUMBER SENSITIVITY_HIGH KOREA_ARN SENSITIVITY_HIGH GERMANY_PASSPORT SENSITIVITY_HIGH AUSTRALIA_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH LOCATION_COORDINATES SENSITIVITY_MODERATE IRELAND_DRIVING_LICENSE_NUMBER SENSITIVITY_HIGH AGE SENSITIVITY_MODERATE AUSTRALIA_MEDICARE_NUMBER SENSITIVITY_HIGH URUGUAY_CDI_NUMBER SENSITIVITY_HIGH POLAND_PESEL_NUMBER SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/PYTHON SENSITIVITY_MODERATE GOVERNMENT_ID SENSITIVITY_HIGH DOCUMENT_TYPE/FINANCE/SEC_FILING SENSITIVITY_MODERATE TIME SENSITIVITY_LOW SPAIN_NIE_NUMBER SENSITIVITY_HIGH IMEI_HARDWARE_ID SENSITIVITY_HIGH POLAND_NATIONAL_ID_NUMBER SENSITIVITY_HIGH JSON_WEB_TOKEN SENSITIVITY_HIGH ETHNIC_GROUP SENSITIVITY_MODERATE DOCUMENT_TYPE/LEGAL/PLEADING SENSITIVITY_MODERATE CREDIT_CARD_TRACK_NUMBER SENSITIVITY_HIGH GERMANY_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH FINLAND_BUSINESS_ID SENSITIVITY_MODERATE MAC_ADDRESS_LOCAL SENSITIVITY_MODERATE FRANCE_PASSPORT SENSITIVITY_HIGH CANADA_SOCIAL_INSURANCE_NUMBER SENSITIVITY_HIGH FEMALE_NAME SENSITIVITY_MODERATE DOCUMENT_TYPE/R&D/SOURCE_CODE/HTML SENSITIVITY_MODERATE ITALY_PASSPORT SENSITIVITY_HIGH US_EMPLOYER_IDENTIFICATION_NUMBER SENSITIVITY_MODERATE KOREA_RRN SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/PATENT SENSITIVITY_MODERATE KAZAKHSTAN_PASSPORT SENSITIVITY_HIGH AUSTRALIA_PASSPORT SENSITIVITY_HIGH CREDIT_CARD_EXPIRATION_DATE SENSITIVITY_HIGH PERU_DNI_NUMBER SENSITIVITY_HIGH COLOMBIA_CDC_NUMBER SENSITIVITY_HIGH GENERIC_ID SENSITIVITY_MODERATE SPAIN_NIF_NUMBER SENSITIVITY_HIGH DENMARK_CPR_NUMBER SENSITIVITY_HIGH SPAIN_SOCIAL_SECURITY_NUMBER SENSITIVITY_HIGH SPAIN_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH GEOGRAPHIC_DATA SENSITIVITY_MODERATE US_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH PHONE_NUMBER SENSITIVITY_MODERATE PASSPORT SENSITIVITY_HIGH IRELAND_PASSPORT SENSITIVITY_HIGH GERMANY_SCHUFA_ID SENSITIVITY_HIGH STORAGE_SIGNED_URL SENSITIVITY_HIGH MALE_NAME SENSITIVITY_MODERATE DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVASCRIPT SENSITIVITY_MODERATE MEDICAL_RECORD_NUMBER SENSITIVITY_HIGH TRADE_UNION SENSITIVITY_MODERATE LAST_NAME SENSITIVITY_MODERATE BRAZIL_RG_NUMBER SENSITIVITY_HIGH URL SENSITIVITY_LOW NEW_ZEALAND_IRD_NUMBER SENSITIVITY_HIGH FINLAND_NATIONAL_ID_NUMBER SENSITIVITY_HIGH SWIFT_CODE SENSITIVITY_MODERATE SINGAPORE_PASSPORT SENSITIVITY_HIGH JAPAN_CORPORATE_NUMBER SENSITIVITY_MODERATE DEMOGRAPHIC_DATA SENSITIVITY_MODERATE THAILAND_NATIONAL_ID_NUMBER SENSITIVITY_HIGH CANADA_OHIP SENSITIVITY_HIGH DOCUMENT_TYPE/FINANCE/REGULATORY SENSITIVITY_MODERATE JAPAN_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH OBJECT_TYPE/BARCODE SENSITIVITY_LOW OBJECT_TYPE/LICENSE_PLATE SENSITIVITY_MODERATE XSRF_TOKEN SENSITIVITY_HIGH DOMAIN_NAME SENSITIVITY_LOW DOCUMENT_TYPE/R&D/SOURCE_CODE/SQL SENSITIVITY_MODERATE FRANCE_NIR SENSITIVITY_HIGH NETHERLANDS_BSN_NUMBER SENSITIVITY_HIGH FRANCE_TAX_IDENTIFICATION_NUMBER SENSITIVITY_HIGH AZERBAIJAN_PASSPORT SENSITIVITY_HIGH INDIA_GST_INDIVIDUAL SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVA SENSITIVITY_MODERATE PERSON_NAME SENSITIVITY_MODERATE CANADA_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH CREDIT_CARD_DATA SENSITIVITY_HIGH JAPAN_BANK_ACCOUNT SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SOURCE_CODE/POWERSHELL SENSITIVITY_MODERATE JAPAN_INDIVIDUAL_NUMBER SENSITIVITY_HIGH FDA_CODE SENSITIVITY_LOW NEW_ZEALAND_NHI_NUMBER SENSITIVITY_HIGH ICD10_CODE SENSITIVITY_LOW UK_PASSPORT SENSITIVITY_HIGH VENEZUELA_CDI_NUMBER SENSITIVITY_HIGH PARAGUAY_CIC_NUMBER SENSITIVITY_HIGH JAPAN_PASSPORT SENSITIVITY_HIGH MEDICAL_ID SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/DATABASE_BACKUP SENSITIVITY_MODERATE TAIWAN_PASSPORT SENSITIVITY_HIGH UK_TAXPAYER_REFERENCE SENSITIVITY_HIGH SPAIN_DNI_NUMBER SENSITIVITY_HIGH INDIA_PAN_INDIVIDUAL SENSITIVITY_HIGH DATE SENSITIVITY_LOW IRELAND_PPSN SENSITIVITY_HIGH BASIC_AUTH_HEADER SENSITIVITY_HIGH ARMENIA_PASSPORT SENSITIVITY_HIGH DOCUMENT_TYPE/R&D/SYSTEM_LOG SENSITIVITY_MODERATE PASSWORD SENSITIVITY_HIGH FRANCE_CNI SENSITIVITY_HIGH AUSTRALIA_TAX_FILE_NUMBER SENSITIVITY_HIGH US_PREPARER_TAXPAYER_IDENTIFICATION_NUMBER SENSITIVITY_HIGH US_VEHICLE_IDENTIFICATION_NUMBER SENSITIVITY_MODERATE DOCUMENT_TYPE/R&D/SOURCE_CODE/RUST SENSITIVITY_MODERATE US_TOLLFREE_PHONE_NUMBER SENSITIVITY_MODERATE DOCUMENT_TYPE/LEGAL/BLANK_FORM SENSITIVITY_MODERATE ICCID_NUMBER SENSITIVITY_HIGH FIRST_NAME SENSITIVITY_MODERATE UKRAINE_PASSPORT SENSITIVITY_HIGH MEXICO_PASSPORT SENSITIVITY_HIGH NETHERLANDS_PASSPORT SENSITIVITY_HIGH CHINA_RESIDENT_ID_NUMBER SENSITIVITY_HIGH GENDER SENSITIVITY_MODERATE CANADA_PASSPORT SENSITIVITY_HIGH UZBEKISTAN_PASSPORT SENSITIVITY_HIGH CZECHIA_PERSONAL_ID_NUMBER SENSITIVITY_HIGH DATE_OF_BIRTH SENSITIVITY_MODERATE DOCUMENT_TYPE/R&D/SOURCE_CODE/GO SENSITIVITY_MODERATE CREDIT_CARD_NUMBER SENSITIVITY_HIGH TURKEY_ID_NUMBER SENSITIVITY_HIGH CROATIA_PERSONAL_ID_NUMBER SENSITIVITY_HIGH US_MEDICARE_BENEFICIARY_ID_NUMBER SENSITIVITY_HIGH TECHNICAL_ID SENSITIVITY_MODERATE GERMANY_TAXPAYER_IDENTIFICATION_NUMBER SENSITIVITY_HIGH CANADA_BC_PHN SENSITIVITY_HIGH BELARUS_PASSPORT SENSITIVITY_HIGH KOREA_DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH GCP_API_KEY SENSITIVITY_HIGH ISRAEL_IDENTITY_CARD_NUMBER SENSITIVITY_HIGH INDIA_PASSPORT SENSITIVITY_HIGH CVV_NUMBER SENSITIVITY_HIGH MEDICAL_TERM SENSITIVITY_LOW DRIVERS_LICENSE_NUMBER SENSITIVITY_HIGH UK_NATIONAL_HEALTH_SERVICE_NUMBER SENSITIVITY_HIGH SPAIN_PASSPORT SENSITIVITY_HIGH RUSSIA_PASSPORT SENSITIVITY_HIGH GERMANY_IDENTITY_CARD_NUMBER SENSITIVITY_HIGH IMMIGRATION_STATUS SENSITIVITY_MODERATE IP_ADDRESS SENSITIVITY_MODERATE SWEDEN_NATIONAL_ID_NUMBER SENSITIVITY_HIGH FINANCIAL_ACCOUNT_NUMBER SENSITIVITY_HIGH IBAN_CODE SENSITIVITY_HIGH General infotypes Preview This feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section of the Service Specific Terms . Pre-GA features are available \"as is\" and might have limited support. For more information, see the launch stage descriptions . The following table lists the available general infoTypes and the specific infoTypes that they detect. For more information, see General and specific infotype detectors . General infoType Specific infoTypes included FINANCIAL_ID CANADA_BANK_ACCOUNT CREDIT_CARD_NUMBER CREDIT_CARD_TRACK_NUMBER CVV_NUMBER FINANCIAL_ACCOUNT_NUMBER IBAN_CODE JAPAN_BANK_ACCOUNT PORTUGAL_NIB_NUMBER MEDICAL_DATA BLOOD_TYPE FDA_CODE ICD10_CODE ICD9_CODE MEDICAL_TERM US_HEALTHCARE_NPI VEHICLE_IDENTIFICATION_NUMBER US_VEHICLE_IDENTIFICATION_NUMBER SECURITY_DATA AUTH_TOKEN AWS_CREDENTIALS AZURE_AUTH_TOKEN BASIC_AUTH_HEADER ENCRYPTION_KEY GCP_API_KEY GCP_CREDENTIALS HTTP_COOKIE JSON_WEB_TOKEN OAUTH_CLIENT_SECRET PASSWORD SSL_CERTIFICATE STORAGE_SIGNED_POLICY_DOCUMENT STORAGE_SIGNED_URL TINK_KEYSET WEAK_PASSWORD_HASH XSRF_TOKEN GOVERNMENT_ID ARGENTINA_DNI_NUMBER ARMENIA_PASSPORT AUSTRALIA_DRIVERS_LICENSE_NUMBER AUSTRALIA_MEDICARE_NUMBER AUSTRALIA_PASSPORT AUSTRALIA_TAX_FILE_NUMBER AUSTRIA_SOCIAL_SECURITY_NUMBER AZERBAIJAN_PASSPORT BELARUS_PASSPORT BELGIUM_NATIONAL_ID_CARD_NUMBER BRAZIL_CPF_NUMBER BRAZIL_RG_NUMBER CANADA_BC_PHN CANADA_DRIVERS_LICENSE_NUMBER CANADA_OHIP CANADA_PASSPORT CANADA_QUEBEC_HIN CANADA_SOCIAL_INSURANCE_NUMBER CHILE_CDI_NUMBER CHINA_PASSPORT CHINA_RESIDENT_ID_NUMBER COLOMBIA_CDC_NUMBER CROATIA_PERSONAL_ID_NUMBER CZECHIA_PASSPORT CZECHIA_PERSONAL_ID_NUMBER DENMARK_CPR_NUMBER DOD_ID_NUMBER FINLAND_NATIONAL_ID_NUMBER FRANCE_CNI FRANCE_DRIVERS_LICENSE_NUMBER FRANCE_NIR FRANCE_PASSPORT FRANCE_TAX_IDENTIFICATION_NUMBER GERMANY_DRIVERS_LICENSE_NUMBER GERMANY_IDENTITY_CARD_NUMBER GERMANY_PASSPORT GERMANY_SCHUFA_ID GERMANY_TAXPAYER_IDENTIFICATION_NUMBER HONG_KONG_ID_NUMBER INDIA_AADHAAR_INDIVIDUAL INDIA_GST_INDIVIDUAL INDIA_PAN_INDIVIDUAL INDIA_PASSPORT INDONESIA_NIK_NUMBER INDONESIA_PASSPORT IRELAND_DRIVING_LICENSE_NUMBER IRELAND_PASSPORT IRELAND_PPSN ISRAEL_IDENTITY_CARD_NUMBER ITALY_FISCAL_CODE ITALY_PASSPORT JAPAN_DRIVERS_LICENSE_NUMBER JAPAN_INDIVIDUAL_NUMBER JAPAN_PASSPORT KAZAKHSTAN_PASSPORT KOREA_ARN KOREA_DRIVERS_LICENSE_NUMBER KOREA_PASSPORT KOREA_RRN MEXICO_CURP_NUMBER MEXICO_PASSPORT NETHERLANDS_BSN_NUMBER NETHERLANDS_PASSPORT NEW_ZEALAND_IRD_NUMBER NEW_ZEALAND_NHI_NUMBER NORWAY_NI_NUMBER PARAGUAY_CIC_NUMBER PARAGUAY_TAX_NUMBER PASSPORT PERU_DNI_NUMBER POLAND_NATIONAL_ID_NUMBER POLAND_PASSPORT POLAND_PESEL_NUMBER PORTUGAL_CDC_NUMBER PORTUGAL_SOCIAL_SECURITY_NUMBER RUSSIA_PASSPORT SCOTLAND_COMMUNITY_HEALTH_INDEX_NUMBER SINGAPORE_NATIONAL_REGISTRATION_ID_NUMBER SINGAPORE_PASSPORT SOUTH_AFRICA_ID_NUMBER SPAIN_DNI_NUMBER SPAIN_DRIVERS_LICENSE_NUMBER SPAIN_NIE_NUMBER SPAIN_NIF_NUMBER SPAIN_PASSPORT SPAIN_SOCIAL_SECURITY_NUMBER SWEDEN_NATIONAL_ID_NUMBER SWEDEN_PASSPORT SWITZERLAND_SOCIAL_SECURITY_NUMBER TAIWAN_ID_NUMBER TAIWAN_PASSPORT THAILAND_NATIONAL_ID_NUMBER TURKEY_ID_NUMBER UK_DRIVERS_LICENSE_NUMBER UK_ELECTORAL_ROLL_NUMBER UK_NATIONAL_HEALTH_SERVICE_NUMBER UK_NATIONAL_INSURANCE_NUMBER UK_PASSPORT UK_TAXPAYER_REFERENCE UKRAINE_PASSPORT URUGUAY_CDI_NUMBER US_ADOPTION_TAXPAYER_IDENTIFICATION_NUMBER US_DEA_NUMBER US_DRIVERS_LICENSE_NUMBER US_INDIVIDUAL_TAXPAYER_IDENTIFICATION_NUMBER US_MEDICARE_BENEFICIARY_ID_NUMBER US_PASSPORT US_PREPARER_TAXPAYER_IDENTIFICATION_NUMBER US_SOCIAL_SECURITY_NUMBER UZBEKISTAN_PASSPORT VENEZUELA_CDI_NUMBER GEOGRAPHIC_DATA IRELAND_EIRCODE LOCATION LOCATION_COORDINATES STREET_ADDRESS PHONE_NUMBER US_TOLLFREE_PHONE_NUMBER PASSPORT ARMENIA_PASSPORT AUSTRALIA_PASSPORT AZERBAIJAN_PASSPORT BELARUS_PASSPORT CANADA_PASSPORT CHINA_PASSPORT CZECHIA_PASSPORT FRANCE_PASSPORT GERMANY_PASSPORT INDONESIA_PASSPORT INDIA_PASSPORT IRELAND_PASSPORT ITALY_PASSPORT JAPAN_PASSPORT KAZAKHSTAN_PASSPORT KOREA_PASSPORT MEXICO_PASSPORT NETHERLANDS_PASSPORT POLAND_PASSPORT RUSSIA_PASSPORT SINGAPORE_PASSPORT SPAIN_PASSPORT SWEDEN_PASSPORT TAIWAN_PASSPORT UK_PASSPORT US_PASSPORT UKRAINE_PASSPORT UZBEKISTAN_PASSPORT DEMOGRAPHIC_DATA AGE COUNTRY_DEMOGRAPHIC DATE_OF_BIRTH EMPLOYMENT_STATUS ETHNIC_GROUP GENDER IMMIGRATION_STATUS MARITAL_STATUS POLITICAL_TERM RELIGIOUS_TERM SEXUAL_ORIENTATION TRADE_UNION CREDIT_CARD_DATA CREDIT_CARD_EXPIRATION_DATE CREDIT_CARD_NUMBER CREDIT_CARD_TRACK_NUMBER CVV_NUMBER MEDICAL_ID AUSTRALIA_MEDICARE_NUMBER CANADA_BC_PHN CANADA_OHIP CANADA_QUEBEC_HIN NEW_ZEALAND_NHI_NUMBER SCOTLAND_COMMUNITY_HEALTH_INDEX_NUMBER UK_NATIONAL_HEALTH_SERVICE_NUMBER US_MEDICARE_BENEFICIARY_ID_NUMBER TECHNICAL_ID ADVERTISING_ID ICCID_NUMBER IMEI_HARDWARE_ID IMSI_ID IP_ADDRESS MAC_ADDRESS_LOCAL MAC_ADDRESS_UNIVERSAL DRIVERS_LICENSE_NUMBER AUSTRALIA_DRIVERS_LICENSE_NUMBER CANADA_DRIVERS_LICENSE_NUMBER FRANCE_DRIVERS_LICENSE_NUMBER GERMANY_DRIVERS_LICENSE_NUMBER IRELAND_DRIVING_LICENSE_NUMBER JAPAN_DRIVERS_LICENSE_NUMBER KOREA_DRIVERS_LICENSE_NUMBER SPAIN_DRIVERS_LICENSE_NUMBER UK_DRIVERS_LICENSE_NUMBER US_DRIVERS_LICENSE_NUMBER Documents In addition to its ability to scan and classify information contained within documents, Sensitive Data Protection can classify documents into multiple enterprise-specific categories. When combined with personally identifiable information (PII) inspection scan results, this classification can be useful for document risk assessment, policy enforcement, and similar use cases. DOCUMENT_TYPE/FINANCE/REGULATORY DOCUMENT_TYPE/FINANCE/SEC_FILING DOCUMENT_TYPE/HR/RESUME DOCUMENT_TYPE/LEGAL/BLANK_FORM DOCUMENT_TYPE/LEGAL/BRIEF DOCUMENT_TYPE/LEGAL/COURT_ORDER DOCUMENT_TYPE/LEGAL/LAW DOCUMENT_TYPE/LEGAL/PLEADING DOCUMENT_TYPE/R&D/DATABASE_BACKUP DOCUMENT_TYPE/R&D/PATENT DOCUMENT_TYPE/R&D/SOURCE_CODE DOCUMENT_TYPE/R&D/SOURCE_CODE/C DOCUMENT_TYPE/R&D/SOURCE_CODE/CPP DOCUMENT_TYPE/R&D/SOURCE_CODE/CS DOCUMENT_TYPE/R&D/SOURCE_CODE/GO DOCUMENT_TYPE/R&D/SOURCE_CODE/HTML DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVA DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVASCRIPT DOCUMENT_TYPE/R&D/SOURCE_CODE/JSON DOCUMENT_TYPE/R&D/SOURCE_CODE/PHP DOCUMENT_TYPE/R&D/SOURCE_CODE/POWERSHELL DOCUMENT_TYPE/R&D/SOURCE_CODE/PYTHON DOCUMENT_TYPE/R&D/SOURCE_CODE/RUST DOCUMENT_TYPE/R&D/SOURCE_CODE/SHELL DOCUMENT_TYPE/R&D/SOURCE_CODE/SQL DOCUMENT_TYPE/R&D/SOURCE_CODE/TYPESCRIPT DOCUMENT_TYPE/R&D/SYSTEM_LOG Secrets The following infoType detectors detect credentials and other secret data. AUTH_TOKEN AWS_CREDENTIALS AZURE_AUTH_TOKEN BASIC_AUTH_HEADER ENCRYPTION_KEY GCP_API_KEY GCP_CREDENTIALS HTTP_COOKIE JSON_WEB_TOKEN OAUTH_CLIENT_SECRET PASSWORD SECURITY_DATA SSL_CERTIFICATE STORAGE_SIGNED_POLICY_DOCUMENT STORAGE_SIGNED_URL TINK_KEYSET WEAK_PASSWORD_HASH XSRF_TOKEN Objects in images The following infoType detectors can detect objects in images. For more information, see Inspect an image for sensitive objects . OBJECT_TYPE/BARCODE OBJECT_TYPE/LICENSE_PLATE OBJECT_TYPE/PERSON OBJECT_TYPE/WHITEBOARD Send feedback Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Last updated 2025-09-04 UTC. Need to tell us more? [[[\"Easy to understand\",\"easyToUnderstand\",\"thumb-up\"],[\"Solved my problem\",\"solvedMyProblem\",\"thumb-up\"],[\"Other\",\"otherUp\",\"thumb-up\"]],[[\"Hard to understand\",\"hardToUnderstand\",\"thumb-down\"],[\"Incorrect information or sample code\",\"incorrectInformationOrSampleCode\",\"thumb-down\"],[\"Missing the information/samples I need\",\"missingTheInformationSamplesINeed\",\"thumb-down\"],[\"Other\",\"otherDown\",\"thumb-down\"]],[\"Last updated 2025-09-04 UTC.\"],[],[],null,[\"# InfoType detector reference\\n\\nSensitive Data Protection uses *information types* ---or *infoTypes*---to define\\nwhat it scans for. An infoType is a type of sensitive data, such as a name,\\nemail address, telephone number, identification number, or credit card number.\\n\\nEvery infoType defined in Sensitive Data Protection has a corresponding *detector*.\\nSensitive Data Protection uses infoType detectors in the configuration for its\\nscans to determine what to inspect for and how to transform findings. InfoType\\nnames are also used when displaying or reporting scan results.\\n\\nFor more in-depth information about infoType detectors, see [InfoTypes and\\ninfoType detectors](/sensitive-data-protection/docs/concepts-infotypes).\\n\\nThe Sensitive Data Protection team releases new infoType detectors and groups\\nperiodically. To get the latest list of built-in infoTypes, call the\\n[`infoTypes.list`](/sensitive-data-protection/docs/reference/rest/v2/infoTypes/list)\\nmethod of Sensitive Data Protection.\\n| **Important:** Built-in infoType detectors are not a perfectly accurate detection method. For example, they can't guarantee compliance with regulatory requirements. You must decide what data is sensitive and how to best protect it. Google recommends that you test your settings to make sure that your configuration meets your requirements.\\n\\nInfoType descriptions\\n---------------------\\n\\nInfoType categories\\n-------------------\\n\\nThe following table shows the categories of each infoType. **Location**\\nspecifies the geographic location that the infoType is typically associated\\nwith. **Availability** indicates the regions or multi-regions where the infoType\\nis supported. The value `ANY_LOCATION` means that the infoType is available in\\nall regions. \\nSelect a location GLOBAL ARGENTINA ARMENIA AUSTRALIA AUSTRIA AZERBAIJAN BELARUS BELGIUM BRAZIL CANADA CHILE CHINA COLOMBIA CROATIA CZECHIA DENMARK FRANCE FINLAND GERMANY HONG_KONG INDIA INDONESIA IRELAND ISRAEL ITALY JAPAN KAZAKHSTAN KOREA MEXICO THE_NETHERLANDS NEW_ZEALAND NORWAY PARAGUAY PERU POLAND PORTUGAL RUSSIA SINGAPORE SOUTH_AFRICA SPAIN SWEDEN SWITZERLAND TAIWAN THAILAND TURKEY UKRAINE UNITED_KINGDOM UNITED_STATES URUGUAY UZBEKISTAN VENEZUELA Finance Health Communications PII SPII Demographic Credential Government ID Document Contextual information Custom Any Regional Clear all \\n\\nSensitivity scores\\n------------------\\n\\nThe following table shows the default sensitivity score of each infoType. For\\ninformation about how to customize default sensitivity values, see [Edit the\\nsettings of a built-in\\ninfoType](/sensitive-data-protection/docs/manage-infotypes-console#edit-builtin-infotypes). \\n\\nGeneral infotypes\\n-----------------\\n\\n\\n| **Preview**\\n|\\n|\\n| This feature is subject to the \\\"Pre-GA Offerings Terms\\\" in the General Service Terms section\\n| of the [Service Specific Terms](/terms/service-terms#1).\\n|\\n| Pre-GA features are available \\\"as is\\\" and might have limited support.\\n|\\n| For more information, see the\\n| [launch stage descriptions](/products#product-launch-stages).\\n\\n\\u003cbr /\\u003e\\n\\nThe following table lists the available general infoTypes and the specific\\ninfoTypes that they detect. For more information, see [General and specific\\ninfotype\\ndetectors](/sensitive-data-protection/docs/concepts-infotypes#general-specific-infotypes). \\n\\nDocuments\\n---------\\n\\nIn addition to its ability to scan and classify information contained within\\ndocuments, Sensitive Data Protection can classify documents into multiple\\nenterprise-specific categories. When combined with personally identifiable\\ninformation (PII) inspection scan results, this classification can be useful\\nfor document risk assessment, policy enforcement, and similar use cases.\\n- `DOCUMENT_TYPE/FINANCE/REGULATORY`\\n- `DOCUMENT_TYPE/FINANCE/SEC_FILING`\\n- `DOCUMENT_TYPE/HR/RESUME`\\n- `DOCUMENT_TYPE/LEGAL/BLANK_FORM`\\n- `DOCUMENT_TYPE/LEGAL/BRIEF`\\n- `DOCUMENT_TYPE/LEGAL/COURT_ORDER`\\n- `DOCUMENT_TYPE/LEGAL/LAW`\\n- `DOCUMENT_TYPE/LEGAL/PLEADING`\\n- `DOCUMENT_TYPE/R&D/DATABASE_BACKUP`\\n- `DOCUMENT_TYPE/R&D/PATENT`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/C`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/CPP`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/CS`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/GO`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/HTML`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVA`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/JAVASCRIPT`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/JSON`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/PHP`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/POWERSHELL`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/PYTHON`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/RUST`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/SHELL`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/SQL`\\n- `DOCUMENT_TYPE/R&D/SOURCE_CODE/TYPESCRIPT`\\n- `DOCUMENT_TYPE/R&D/SYSTEM_LOG`\\n\\nSecrets\\n-------\\n\\n- The following infoType detectors detect credentials and other secret data.\\n- `AUTH_TOKEN`\\n- `AWS_CREDENTIALS`\\n- `AZURE_AUTH_TOKEN`\\n- `BASIC_AUTH_HEADER`\\n- `ENCRYPTION_KEY`\\n- `GCP_API_KEY`\\n- `GCP_CREDENTIALS`\\n- `HTTP_COOKIE`\\n- `JSON_WEB_TOKEN`\\n- `OAUTH_CLIENT_SECRET`\\n- `PASSWORD`\\n- `SECURITY_DATA`\\n- `SSL_CERTIFICATE`\\n- `STORAGE_SIGNED_POLICY_DOCUMENT`\\n- `STORAGE_SIGNED_URL`\\n- `TINK_KEYSET`\\n- `WEAK_PASSWORD_HASH`\\n- `XSRF_TOKEN`\\n\\nObjects in images\\n-----------------\\n\\n- The following infoType detectors can detect objects in images. For more information, see [Inspect an image for sensitive objects](/sensitive-data-protection/docs/inspecting-images#inspect_an_image_for_sensitive_objects).\\n- `OBJECT_TYPE/BARCODE`\\n- `OBJECT_TYPE/LICENSE_PLATE`\\n- `OBJECT_TYPE/PERSON`\\n- `OBJECT_TYPE/WHITEBOARD`\"]] Why Google Choosing Google Cloud Trust and security Modern Infrastructure Cloud Multicloud Global infrastructure Customers and case studies Analyst reports Whitepapers Products and pricing See all products See all solutions Google Cloud for Startups Google Cloud Marketplace Google Cloud pricing Contact sales Support Community forums Support Release Notes System status Resources GitHub Getting Started with Google Cloud Google Cloud documentation Code samples Cloud Architecture Center Training and Certification Developer Center Engage Blog Events X (Twitter) Google Cloud on YouTube Google Cloud Tech on YouTube Become a Partner Google Cloud Affiliate Program Press Corner About Google Privacy Site terms Google Cloud terms Manage cookies Our third decade of climate action: join us Sign up for the Google Cloud newsletter Subscribe English Deutsch Español – América Latina Français Indonesia Italiano Português – Brasil 中文 – 简体 中文 – 繁體 日本語 한국어 ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://cloud.google.com/tpu/docs/intro-to-tpu",
      "full_text": " Introduction to Cloud TPU &nbsp;|&nbsp; Google Cloud Skip to main content Documentation Technology areas close AI and ML Application development Application hosting Compute Data analytics and pipelines Databases Distributed, hybrid, and multicloud Generative AI Industry solutions Networking Observability and monitoring Security Storage Cross-product tools close Access and resources management Costs and usage management Google Cloud SDK, languages, frameworks, and tools Infrastructure as code Migration Related sites close Google Cloud Home Free Trial and Free Tier Architecture Center Blog Contact Sales Google Cloud Developer Center Google Developer Center Google Cloud Marketplace Google Cloud Marketplace Documentation Google Cloud Skills Boost Google Cloud Solution Center Google Cloud Support Google Cloud Tech Youtube Channel / English Deutsch Español – América Latina Français Indonesia Italiano Português – Brasil 中文 – 简体 中文 – 繁體 日本語 한국어 Console Sign in Cloud TPU Guides Reference Support Resources Contact Us Start free Documentation Guides Reference Support Resources Technology areas More Cross-product tools More Related sites More Console Contact Us Start free Discover Introduction to Cloud TPU TPU architecture TPU software versions TPU versions TPU v6e TPU v5p TPU v5e TPU v4 TPU v3 TPU v2 Regions and zones TPU consumption options Get started All getting started guides Set up the Cloud TPU environment Reserve TPUs About TPU reservations Request a reservation for up to 90 days (in calendar mode) Request a future reservation for one year or longer Share a reservation Consume a reservation Run JAX on Cloud TPU VM Run PyTorch on Cloud TPU VM Train on Cloud TPU slices Run JAX on Cloud TPU slices Run PyTorch on Cloud TPU slices Configure TPUs Connect a TPU to a shared VPC network Connect to a TPU VM without a public IP address Configure networking and access Use a cross-project service account Storage options Storage options for Cloud TPU Attach durable block storage to a TPU VM Connect to Cloud Storage buckets Mount a Filestore instance on a TPU VM Training and inference Trillium (v6e) introduction Train a model using v5e TPU inference Multislice training Scale ML workloads using Ray Run TPU applications in a Docker container About TPUs in GKE Work with image datasets Convert an image classification dataset for use with Cloud TPU Download, pre-process and upload the ImageNet dataset Download, pre-process and upload the COCO dataset Manage TPUs Manage TPU resources Manage queued resources Request TPUs using Flex-start Manage TPU Spot VMs Prepare for maintenance events Schedule TPU collections for inference workloads Autocheckpoint View maintenance notifications Manually start host maintenance Preemptible TPUs Optimize performance Cloud TPU performance guide Improve your model&#39;s performance with bfloat16 Monitor and troubleshoot TPUs Troubleshoot TPU VMs Monitor TPU VMs Dashboards for monitoring and logging TPU monitoring Library Troubleshoot TensorFlow models Troubleshoot PyTorch models Troubleshoot JAX models Cloud TPU error glossary Cloud TPU audit logs Profile TPUs Profile TPU VMs Profile Multislice environments Profile PyTorch XLA workloads Tutorials All tutorials ResNet Serve generative AI models JetStream MaxText inference on v6e JetStream PyTorch inference on v6e MaxDiffusion inference on v6e vLLM inference on v6e Serve an LLM with vLLM (GKE) Notebooks Notebooks AI and ML Application development Application hosting Compute Data analytics and pipelines Databases Distributed, hybrid, and multicloud Generative AI Industry solutions Networking Observability and monitoring Security Storage Access and resources management Costs and usage management Google Cloud SDK, languages, frameworks, and tools Infrastructure as code Migration Google Cloud Home Free Trial and Free Tier Architecture Center Blog Contact Sales Google Cloud Developer Center Google Developer Center Google Cloud Marketplace Google Cloud Marketplace Documentation Google Cloud Skills Boost Google Cloud Solution Center Google Cloud Support Google Cloud Tech Youtube Channel Home Cloud TPU Documentation Guides Send feedback Stay organized with collections Save and categorize content based on your preferences. Introduction to Cloud TPU Tensor Processing Units (TPUs) are Google&#39;s custom-developed, application-specific integrated circuits (ASICs) used to accelerate machine learning workloads. For more information about TPU hardware, see TPU architecture . Cloud TPU is a web service that makes TPUs available as scalable computing resources on Google Cloud. TPUs train your models more efficiently using hardware designed for performing large matrix operations often found in machine learning algorithms. TPUs have on-chip high-bandwidth memory (HBM) letting you use larger models and batch sizes. TPUs can be connected in groups called slices that scale up your workloads with little to no code changes. Code that runs on TPUs must be compiled by the accelerator linear algebra (XLA) compiler. XLA is a just-in-time compiler that takes the graph emitted by an ML framework application and compiles the linear algebra, loss, and gradient components of the graph into TPU machine code. The rest of the program runs on the TPU host machine. The XLA compiler is part of the TPU VM image that runs on a TPU host machine. For more information about Tensor Processing Units, see How to think about TPUs . When to use TPUs Cloud TPUs are optimized for specific workloads. In some situations, you might want to use GPUs or CPUs on Compute Engine instances to run your machine learning workloads. In general, you can decide what hardware is best for your workload based on the guidelines that follow. CPUs Quick prototyping that requires maximum flexibility Simple models that don&#39;t take long to train Small models with small, effective batch sizes Models that contain many custom TensorFlow operations written in C++ Models that are limited by available I/O or the networking bandwidth of the host system GPUs Models with a significant number of custom PyTorch/JAX operations that must run at least partially on CPUs Models with TensorFlow ops that are not available on Cloud TPU (see the list of available TensorFlow ops ) Medium-to-large models with larger effective batch sizes TPUs Models dominated by matrix computations Models with no custom PyTorch/JAX operations inside the main training loop Models that train for weeks or months Large models with large effective batch sizes Models with ultra-large embeddings common in advanced ranking and recommendation workloads Cloud TPUs are not suited to the following workloads: Linear algebra programs that require frequent branching or contain many element-wise algebra operations Workloads that require high-precision arithmetic Neural network workloads that contain custom operations in the main training loop TPUs in Google Cloud You can use TPUs through Cloud TPU VMs, Google Kubernetes Engine, and Vertex AI. The following table lists resources for each Google Cloud service. Google Cloud service Resources Cloud TPU Get started with Cloud TPU VMs Google Kubernetes Engine About TPUs in GKE Run Ray on GKE with TPUs Vertex AI Training on Vertex AI with TPUs Use TPUs for online prediction on Vertex AI Best practices for model development A program whose computation is dominated by non-matrix operations such as add, reshape, or concatenate, will likely not achieve high MXU utilization. The following are some guidelines to help you choose and build models that are suitable for Cloud TPU. Layout The XLA compiler performs code transformations, including tiling a matrix multiply into smaller blocks, to efficiently execute computations on the matrix unit (MXU). The structure of the MXU hardware, a 128x128 systolic array , and the design of TPUs memory subsystem, which prefers dimensions that are multiples of 8, are used by the XLA compiler for tiling efficiency. Consequently, certain layouts are more conducive to tiling, while others require reshapes to be performed before they can be tiled. Reshape operations are often memory bound on the Cloud TPU. Shapes The XLA compiler compiles an ML graph just in time for the first batch. If any subsequent batches have different shapes, the model doesn&#39;t work. (Re-compiling the graph every time the shape changes is too slow.) Therefore, any model that has tensors with dynamic shapes isn&#39;t well suited to TPUs. Padding A high performing Cloud TPU program is one where the dense compute can be tiled into 128x128 chunks. When a matrix computation cannot occupy an entire MXU, the compiler pads tensors with zeros. There are two drawbacks to padding: Tensors padded with zeros underutilize the TPU core. Padding increases the amount of on-chip memory storage required for a tensor and can lead to an out-of-memory error in the extreme case. While padding is automatically performed by the XLA compiler when necessary, one can determine the amount of padding performed by means of the op_profile tool. You can avoid padding by picking tensor dimensions that are well suited to TPUs. Dimensions Choosing suitable tensor dimensions goes a long way in extracting maximum performance from the TPU hardware, particularly the MXU. The XLA compiler attempts to use either the batch size or a feature dimension to maximally use the MXU. Therefore, one of these must be a multiple of 128. Otherwise, the compiler will pad one of them to 128. Ideally, batch size and feature dimensions should be multiples of 8, which enables extracting high performance from the memory subsystem. Getting started with Cloud TPU Set up a Google Cloud account Activate the Cloud TPU API Grant Cloud TPU access to your Cloud Storage buckets Run a basic calculation on a TPU Train a reference model on a TPU Analyze your model Requesting help To get help, contact Cloud TPU support . If you have an active Google Cloud project, be prepared to provide the following information: Your Google Cloud project ID Your TPU name, if one exists Other information you want to provide What's next? Looking to learn more about Cloud TPU? The following resources may help: Cloud TPU architecture Cloud TPU pricing Contact sales Send feedback Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Last updated 2025-09-04 UTC. Need to tell us more? [[[\"Easy to understand\",\"easyToUnderstand\",\"thumb-up\"],[\"Solved my problem\",\"solvedMyProblem\",\"thumb-up\"],[\"Other\",\"otherUp\",\"thumb-up\"]],[[\"Hard to understand\",\"hardToUnderstand\",\"thumb-down\"],[\"Incorrect information or sample code\",\"incorrectInformationOrSampleCode\",\"thumb-down\"],[\"Missing the information/samples I need\",\"missingTheInformationSamplesINeed\",\"thumb-down\"],[\"Other\",\"otherDown\",\"thumb-down\"]],[\"Last updated 2025-09-04 UTC.\"],[],[],null,[\"# Introduction to Cloud TPU\\n=========================\\n\\n\\u003cbr /\\u003e\\n\\nTensor Processing Units (TPUs) are Google's custom-developed,\\napplication-specific integrated circuits (ASICs) used to accelerate machine\\nlearning workloads. For more information about TPU hardware, see [TPU architecture](/tpu/docs/system-architecture-tpu-vm).\\nCloud TPU is a web service that makes TPUs available as scalable computing\\nresources on Google Cloud.\\n\\nTPUs train your models more efficiently using hardware designed for performing\\nlarge matrix operations often found in machine learning algorithms. TPUs have\\non-chip high-bandwidth memory (HBM) letting you use larger models and batch\\nsizes. TPUs can be connected in groups called slices that scale up your\\nworkloads with little to no code changes.\\n\\nCode that runs on TPUs must be compiled by the accelerator linear algebra (XLA)\\ncompiler. [XLA](https://www.tensorflow.org/performance/xla/) is a just-in-time\\ncompiler that takes the graph emitted by an ML framework application and\\ncompiles the linear algebra, loss, and gradient components of the graph into\\nTPU machine code. The rest of the program runs on the TPU host machine. The XLA\\ncompiler is part of the TPU VM image that runs on a TPU host machine.\\n\\nFor more information about Tensor Processing Units, see\\n[How to think about TPUs](https://jax-ml.github.io/scaling-book/tpus/).\\n\\nWhen to use TPUs\\n----------------\\n\\nCloud TPUs are optimized for specific workloads. In some situations, you might\\nwant to use GPUs or CPUs on Compute Engine instances to run your\\nmachine learning workloads. In general, you can decide what hardware is best for\\nyour workload based on the guidelines that follow.\\n\\n### CPUs\\n\\n- Quick prototyping that requires maximum flexibility\\n- Simple models that don't take long to train\\n- Small models with small, effective batch sizes\\n- Models that contain many [custom TensorFlow operations written in C++](https://www.tensorflow.org/guide/create_op)\\n- Models that are limited by available I/O or the networking bandwidth of the host system\\n\\n### GPUs\\n\\n- Models with a significant number of custom PyTorch/JAX operations that must run at least partially on CPUs\\n- Models with TensorFlow ops that are not available on Cloud TPU (see the list of [available TensorFlow ops](/tpu/docs/tensorflow-ops))\\n- Medium-to-large models with larger effective batch sizes\\n\\n### TPUs\\n\\n- Models dominated by matrix computations\\n- Models with no custom PyTorch/JAX operations inside the main training loop\\n- Models that train for weeks or months\\n- Large models with large effective batch sizes\\n- Models with ultra-large embeddings common in advanced ranking and recommendation workloads\\n\\nCloud TPUs are *not* suited to the following workloads:\\n\\n- Linear algebra programs that require frequent branching or contain many element-wise algebra operations\\n- Workloads that require high-precision arithmetic\\n- Neural network workloads that contain custom operations in the main training loop\\n\\nTPUs in Google Cloud\\n--------------------\\n\\nYou can use TPUs through Cloud TPU VMs, Google Kubernetes Engine, and\\nVertex AI. The following table lists resources for each Google Cloud\\nservice.\\n\\nBest practices for model development\\n------------------------------------\\n\\nA program whose computation is dominated by non-matrix operations such as add,\\nreshape, or concatenate, will likely not achieve high MXU utilization. The\\nfollowing are some guidelines to help you choose and build models that are\\nsuitable for Cloud TPU.\\n\\n### Layout\\n\\nThe XLA compiler performs code transformations, including tiling a matrix\\nmultiply into smaller blocks, to efficiently execute computations on the\\nmatrix unit (MXU). The structure of the MXU hardware, a 128x128 [systolic array](https://en.wikipedia.org/wiki/Systolic_array),\\nand the design of TPUs memory subsystem, which prefers dimensions that are\\nmultiples of 8, are used by the XLA compiler for tiling efficiency.\\n\\nConsequently, certain layouts are more conducive to tiling, while others require\\n*reshapes* to be performed before they can be tiled. Reshape operations are\\noften memory bound on the Cloud TPU.\\n\\n### Shapes\\n\\nThe XLA compiler compiles an ML graph just in time for the first batch. If any\\nsubsequent batches have different shapes, the model doesn't work. (Re-compiling\\nthe graph every time the shape changes is too slow.) Therefore, any model that\\nhas tensors with dynamic shapes isn't well suited to TPUs.\\n\\n### Padding\\n\\nA high performing Cloud TPU program is one where the dense compute\\ncan be tiled into 128x128 chunks. When a matrix computation cannot occupy\\nan entire MXU, the compiler pads tensors with zeros. There are two drawbacks\\nto padding:\\n\\n- Tensors padded with zeros underutilize the TPU core.\\n- Padding increases the amount of on-chip memory storage required for a tensor and can lead to an out-of-memory error in the extreme case.\\n\\nWhile padding is automatically performed by the XLA compiler when necessary, one\\ncan determine the amount of padding performed by means of the\\n[op_profile](/tpu/docs/cloud-tpu-tools#interpreting_the_results_1) tool. You can\\navoid padding by picking tensor dimensions that are well suited to TPUs.\\n\\n### Dimensions\\n\\nChoosing suitable tensor dimensions goes a long way in extracting maximum\\nperformance from the TPU hardware, particularly the MXU. The XLA compiler\\nattempts to use either the batch size or a feature dimension to maximally\\nuse the MXU. Therefore, one of these must be a multiple of 128. Otherwise,\\nthe compiler will pad one of them to 128. Ideally, batch size and feature\\ndimensions should be multiples of 8, which enables extracting high performance\\nfrom the memory subsystem.\\n\\nGetting started with Cloud TPU\\n------------------------------\\n\\n1. [Set up a Google Cloud account](/tpu/docs/setup-gcp-account)\\n2. [Activate the Cloud TPU API](/tpu/docs/activate-apis)\\n3. [Grant Cloud TPU access to your Cloud Storage buckets](/tpu/docs/storage-buckets)\\n4. [Run a basic calculation on a TPU](/tpu/docs/quick-starts)\\n5. [Train a reference model on a TPU](/tpu/docs/tutorials)\\n6. [Analyze your model](/tpu/docs/cloud-tpu-tools)\\n\\nRequesting help\\n---------------\\n\\nTo get help, contact [Cloud TPU support](/tpu/docs/getting-support).\\nIf you have an active Google Cloud project, be prepared to provide the\\nfollowing information:\\n\\n- Your Google Cloud project ID\\n- Your TPU name, if one exists\\n- Other information you want to provide\\n\\nWhat's next?\\n------------\\n\\nLooking to learn more about Cloud TPU? The following resources may help:\\n\\n- [Cloud TPU architecture](/tpu/docs/system-architecture-tpu-vm)\\n- [Cloud TPU pricing](/tpu/docs/pricing)\\n- [Contact sales](/contact)\"]] Why Google Choosing Google Cloud Trust and security Modern Infrastructure Cloud Multicloud Global infrastructure Customers and case studies Analyst reports Whitepapers Products and pricing See all products See all solutions Google Cloud for Startups Google Cloud Marketplace Google Cloud pricing Contact sales Support Community forums Support Release Notes System status Resources GitHub Getting Started with Google Cloud Google Cloud documentation Code samples Cloud Architecture Center Training and Certification Developer Center Engage Blog Events X (Twitter) Google Cloud on YouTube Google Cloud Tech on YouTube Become a Partner Google Cloud Affiliate Program Press Corner About Google Privacy Site terms Google Cloud terms Manage cookies Our third decade of climate action: join us Sign up for the Google Cloud newsletter Subscribe English Deutsch Español – América Latina Français Indonesia Italiano Português – Brasil 中文 – 简体 中文 – 繁體 日本語 한국어 ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/",
      "full_text": " Introducing Pathways: A next-generation AI architecture Skip to main content The Keyword Introducing Pathways: A next-generation AI architecture Share Twitter Facebook LinkedIn Mail Copy link Home Product news Product news Android, Chrome &amp; Play Android Chrome Chromebooks Google Play Wear OS See all Platforms &amp; Devices Fitbit Google Nest Pixel See all Explore &amp; Get Answers Gemini Maps News Search Shopping See all Connect &amp; Communicate Classroom Photos Registry Translate In the Cloud Google Workspace More on the Cloud Blog Google Cloud See all See all product updates Android, Chrome &amp; Play Android Chrome Chromebooks Google Play Wear OS See all Platforms &amp; Devices Fitbit Google Nest Pixel See all Explore &amp; Get Answers Gemini Maps News Search Shopping See all Connect &amp; Communicate Classroom Photos Registry Translate In the Cloud Google Workspace More on the Cloud Blog Google Cloud See all See all product updates Company news Company news Outreach &amp; initiatives Arts &amp; Culture Education Entrepreneurs Public Policy Sustainability See all Technology AI Developers Health Google DeepMind Google Labs Safety and security See all Inside Google Data centers and infrastructure Doodles Googlers Life at Google See all Around the globe Google in Asia Google in Europe Google in Latin America See all Authors Sundar Pichai, CEO Demis Hassabis, CEO and Co-Founder, Google DeepMind Kent Walker, SVP James Manyika, SVP Ruth Porat, President &amp; Chief Investment Officer See all Outreach &amp; initiatives Arts &amp; Culture Education Entrepreneurs Public Policy Sustainability See all Technology AI Developers Health Google DeepMind Google Labs Safety and security See all Inside Google Data centers and infrastructure Doodles Googlers Life at Google See all Around the globe Google in Asia Google in Europe Google in Latin America See all Authors Sundar Pichai, CEO Demis Hassabis, CEO and Co-Founder, Google DeepMind Kent Walker, SVP James Manyika, SVP Ruth Porat, President &amp; Chief Investment Officer See all Feed Subscribe Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) Nederlands (Nederland) Polska (Polski) Portugal (Português) Italia (Italiano) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文) MENA (English) Subscribe The Keyword Home Product news Product news Android, Chrome &amp; Play Android Chrome Chromebooks Google Play Wear OS See all Platforms &amp; Devices Fitbit Google Nest Pixel See all Explore &amp; Get Answers Gemini Maps News Search Shopping See all Connect &amp; Communicate Classroom Photos Registry Translate In the Cloud Google Workspace More on the Cloud Blog Google Cloud See all See all product updates Company news Company news Outreach &amp; initiatives Arts &amp; Culture Education Entrepreneurs Public Policy Sustainability See all Technology AI Developers Health Google DeepMind Google Labs Safety and security See all Inside Google Data centers and infrastructure Doodles Googlers Life at Google See all Around the globe Google in Asia Google in Europe Google in Latin America See all Authors Sundar Pichai, CEO Demis Hassabis, CEO and Co-Founder, Google DeepMind Kent Walker, SVP James Manyika, SVP Ruth Porat, President &amp; Chief Investment Officer See all Feed Press corner RSS feed Subscribe Breadcrumb Technology AI Introducing Pathways: A next-generation AI architecture Oct 28, 2021 · Share Twitter Facebook LinkedIn Mail Copy link Too often, machine learning systems overspecialize at individual tasks, when they could excel at many. That’s why we’re building Pathways—a new AI architecture that will handle many tasks at once, learn new tasks quickly and reflect a better understanding of the world. Jeff Dean Google Senior Fellow and SVP, Google Research Share Twitter Facebook LinkedIn Mail Copy link When I reflect on the past two decades of computer science research, few things inspire me more than the remarkable progress we’ve seen in the field of artificial intelligence. In 2001, some colleagues sitting just a few feet away from me at Google realized they could use an obscure technique called machine learning to help correct misspelled Search queries. (I remember I was amazed to see it work on everything from “ayambic pitnamiter” to “unnblevaiabel”). Today, AI augments many of the things that we do, whether that’s helping you capture a nice selfie , or providing more useful search results , or warning hundreds of millions of people when and where flooding will occur . Twenty years of advances in research have helped elevate AI from a promising idea to an indispensable aid in billions of people’s daily lives. And for all that progress, I’m still excited about its as-yet-untapped potential – AI is poised to help humanity confront some of the toughest challenges we’ve ever faced, from persistent problems like illness and inequality to emerging threats like climate change. But matching the depth and complexity of those urgent challenges will require new, more capable AI systems – systems that can combine AI’s proven approaches with nascent research directions to be able to solve problems we are unable to solve today. To that end, teams across Google Research are working on elements of a next-generation AI architecture we think will help realize such systems. We call this new AI architecture Pathways. Pathways is a new way of thinking about AI that addresses many of the weaknesses of existing systems and synthesizes their strengths. To show you what I mean, let’s walk through some of AI’s current shortcomings and how Pathways can improve upon them. Today&#x27;s AI models are typically trained to do only one thing. Pathways will enable us to train a single model to do thousands or millions of things. Today’s AI systems are often trained from scratch for each new problem – the mathematical model’s parameters are initiated literally with random numbers. Imagine if, every time you learned a new skill (jumping rope, for example), you forgot everything you’d learned – how to balance, how to leap, how to coordinate the movement of your hands – and started learning each new skill from nothing. That’s more or less how we train most machine learning models today. Rather than extending existing models to learn new tasks, we train each new model from nothing to do one thing and one thing only (or we sometimes specialize a general model to a specific task). The result is that we end up developing thousands of models for thousands of individual tasks. Not only does learning each new task take longer this way, but it also requires much more data to learn each new task, since we’re trying to learn everything about the world and the specifics of that task from nothing (completely unlike how people approach new tasks). Instead, we’d like to train one model that can not only handle many separate tasks, but also draw upon and combine its existing skills to learn new tasks faster and more effectively. That way what a model learns by training on one task – say, learning how aerial images can predict the elevation of a landscape – could help it learn another task -- say, predicting how flood waters will flow through that terrain. We want a model to have different capabilities that can be called upon as needed, and stitched together to perform new, more complex tasks – a bit closer to the way the mammalian brain generalizes across tasks. Today&#x27;s models mostly focus on one sense. Pathways will enable multiple senses. People rely on multiple senses to perceive the world. That’s very different from how contemporary AI systems digest information. Most of today’s models process just one modality of information at a time. They can take in text, or images or speech — but typically not all three at once. Pathways could enable multimodal models that encompass vision, auditory, and language understanding simultaneously. So whether the model is processing the word “leopard,” the sound of someone saying “leopard,” or a video of a leopard running, the same response is activated internally: the concept of a leopard. The result is a model that’s more insightful and less prone to mistakes and biases. And of course an AI model needn’t be restricted to these familiar senses; Pathways could handle more abstract forms of data, helping find useful patterns that have eluded human scientists in complex systems such as climate dynamics. Today&#x27;s models are dense and inefficient. Pathways will make them sparse and efficient. A third problem is that most of today’s models are “dense,” which means the whole neural network activates to accomplish a task, regardless of whether it’s very simple or really complicated. This, too, is very unlike the way people approach problems. We have many different parts of our brain that are specialized for different tasks, yet we only call upon the relevant pieces for a given situation. There are close to a hundred billion neurons in your brain, but you rely on a small fraction of them to interpret this sentence. AI can work the same way. We can build a single model that is “sparsely” activated, which means only small pathways through the network are called into action as needed. In fact, the model dynamically learns which parts of the network are good at which tasks -- it learns how to route tasks through the most relevant parts of the model. A big benefit to this kind of architecture is that it not only has a larger capacity to learn a variety of tasks, but it’s also faster and much more energy efficient, because we don’t activate the entire network for every task. For example, GShard and Switch Transformer are two of the largest machine learning models we’ve ever created, but because both use sparse activation, they consume less than 1/10th the energy that you’d expect of similarly sized dense models — while being as accurate as dense models. So to recap: today’s machine learning models tend to overspecialize at individual tasks when they could excel at many. They rely on one form of input when they could synthesize several. And too often they resort to brute force when deftness and specialization of expertise would do. That’s why we’re building Pathways. Pathways will enable a single AI system to generalize across thousands or millions of tasks, to understand different types of data, and to do so with remarkable efficiency – advancing us from the era of single-purpose models that merely recognize patterns to one in which more general-purpose intelligent systems reflect a deeper understanding of our world and can adapt to new needs. That last point is crucial. We’re familiar with many of today’s biggest global challenges, and working on technologies to help address them . But we’re also sure there are major future challenges we haven’t yet anticipated, and many will demand urgent solutions. So, with great care, and always in line with our AI Principles, we’re crafting the kind of next-generation AI system that can quickly adapt to new needs and solve new problems all around the world as they arise, helping humanity make the most of the future ahead of us. POSTED IN: AI Related stories AI The latest Google AI literacy resources all in one place By Jennie Magiera Learning &amp; Education AI Quests: Bringing AI literacy to the classroom By Ronit Levavi Morad Sep 09, 2025 Google Labs 6 ways to use NotebookLM to master any subject By Marvin Paul & Dharti Dhami Sep 08, 2025 Search Google Doodles show how AI Mode can help you learn. Sep 08, 2025 Search How Simplify in the Google app makes complex text easier to understand By Ari Marini Sep 08, 2025 Search AI Mode is now available in five new languages around the world. By Hema Budaraju Sep 08, 2025 . Jump to position 1 Jump to position 2 Jump to position 3 Jump to position 4 Jump to position 5 Jump to position 6 Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks Follow Us Privacy Terms About Google Google Products About the Keyword Help Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) Nederlands (Nederland) Polska (Polski) Portugal (Português) Italia (Italiano) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文) MENA (English) ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2009.03300",
      "full_text": " [2009.03300] Measuring Massive Multitask Language Understanding Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2009.03300 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computers and Society arXiv:2009.03300 (cs) [Submitted on 7 Sep 2020 ( v1 ), last revised 12 Jan 2021 (this version, v3)] Title: Measuring Massive Multitask Language Understanding Authors: Dan Hendrycks , Collin Burns , Steven Basart , Andy Zou , Mantas Mazeika , Dawn Song , Jacob Steinhardt View a PDF of the paper titled Measuring Massive Multitask Language Understanding, by Dan Hendrycks and 6 other authors View PDF Abstract: We propose a new test to measure a text model&#39;s multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model&#39;s academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings. Comments: ICLR 2021; the test and code is available at this https URL Subjects: Computers and Society (cs.CY) ; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG) Cite as: arXiv:2009.03300 [cs.CY] &nbsp; (or arXiv:2009.03300v3 [cs.CY] for this version) &nbsp; https://doi.org/10.48550/arXiv.2009.03300 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Dan Hendrycks [ view email ] [v1] Mon, 7 Sep 2020 17:59:25 UTC (2,172 KB) [v2] Mon, 21 Sep 2020 05:06:57 UTC (2,402 KB) [v3] Tue, 12 Jan 2021 18:57:11 UTC (2,578 KB) Full-text links: Access Paper: View a PDF of the paper titled Measuring Massive Multitask Language Understanding, by Dan Hendrycks and 6 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CY &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2020-09 Change to browse by: cs cs.AI cs.CL cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar 4 blog links ( what is this? ) DBLP - CS Bibliography listing | bibtex Dan Hendrycks Collin Burns Steven Basart Mantas Mazeika Dawn Song &hellip; a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1905.07830",
      "full_text": " [1905.07830] HellaSwag: Can a Machine Really Finish Your Sentence? Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1905.07830 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1905.07830 (cs) [Submitted on 19 May 2019] Title: HellaSwag: Can a Machine Really Finish Your Sentence? Authors: Rowan Zellers , Ari Holtzman , Yonatan Bisk , Ali Farhadi , Yejin Choi View a PDF of the paper titled HellaSwag: Can a Machine Really Finish Your Sentence?, by Rowan Zellers and 4 other authors View PDF Abstract: Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as &#34;A woman sits at a piano,&#34; a machine must select the most likely followup: &#34;She sets her fingers on the keys.&#34; With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans (&gt;95% accuracy), state-of-the-art models struggle (&lt;48%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical &#39;Goldilocks&#39; zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges. Comments: ACL 2019. Project page at this https URL Subjects: Computation and Language (cs.CL) Cite as: arXiv:1905.07830 [cs.CL] &nbsp; (or arXiv:1905.07830v1 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1905.07830 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Rowan Zellers [ view email ] [v1] Sun, 19 May 2019 23:57:23 UTC (1,063 KB) Full-text links: Access Paper: View a PDF of the paper titled HellaSwag: Can a Machine Really Finish Your Sentence?, by Rowan Zellers and 4 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2019-05 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar 1 blog link ( what is this? ) DBLP - CS Bibliography listing | bibtex Rowan Zellers Ari Holtzman Yonatan Bisk Ali Farhadi Yejin Choi a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1911.11641",
      "full_text": " [1911.11641] PIQA: Reasoning about Physical Commonsense in Natural Language Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1911.11641 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1911.11641 (cs) [Submitted on 26 Nov 2019] Title: PIQA: Reasoning about Physical Commonsense in Natural Language Authors: Yonatan Bisk , Rowan Zellers , Ronan Le Bras , Jianfeng Gao , Yejin Choi View a PDF of the paper titled PIQA: Reasoning about Physical Commonsense in Natural Language, by Yonatan Bisk and 4 other authors View PDF Abstract: To apply eyeshadow without a brush, should I use a cotton swab or a toothpick? Questions requiring this kind of physical commonsense pose a challenge to today&#39;s natural language understanding systems. While recent pretrained models (such as BERT) have made progress on question answering over more abstract domains - such as news articles and encyclopedia entries, where text is plentiful - in more physical domains, text is inherently limited due to reporting bias. Can AI systems learn to reliably answer physical common-sense questions without experiencing the physical world? In this paper, we introduce the task of physical commonsense reasoning and a corresponding benchmark dataset Physical Interaction: Question Answering or PIQA. Though humans find the dataset easy (95% accuracy), large pretrained models struggle (77%). We provide analysis about the dimensions of knowledge that existing models lack, which offers significant opportunities for future research. Comments: AAAI 2020 Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG) Cite as: arXiv:1911.11641 [cs.CL] &nbsp; (or arXiv:1911.11641v1 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1911.11641 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Yonatan Bisk [ view email ] [v1] Tue, 26 Nov 2019 15:31:46 UTC (854 KB) Full-text links: Access Paper: View a PDF of the paper titled PIQA: Reasoning about Physical Commonsense in Natural Language, by Yonatan Bisk and 4 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2019-11 Change to browse by: cs cs.AI cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Yonatan Bisk Rowan Zellers Ronan Le Bras Jianfeng Gao Yejin Choi a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1904.09728",
      "full_text": " [1904.09728] SocialIQA: Commonsense Reasoning about Social Interactions Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1904.09728 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1904.09728 (cs) [Submitted on 22 Apr 2019 ( v1 ), last revised 9 Sep 2019 (this version, v3)] Title: SocialIQA: Commonsense Reasoning about Social Interactions Authors: Maarten Sap , Hannah Rashkin , Derek Chen , Ronan LeBras , Yejin Choi View a PDF of the paper titled SocialIQA: Commonsense Reasoning about Social Interactions, by Maarten Sap and 4 other authors View PDF Abstract: We introduce Social IQa, the first largescale benchmark for commonsense reasoning about social situations. Social IQa contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., Q: &#34;Jordan wanted to tell Tracy a secret, so Jordan leaned towards Tracy. Why did Jordan do this?&#34; A: &#34;Make sure no one else could hear&#34;). Through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. Empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance (&gt;20% gap). Notably, we further establish Social IQa as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (Winograd Schemas, COPA). Comments: the first two authors contributed equally; accepted to EMNLP 2019; camera ready version Subjects: Computation and Language (cs.CL) Cite as: arXiv:1904.09728 [cs.CL] &nbsp; (or arXiv:1904.09728v3 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1904.09728 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Maarten Sap [ view email ] [v1] Mon, 22 Apr 2019 05:36:37 UTC (313 KB) [v2] Sat, 17 Aug 2019 00:10:30 UTC (785 KB) [v3] Mon, 9 Sep 2019 17:29:55 UTC (358 KB) Full-text links: Access Paper: View a PDF of the paper titled SocialIQA: Commonsense Reasoning about Social Interactions, by Maarten Sap and 4 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2019-04 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Maarten Sap Hannah Rashkin Derek Chen Ronan LeBras Yejin Choi a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1905.10044",
      "full_text": " [1905.10044] BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1905.10044 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1905.10044 (cs) [Submitted on 24 May 2019] Title: BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions Authors: Christopher Clark , Kenton Lee , Ming-Wei Chang , Tom Kwiatkowski , Michael Collins , Kristina Toutanova View a PDF of the paper titled BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions, by Christopher Clark and 5 other authors View PDF Abstract: In this paper we study yes/no questions that are naturally occurring --- meaning that they are generated in unprompted and unconstrained settings. We build a reading comprehension dataset, BoolQ, of such questions, and show that they are unexpectedly challenging. They often query for complex, non-factoid information, and require difficult entailment-like inference to solve. We also explore the effectiveness of a range of transfer learning baselines. We find that transferring from entailment data is more effective than transferring from paraphrase or extractive QA data, and that it, surprisingly, continues to be very beneficial even when starting from massive pre-trained language models such as BERT. Our best method trains BERT on MultiNLI and then re-trains it on our train set. It achieves 80.4% accuracy compared to 90% accuracy of human annotators (and 62% majority-baseline), leaving a significant gap for future work. Comments: In NAACL 2019 Subjects: Computation and Language (cs.CL) Cite as: arXiv:1905.10044 [cs.CL] &nbsp; (or arXiv:1905.10044v1 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1905.10044 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Christopher Clark [ view email ] [v1] Fri, 24 May 2019 05:48:49 UTC (43 KB) Full-text links: Access Paper: View a PDF of the paper titled BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions, by Christopher Clark and 5 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2019-05 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar 1 blog link ( what is this? ) DBLP - CS Bibliography listing | bibtex Christopher Clark Kenton Lee Ming-Wei Chang Tom Kwiatkowski Michael Collins &hellip; export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1907.10641",
      "full_text": " [1907.10641] WinoGrande: An Adversarial Winograd Schema Challenge at Scale Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1907.10641 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1907.10641 (cs) [Submitted on 24 Jul 2019 ( v1 ), last revised 21 Nov 2019 (this version, v2)] Title: WinoGrande: An Adversarial Winograd Schema Challenge at Scale Authors: Keisuke Sakaguchi , Ronan Le Bras , Chandra Bhagavatula , Yejin Choi View a PDF of the paper titled WinoGrande: An Adversarial Winograd Schema Challenge at Scale, by Keisuke Sakaguchi and 3 other authors View PDF Abstract: The Winograd Schema Challenge (WSC) (Levesque, Davis, and Morgenstern 2011), a benchmark for commonsense reasoning, is a set of 273 expert-crafted pronoun resolution problems originally designed to be unsolvable for statistical models that rely on selectional preferences or word associations. However, recent advances in neural language models have already reached around 90% accuracy on variants of WSC. This raises an important question whether these models have truly acquired robust commonsense capabilities or whether they rely on spurious biases in the datasets that lead to an overestimation of the true capabilities of machine commonsense. To investigate this question, we introduce WinoGrande, a large-scale dataset of 44k problems, inspired by the original WSC design, but adjusted to improve both the scale and the hardness of the dataset. The key steps of the dataset construction consist of (1) a carefully designed crowdsourcing procedure, followed by (2) systematic bias reduction using a novel AfLite algorithm that generalizes human-detectable word associations to machine-detectable embedding associations. The best state-of-the-art methods on WinoGrande achieve 59.4-79.1%, which are 15-35% below human performance of 94.0%, depending on the amount of the training data allowed. Furthermore, we establish new state-of-the-art results on five related benchmarks - WSC (90.1%), DPR (93.1%), COPA (90.6%), KnowRef (85.6%), and Winogender (97.1%). These results have dual implications: on one hand, they demonstrate the effectiveness of WinoGrande when used as a resource for transfer learning. On the other hand, they raise a concern that we are likely to be overestimating the true capabilities of machine commonsense across all these benchmarks. We emphasize the importance of algorithmic bias reduction in existing and future benchmarks to mitigate such overestimation. Subjects: Computation and Language (cs.CL) Cite as: arXiv:1907.10641 [cs.CL] &nbsp; (or arXiv:1907.10641v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1907.10641 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Keisuke Sakaguchi [ view email ] [v1] Wed, 24 Jul 2019 18:11:59 UTC (2,699 KB) [v2] Thu, 21 Nov 2019 19:01:32 UTC (1,474 KB) Full-text links: Access Paper: View a PDF of the paper titled WinoGrande: An Adversarial Winograd Schema Challenge at Scale, by Keisuke Sakaguchi and 3 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2019-07 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar 1 blog link ( what is this? ) DBLP - CS Bibliography listing | bibtex Keisuke Sakaguchi Ronan Le Bras Chandra Bhagavatula Yejin Choi a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1811.00937",
      "full_text": " [1811.00937] CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1811.00937 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1811.00937 (cs) [Submitted on 2 Nov 2018 ( v1 ), last revised 15 Mar 2019 (this version, v2)] Title: CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge Authors: Alon Talmor , Jonathan Herzig , Nicholas Lourie , Jonathan Berant View a PDF of the paper titled CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge, by Alon Talmor and 3 other authors View PDF Abstract: When answering a question, people often draw upon their rich world knowledge in addition to the particular context. Recent work has focused primarily on answering questions given some relevant document or context, and required very little general background. To investigate question answering with prior knowledge, we present CommonsenseQA: a challenging new dataset for commonsense question answering. To capture common sense beyond associations, we extract from ConceptNet (Speer et al., 2017) multiple target concepts that have the same semantic relation to a single source concept. Crowd-workers are asked to author multiple-choice questions that mention the source concept and discriminate in turn between each of the target concepts. This encourages workers to create questions with complex semantics that often require prior knowledge. We create 12,247 questions through this procedure and demonstrate the difficulty of our task with a large number of strong baselines. Our best baseline is based on BERT-large (Devlin et al., 2018) and obtains 56% accuracy, well below human performance, which is 89%. Comments: accepted as a long paper at NAACL 2019 Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG) Cite as: arXiv:1811.00937 [cs.CL] &nbsp; (or arXiv:1811.00937v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1811.00937 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Alon Talmor [ view email ] [v1] Fri, 2 Nov 2018 15:34:29 UTC (1,346 KB) [v2] Fri, 15 Mar 2019 18:02:58 UTC (1,455 KB) Full-text links: Access Paper: View a PDF of the paper titled CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge, by Alon Talmor and 3 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2018-11 Change to browse by: cs cs.AI cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Alon Talmor Jonathan Herzig Nicholas Lourie Jonathan Berant export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1809.02789",
      "full_text": " [1809.02789] Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1809.02789 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1809.02789 (cs) [Submitted on 8 Sep 2018] Title: Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering Authors: Todor Mihaylov , Peter Clark , Tushar Khot , Ashish Sabharwal View a PDF of the paper titled Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering, by Todor Mihaylov and 3 other authors View PDF Abstract: We present a new kind of question answering dataset, OpenBookQA, modeled after open book exams for assessing human understanding of a subject. The open book that comes with our questions is a set of 1329 elementary level science facts. Roughly 6000 questions probe an understanding of these facts and their application to novel situations. This requires combining an open book fact (e.g., metals conduct electricity) with broad common knowledge (e.g., a suit of armor is made of metal) obtained from other sources. While existing QA datasets over documents or knowledge bases, being generally self-contained, focus on linguistic understanding, OpenBookQA probes a deeper understanding of both the topic---in the context of common knowledge---and the language it is expressed in. Human performance on OpenBookQA is close to 92%, but many state-of-the-art pre-trained QA methods perform surprisingly poorly, worse than several simple neural baselines we develop. Our oracle experiments designed to circumvent the knowledge retrieval bottleneck demonstrate the value of both the open book and additional facts. We leave it as a challenge to solve the retrieval problem in this multi-hop setting and to close the large gap to human performance. Comments: Published as conference long paper at EMNLP 2018 Subjects: Computation and Language (cs.CL) Cite as: arXiv:1809.02789 [cs.CL] &nbsp; (or arXiv:1809.02789v1 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1809.02789 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Todor Mihaylov [ view email ] [v1] Sat, 8 Sep 2018 11:47:16 UTC (162 KB) Full-text links: Access Paper: View a PDF of the paper titled Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering, by Todor Mihaylov and 3 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2018-09 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Todor Mihaylov Peter Clark Tushar Khot Ashish Sabharwal export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1911.01547",
      "full_text": " [1911.01547] On the Measure of Intelligence Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1911.01547 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Artificial Intelligence arXiv:1911.01547 (cs) [Submitted on 5 Nov 2019 ( v1 ), last revised 25 Nov 2019 (this version, v2)] Title: On the Measure of Intelligence Authors: François Chollet View a PDF of the paper titled On the Measure of Intelligence, by Fran\\c{c}ois Chollet View PDF Abstract: To make deliberate progress towards more intelligent and more human-like artificial systems, we need to be following an appropriate feedback signal: we need to be able to define and evaluate intelligence in a way that enables comparisons between two systems, as well as comparisons with humans. Over the past hundred years, there has been an abundance of attempts to define and measure intelligence, across both the fields of psychology and AI. We summarize and critically assess these definitions and evaluation approaches, while making apparent the two historical conceptions of intelligence that have implicitly guided them. We note that in practice, the contemporary AI community still gravitates towards benchmarking intelligence by comparing the skill exhibited by AIs and humans at specific tasks such as board games and video games. We argue that solely measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience: unlimited priors or unlimited training data allow experimenters to &#34;buy&#34; arbitrary levels of skills for a system, in a way that masks the system&#39;s own generalization power. We then articulate a new formal definition of intelligence based on Algorithmic Information Theory, describing intelligence as skill-acquisition efficiency and highlighting the concepts of scope, generalization difficulty, priors, and experience. Using this definition, we propose a set of guidelines for what a general AI benchmark should look like. Finally, we present a benchmark closely following these guidelines, the Abstraction and Reasoning Corpus (ARC), built upon an explicit set of priors designed to be as close as possible to innate human priors. We argue that ARC can be used to measure a human-like form of general fluid intelligence and that it enables fair general intelligence comparisons between AI systems and humans. Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:1911.01547 [cs.AI] &nbsp; (or arXiv:1911.01547v2 [cs.AI] for this version) &nbsp; https://doi.org/10.48550/arXiv.1911.01547 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Francois Chollet [ view email ] [v1] Tue, 5 Nov 2019 00:31:38 UTC (771 KB) [v2] Mon, 25 Nov 2019 13:02:04 UTC (770 KB) Full-text links: Access Paper: View a PDF of the paper titled On the Measure of Intelligence, by Fran\\c{c}ois Chollet View PDF TeX Source Other Formats view license Current browse context: cs.AI &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2019-11 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar 2 blog links ( what is this? ) DBLP - CS Bibliography listing | bibtex François Chollet a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1705.03551",
      "full_text": " [1705.03551] TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1705.03551 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1705.03551 (cs) [Submitted on 9 May 2017 ( v1 ), last revised 13 May 2017 (this version, v2)] Title: TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension Authors: Mandar Joshi , Eunsol Choi , Daniel S. Weld , Luke Zettlemoyer View a PDF of the paper titled TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension, by Mandar Joshi and 3 other authors View PDF Abstract: We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at -- this http URL Comments: Added references, fixed typos, minor baseline update Subjects: Computation and Language (cs.CL) Cite as: arXiv:1705.03551 [cs.CL] &nbsp; (or arXiv:1705.03551v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1705.03551 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Mandar Joshi [ view email ] [v1] Tue, 9 May 2017 21:35:07 UTC (1,148 KB) [v2] Sat, 13 May 2017 21:12:37 UTC (1,149 KB) Full-text links: Access Paper: View a PDF of the paper titled TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension, by Mandar Joshi and 3 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2017-05 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Mandar Joshi Eunsol Choi Daniel S. Weld Luke Zettlemoyer a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2107.03374",
      "full_text": " [2107.03374] Evaluating Large Language Models Trained on Code Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2107.03374 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Machine Learning arXiv:2107.03374 (cs) [Submitted on 7 Jul 2021 ( v1 ), last revised 14 Jul 2021 (this version, v2)] Title: Evaluating Large Language Models Trained on Code Authors: Mark Chen , Jerry Tworek , Heewoo Jun , Qiming Yuan , Henrique Ponde de Oliveira Pinto , Jared Kaplan , Harri Edwards , Yuri Burda , Nicholas Joseph , Greg Brockman , Alex Ray , Raul Puri , Gretchen Krueger , Michael Petrov , Heidy Khlaaf , Girish Sastry , Pamela Mishkin , Brooke Chan , Scott Gray , Nick Ryder , Mikhail Pavlov , Alethea Power , Lukasz Kaiser , Mohammad Bavarian , Clemens Winter , Philippe Tillet , Felipe Petroski Such , Dave Cummings , Matthias Plappert , Fotios Chantzis , Elizabeth Barnes , Ariel Herbert-Voss , William Hebgen Guss , Alex Nichol , Alex Paino , Nikolas Tezak , Jie Tang , Igor Babuschkin , Suchir Balaji , Shantanu Jain , William Saunders , Christopher Hesse , Andrew N. Carr , Jan Leike , Josh Achiam , Vedant Misra , Evan Morikawa , Alec Radford , Matthew Knight , Miles Brundage , Mira Murati , Katie Mayer , Peter Welinder , Bob McGrew , Dario Amodei , Sam McCandlish , Ilya Sutskever , Wojciech Zaremba View a PDF of the paper titled Evaluating Large Language Models Trained on Code, by Mark Chen and 57 other authors View PDF Abstract: We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics. Comments: corrected typos, added references, added authors, added acknowledgements Subjects: Machine Learning (cs.LG) Cite as: arXiv:2107.03374 [cs.LG] &nbsp; (or arXiv:2107.03374v2 [cs.LG] for this version) &nbsp; https://doi.org/10.48550/arXiv.2107.03374 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Mark Chen [ view email ] [v1] Wed, 7 Jul 2021 17:41:24 UTC (1,466 KB) [v2] Wed, 14 Jul 2021 17:16:02 UTC (1,467 KB) Full-text links: Access Paper: View a PDF of the paper titled Evaluating Large Language Models Trained on Code, by Mark Chen and 57 other authors View PDF TeX Source Other Formats view license Current browse context: cs.LG &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2021-07 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar 4 blog links ( what is this? ) DBLP - CS Bibliography listing | bibtex Heewoo Jun Jared Kaplan Harrison Edwards Yuri Burda Greg Brockman &hellip; export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2108.07732",
      "full_text": " [2108.07732] Program Synthesis with Large Language Models Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2108.07732 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Programming Languages arXiv:2108.07732 (cs) [Submitted on 16 Aug 2021] Title: Program Synthesis with Large Language Models Authors: Jacob Austin , Augustus Odena , Maxwell Nye , Maarten Bosma , Henryk Michalewski , David Dohan , Ellen Jiang , Carrie Cai , Michael Terry , Quoc Le , Charles Sutton View a PDF of the paper titled Program Synthesis with Large Language Models, by Jacob Austin and 10 other authors View PDF Abstract: This paper explores the limits of the current generation of large language models for program synthesis in general purpose programming languages. We evaluate a collection of such models (with between 244M and 137B parameters) on two new benchmarks, MBPP and MathQA-Python, in both the few-shot and fine-tuning regimes. Our benchmarks are designed to measure the ability of these models to synthesize short Python programs from natural language descriptions. The Mostly Basic Programming Problems (MBPP) dataset contains 974 programming tasks, designed to be solvable by entry-level programmers. The MathQA-Python dataset, a Python version of the MathQA benchmark, contains 23914 problems that evaluate the ability of the models to synthesize code from more complex text. On both datasets, we find that synthesis performance scales log-linearly with model size. Our largest models, even without finetuning on a code dataset, can synthesize solutions to 59.6 percent of the problems from MBPP using few-shot learning with a well-designed prompt. Fine-tuning on a held-out portion of the dataset improves performance by about 10 percentage points across most model sizes. On the MathQA-Python dataset, the largest fine-tuned model achieves 83.8 percent accuracy. Going further, we study the model&#39;s ability to engage in dialog about code, incorporating human feedback to improve its solutions. We find that natural language feedback from a human halves the error rate compared to the model&#39;s initial prediction. Additionally, we conduct an error analysis to shed light on where these models fall short and what types of programs are most difficult to generate. Finally, we explore the semantic grounding of these models by fine-tuning them to predict the results of program execution. We find that even our best models are generally unable to predict the output of a program given a specific input. Comments: Jacob and Augustus contributed equally Subjects: Programming Languages (cs.PL) ; Machine Learning (cs.LG) Cite as: arXiv:2108.07732 [cs.PL] &nbsp; (or arXiv:2108.07732v1 [cs.PL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2108.07732 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Augustus Odena [ view email ] [v1] Mon, 16 Aug 2021 03:57:30 UTC (2,247 KB) Full-text links: Access Paper: View a PDF of the paper titled Program Synthesis with Large Language Models, by Jacob Austin and 10 other authors View PDF TeX Source Other Formats view license Current browse context: cs.PL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2021-08 Change to browse by: cs cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar 1 blog link ( what is this? ) DBLP - CS Bibliography listing | bibtex Augustus Odena Maxwell Nye Henryk Michalewski David Dohan Carrie J. Cai &hellip; export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2110.14168",
      "full_text": " [2110.14168] Training Verifiers to Solve Math Word Problems Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2110.14168 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Machine Learning arXiv:2110.14168 (cs) [Submitted on 27 Oct 2021 ( v1 ), last revised 18 Nov 2021 (this version, v2)] Title: Training Verifiers to Solve Math Word Problems Authors: Karl Cobbe , Vineet Kosaraju , Mohammad Bavarian , Mark Chen , Heewoo Jun , Lukasz Kaiser , Matthias Plappert , Jerry Tworek , Jacob Hilton , Reiichiro Nakano , Christopher Hesse , John Schulman View a PDF of the paper titled Training Verifiers to Solve Math Word Problems, by Karl Cobbe and 11 other authors View PDF Abstract: State-of-the-art language models can match human performance on many tasks, but they still struggle to robustly perform multi-step mathematical reasoning. To diagnose the failures of current models and support research, we introduce GSM8K, a dataset of 8.5K high quality linguistically diverse grade school math word problems. We find that even the largest transformer models fail to achieve high test performance, despite the conceptual simplicity of this problem distribution. To increase performance, we propose training verifiers to judge the correctness of model completions. At test time, we generate many candidate solutions and select the one ranked highest by the verifier. We demonstrate that verification significantly improves performance on GSM8K, and we provide strong empirical evidence that verification scales more effectively with increased data than a finetuning baseline. Subjects: Machine Learning (cs.LG) ; Computation and Language (cs.CL) Cite as: arXiv:2110.14168 [cs.LG] &nbsp; (or arXiv:2110.14168v2 [cs.LG] for this version) &nbsp; https://doi.org/10.48550/arXiv.2110.14168 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Karl Cobbe [ view email ] [v1] Wed, 27 Oct 2021 04:49:45 UTC (3,262 KB) [v2] Thu, 18 Nov 2021 00:23:45 UTC (3,262 KB) Full-text links: Access Paper: View a PDF of the paper titled Training Verifiers to Solve Math Word Problems, by Karl Cobbe and 11 other authors View PDF TeX Source Other Formats view license Current browse context: cs.LG &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2021-10 Change to browse by: cs cs.CL References &amp; Citations NASA ADS Google Scholar Semantic Scholar 3 blog links ( what is this? ) DBLP - CS Bibliography listing | bibtex Karl Cobbe Vineet Kosaraju Mohammad Bavarian Reiichiro Nakano Christopher Hesse &hellip; a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2009.11462",
      "full_text": " [2009.11462] RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2009.11462 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2009.11462 (cs) [Submitted on 24 Sep 2020 ( v1 ), last revised 25 Sep 2020 (this version, v2)] Title: RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models Authors: Samuel Gehman , Suchin Gururangan , Maarten Sap , Yejin Choi , Noah A. Smith View a PDF of the paper titled RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models, by Samuel Gehman and 4 other authors View PDF Abstract: Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning &#34;bad&#34; words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining. Comments: Findings in EMNLP 2020 Subjects: Computation and Language (cs.CL) Cite as: arXiv:2009.11462 [cs.CL] &nbsp; (or arXiv:2009.11462v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2009.11462 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Suchin Gururangan [ view email ] [v1] Thu, 24 Sep 2020 03:17:19 UTC (1,761 KB) [v2] Fri, 25 Sep 2020 20:22:26 UTC (1,762 KB) Full-text links: Access Paper: View a PDF of the paper titled RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models, by Samuel Gehman and 4 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2020-09 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Suchin Gururangan Maarten Sap Yejin Choi Noah A. Smith a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2101.11718",
      "full_text": " [2101.11718] BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2101.11718 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2101.11718 (cs) [Submitted on 27 Jan 2021] Title: BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation Authors: Jwala Dhamala , Tony Sun , Varun Kumar , Satyapriya Krishna , Yada Pruksachatkun , Kai-Wei Chang , Rahul Gupta View a PDF of the paper titled BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation, by Jwala Dhamala and 6 other authors View PDF Abstract: Recent advances in deep learning techniques have enabled machines to generate cohesive open-ended text when prompted with a sequence of words as context. While these models now empower many downstream applications from conversation bots to automatic storytelling, they have been shown to generate texts that exhibit social biases. To systematically study and benchmark social biases in open-ended language generation, we introduce the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that consists of 23,679 English text generation prompts for bias benchmarking across five domains: profession, gender, race, religion, and political ideology. We also propose new automated metrics for toxicity, psycholinguistic norms, and text gender polarity to measure social biases in open-ended text generation from multiple angles. An examination of text generated from three popular language models reveals that the majority of these models exhibit a larger social bias than human-written Wikipedia text across all domains. With these results we highlight the need to benchmark biases in open-ended language generation and caution users of language generation models on downstream tasks to be cognizant of these embedded prejudices. Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG) Cite as: arXiv:2101.11718 [cs.CL] &nbsp; (or arXiv:2101.11718v1 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2101.11718 Focus to learn more arXiv-issued DOI via DataCite Related DOI : https://doi.org/10.1145/3442188.3445924 Focus to learn more DOI(s) linking to related resources Submission history From: Jwala Dhamala [ view email ] [v1] Wed, 27 Jan 2021 22:07:03 UTC (1,443 KB) Full-text links: Access Paper: View a PDF of the paper titled BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation, by Jwala Dhamala and 6 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2021-01 Change to browse by: cs cs.AI cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar 2 blog links ( what is this? ) DBLP - CS Bibliography listing | bibtex Jwala Dhamala Tony Sun Varun Kumar Yada Pruksachatkun Kai-Wei Chang &hellip; a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2110.08193v2",
      "full_text": " [2110.08193v2] BBQ: A Hand-Built Bias Benchmark for Question Answering Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2110.08193v2 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2110.08193v2 (cs) [Submitted on 15 Oct 2021 ( v1 ), last revised 16 Mar 2022 (this version, v2)] Title: BBQ: A Hand-Built Bias Benchmark for Question Answering Authors: Alicia Parrish , Angelica Chen , Nikita Nangia , Vishakh Padmakumar , Jason Phang , Jana Thompson , Phu Mon Htut , Samuel R. Bowman View a PDF of the paper titled BBQ: A Hand-Built Bias Benchmark for Question Answering, by Alicia Parrish and 7 other authors View PDF Abstract: It is well documented that NLP models learn social biases, but little work has been done on how these biases manifest in model outputs for applied tasks like question answering (QA). We introduce the Bias Benchmark for QA (BBQ), a dataset of question sets constructed by the authors that highlight attested social biases against people belonging to protected classes along nine social dimensions relevant for U.S. English-speaking contexts. Our task evaluates model responses at two levels: (i) given an under-informative context, we test how strongly responses reflect social biases, and (ii) given an adequately informative context, we test whether the model&#39;s biases override a correct answer choice. We find that models often rely on stereotypes when the context is under-informative, meaning the model&#39;s outputs consistently reproduce harmful biases in this setting. Though models are more accurate when the context provides an informative answer, they still rely on stereotypes and average up to 3.4 percentage points higher accuracy when the correct answer aligns with a social bias than when it conflicts, with this difference widening to over 5 points on examples targeting gender for most models tested. Comments: Accepted to ACL 2022 Findings. 20 pages, 10 figures Subjects: Computation and Language (cs.CL) Cite as: arXiv:2110.08193 [cs.CL] &nbsp; (or arXiv:2110.08193v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2110.08193 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Alicia Parrish [ view email ] [v1] Fri, 15 Oct 2021 16:43:46 UTC (1,587 KB) [v2] Wed, 16 Mar 2022 01:35:45 UTC (1,231 KB) Full-text links: Access Paper: View a PDF of the paper titled BBQ: A Hand-Built Bias Benchmark for Question Answering, by Alicia Parrish and 7 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2021-10 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar 1 blog link ( what is this? ) DBLP - CS Bibliography listing | bibtex Angelica Chen Nikita Nangia Jason Phang Phu Mon Htut Samuel R. Bowman a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1804.09301",
      "full_text": " [1804.09301] Gender Bias in Coreference Resolution Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1804.09301 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1804.09301 (cs) [Submitted on 25 Apr 2018] Title: Gender Bias in Coreference Resolution Authors: Rachel Rudinger , Jason Naradowsky , Brian Leonard , Benjamin Van Durme View a PDF of the paper titled Gender Bias in Coreference Resolution, by Rachel Rudinger and 3 other authors View PDF Abstract: We present an empirical study of gender bias in coreference resolution systems. We first introduce a novel, Winograd schema-style set of minimal pair sentences that differ only by pronoun gender. With these &#34;Winogender schemas,&#34; we evaluate and confirm systematic gender bias in three publicly-available coreference resolution systems, and correlate this bias with real-world and textual gender statistics. Comments: Accepted to NAACL-HLT 2018 Subjects: Computation and Language (cs.CL) Cite as: arXiv:1804.09301 [cs.CL] &nbsp; (or arXiv:1804.09301v1 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1804.09301 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Rachel Rudinger [ view email ] [v1] Wed, 25 Apr 2018 00:46:14 UTC (203 KB) Full-text links: Access Paper: View a PDF of the paper titled Gender Bias in Coreference Resolution, by Rachel Rudinger and 3 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2018-04 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Rachel Rudinger Jason Naradowsky Brian Leonard Benjamin Van Durme a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2109.07958",
      "full_text": " [2109.07958] TruthfulQA: Measuring How Models Mimic Human Falsehoods Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2109.07958 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2109.07958 (cs) [Submitted on 8 Sep 2021 ( v1 ), last revised 8 May 2022 (this version, v2)] Title: TruthfulQA: Measuring How Models Mimic Human Falsehoods Authors: Stephanie Lin , Jacob Hilton , Owain Evans View a PDF of the paper titled TruthfulQA: Measuring How Models Mimic Human Falsehoods, by Stephanie Lin and 2 other authors View PDF Abstract: We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58% of questions, while human performance was 94%. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web. Comments: ACL 2022 (main conference); the TruthfulQA benchmark and evaluation code is available at this https URL Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG) Cite as: arXiv:2109.07958 [cs.CL] &nbsp; (or arXiv:2109.07958v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2109.07958 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Stephanie Lin [ view email ] [v1] Wed, 8 Sep 2021 17:15:27 UTC (793 KB) [v2] Sun, 8 May 2022 02:43:02 UTC (7,171 KB) Full-text links: Access Paper: View a PDF of the paper titled TruthfulQA: Measuring How Models Mimic Human Falsehoods, by Stephanie Lin and 2 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2021-09 Change to browse by: cs cs.AI cs.CY cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar 2 blog links ( what is this? ) DBLP - CS Bibliography listing | bibtex Owain Evans a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1804.06876",
      "full_text": " [1804.06876] Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1804.06876 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1804.06876 (cs) [Submitted on 18 Apr 2018] Title: Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods Authors: Jieyu Zhao , Tianlu Wang , Mark Yatskar , Vicente Ordonez , Kai-Wei Chang View a PDF of the paper titled Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods, by Jieyu Zhao and 4 other authors View PDF Abstract: We introduce a new benchmark, WinoBias, for coreference resolution focused on gender bias. Our corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a neural coreference system all link gendered pronouns to pro-stereotypical entities with higher accuracy than anti-stereotypical entities, by an average difference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation approach that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by these systems in WinoBias without significantly affecting their performance on existing coreference benchmark datasets. Our dataset and code are available at this http URL . Comments: NAACL &#39;18 Camera Ready Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI) Cite as: arXiv:1804.06876 [cs.CL] &nbsp; (or arXiv:1804.06876v1 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1804.06876 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Mark Yatskar [ view email ] [v1] Wed, 18 Apr 2018 18:51:00 UTC (620 KB) Full-text links: Access Paper: View a PDF of the paper titled Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods, by Jieyu Zhao and 4 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2018-04 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Jieyu Zhao Tianlu Wang Mark Yatskar Vicente Ordonez Kai-Wei Chang a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2103.03874",
      "full_text": " [2103.03874] Measuring Mathematical Problem Solving With the MATH Dataset arXiv Is Hiring a DevOps Engineer Work on one of the world's most important websites and make an impact on open science. View Jobs Skip to main content arXiv Is Hiring a DevOps Engineer View Jobs We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2103.03874 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Machine Learning arXiv:2103.03874 (cs) [Submitted on 5 Mar 2021 ( v1 ), last revised 8 Nov 2021 (this version, v2)] Title: Measuring Mathematical Problem Solving With the MATH Dataset Authors: Dan Hendrycks , Collin Burns , Saurav Kadavath , Akul Arora , Steven Basart , Eric Tang , Dawn Song , Jacob Steinhardt View a PDF of the paper titled Measuring Mathematical Problem Solving With the MATH Dataset, by Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt View PDF Abstract: Many intellectual endeavors require mathematical problem solving, but this skill remains beyond the capabilities of computers. To measure this ability in machine learning models, we introduce MATH, a new dataset of 12,500 challenging competition mathematics problems. Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations. To facilitate future research and increase accuracy on MATH, we also contribute a large auxiliary pretraining dataset which helps teach models the fundamentals of mathematics. Even though we are able to increase accuracy on MATH, our results show that accuracy remains relatively low, even with enormous Transformer models. Moreover, we find that simply increasing budgets and model parameter counts will be impractical for achieving strong mathematical reasoning if scaling trends continue. While scaling Transformers is automatically solving most other text-based tasks, scaling is not currently solving MATH. To have more traction on mathematical problem solving we will likely need new algorithmic advancements from the broader research community. Comments: NeurIPS 2021. Code and the MATH dataset is available at this https URL Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI); Computation and Language (cs.CL) Cite as: arXiv:2103.03874 [cs.LG] &nbsp; (or arXiv:2103.03874v2 [cs.LG] for this version) &nbsp; https://doi.org/10.48550/arXiv.2103.03874 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Dan Hendrycks [ view email ] [v1] Fri, 5 Mar 2021 18:59:39 UTC (1,943 KB) [v2] Mon, 8 Nov 2021 21:30:18 UTC (1,581 KB) Full-text links: Access Paper: View a PDF of the paper titled Measuring Mathematical Problem Solving With the MATH Dataset, by Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt View PDF TeX Source Other Formats view license Current browse context: cs.LG &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2021-03 Change to browse by: cs cs.AI cs.CL References &amp; Citations NASA ADS Google Scholar Semantic Scholar 1 blog link ( what is this? ) DBLP - CS Bibliography listing | bibtex Dan Hendrycks Collin Burns Saurav Kadavath Steven Basart Dawn Song &hellip; a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2304.06364",
      "full_text": " [2304.06364] AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2304.06364 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2304.06364 (cs) [Submitted on 13 Apr 2023 ( v1 ), last revised 18 Sep 2023 (this version, v2)] Title: AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models Authors: Wanjun Zhong , Ruixiang Cui , Yiduo Guo , Yaobo Liang , Shuai Lu , Yanlin Wang , Amin Saied , Weizhu Chen , Nan Duan View a PDF of the paper titled AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models, by Wanjun Zhong and 7 other authors View PDF Abstract: Evaluating the general abilities of foundation models to tackle human-level tasks is a vital aspect of their development and application in the pursuit of Artificial General Intelligence (AGI). Traditional benchmarks, which rely on artificial datasets, may not accurately represent human-level capabilities. In this paper, we introduce AGIEval, a novel benchmark specifically designed to assess foundation model in the context of human-centric standardized exams, such as college entrance exams, law school admission tests, math competitions, and lawyer qualification tests. We evaluate several state-of-the-art foundation models, including GPT-4, ChatGPT, and Text-Davinci-003, using this benchmark. Impressively, GPT-4 surpasses average human performance on SAT, LSAT, and math competitions, attaining a 95% accuracy rate on the SAT Math test and a 92.5% accuracy on the English test of the Chinese national college entrance exam. This demonstrates the extraordinary performance of contemporary foundation models. In contrast, we also find that GPT-4 is less proficient in tasks that require complex reasoning or specific domain knowledge. Our comprehensive analyses of model capabilities (understanding, knowledge, reasoning, and calculation) reveal these models&#39; strengths and limitations, providing valuable insights into future directions for enhancing their general capabilities. By concentrating on tasks pertinent to human cognition and decision-making, our benchmark delivers a more meaningful and robust evaluation of foundation models&#39; performance in real-world scenarios. The data, code, and all model outputs are released in this https URL . Comments: 19 pages Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2304.06364 [cs.CL] &nbsp; (or arXiv:2304.06364v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2304.06364 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Wanjun Zhong [ view email ] [v1] Thu, 13 Apr 2023 09:39:30 UTC (13,276 KB) [v2] Mon, 18 Sep 2023 14:23:02 UTC (6,512 KB) Full-text links: Access Paper: View a PDF of the paper titled AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models, by Wanjun Zhong and 7 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2023-04 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/1903.00161",
      "full_text": " [1903.00161] DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:1903.00161 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:1903.00161 (cs) [Submitted on 1 Mar 2019 ( v1 ), last revised 16 Apr 2019 (this version, v2)] Title: DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs Authors: Dheeru Dua , Yizhong Wang , Pradeep Dasigi , Gabriel Stanovsky , Sameer Singh , Matt Gardner View a PDF of the paper titled DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs, by Dheeru Dua and 5 other authors View PDF Abstract: Reading comprehension has recently seen rapid progress, with systems matching humans on the most popular datasets for the task. However, a large body of work has highlighted the brittleness of these systems, showing that there is much work left to be done. We introduce a new English reading comprehension benchmark, DROP, which requires Discrete Reasoning Over the content of Paragraphs. In this crowdsourced, adversarially-created, 96k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs than what was necessary for prior datasets. We apply state-of-the-art methods from both the reading comprehension and semantic parsing literature on this dataset and show that the best systems only achieve 32.7% F1 on our generalized accuracy metric, while expert human performance is 96.0%. We additionally present a new model that combines reading comprehension methods with simple numerical reasoning to achieve 47.0% F1. Subjects: Computation and Language (cs.CL) Cite as: arXiv:1903.00161 [cs.CL] &nbsp; (or arXiv:1903.00161v2 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.1903.00161 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Dheeru Dua [ view email ] [v1] Fri, 1 Mar 2019 05:32:01 UTC (2,543 KB) [v2] Tue, 16 Apr 2019 21:22:39 UTC (3,145 KB) Full-text links: Access Paper: View a PDF of the paper titled DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs, by Dheeru Dua and 5 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2019-03 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar DBLP - CS Bibliography listing | bibtex Dheeru Dua Yizhong Wang Pradeep Dasigi Gabriel Stanovsky Sameer Singh &hellip; a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2206.04615",
      "full_text": " [2206.04615] Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2206.04615 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2206.04615 (cs) [Submitted on 9 Jun 2022 ( v1 ), last revised 12 Jun 2023 (this version, v3)] Title: Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models Authors: Aarohi Srivastava , Abhinav Rastogi , Abhishek Rao , Abu Awal Md Shoeb , Abubakar Abid , Adam Fisch , Adam R. Brown , Adam Santoro , Aditya Gupta , Adrià Garriga-Alonso , Agnieszka Kluska , Aitor Lewkowycz , Akshat Agarwal , Alethea Power , Alex Ray , Alex Warstadt , Alexander W. Kocurek , Ali Safaya , Ali Tazarv , Alice Xiang , Alicia Parrish , Allen Nie , Aman Hussain , Amanda Askell , Amanda Dsouza , Ambrose Slone , Ameet Rahane , Anantharaman S. Iyer , Anders Andreassen , Andrea Madotto , Andrea Santilli , Andreas Stuhlmüller , Andrew Dai , Andrew La , Andrew Lampinen , Andy Zou , Angela Jiang , Angelica Chen , Anh Vuong , Animesh Gupta , Anna Gottardi , Antonio Norelli , Anu Venkatesh , Arash Gholamidavoodi , Arfa Tabassum , Arul Menezes , Arun Kirubarajan , Asher Mullokandov , Ashish Sabharwal , Austin Herrick , Avia Efrat , Aykut Erdem , Ayla Karakaş , B. Ryan Roberts , Bao Sheng Loe , Barret Zoph , Bartłomiej Bojanowski , Batuhan Özyurt , Behnam Hedayatnia , Behnam Neyshabur , Benjamin Inden , Benno Stein , Berk Ekmekci , Bill Yuchen Lin , Blake Howald , Bryan Orinion , Cameron Diao , Cameron Dour , Catherine Stinson , Cedrick Argueta , César Ferri Ramírez , Chandan Singh , Charles Rathkopf , Chenlin Meng , Chitta Baral , Chiyu Wu , Chris Callison-Burch , Chris Waites , Christian Voigt , Christopher D. Manning , Christopher Potts , Cindy Ramirez , Clara E. Rivera , Clemencia Siro , Colin Raffel , Courtney Ashcraft , Cristina Garbacea , Damien Sileo , Dan Garrette , Dan Hendrycks , Dan Kilman , Dan Roth , Daniel Freeman , Daniel Khashabi , Daniel Levy , Daniel Moseguí González , Danielle Perszyk , Danny Hernandez , Danqi Chen , Daphne Ippolito , Dar Gilboa , David Dohan , David Drakard , David Jurgens , Debajyoti Datta , Deep Ganguli , Denis Emelin , Denis Kleyko , Deniz Yuret , Derek Chen , Derek Tam , Dieuwke Hupkes , Diganta Misra , Dilyar Buzan , Dimitri Coelho Mollo , Diyi Yang , Dong-Ho Lee , Dylan Schrader , Ekaterina Shutova , Ekin Dogus Cubuk , Elad Segal , Eleanor Hagerman , Elizabeth Barnes , Elizabeth Donoway , Ellie Pavlick , Emanuele Rodola , Emma Lam , Eric Chu , Eric Tang , Erkut Erdem , Ernie Chang , Ethan A. Chi , Ethan Dyer , Ethan Jerzak , Ethan Kim , Eunice Engefu Manyasi , Evgenii Zheltonozhskii , Fanyue Xia , Fatemeh Siar , Fernando Martínez-Plumed , Francesca Happé , Francois Chollet , Frieda Rong , Gaurav Mishra , Genta Indra Winata , Gerard de Melo , Germán Kruszewski , Giambattista Parascandolo , Giorgio Mariani , Gloria Wang , Gonzalo Jaimovitch-López , Gregor Betz , Guy Gur-Ari , Hana Galijasevic , Hannah Kim , Hannah Rashkin , Hannaneh Hajishirzi , Harsh Mehta , Hayden Bogar , Henry Shevlin , Hinrich Schütze , Hiromu Yakura , Hongming Zhang , Hugh Mee Wong , Ian Ng , Isaac Noble , Jaap Jumelet , Jack Geissinger , Jackson Kernion , Jacob Hilton , Jaehoon Lee , Jaime Fernández Fisac , James B. Simon , James Koppel , James Zheng , James Zou , Jan Kocoń , Jana Thompson , Janelle Wingfield , Jared Kaplan , Jarema Radom , Jascha Sohl-Dickstein , Jason Phang , Jason Wei , Jason Yosinski , Jekaterina Novikova , Jelle Bosscher , Jennifer Marsh , Jeremy Kim , Jeroen Taal , Jesse Engel , Jesujoba Alabi , Jiacheng Xu , Jiaming Song , Jillian Tang , Joan Waweru , John Burden , John Miller , John U. Balis , Jonathan Batchelder , Jonathan Berant , Jörg Frohberg , Jos Rozen , Jose Hernandez-Orallo , Joseph Boudeman , Joseph Guerr , Joseph Jones , Joshua B. Tenenbaum , Joshua S. Rule , Joyce Chua , Kamil Kanclerz , Karen Livescu , Karl Krauth , Karthik Gopalakrishnan , Katerina Ignatyeva , Katja Markert , Kaustubh D. Dhole , Kevin Gimpel , Kevin Omondi , Kory Mathewson , Kristen Chiafullo , Ksenia Shkaruta , Kumar Shridhar , Kyle McDonell , Kyle Richardson , Laria Reynolds , Leo Gao , Li Zhang , Liam Dugan , Lianhui Qin , Lidia Contreras-Ochando , Louis-Philippe Morency , Luca Moschella , Lucas Lam , Lucy Noble , Ludwig Schmidt , Luheng He , Luis Oliveros Colón , Luke Metz , Lütfi Kerem Şenel , Maarten Bosma , Maarten Sap , Maartje ter Hoeve , Maheen Farooqi , Manaal Faruqui , Mantas Mazeika , Marco Baturan , Marco Marelli , Marco Maru , Maria Jose Ramírez Quintana , Marie Tolkiehn , Mario Giulianelli , Martha Lewis , Martin Potthast , Matthew L. Leavitt , Matthias Hagen , Mátyás Schubert , Medina Orduna Baitemirova , Melody Arnaud , Melvin McElrath , Michael A. Yee , Michael Cohen , Michael Gu , Michael Ivanitskiy , Michael Starritt , Michael Strube , Michał Swędrowski , Michele Bevilacqua , Michihiro Yasunaga , Mihir Kale , Mike Cain , Mimee Xu , Mirac Suzgun , Mitch Walker , Mo Tiwari , Mohit Bansal , Moin Aminnaseri , Mor Geva , Mozhdeh Gheini , Mukund Varma T , Nanyun Peng , Nathan A. Chi , Nayeon Lee , Neta Gur-Ari Krakover , Nicholas Cameron , Nicholas Roberts , Nick Doiron , Nicole Martinez , Nikita Nangia , Niklas Deckers , Niklas Muennighoff , Nitish Shirish Keskar , Niveditha S. Iyer , Noah Constant , Noah Fiedel , Nuan Wen , Oliver Zhang , Omar Agha , Omar Elbaghdadi , Omer Levy , Owain Evans , Pablo Antonio Moreno Casares , Parth Doshi , Pascale Fung , Paul Pu Liang , Paul Vicol , Pegah Alipoormolabashi , Peiyuan Liao , Percy Liang , Peter Chang , Peter Eckersley , Phu Mon Htut , Pinyu Hwang , Piotr Miłkowski , Piyush Patil , Pouya Pezeshkpour , Priti Oli , Qiaozhu Mei , Qing Lyu , Qinlang Chen , Rabin Banjade , Rachel Etta Rudolph , Raefer Gabriel , Rahel Habacker , Ramon Risco , Raphaël Millière , Rhythm Garg , Richard Barnes , Rif A. Saurous , Riku Arakawa , Robbe Raymaekers , Robert Frank , Rohan Sikand , Roman Novak , Roman Sitelew , Ronan LeBras , Rosanne Liu , Rowan Jacobs , Rui Zhang , Ruslan Salakhutdinov , Ryan Chi , Ryan Lee , Ryan Stovall , Ryan Teehan , Rylan Yang , Sahib Singh , Saif M. Mohammad , Sajant Anand , Sam Dillavou , Sam Shleifer , Sam Wiseman , Samuel Gruetter , Samuel R. Bowman , Samuel S. Schoenholz , Sanghyun Han , Sanjeev Kwatra , Sarah A. Rous , Sarik Ghazarian , Sayan Ghosh , Sean Casey , Sebastian Bischoff , Sebastian Gehrmann , Sebastian Schuster , Sepideh Sadeghi , Shadi Hamdan , Sharon Zhou , Shashank Srivastava , Sherry Shi , Shikhar Singh , Shima Asaadi , Shixiang Shane Gu , Shubh Pachchigar , Shubham Toshniwal , Shyam Upadhyay , Shyamolima (Shammie) Debnath , Siamak Shakeri , Simon Thormeyer , Simone Melzi , Siva Reddy , Sneha Priscilla Makini , Soo-Hwan Lee , Spencer Torene , Sriharsha Hatwar , Stanislas Dehaene , Stefan Divic , Stefano Ermon , Stella Biderman , Stephanie Lin , Stephen Prasad , Steven T. Piantadosi , Stuart M. Shieber , Summer Misherghi , Svetlana Kiritchenko , Swaroop Mishra , Tal Linzen , Tal Schuster , Tao Li , Tao Yu , Tariq Ali , Tatsu Hashimoto , Te-Lin Wu , Théo Desbordes , Theodore Rothschild , Thomas Phan , Tianle Wang , Tiberius Nkinyili , Timo Schick , Timofei Kornev , Titus Tunduny , Tobias Gerstenberg , Trenton Chang , Trishala Neeraj , Tushar Khot , Tyler Shultz , Uri Shaham , Vedant Misra , Vera Demberg , Victoria Nyamai , Vikas Raunak , Vinay Ramasesh , Vinay Uday Prabhu , Vishakh Padmakumar , Vivek Srikumar , William Fedus , William Saunders , William Zhang , Wout Vossen , Xiang Ren , Xiaoyu Tong , Xinran Zhao , Xinyi Wu , Xudong Shen , Yadollah Yaghoobzadeh , Yair Lakretz , Yangqiu Song , Yasaman Bahri , Yejin Choi , Yichi Yang , Yiding Hao , Yifu Chen , Yonatan Belinkov , Yu Hou , Yufang Hou , Yuntao Bai , Zachary Seid , Zhuoye Zhao , Zijian Wang , Zijie J. Wang , Zirui Wang , Ziyi Wu et al. (351 additional authors not shown) &nbsp;You must enable JavaScript to view entire author list. View a PDF of the paper titled Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models, by Aarohi Srivastava and 449 other authors View PDF Abstract: Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI&#39;s GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit &#34;breakthrough&#34; behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting. Comments: 27 pages, 17 figures + references and appendices, repo: this https URL Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG); Machine Learning (stat.ML) Cite as: arXiv:2206.04615 [cs.CL] &nbsp; (or arXiv:2206.04615v3 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2206.04615 Focus to learn more arXiv-issued DOI via DataCite Journal&nbsp;reference: Transactions on Machine Learning Research, May/2022, https://openreview.net/forum?id=uyTL5Bvosj Submission history From: Jaehoon Lee [ view email ] [v1] Thu, 9 Jun 2022 17:05:34 UTC (1,965 KB) [v2] Fri, 10 Jun 2022 17:17:09 UTC (1,966 KB) [v3] Mon, 12 Jun 2023 17:51:15 UTC (1,948 KB) Full-text links: Access Paper: View a PDF of the paper titled Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models, by Aarohi Srivastava and 449 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2022-06 Change to browse by: cs cs.AI cs.CY cs.LG stat stat.ML References &amp; Citations NASA ADS Google Scholar Semantic Scholar 2 blog links ( what is this? ) a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2203.09509",
      "full_text": " [2203.09509] ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2203.09509 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2203.09509 (cs) [Submitted on 17 Mar 2022 ( v1 ), last revised 14 Jul 2022 (this version, v4)] Title: ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection Authors: Thomas Hartvigsen , Saadia Gabriel , Hamid Palangi , Maarten Sap , Dipankar Ray , Ece Kamar View a PDF of the paper titled ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection, by Thomas Hartvigsen and 5 other authors View PDF Abstract: Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model. Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset. Our code and data can be found at this https URL . Comments: Published as a long paper at ACL 2022. Code: this https URL Subjects: Computation and Language (cs.CL) Cite as: arXiv:2203.09509 [cs.CL] &nbsp; (or arXiv:2203.09509v4 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2203.09509 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Thomas Hartvigsen [ view email ] [v1] Thu, 17 Mar 2022 17:57:56 UTC (4,824 KB) [v2] Tue, 3 May 2022 11:54:40 UTC (4,826 KB) [v3] Tue, 10 May 2022 10:50:46 UTC (4,830 KB) [v4] Thu, 14 Jul 2022 13:04:29 UTC (4,826 KB) Full-text links: Access Paper: View a PDF of the paper titled ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection, by Thomas Hartvigsen and 5 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2022-03 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2403.13793",
      "full_text": " [2403.13793] Evaluating Frontier Models for Dangerous Capabilities Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2403.13793 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Machine Learning arXiv:2403.13793 (cs) [Submitted on 20 Mar 2024 ( v1 ), last revised 5 Apr 2024 (this version, v2)] Title: Evaluating Frontier Models for Dangerous Capabilities Authors: Mary Phuong , Matthew Aitchison , Elliot Catt , Sarah Cogan , Alexandre Kaskasoli , Victoria Krakovna , David Lindner , Matthew Rahtz , Yannis Assael , Sarah Hodkinson , Heidi Howard , Tom Lieberum , Ramana Kumar , Maria Abi Raad , Albert Webson , Lewis Ho , Sharon Lin , Sebastian Farquhar , Marcus Hutter , Gregoire Deletang , Anian Ruoss , Seliem El-Sayed , Sasha Brown , Anca Dragan , Rohin Shah , Allan Dafoe , Toby Shevlane View a PDF of the paper titled Evaluating Frontier Models for Dangerous Capabilities, by Mary Phuong and 26 other authors View PDF Abstract: To understand the risks posed by a new AI system, we must understand what it can and cannot do. Building on prior work, we introduce a programme of new &#34;dangerous capability&#34; evaluations and pilot them on Gemini 1.0 models. Our evaluations cover four areas: (1) persuasion and deception; (2) cyber-security; (3) self-proliferation; and (4) self-reasoning. We do not find evidence of strong dangerous capabilities in the models we evaluated, but we flag early warning signs. Our goal is to help advance a rigorous science of dangerous capability evaluation, in preparation for future models. Subjects: Machine Learning (cs.LG) Cite as: arXiv:2403.13793 [cs.LG] &nbsp; (or arXiv:2403.13793v2 [cs.LG] for this version) &nbsp; https://doi.org/10.48550/arXiv.2403.13793 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Matthew Rahtz [ view email ] [v1] Wed, 20 Mar 2024 17:54:26 UTC (838 KB) [v2] Fri, 5 Apr 2024 12:26:11 UTC (1,042 KB) Full-text links: Access Paper: View a PDF of the paper titled Evaluating Frontier Models for Dangerous Capabilities, by Mary Phuong and 26 other authors View PDF TeX Source Other Formats view license Current browse context: cs.LG &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2024-03 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2402.19427",
      "full_text": " [2402.19427] Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2402.19427 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Machine Learning arXiv:2402.19427 (cs) [Submitted on 29 Feb 2024] Title: Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models Authors: Soham De , Samuel L. Smith , Anushan Fernando , Aleksandar Botev , George Cristian-Muraru , Albert Gu , Ruba Haroun , Leonard Berrada , Yutian Chen , Srivatsan Srinivasan , Guillaume Desjardins , Arnaud Doucet , David Budden , Yee Whye Teh , Razvan Pascanu , Nando De Freitas , Caglar Gulcehre View a PDF of the paper titled Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models, by Soham De and 15 other authors View PDF HTML (experimental) Abstract: Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated linear recurrences with local attention. Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of Llama-2 despite being trained on over 6 times fewer tokens. We also show that Griffin can extrapolate on sequences significantly longer than those seen during training. Our models match the hardware efficiency of Transformers during training, and during inference they have lower latency and significantly higher throughput. We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training. Comments: 25 pages, 11 figures Subjects: Machine Learning (cs.LG) ; Computation and Language (cs.CL) Cite as: arXiv:2402.19427 [cs.LG] &nbsp; (or arXiv:2402.19427v1 [cs.LG] for this version) &nbsp; https://doi.org/10.48550/arXiv.2402.19427 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Aleksandar Botev [ view email ] [v1] Thu, 29 Feb 2024 18:24:46 UTC (260 KB) Full-text links: Access Paper: View a PDF of the paper titled Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models, by Soham De and 15 other authors View PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.LG &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2024-02 Change to browse by: cs cs.CL References &amp; Citations NASA ADS Google Scholar Semantic Scholar a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2412.03555",
      "full_text": " [2412.03555] PaliGemma 2: A Family of Versatile VLMs for Transfer Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2412.03555 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computer Vision and Pattern Recognition arXiv:2412.03555 (cs) [Submitted on 4 Dec 2024] Title: PaliGemma 2: A Family of Versatile VLMs for Transfer Authors: Andreas Steiner , André Susano Pinto , Michael Tschannen , Daniel Keysers , Xiao Wang , Yonatan Bitton , Alexey Gritsenko , Matthias Minderer , Anthony Sherbondy , Shangbang Long , Siyang Qin , Reeve Ingle , Emanuele Bugliarello , Sahar Kazemzadeh , Thomas Mesnard , Ibrahim Alabdulmohsin , Lucas Beyer , Xiaohua Zhai View a PDF of the paper titled PaliGemma 2: A Family of Versatile VLMs for Transfer, by Andreas Steiner and 17 other authors View PDF HTML (experimental) Abstract: PaliGemma 2 is an upgrade of the PaliGemma open Vision-Language Model (VLM) based on the Gemma 2 family of language models. We combine the SigLIP-So400m vision encoder that was also used by PaliGemma with the whole range of Gemma 2 models, from the 2B one all the way up to the 27B model. We train these models at three resolutions (224px, 448px, and 896px) in multiple stages to equip them with broad knowledge for transfer via fine-tuning. The resulting family of base models covering different model sizes and resolutions allows us to investigate factors impacting transfer performance (such as learning rate) and to analyze the interplay between the type of task, model size, and resolution. We further increase the number and breadth of transfer tasks beyond the scope of PaliGemma including different OCR-related tasks such as table structure recognition, molecular structure recognition, music score recognition, as well as long fine-grained captioning and radiography report generation, on which PaliGemma 2 obtains state-of-the-art results. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2412.03555 [cs.CV] &nbsp; (or arXiv:2412.03555v1 [cs.CV] for this version) &nbsp; https://doi.org/10.48550/arXiv.2412.03555 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Michael Tschannen [ view email ] [v1] Wed, 4 Dec 2024 18:50:42 UTC (1,707 KB) Full-text links: Access Paper: View a PDF of the paper titled PaliGemma 2: A Family of Versatile VLMs for Transfer, by Andreas Steiner and 17 other authors View PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.CV &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2024-12 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack ",
      "fetch_method": "direct-html"
    }
  ]
}