{
  "model_id": "microsoft/phi-4",
  "full_texts": [
    {
      "arxiv_id": "2412.08905",
      "full_text": "Phi-4 Technical Report\nMarah Abdin\nJyoti Aneja\nHarkirat Behl\nS´ebastien Bubeck\nRonen Eldan\nSuriya Gunasekar\nMichael Harrison\nRussell J. Hewett\nMojan Javaheripi\nPiero Kauffmann\nJames R. Lee\nYin Tat Lee\nYuanzhi Li\nWeishung Liu\nCaio C. T. Mendes\nAnh Nguyen\nEric Price\nGustavo de Rosa\nOlli Saarikivi\nAdil Salim\nShital Shah\nXin Wang\nRachel Ward\nYue Wu\nDingli Yu\nCyril Zhang\nYi Zhang\nMicrosoft Research\nAbstract\nWe present phi-4, a 14-billion parameter language model developed with a training recipe that\nis centrally focused on data quality. Unlike most language models, where pre-training is based pri-\nmarily on organic data sources such as web content or code, phi-4 strategically incorporates synthetic\ndata throughout the training process. While previous models in the Phi family largely distill the\ncapabilities of a teacher model (specifically GPT-4), phi-4 substantially surpasses its teacher model\non STEM-focused QA capabilities, giving evidence that our data-generation and post-training tech-\nniques go beyond distillation. Despite minimal changes to the phi-3 architecture, phi-4 achieves strong\nperformance relative to its size – especially on reasoning-focused benchmarks – due to improved data,\ntraining curriculum, and innovations in the post-training scheme.\n1\nIntroduction\nRecent advancements in Large Language Models (LLMs) have shown that significant improvements in\ndata quality can rival, and sometimes surpass, the performance gains traditionally achieved by scaling\ncompute with model and dataset size. Building on the success of the Phi family [GZA+23, LBE+23,\nJBA+23, AAA+24], we introduce phi-4, a 14-billion parameter model that further advances performance\nof small language models by introducing innovative synthetic data generation methods for reasoning-\nfocused tasks, by optimizing the training curriculum and data mixture, and by introducing new tech-\nniques in post-training.\nSynthetic data constitutes the bulk of the training data for phi-4 and is generated using a diverse\narray of techniques, including multi-agent prompting, self-revision workflows, and instruction reversal.\nThese methods enable the construction of datasets that induce stronger reasoning and problem-solving\nabilities in the model, addressing some of the weaknesses in traditional unsupervised datasets. Synthetic\ndata in phi-4 also plays a crucial role in post-training, where techniques such as rejection sampling and\na novel approach to Direct Preference Optimization (DPO) are employed to refine the model’s outputs.\nThe development of phi-4 is guided by three core pillars:\n1. Synthetic Data for Pretraining and Midtraining: High-quality synthetic datasets are de-\nsigned to prioritize reasoning and problem-solving, carefully generated to ensure diversity and\n1\narXiv:2412.08905v1  [cs.CL]  12 Dec 2024\n\nSmall models\nLarge models\nphi-4\n14b\nphi-3\n14b\nQwen 2.5\n14b instruct\nGPT\n4o-mini\nLlama-3.3\n70b instruct\nQwen 2.5\n72b instruct\nGPT\n4o\nsimple-evals\nMMLU\n84.8\n77.9\n79.9\n81.8\n86.3\n85.3\n88.1\nGPQA\n56.1\n31.2\n42.9\n40.9\n49.1\n49.0\n50.6\nMATH\n80.4\n44.6\n75.6\n73.0\n66.31\n80.0\n74.6\nHumanEval\n82.6\n67.8\n72.1\n86.2\n78.91\n80.4\n90.6\nMGSM\n80.6\n53.5\n79.6\n86.5\n89.1\n87.3\n90.4\nSimpleQA\n3.0\n7.6\n5.4\n9.9\n20.9\n10.2\n39.4\nDROP\n75.5\n68.3\n85.5\n79.3\n90.2\n76.7\n80.9\nMMLUPro\n70.4\n51.3\n63.2\n63.4\n64.4\n69.6\n73.0\nHumanEval+\n82.8\n69.2\n79.1\n82.0\n77.9\n78.4\n88.0\nArenaHard\n75.4\n45.8\n70.2\n76.2\n65.5\n78.4\n75.6\nLiveBench\n47.6\n28.1\n46.6\n48.1\n57.6\n55.3\n57.6\nIFEval\n63.0\n57.9\n78.7\n80.0\n89.3\n85.0\n84.8\nPhiBench\n(internal)\n56.2\n43.9\n49.8\n58.7\n57.1\n64.6\n72.4\nTable 1: Performance of phi-4\non a set of standard benchmarks. The first set of benchmarks uses OpenAI’s\nsimple-evals framework [Ope24b], specifying the prompts/extraction/temperature=0.5. We compare to small\nmodels of similar inference cost, as well as to larger models.\nrelevance. We change our training curriculum and create new pretraining and midtraining data\nmixtures to increase the allocation of synthetic tokens, compared to older generations of phi.\n2. Curation and Filtering of High-Quality Organic Data: We meticulously curate and filter\norganic2 data sources, including web content, licensed books, and code repositories to extract seeds\nfor the synthetic data pipeline that encourage high-depth reasoning and prioritize educational\nvalue (to the model). These seeds form the foundation of the synthetic generation pipeline. To\ncomplement these synthetic datasets, we also filter the web for high-quality data (in terms of\nknowledge and reasoning) to use directly in pretraining.\n3. Post-Training: We further advance the post-training recipe in phi-4 by creating new refined\nversions of SFT datasets, as well as by developing a new technique to create DPO pairs, based on\npivotal token search.\nWith these innovations, the performance of phi-4 on reasoning-related tasks is comparable to or\nsurpasses much larger models. For example, its performance on many widely used reasoning-related\nbenchmarks meets or exceeds that of Llama-3.1-405B.\nIn Table 1 we compare the performance of\nour model on academic benchmarks to several contemporary foundation models.\nWe find that phi-\n4 significantly exceeds its teacher GPT-4o on the GPQA (graduate-level STEM Q&A) and MATH\n(math competition) benchmarks.\n1These scores are lower than those reported by Meta, perhaps because simple-evals has a strict formatting requirement\nthat Llama models have particular trouble following. We use the simple-evals framework because it is reproducible, but\nMeta reports 77 for MATH and 88 for HumanEval on Llama-3.3.\n2We use organic to refer to human-generated or otherwise non-synthetic data.\n2\n\nLlama-3.3\n70B Instruct\nClaude 3.5\nSonnet\nQwen 2.5\n14b-Instruct\nGPT\n4o\nGPT\n4o-mini\nQwen 2.5\n72b-Instruct\nGemini\nFlash 1.5\nGemini\nPro 1.5\nphi-4\n60\n70\n80\n90\nAverage score\n(temperature = 0.5)\n66.4\n74.8\n77.4\n77.9\n78.2\n78.7\n81.6\n89.8\n91.8\nAverage performance on November 2024 AMC 10/12 tests\nLarge model\nSmall model\nFigure 1: Average performance of different models on the November 2024 AMC-10 and AMC-12 tests. This is\nthe average score (with maximum score 150) over the four tests on 100 runs with temperature t = 0.5. We chose\nt = 0.5 to follow simple-evals [Ope24b]. Error bars are 2σ of the estimate. On competition math, phi-4 scores\nwell above its weight-class even compared to non–open-weight models.\n1.1\nAddressing Overfitting and Data Contamination\nDecontamination:\nOne pitfall of foundation models is overfitting to benchmarks, such as through\nthe leakage of benchmark test sets via the web corpus. We improved the data decontamination process\nfor phi-4 compared to previous Phi models to ensure no unfair influence on evaluation results. More\ndetails of the decontamination method are given in Appendix B.\nAMC Benchmark:\nThe surest way to guard against overfitting to the test set is to test on fresh data.\nWe tested our model on the November 2024 AMC-10 and AMC-12 math competitions [Com24], which\noccurred after all our training data was collected, and we only measured our performance after choosing\nall the hyperparameters in training our final model. These contests are the entry points to the Math\nOlympiad track in the United States and over 150,000 students take the tests each year.\nIn Figure 1 we plot the average score over the four versions of the test, all of which have a maximum\nscore of 150. phi-4 outperforms not only similar-size or open-weight models but also much larger frontier\nmodels. Such strong performance on a fresh test set suggests that phi-4’s top-tier performance on the\nMATH benchmark is not due to overfitting or contamination. We provide further details in Appendix C.\nRelying on Contamination-Proof Benchmarks:\nWe give significant weight to benchmarks which\nwere designed in such a way that the questions are original and do not appear on the web, such as\nGPQA [RHS+23]. While optimizing our model, we relied on an internal benchmark composed primarily\nof original prompts written by the team (see Section 5 for further details).\nLong Chain-of-Thought Models:\nA style of LLM that scales inference-time compute by generating\nlong chains of thought has emerged over the past few months, as pioneered by OpenAI O1 [Ope24a] and\nfollowed by DeepSeek-R1-Lite-Preview [Dee24] and Qwen/QwQ-32B-Preview [Tea24].\nThese models\nperform well on reasoning benchmarks, where QwQ, the only such model with open weights, averages\n124.5 points in the AMC-10/12 setting of Figure 1. However, QwQ also uses 4X more tokens on this\ntask than phi-4 and has more than twice as many parameters. Thus, the inference cost of QwQ is an\n3\n\norder of magnitude higher than phi-4. Consequently, these models are not in the same class as phi-4 with\nrespect to cost or latency.\n2\nApproach to Data\nThe pretraining phase of phi-4 relies heavily on synthetic datasets generated through a variety of tech-\nniques. In addition, we employ several methods for filtering organic data sources that are used both as\ncomplementary datasets in the pretraining and as seeds for generating synthetic data.\n2.1\nPurpose of Synthetic Data\nSynthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi\nseries of models has consistently emphasized the importance of synthetic data. Rather than serving as\na cheap substitute for organic data, synthetic data has several direct advantages over organic data.\nStructured and Gradual Learning.\nIn organic datasets, the relationship between tokens is often\ncomplex and indirect. Many reasoning steps may be required to connect the current token to the next,\nmaking it challenging for the model to learn effectively from next-token prediction. By contrast, each\ntoken generated by a language model is by definition predicted by the preceding tokens, making it easier\nfor a model to follow the resulting reasoning patterns. In this way, synthetic data may act as a form of\n“spoonfeeding,” presenting challenges in a digestible and progression-oriented manner.\nA simple example to illustrate this is that a human-written solution to a math problem might start\nwith the final answer. This answer is much too hard to output immediately, for either a human or an\nLLM—the human produced it by nonlinear editing, but pretraining expects the LLM to learn to produce\nit linearly. Synthetic solutions to math problems will not have such roadblocks.\nAlignment with Inference Contexts.\nSynthetic data is typically closer to the format of outputs\nwe expect our models to generate. Training on such data helps align the model’s pretraining experience\nwith the scenarios it encounters during inference. This alignment ensures that the context seen during\ngeneration remains in-distribution with respect to the data the model was pretrained on.\nFor example, web forums are very different in style from LLM interactions. If a fact only appears\nin web forum data, the pretrained model will think it is very unlikely to occur in the chats it produces.\nRewriting facts from the web forum into the language style of an LLM makes the facts more accessible\nduring the LLM chat context of inference.\nPrinciples.\nOur approach to generating synthetic data for phi-4 is guided by the following principles:\n1. Diversity: The data should comprehensively cover subtopics and skills within each domain. This\nrequires curating diverse seeds from organic sources.\n2. Nuance and Complexity: Effective training requires nuanced, non-trivial examples that reflect\nthe complexity and the richness of the domain. Data must go beyond basics to include edge cases\nand advanced examples.\n3. Accuracy: Code should execute correctly, proofs should be valid, and explanations should adhere\nto established knowledge, etc.\n4\n\n4. Chain-of-Thought: Data should encourage systematic reasoning, teaching the model various\napproaches to the problems in a step-by-step manner. This fosters coherent outputs for complex\ntasks.\n2.2\nSynthetic Data for Pretraining and Midtraining\nWe created 50 broad types of synthetic datasets, each one relying on a different set of seeds and dif-\nferent multi-stage prompting procedure, spanning an array of topics, skills, and natures of interaction,\naccumulating to a total of about 400B unweighted tokens. In Appendix D, we give a few examples\nof transcripts taken from our synthetic generations. Here, we highlight novel methodologies used in\ngenerating synthetic datasets for phi-4:\n• Seed Curation: The synthetic dataset generation begins with high-quality seeds sourced from\nmultiple domains.\nThese curated seeds provide the foundation for synthetic data generation,\nenabling the creation of exercises, discussions, and reasoning tasks tailored to the model’s training\nobjectives.\n1. Web and Code-based Seeds: Excerpts and snippets are extracted from web pages, books,\nand code repositories with a focus on content that demonstrates high complexity, reasoning\ndepth, and educational value. To ensure quality, we employ a two-stage filtering process:\nfirst, identifying pages with strong educational potential, and second, segmenting the selected\npages into passages, scoring each for its factual and reasoning content.\n2. Question Datasets: A large set of questions was collected from websites, forums, and Q&A\nplatforms. These questions were then filtered using a plurality-based technique to balance\ndifficulty.\nSpecifically, we generated multiple independent answers for each question and\napplied majority voting to assess the consistency of responses. We discarded questions where\nall answers agreed (indicating the question was too easy) or where answers were entirely\ninconsistent (indicating the question was too difficult or ambiguous). This filtering process\nproduces a dataset of questions that challenge the model’s reasoning and problem-solving\nabilities while remaining approachable.\nThe plurality answers were used in place of the\nground truth in our rejection-sampling based generations.\n3. Creating Question-Answer pairs from Diverse Sources: Another technique we use\nfor seed curation involves leveraging language models to extract question-answer pairs from\norganic sources such as books, scientific papers, and code. This approach does not rely on\nmerely identifying explicit Q&A pairs within the text. Instead, it involves a pipeline designed\nto detect deduction chains or logical progressions in the text. The language model identifies\nkey steps in reasoning or problem-solving processes and reformulates them into questions\nand corresponding answers. Our experiments show that, if done correctly, training on the\nresulting content can be far more effective (in terms of improvement on academic and internal\nbenchmarks) than training on the original content.\n• Rewrite and Augment: Seeds are transformed into synthetic data through multi-step prompting\nworkflows. This includes rewriting most of the useful content in given passages into exercises,\ndiscussions, or structured reasoning tasks.\n• Self-revision: The initial responses are then iteratively refined through a feedback loop where\na model critiques and subsequently improves its own outputs, guided by the rubrics focused on\nreasoning and factual accuracy.\n5\n\n• Instruction Reversal for Code and Other Tasks: To enhance the model’s ability to generate\noutputs from instructions, we used an instruction reversal technique. For example, we take existing\ncode snippets from the code data corpus and use it to generate corresponding instructions that\ninclude the problem description or task prompt. The resulting synthetic data pairs were structured\nwith the instruction appearing before the code. Only data with high fidelity between the original\nand regenerated code are retained, ensuring alignment between the instructions and the outputs.\nThis method can be generalized to other targeted use cases.\n• Validation of Code and Other Scientific Data: When appropriate, we incorporate tests for\nvalidating our reasoning-heavy synthetic datasets. The synthetic code data is validated through ex-\necution loops and tests. For scientific datasets, the questions are extracted from scientific materials\nusing a method designed to ensure high relevance, groundedness, and difficulty balance.\n2.3\nCuration and Filtering of Web and Q&A Data\nQ&A datasets.\nWe collected tens-of-millions high-quality organic problems and solutions by review-\ning public websites, relying on existing datasets, and acquiring external datasets. Our experience from\nprevious models showed that question-answer data contributed significantly to various capabilities, such\nas mathematical reasoning and academic performance. Our ablation studies showed that organic ques-\ntions are substantially more effective than synthetic questions. We used several ways to synthetically\naugment the dataset of organic questions to obtain a larger dataset. While these rewritten questions\nimproved the model’s capabilities, the gains were not as pronounced. A significant portion of the col-\nlected questions lacked accurate solutions. To address this, we replaced the answers with synthetically\ngenerated ones and used majority-voting to increase accuracy. All collected questions and solutions\nunderwent a thorough decontamination process to ensure there is no overlap with test sets3.\nTargeting High-quality Web Data.\nWe collected a wide variety of high-quality organic data sources\nfor phi-4, prioritizing reasoning-dense and nuanced material (e.g., academic papers, educational forums,\nand programming tutorials). In addition to directly training on this text, we used various web sources\nas seeds for specialized synthetic data generation pipelines. We found clean and correct natural data to\nbe absolutely crucial for seeding synthetic data: minor errors can result in severe quality degradations\nfor derived synthetic documents. We therefore invested heavily in the perfectionistic curation of our web\ndata. We discuss the main techniques and considerations below:\n• Targeted Acquisitions: We included major repositories of reasoning-dense documents that are\npublicly permissible for use (e.g., arXiv, PubMed Central, GitHub) or explicitly licensed (e.g.,\nlicensed books) aiming for a level of comprehensiveness, recency, and cleanliness above the typical\nstandard of externally available corpora.\n• Filtering Web Dumps: To capture the long tail of information-rich web sources (e.g., forums,\nblogs, course material, domain-specific wikis), we took the approach of selecting a small fraction\nof highest-quality documents from bulk web dumps, using small (non-LLM) classifiers trained on\n∼106 LLM-generated annotations. This approach tends to over-index on STEM-related keywords,\nso we created a specialized pipeline to amplify high-quality non-STEM content (e.g., arts, history,\ntravel, culture, and entertainment). These topic classifications were also obtained by distilling an\n3This step is crucial to the reliability of some of the academic benchmarks: for instance, some test benchmark variants\ncan be found on platforms like Hugging Face. Moreover, benchmarks such as MMLU are frequently compiled from web-\nsourced questions.\n6\n\nLLM annotator. Finally, we removed corrupted text and binary files by detecting outliers according\nto n-gram statistics and compression ratios.\n• Multilingual Data: We incorporated multilingual datasets to ensure that our model could han-\ndle a wide range of languages, including German, Spanish, French, Portuguese, Italian, Hindi\nand Japanese. This involved sourcing and processing high-quality multilingual documents from\nCommonCrawl and Wikipedia. Our multilingual processing pipeline consists of a language identifi-\ncation model, based on fastText used to categorize documents into 176 languages, then uses the\nsame classifiers for filtering web dumps to filter for quality. Note that the classifiers were trained\non multilingual LLM-generated annotations.\n• Custom Extraction and Cleaning Pipelines: To ensure sufficient cleanliness and uniformity\nbetween heterogeneous organic data sources, we needed a collection of customized heuristics and\nparsers. For each targeted data source, we built custom pipelines to ingest a variety of file formats\n(e.g., multi-file TeX source, ePub and other XML-like formats, Microsoft Word documents, and\nPDFs).\nFor general web data, we built a custom HTML-to-text extractor, taking significant\ncare to preserve fragile content that is frequently corrupted by na¨ıve parsers (e.g., TeX/MathML\nequations, code blocks, tables, and forum thread structure). This extractor prunes and normalizes\nthe DOM tree, using a variety of signals (e.g., HTML tag names, CSS classes, content length, and\ntree depth) to distinguish elements such as boilerplate, advertisements, equations, and syntax-\nhighlighter artifacts.\n2.4\nPost-Training datasets\nOur post-training data is composed of:\n• Supervised Fine-Tuning (SFT) Datasets: Using carefully curated user prompts taken from\na mixture of publicly available datasets and synthetically generated data, we generate multiple\nmodel responses and select the best using an LLM-based evaluation process.\n• Direct Preference Optimization (DPO): We generate DPO pairs based on rejection sampling\nand LLM evaluation, a part of which is based on our approach to creating pivotal token-based\npairs, explained in Section 4.3 below.\n3\nPretraining details\nThe phi-4 model is based on a decoder-only transformer architecture [VSP+17] with 14B parameters and\na default context length of 4096. This is later extended to a 16K context length during midtraining. The\narchitecture closely follows phi-3-medium, except that we now use the tiktoken tokenizer (for better\nmultilingual support) with a padded vocabulary size of 100,352 (including unused tokens) and we use\nfull attention over the 4K context length, rather than a 2K sliding window used in phi-3-medium.\nThe model was pretrained for approximately 10T tokens using linear warm-up and decay schedules\nwith peak learning rate of 0.0003, constant weight decay of 0.1, and global batch size of 5760. The\ntraining hyperparameters are tuned using interpolations from shorter horizon runs and further adjusted\nby stress testing the learning rate warm-up stage for stability.\nPretraining is followed by a shorter\nmidtraining stage to increase the original context length of 4k to 16k.\nSince pre-trained models are not good at instruction following, it is not very informative to use\n0-shot evaluations that require the answer to be in a specific format, for example simple-evals. We\n7\n\nMMLU\nMMLU pro\nGSM8k\nHuman-Eval\nARCC\nMBPP\nMATH\nTQA\nphi-4 (4k)\n+3.0\n+10.3\n+2.2\n+7.8\n+1.1\n+6.8\n+8.9\n-0.7\nphi-4 (16k)\n+2.7\n+8.9\n+1.2\n+9.0\n+0.9\n+9.6\n+8.4\n-1.5\nTable 2: Pretraining benchmarks for phi-4 compared to its predecessor, phi-3-medium after pretraining.\ntherefore use an internal implementation of benchmarks for pretraining which uses a mixture of log-\nlikelihood and/or few-shot prompts for various tasks. Specifically, we used log-likelihood evaluations\nfor MMLU (5-shot), MMLU-pro, and ARCC (1-shot). We used 1, 3, 4, and 8 few-shot examples for\nTriviaQA (TQA), MBPP, MATH, and GSM8k to help the model adhere to the answer format for easier\nextraction of the solution. We use this evaluation method throughout Section 3. Table 2 summarizes\nthe performance boost of pretrained phi-4 compared with its predecessor phi-3-medium.\n3.1\nData Composition in Pretraining\nThe phi-3 model family were trained using a two-phase strategy. Most of the training tokens were used\nin phase 1 of the training, which consisted largely of filtered web data. Phase 2 was trained with a\ndata mixture consisting primarily of synthetic tokens and a much smaller allocation for ultra-filtered\nand reasoning-heavy web data. As the size and complexity of our synthetic data grew, we observed a\nmarginal drop in the benefit from using non-synthetic tokens for the phi-3 family of model sizes. We\nnote two key observations.\n• Web datasets showed small benefits on reasoning heavy benchmarks. Prioritizing more epochs\nover our synthetic data led to better performance with respect to adding fresh web tokens.\n• Models trained only with synthetic data underperformed on the knowledge-heavy benchmarks and\ndemonstrated increased hallucinations.\nFigure 2 demonstrates the first phenomenon using smaller scale phase 2 pretraining exercises. In\nthis example, we conduct two training runs per model scale, using the same number of training tokens\non top of phase 1 pretrained checkpoints. For all runs, the number of unique synthetic tokens is fixed\n(a subsample of full synthetic data) but the number of repetitions on this data changes, namely 4 and\n12 epochs. The rest of the training tokens are fresh unique tokens supplied from web sources. As seen,\nperforming more iterations on the synthetic data is more beneficial than supplying more web tokens.\nInspired by this scaling behavior of our synthetic data, we trained a 13B parameter model solely on\nsynthetic4 data, for ablation purposes only – the model sees over 20 repetitions of each data source. For\nthe sake of ablations, we partitioned our synthetic data into web rewrites, which includes more direct\nrewrites of our filtered web content relative to all other types of synthetic data. Table 3 compares the\nprevious phi-3-medium model with the new model trained entirely on the synthetic data. Throughout\ntraining, all benchmarks consistently improved, despite the increase in epochs, and the majority of\nthe benchmarks showed improvements over phi-3. However, knowledge-related benchmarks, like 1-shot\ntriviaqa (TQA), show a large gap where synthetic models are subpar. These observations led us to\nrethink the role of web data in our data mixture.\n4This is an updated mixture of synthetic data that contains new sources compared to phi-3.\n8\n\nFigure 2: 5-shot MMLU score for phase 2 pretraining runs with 4 and 12 epochs of synthetic data. All models are\ntrained for the same token horizon, thus the model with 4 epochs of synthetic has seen more (unique) web tokens.\nWe see that despite many epochs on synthetic data, we do not see overfitting behavior and in fact the 12 epoch\nmodels perform better than those that have seen more unique web tokens.\nMMLU\nMMLU pro\nGSM8k\nHuman-Eval\nARCC\nMBPP\nMATH\nTQA\nSynthetic\n+0.8\n+4.0\n+2.2\n+12.1\n0.0\n+5.0\n+4.9\n-14.8\nSynthetic + Web Rewrites\n+0.3\n+4.1\n+1.8\n+13.3\n+3.0\n+7.6\n+8.1\n-7.7\nTable 3: Benchmark performance of 13B models (used for ablations only) trained on data mixtures containing\nno web data. The respective training tokens are either from synthetic sources, or an equal share of synthetic\ndata and web rewrites. All numbers are reported relative to the performance of phi-3-medium, which has seen a\ncombination of web and synthetic data.\n3.2\nData Mixture\nTo design our pretraining data mixture for a given training token budget, we search over different\nallocation of tokens coming from various sources, namely, 1) synthetic, 2) web rewrites5, 3) filtered web\n(divided into reasoning and knowledge-heavy portions), 4) targeted acquisitions and organic data (e.g.,\nacademic data, books, and forums), and 5) code data.\nWe conducted ablations using a shorter token horizon of 1T tokens to derive the data mixture.\nThese ablations rely on our established result on the high-rank correlation of short training with longer\ntraining, up to the over-fitting saturation threshold of data sources. In addition we observe a high rank\ncorrelation between the performance of the 7B and 14B models on different data mixtures, given a large\nenough distance between the data mixtures. This allowed us to conduct the experiments at 7B scale and\ntransfer the findings to phi-4. Among the numerous ablations, we highlight a few that show best insights\non our data composition. Specifically, we freeze the ratio of tokens coming from targeted acquisitions\nand code categories, and change the ratio of tokens for the synthetic, web, and web rewrites clusters.\nTable 4 summarizes the results for the hand-picked ablations, as compared with the data mixture\nthat was used for the final training run. A uniform allocation of tokens among the three categories is\nsuboptimal due to the higher quality of synthetic data and the only benchmark that shows a clear benefit\nfrom web data is TQA. While the synthetic-heavy variations on rows 2 and 3 of the table are marginally\nbetter than the chosen final data mixture, we decided to integrate the targeted and knowledge-heavy\nfiltered web data sources to improve knowledge benchmarks (see Section 3.1) to balance all model\n5Web rewrites is a sub-category of synthetic data that is substantially large and contains direct rewrites of web content.\n9\n\nMMLU\nMATH\nGSM8k\nHuman-Eval\nARCC\nMBPP\nTQA\nMMLU pro\nAverage\nUniform\n-3.3\n-5.4\n-5.8\n-1.2\n+0.6\n-2.0\n+3.3\n-3.6\n-2.2\nS\n+3.3\n+4.0\n+2.1\n-6.1\n+1.9\n+0.4\n-3.0\n+3.7\n+0.8\nS + WR\n+0.6\n+1.2\n+1.5\n-1.2\n+1.6\n+1.6\n-3.7\n+1.2\n+0.4\nS + W\n-0.6\n-0.7\n-0.7\n-4.3\n+0.3\n-2.0\n+6.9\n+0.9\n0.0\nTable 4: Ablations on the allocation of 75% of training tokens to synthetic (S), filtered web (W), and web rewrite\n(WR) categories, while other data sources are held constant in the remaining 25% token budget. All benchmark\nnumbers are measured relative to the final data mixture used for training phi-4.\ncapabilities. We also note that we observed the gap between the chosen data mixture and the synthetic\nheavy runs largely closes as the model goes through the post-training stage. An end-to-end optimization\nof pretraining data mixture that also takes into account the effects of post-training is an interesting\nfuture area of investigation.\nData\nSource\nFraction\nof Training\nUnique\nToken Count\nNumber of\nEpochs\nWeb\n15%\n1.3T\n1.2\nWeb rewrites\n15%\n290B\n5.2\nSynthetic\n40%\n290B\n13.8\nCode data\n20%\n820B\n2.4\nAcquired sources\n10%\n580B\n1.7\nTable 5: Data mixture for pretraining.\nThe final data mixture used for phi-4 allocates 30% of the training tokens to web and web rewrites\ndata sources, divided equally between them. The remaining tokens are largely sourced from synthetic\ndata which accounts for 40% of the data mixture tokens. Finally we allocate 20% of tokens to code data\n(mixture of synthetic and raw code) and 10% to targeted acquired sources like academic data and books.\nIn terms of total number of unique tokens in each data mixture cluster, filtered web data is the largest\ncluster with ∼1.3T tokens. Code and targeted acquisitions are the second and third largest clusters with\n∼820B and ∼580B tokens, respectively. Finally, web rewrites and synthetic data have similar token\ncount of ∼290B tokens. The total number of epochs on each data source is determined using the ratio\nof allocated tokens in the mixture and the number of unique tokens in that source.\n3.3\nMidtraining Details\nphi-4 includes a midtraining stage where the context length is increased from the original 4K to 16K.\nWe conduct several ablations to study the role of data on long-context performance. Specifically, we try\ndata sources that are inherently long context, and compare them with artificially created long context\ndata where samples are padded together to fill the sequence. We observe the former to perform better\nin longer context tasks.\nInspired by this, we further filter our high-quality non-synthetic datasets (i.e., academic, books, and\ncode data) to separate samples above 8K context. We then up-weight the data subsets that are 16K or\nhigher in length. We also create new synthetic datasets that satisfy the > 4K sequence requirement. The\nfinal data mixture includes 30% of the newly curated longer context data and a 70% portion of recall\n10\n\nModel\nMax Length\nRecall\nRAG\nICL\nRe-rank\nQA\nSumm\nphi-4\n8K\n100.0\n58.1\n68.0\n65.3\n26.7\n38.3\nQwen-2.5-14B\n8K\n100.0\n62.2\n67.8\n58.2\n24.7\n37.2\nLlama-3.3-70B\n8K\n92.0\n65.3\n69.4\n64.4\n30.0\n37.8\nGPT-4o-mini\n8K\n99.2\n65.8\n74.4\n69.4\n31.3\n38.5\nGPT-4o\n8K\n100.0\n66.9\n83.0\n75.1\n37.3\n43.0\nphi-4\n16K\n99.0\n57.1\n77.0\n54.4\n36.0\n40.5\nQwen-2.5-14B\n16K\n100.0\n59.1\n67.6\n50.3\n29.7\n42.3\nLlama-3.3-70B\n16K\n92.0\n62.2\n70.0\n63.3\n36.7\n41.9\nGPT-4o-mini\n16K\n100.0\n63.6\n78.4\n63.9\n36.0\n45.2\nGPT-4o\n16K\n100.0\n66.7\n85.6\n73.8\n43.7\n46.3\nTable 6: Evaluation results on the long-context benchmark HELMET [YGH+24].\ntokens from the pretraining stage. To accommodate longer context, we increase the base frequency of\nrope position encoding to 250K following [AI23b]. We drop the maximum learning rate by a factor of\n10 compared to the pretraining stage and train for a total of 250B tokens.\nTo effectively evaluate the long-context capability of our model, it is essential to have a comprehensive\nevaluation framework with practical scenarios. While synthetic benchmarks like needle-in-a-haystack and\nRULER are preferred for their simplicity and control, our emphasis is on a diverse range of tasks that\nreflect real-world applications, such as reasoning across entire documents. We report the performance\nof phi-4 and other models on the tasks we selected from the HELMET [YGH+24] evaluation suite in\nTable 6 and outline our evaluation methods below. Note that results are average across 5 runs for each\ncategories.\n• Recall: The task involves retrieving the corresponding value from a randomly-generated long JSON\nfile given a specific key (Metric: SubEM)\n• RAG: Answer questions based on many retrieved and shuffled Wikipedia documents. The datasets\nused for this task are NaturalQuestions, HotpotQA, and PopQA. Final results are average of all\ndatasets (Metric: SubEM)\n• Re-rank: The task is to re-rank the top-10 documents given a query and many retrieved and\nshuffled documents. This uses the MSMARCO dataset (Metric: nDCG@10)\n• ICL: The task involves many-shot in-context learning with datasets such as TREC coarse, TREC\nfine, Banking77, NLU and CLINC150. Final results are average of all datasets (Metric: F1)\n• QA: Answer questions given a lengthy document. The dataset associated with this task is Narra-\ntiveQAv2 (Metric: GPT-4o scoring)\n• Summ: The task involves summarizing a lengthy legal document, and the dataset used is Multi-\nLexSum (Metric: GPT-4o scoring)\n11\n\nDataset Name\nSample Count\nunknown + safety data\n3,000\ngeneric multiple-choice Q&A\n132,859\nmath data\n76,552\npython data\n16,080\ncpp, go, java, js, rust data\n21,806\nTable 7: Data Mixture for Pivotal Token DPO\nDataset Name\nSample Count\nunknown + safety data\n43,842\nany vs any overall\n266,000\nany vs any accuracy\n532,000\nTable 8: Data Mixture for Judge Guided DPO\n4\nPost-Training\nPost-training is aimed at transforming the pretrained language model into an AI assistant that users\ncan safely interact with.\nWe align the pretrained model with one round of SFT 4.1, one round of\nDPO [RSM+23] on data from our pivotal token search method (see Section 4.3), and one round of DPO\non full length preference pairs. The model is chat finetuned using the standard chatml format, example\nusage template for two rounds of a conversation is as follows:\n<|im start|>system<|im sep|>system message<|im end|>\n<|im start|>user<|im sep|>prompt1<|im end|><|im start|>assistant<|im sep|>response1<|im end|>\n<|im start|>user<|im sep|>prompt2<|im end|><|im start|>assistant<|im sep|>\n4.1\nSupervised Fine-Tuning\nIn this phase, we fine-tune the pretrained model with a learning rate of 10−6 on a variety of data generated\nfrom high-quality data across diverse domains, including math, coding, reasoning, conversation, model\nidentity, and safety. We also added multilingual data for 40 languages. We use around 8B tokens of\ndata in this phase, all formatted in the chatml format.\n4.2\nDirect Preference Optimization\nWe use DPO [RSM+23] to align the model with human preferences, and also to steer the model away\nfrom unwanted behavior through pairs of desired and undesired outputs. DPO data covers chat format\ndata, reasoning, and Responsible AI (RAI) data and improves the model in math, coding, reasoning,\nrobustness, and safety. We do two rounds of DPO on the SFT model. We introduce a technique, Pivotal\nToken Search (PTS), to generate pairs for DPO for the first DPO round. Details of the data mixture\nfor first round are provided in Table 7.\nFor the second round, which we call judge-guided DPO, we gather approximately 850k pairs of\ndesired and undesired outputs. The prompts are sourced from various publicly available instruction\ntuning datasets and also include prompts related to safety and Responsible AI (RAI). Next, for each of\nthese prompts, we generate responses from GPT-4o, GPT-4t and our model. From these responses, we\ncreate various combinations of DPO pairs and use GPT-4o as a judge to label positive or negative for\na given pair. For a given pair of responses, each assistant response is given a score based on accuracy,\nstyle, and detail. We label the response with higher accuracy or overall (average of accuracy, style, and\ndetail) score as the positive response. We provide the prompt we used in Appendix A. The data mixture\nfor this round is provided in Table 8. Both stages also include a small amount of data for safety and\nmitigating hallucinations.\n12\n\nUser:\nSuppose that the roots of x3 + 3x2 + 4x −11 = 0 are a, b, and c, and that the roots\nof x3 + rx2 + sx + t = 0 are a + b, b + c, and c + a.\nFind t.\nAI: To solve the problem, we need to deal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal\ndeal with the roots of the two cubic equations\ngiven.\nFirst, consider the cubic polynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial\npolynomial \\( xˆ3 + 3xˆ2 + 4x - 11 = 0 \\),\nwith roots \\( a \\), \\( b \\), and \\( c \\).\nBy Vieta’s formulas, we have:\n\\[ a +\nb + c = -3, \\] \\[ ab + bc + ca = 4, \\] \\[ abc = 11.\n\\] Now, consider the other\nother\nother\nother\nother\nother\nother\nother\nother\nother\nother\nother\nother\nother\nother\nother\nother\npolynomial \\( xˆ3 + rxˆ2 + sx + t = 0 \\) with roots \\( a+b \\), \\( b+c \\), and \\(\nc+a \\).\nWe need to find the value of \\( t \\), which corresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds\ncorresponds to the\nnegative\n0.42 →0.93\nof\nthe product of the roots according\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording\naccording to Vieta’s formulas::::\n\\[\n(a\n0.95 →0.71 +b)(b+c)(c+a).\n\\] First\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst\nFirst, note\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote\nnote the important\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant\nimportant identity:\n\\[ (a+b)(b+c)(c+a) = (a+b+c)(ab+bc+ca) -\nabc.\n\\] Plug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlug\nPlugging in known\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown\nknown values from our\nour\nour\nour\nour\nour\nour\nour\nour\nour\nour\nour\nour\nour\nour\nour\nour Vieta’s results for\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor\nfor \\( a \\), \\( b \\), and\n\\( c \\), we have:\n\\[ a ++++ b + c = -3, \\] \\[ ab + bc + ca = 4, \\] \\[ abc = 11.\n\\]\nSubstitute these into the identity:\n\\[ (a+b)(b+c)(c+a) = (-3)(4) - 11 = -12 - 11 =\n-23.\n\\] Thus, \\( t = -(a+b)(b+c)(c+a) = 23 \\).\nTherefore, the value of \\( t \\) is\n\\(\\boxed\\23\\\\).\n0\n1\np(success)\nFigure 3: Illustration of pivotal tokens for GPT-4o at temperature 1 on a problem from the MATH bench-\nmark [HBK+21], where the initial success probability is 0.31. Each token is colorized by the probability of success\nfor an independent completion (N = 529) continued from after the token, with red for p(success) = 0 and blue\nfor p(success) = 1. The line plot shows the same probabilities. The tokens that changes p(success) by ≥0.2 are\nshown boxed , with subscripts showing the change in probability. Tokens with probability ≤0.1 are underlined to\nillustrate that pivotal tokens are distinct from low-probability tokens. The token probabilities of\nnegative and\n(a were 0.31 and 0.12, respectively. The greedy tokens for the same prefixes are\nproduct with 0.66 probability\nand t with 0.88 probability.\nprocedure PivotalTokenSearch(Q,Tfull,pgap)\nprocedure Subdivide(Tprefix,T)\nif ∣T∣≤1 or ∣p(success ∣Tprefix) −p(success ∣Tprefix + T)∣< pgap then\n▷Base cases.\nreturn [T]\nTleft,Tright ←Split(T)\n▷We split at the cumulative midpoint of token log probabilities.\nreturn Subdivide(Tprefix,Tleft) ∪Subdivide(Tprefix + Tleft,Tright)\nTprefix ←ϵ\nfor all T ∈Subdivide(ϵ,Tfull) do\nif ∣T∣= 1 and ∣p(success ∣Tprefix) −p(success ∣Tprefix + T)∣≥pgap then\nyield (Q,Tprefix,T)\n▷Output pivotal tokens T and context for postprocessing.\nTprefix ←Tprefix + T\nFigure 4: Pseudocode for Pivotal Token Search (PTS). Note that estimating p(success ∣...) involves sampling the\nlanguage model and invoking the oracle. In an efficient implementation p(success ∣...) should be memoized.\n13\n\n4.3\nPivotal Token Search\nConsider a generative model producing a token-by-token response to a given prompt. For each token\nproduced, which corresponds to a prefix of the model response, one can consider the conditional proba-\nbility of the model’s answer being correct given that prefix, as well as the increment in this probability\nwith respect to that token (in other words, the difference in the probability of being correct before and\nafter producing that token). It is often the case that the overall correctness is highly dependent on\na successful generation of a small number of key tokens. For example, we can see in Figure 3 where\nthe model outputs a math solution and a “fortunate” sampling of a crucial token\nnegative shifts the\nsolution from possible failure to likely success, while sampling of the token (a subsequently risks failure\nagain. We refer to these tokens as pivotal tokens as they have an outsized effect on the course of the\nsolution.\nNow, consider how the solution from Figure 3 would be used in DPO as a full-length accepted\nresponse. As the figure shows, there are many tokens with probabilities much lower than the 0.31 of\nnegative , which would contribute to noise in the gradients diluting the signal from the pivotal token.\nEven worse, the token (a that contributed to the lack of robustness would receive a strong positive\nlearning signal thanks to its low probability of 0.12.\nMoreover, intuition suggests that when two texts substantially deviate from each other, comparison\nof their individual next-token log probabilities (as done in DPO) is not very meaningful. Rather, it\nmakes more sense that the signal should come from the first tokens after the two texts starts diverging\nfrom each other.\nTo alleviate these effects, we employ a method we call Pivotal Token Search (PTS) for generating\npreference data that specifically targets pivotal tokens in isolation, creating DPO pairs in which the\npreference optimization takes effect with respect to a single token.\nPTS identifies points of a completion token sequence Tfull = t1,t2,... for some user query Q where\nthe next token ti has a significant impact on the probability of success p(success ∣t1,...,ti). PTS es-\ntimates these probabilities by sampling completions starting from Q + t1,...,ti, which are checked for\ncorrectness with an oracle6 for Q. Figure 4 shows a basic instantiation of the algorithm. The proce-\ndure Subdivide recursively splits the sequence into segments ti,...,tj until the change in probability\n∣p(success ∣t1,...,ti−1) −p(success ∣t1,...,tj)∣for each segment is below a threshold pgap or the segment\nis just a single token. Tokens with a sharp change in success probability are kept as pivotal. We turn\npivotal tokens into preference data by taking Q + t1,...,ti−1 as the query, and single tokens tacc and trej\nthat increase/decrease p(success ∣t1,...,ti−1,tacc/rej) as the accepted and rejected completions, respec-\ntively.7 The binary-search algorithm for PTS is not always guaranteed to find all pivotal tokens, but\nit only finds pivotal tokens and it finds all of them if the success probability is near-monotone over the\ncourse of the solution.\nWe used PTS to generate preference data for tasks where ground-truth is readily available, such as\nmathematics, various forms of question answering and coding. To improve sample efficiency, we filter\nthe target questions to only include those with 0.2 ≤p(success) ≤0.8, as pivotal tokens are rare for tasks\nthat are very easy or hard.\nSee Figure 5 for examples of preference data we generated using PTS. The math question answering\nexample shows how pivotal tokens often are not actual mistakes, but choices that drive the model down\na less advantageous path. Here, multiplying both sides by the denominators separately is equally valid\nto directly cross-multiplying, but for the model doing the latter here is more robust. By generating\nDPO data targeting such choices, we believe PTS helps phi-4 work better in the modes it is especially\n6For coding, a comprehensive test suite can be used. For math problems, answers can be compared to the ground truth.\n7We find drawing tacc and trej from rollouts PTS already used to estimate p(success ∣t1, . . . , ti−1) to be effective.\n14\n\nUser:\nFind the product of all real values of r for which\n1\n2x\n=\nr−x\n7\nhas exactly one real\nsolution.\nAI: To solve the problem, we need to determine the values of r such that the equation\n1\n2x = r −x\n7\nhas exactly one real solution for x.\nFirst, clear the fractions by\nGood:\ncross-multiplying\nBad:\nmultiplying both sides by\nUser:\nConsider a 1 keV helium atom impinging at a one-degree incidence angle on a LiF\ncrystal surface.\nAdopt the axial channeling approximation to model the interaction\nbetween the helium atom and the crystal as a 2D potential energy landscape.\nApply\nNewton’s equations to compute the helium atom’s trajectory and determine the subsequent\nmomentum transfers from binary collisions with surface atoms.\nSum the total virtual\nenergy transferred across all collisions and compute the probability, Pe, that the\nhelium atom remains elastically scattered assuming a vibrational frequency for surface\natoms of ω = 1 × 1014Hz.\nWhat is Pe?\n1.\nPe = exp(−Eloss\n2̵hω ), 2.\nPe = exp( Eloss\n̵hω ), 3.\nPe = exp(−Eloss\n̵hω ), or 4.\nPe = 1 −exp(−Eloss\n̵hω )\nAI: To determine the probability Pe that the helium atom remains elastically scattered,\nwe need to calculate the total virtual energy transferred, Eloss, during the helium\natom’s interaction with the LiF crystal surface.\nGiven\nGood:\nthe vibrational frequency\nBad:\nthat the potential interactions\nUser:\nRead the following function signature and docstring, and fully implement the\nfunction described.\nYour response should only contain the code for this function.\ndef reorder_sequence(n: int, sequence: list[int]) -> list[int]:\n\"\"\"\nGiven a sequence of integer numbers that Polycarp wrote down on the board, this\nfunction rearranges (reorders) elements of this sequence to match the order\nPolycarp could have possibly written them. Each next number should be exactly two\ntimes the previous number or exactly one third of the previous number.\n:param n: The number of elements in the sequence (2 <= n <= 100).\n:param sequence: A list of integer numbers in arbitrary order (1 <= elements <= 3 *\n10ˆ18).\n:return: A reordered list of integer numbers representing a valid sequence Polycarp\ncould have written.\n\"\"\"\nAI: ...\nfrom collections import defaultdict\n# Create adjacency list where each number can point to its possible predecessor and\nsuccessors\ngraph = defaultdict(list)\nfor num in sequence:\nfor other in sequence:\nif num != other:\nif num == other * 2 or (\nGood:\nother % 3\nBad:\nnum * 2\nFigure 5: Preference data generated by Pivotal Token Search in answering math and physics questions, and\nimplementing a function in Python. The tokens that form the actual pair for DPO are underlined.\n15\n\nBase\nSFT\nDPO Stage 1\nFinal\n0\n20\n40\n60\n80\n100\nPercentage (%)\n6.8%\n3.2%\n90.0%\n3.7%\n57.5%\n38.7%\n2.9%\n79.8%\n17.4%\n3.0%\n81.1%\n15.8%\nSimpleQA performance over the course of post-training\nCorrect\nNot Attempted\nIncorrect\nFigure 6: The post-training process described in Appendix A.1 decreases hallucinations. One measure is that\nthe problems in SimpleQA—which the model very rarely gets correct—are increasingly not attempted during the\ncourse of post-training. We believe the final result is better behavior, even though the simple-evals score for\nSimpleQA (the F1 score) actually gives our base model a higher score than our final model.\nstronger.\nRelated Work:\nIn [LLX+24] a contrastive estimation approach involving a model trained on incorrect\ntrajectories is used to score which tokens likely contributed to failure, which is further employed to\nweigh rejected responses in DPO. In comparison, our PTS avoids complications from learned proxies by\ndirectly estimating p(success). They also report difficulties applying their method to accepted responses\nin DPO, while our method generates both positive and negative preference data directly targeting pivotal\ntokens. Automated process supervision methods [WLS+24, LLL+24] have applied search and rollouts to\ngenerate data for training process reward models. PTS can be seen as an automated process supervision\nmethod that generates token-level preference data suitable for DPO.\n4.4\nHallucination mitigation\nWe generate SFT data and DPO pairs to mitigate hallucination. If the model does not know the answer,\nwe would rather it refuse to answer than to make up a hallucination. We present the details of this\nprocess, including prompts to create the data, in Appendix A.1. This greatly decreases hallucinations\nin SimpleQA (see Figure 6).\n4.5\nPost-Training Ablation\nIn Table 1 we show how our benchmark scores evolve during post-training. We also evaluate dropping\npivotal token DPO and only performing the second stage of DPO. In general, we find that pivotal token\nDPO is most useful on reasoning-heavy tasks (GPQA, MATH) while judge-guided DPO is particularly\nuseful for the benchmark that itself involves a GPT-4 judge: ArenaHard. We also find the two approaches\nto be complementary.\n5\nBenchmarking Considerations\nWhile academic benchmarks are a widely used to measure the progress in LLM advancement, they\nsuffer from several limitations that can fail to reveal a model’s true capabilities and weaknesses. These\nlimitations include:\n• Data Contamination: Many benchmarks rely on datasets that overlap with pretraining corpora,\ncreating a risk of data contamination. Although we took extensive measures to deduplicate and\n16\n\nSFT\nDPO\nstage 1\nDPO\nstage 2 only\nphi-4\n(stage 1 + 2)\nsimple-evals\nMMLU\n82.8\n84.8\n84.2\n84.8\nGPQA\n47.3\n53.6\n52.4\n56.1\nMATH\n77.1\n80.5\n77.6\n80.4\nHumanEval\n79.5\n81.6\n81.5\n82.6\nMGSM\n80.8\n80.8\n81.5\n80.6\nSimpleQA\n3.7\n2.9\n2.9\n3.0\nDROP\n82.8\n86.1\n71.8\n75.5\nMMLUPro\n61.9\n70.0\n67.2\n70.4\nHumanEval+\n77.9\n81.9\n81.4\n82.8\nArenaHard\n56.7\n66.5\n69.8\n75.4\nIFEval\n66.2\n63.0\n63.0\n63.0\nPhiBench\n(internal)\n48.2\n54.5\n53.0\n56.2\nTable 9: Performance through the post-training process. DPO stage 1 is pivotal token DPO, and DPO stage 2 is\nmore standard judge-guided DPO. Each also has 1-5% hallucination and safety data mixed in.\ndecontaminate our training data, including standard n-gram deduplication and decontamination,\nthese methods are not effective against all scenarios, including rephrasing, which leaves some\nuncertainty about the true extent of generalization.\n• Limited Skill Scope: Most benchmarks evaluate models on narrowly defined skills, such as\nsolving specific style of math problems at certain grade level or implementing isolated Python\nfunctions. This narrow scope can fail to capture a model’s broader capabilities and weaknesses.\n• Bias in Generation-Based Benchmarks: Some benchmarks use LLM-as-judge for evaluat-\ning generated outputs. These judgments sometimes may prioritize style, fluency, or surface-level\nqualities over accuracy and validity of the reasoning chain, leading to potential biases in scoring.\n• Limitations of Multiple-Choice Tasks: Benchmarks that rely on multiple-choice questions\noften test a model’s ability to make clever guesses that can be achieved by pattern matching\nrather than effectively utilizing the underlying concepts through reasoning.\nTo address these issues, we maintain an internal benchmark called PhiBench, which is tailored to\nevaluate the diverse skills and reasoning abilities that we found critical to phi-4’s development. This\nbenchmark was designed with the following goals:\n1. Originality: All questions in the benchmark were composed by our team making sure that they\nwere not present in our pretraining data. Our goal for the internal benchmark is to reveal model’s\ngeneralization ability in various domains.\n2. Skill Diversity: Our benchmark includes a wide range of tasks to assess multiple dimensions\nof model performance. For instance, in coding, it goes beyond isolated function implementation\nto include debugging, extending incomplete code, and explaining code snippets.\nSimilarly, in\n17\n\nmathematics, it incorporates tasks like identifying the errors in proofs or generating related prob-\nlems, rather than simply solving equations. This ensures that the benchmark captures a broader\nspectrum of skills and reasoning processes.\n3. Rigorous Scoring for Generation Tasks: For tasks requiring judgment of model-generated\noutputs, we addressed the common pitfalls of LLM-based scoring by carefully curating detailed\njudge instructions (or “judge notes”). These rubrics specify exactly how to evaluate responses,\nfocusing on achieving accuracy, logical structure, and adherence to task requirements, while min-\nimizing tendencies towards stylistic biases. We observed significantly improved consistency and\nreduction of adverse impact due to subjective preferences in the scoring outcomes.\nPhiBench played a central role in optimizing phi-4. We used it to guide decisions about dataset\nmixtures and hyperparameter choices for more effective post-training techniques. PhiBench was also\nused to perform high-signal studies that identify weaknesses in the model and provide feedback for new\nincoming data sources.\n6\nPerformance on Key Benchmarks\nOur benchmark results were presented in Table 1, along with comparisons to other models. We first re-\nport the values from OpenAI’s simple-evals benchmark, which is a framework (including prompts, tem-\nperature, and extraction) for evaluating MMLU [HBB+20], GPQA diamond [RHS+23], MATH [HBK+21],\nHumanEval [CTJ+21], MGSM [SSF+22], and the SimpleQA [WKC+24] F1-score.\nWe also consider\nMMLU-pro [WMZ+24], HumanEval+ [LXWZ23], ArenaHard [CZS+24], and IFEval [ZLM+23], for which\nwe use an internal framework and prompting and extraction. Finally, we use PhiBench, our internal\ncollection of evaluations (see Section 5).\nphi-4 outperforms the closest in-class contemporary model, Qwen-2.5-14B-Instruct, in 9 out of 12\nbenchmarks. While phi-4 underperforms relative to Qwen-2.5-14B-Instruct on the benchmark numbers\nfor SimpleQA, DROP, and IFEval, we consider phi-4’s behavior on SimpleQA to actually be better\nthan Qwen’s. In fact, our base model gets a higher benchmark score than Qwen-2.5-14B-Instruct on\nSimpleQA, and we intentionally modified the model’s behavior in post-training to optimize for a better\nuser experience rather than a higher benchmark score. See Figure 6 and Appendix A.1 for details.\nOur model excels at STEM Q&A tasks. For example, on GPQA (graduate-level STEM questions)\nand MATH (math competitions), it even outscores its teacher model, GPT-4o. It also scores higher at\ncoding, as measured by HumanEval and HumanEval+, than any other open-weight model we benchmark\nagainst, including much larger Llama models.\nphi-4’s weakest benchmark scores are on SimpleQA, DROP, and IFEval. We believe for the first\ntwo that the number reported by simple-evals is reductive and does not accurately reflect model\nperformance on the benchmark problems. However, IFEval reveals a real weakness of our model – it\nhas trouble strictly following instructions. While strict instruction following was not an emphasis of our\nsynthetic data generations for this model, we are confident that phi-4’s instruction-following performance\ncould be significantly improved with targeted synthetic data.\n7\nSafety\nWe developed phi-4 in accordance with Microsoft’s Responsible AI principles. Our overall approach to\nRAI consisted of safety alignment in post-training, red-teaming, and automated testing and evaluations\nacross dozens of RAI harm categories. We leveraged helpfulness and harmlessness preference datasets\n18\n\nphi-3\n(3B-4K)\nphi-3\n(7B-8K)\nphi-3\n(14B-4K)\nMistral\n(7B-v0.1)\nMistral\n(7B-v0.2)\nLlama-3\n(8B)\nGemma\n(7B)\nphi-4\nGrounding\n4.469\n4.701\n4.787\n4.065\n4.692\n4.672\n4.32\n4.619\n3P Content Harms\n(DR1)\nBooks, News, Recipes, Songs\n0.26\n0.253\n0.251\n0.562\n0.399\n0.373\n0.383\n0.121\nHarmful Content\nContinuation (DR3)\nHate/Fairness, Self-Harm, Sexual, Violence\n0.007\n0.003\n0.01\n0.026\n0.018\n0.013\n0.013\n0.036\nHarmful Content\nSummarization (DR3)\nHate/Fairness, Self-Harm, Sexual, Violence\n0.105\n0.11\n0.112\n0.223\n0.16\n0.082\n0.103\n0.102\nJailbreak(DR1)\nSee text for covered topics\n0.117\n0.107\n0.111\n0.156\n0.153\n0.13\n0.114\n0.073\nTable 10: Performance comparison across models. Lower scores are better, except for “Grounding,” where a higher\nscore is better. phi-4 values are bold for readability.\n[BJN+22, JLD+23] with modifications inspired by [BSA+24] and multiple in-house generated datasets to\naddress the RAI harm categories in safety post-training.\n7.1\nRAI Benchmarks\nTable 10 shows the results of in-house RAI benchmarks [MHJ+23] for phi-4 compared to the phi-3 models\n[AAA+24], Mistral-7b-v0.1 [JSM+23], Mistral-7b-v0.2, Gemma 7b [TMH+24], and Llama-3-instruct-\n8b [AI23b].\nThis benchmark utilized GPT-4o to simulate multi-turn conversations in five different\ncategories and to evaluate the model responses. Grounding is scored between 0 (not grounded) and 5\n(fully grounded), and measures if the information in a response is based on a given prompt. In other\ncategories, responses were evaluated in terms of the severity of harmfulness and scored from 0 (no harm)\nto 7 (severe harm) and the defect rates (DR-x) were computed as the percentage of samples with the\nseverity score being greater than or equal to x. The Jailbreak (DR1) benchmark consists of simulated\nconversations around child grooming, illegal persuasion, leaking of 100 words of guidelines, popular\nconspiracy, prejudice against real people, step-by-step illegal advice, and violence against real people.\nFor more details on the RAI prompts and evaluation framework, see [HPBP+24].\n7.2\nRed Teaming\nIn addition to RAI benchmarking, we collaborated with the Microsoft AI Red Team (AIRT), an inde-\npendent group tasked with identifying safety and security vulnerabilities in Microsoft’s GenAI products.\nAIRT conducted a two-week red-teaming exercise that tested phi-4 for risky behaviors by emulating both\naverage and adversarial users in single and multi-turn scenarios. Overall, AIRT found that the behavior\nof phi-4 was similar to that of the phi-3 family, but identified several risky behaviors that were addressed\nby further rounds of safety post-training. In addition, the adversarial user scenario tested a wide range\nof techniques aimed at intentionally subverting the model’s safety training including jailbreaks, prompt\nencodings, and multi-turn attacks. phi-4 showed strong defenses against these techniques. AIRT also\ngenerated adversarial suffixes using the GCG algorithm [ZWC+23] on phi-3-medium, but found that\nthese suffixes did not transfer to phi-4. Further red teaming is required to identify possible risks across\na broader range of scenarios and harm categories.\n19\n\n8\nWeaknesses\nWhile phi-4 achieves similar level of language understanding and reasoning ability as much larger models,\nit is still fundamentally limited by its size for certain tasks, specifically in hallucinations around factual\nknowledge. For example, if X is a plausible human name, the model sometimes responds to prompts of the\nform “Who is X?” with a hallucinated biography of the person X. This limitation would be improved by\naugmenting the model with a search engine, but factual hallucinations cannot be eliminated completely.\nWhile phi-4 demonstrates relatively strong performance in answering questions and performing rea-\nsoning tasks, it is less proficient at rigorously following detailed instructions, particularly those involving\nspecific formatting requirements. For instance, when tasked with generating outputs in strict tabular\nformats, adhering to predefined bullet structures, or precisely matching stylistic constraints, the model\nmay produce outputs that deviate from the specified guidelines. This limitation arises in part from the\nmodel’s training focus, which prioritized synthetic datasets tailored toward Q&A and reasoning tasks\nover instruction-following scenarios.\nEven on reasoning tasks, phi-4 can make mistakes.\nFor example, when asked “which number is\nsmaller, 9.9 or 9.11?”, the model can conclude incorrectly that “9.9 is smaller than 9.11”.\nMoreover, as our data contains a lot of chain-of-thought examples, phi-4 sometimes gives long elab-\norate answers even for simple problems—this might make user interactions tedious. We also note that\nwhile phi-4 can function as a chat bot, it has been fine-tuned to maximize performance on single-turn\nqueries.\nDespite diligent RAI efforts, we acknowledge challenges around reproduction or amplification of\nbiases, inappropriate content generation, and safety issues. The use of carefully curated training data, as\nwell as targeted post-training, and improvements from red-teaming insights, have resulted in mitigating\nthese issues across all dimensions, but have not resolved the issues completely.\nAcknowledgments\nWe thank Janardhan Kulkarni and Sivakanth Gopi from Microsoft Research for the initial discussion\naround Pivotal Token Search.\nWe thank the AI Red Team (AIRT) at Microsoft, especially Blake\nBullwinkel, Bolor-Erdene Jagdagdorj, Daniel Jones, Shiven Chawla, Tori Westerhoff, and Ram Shankar\nSiva Kumar, and Olga Dutova-Fairfax from the Deployment Safety Board and the Office of Responsible\nAI at Microsoft for collaborating with us on evaluating and improving our model on vulnerabilities in\nsafety and security, which helped us adhere to the Microsoft’s RAI standards. Finally, we are grateful to\nEce Kamar, Doug Burger and Peter Lee from Microsoft Research for the support provided to the team\nduring the work on the model.\nReferences\n[AAA+24] Marah Abdin, Sam Jacobs Ade, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah,\nHany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al. Phi-3\ntechnical report: A highly capable language model locally on your phone. arXiv preprint\narXiv:2404.14219, 2024.\n[AI23a] Meta AI. Introducing Meta Llama 3: The most capable openly available llm to date, 2023.\n[AI23b] Meta AI. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2023.\n20\n\n[BJN+22] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,\nDawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Ka-\ndavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-\nDodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt,\nNeel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish,\nChris Olah, Ben Mann, and Jared Kaplan. Training a helpful and harmless assistant with\nreinforcement learning from human feedback, 2022.\n[BSA+24] Federico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul R¨ottger, Dan Jurafsky, Tatsunori\nHashimoto, and James Zou. Safety-tuned Llamas: Lessons from improving the safety of large\nlanguage models that follow instructions, 2024.\n[Com24] American Mathematics Competitions. American mathematics competitions problems and\nsolutions: Amc 10/12. https://www.maa.org/math-competitions, 2024. Accessed:\n2024-12-08.\n[CTJ+21] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto,\nJared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evalu-\nating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.\n[CZS+24] Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li,\nDacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica.\nChatbot arena: An open platform for evaluating llms by human preference, 2024.\n[Dee24] DeepSeek.\nDeepseek r1 lite preview.\nhttps://api-docs.deepseek.com/news/\nnews1120, 2024. Accessed: 2024-12-08.\n[GZA+23] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C´esar Teodoro Mendes, Allie Del Giorno,\nSivakanth Gopi, Mojan Javaheripi, Gustavo de Rosa Piero Kauffmann, Olli Saarikivi, Adil\nSalim, Shital Shah, Harkirat Singh Behl, Xin Wang, S´ebastien Bubeck, Ronen Eldan,\nAdam Tauman Kalai, Yin Tat Lee, and Yuanzhi Li. Textbooks are all you need. arXiv\npreprint arXiv:2306.11644, 2023.\n[HBB+20] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and\nJacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint\narXiv:2009.03300, 2020.\n[HBK+21] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,\nDawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math\ndataset. NeurIPS, 2021.\n[HPBP+24] Emman Haider,\nDaniel Perez-Becker,\nThomas Portet,\nPiyush Madan,\nAmit Garg,\nAtabak Ashfaq, David Majercak, Wen Wen, Dongwoo Kim, Ziyi Yang, et al.\nPhi-3\nsafety post-training: Aligning language models with a “break-fix”cycle.\narXiv preprint\narXiv:2407.13833, 2024.\n[JBA+23] Mojan\nJavaheripi,\nS´ebastien\nBubeck,\nMarah\nAbdin,\nJyoti\nAneja,\nCaio\nC´esar\nTeodoro Mendes, Weizhu Chen, Allie Del Giorno, Ronen Eldan, Sivakanth Gopi, Suriya\nGunasekar, Piero Kauffmann, Yin Tat Lee, Yuanzhi Li, Anh Nguyen, Gustavo de Rosa, Olli\nSaarikivi, Adil Salim, Shital Shah, Michael Santacroce, Harkirat Singh Behl, Adam Tau-\nmann Kalai, Xin Wang, Rachel Ward, Philipp Witte, Cyril Zhang, and Yi Zhang. Phi-2:\nThe surprising power of small language models. Microsoft Research Blog, 2023.\n21\n\n[JCWZ17] Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale\ndistantly supervised challenge dataset for reading comprehension, 2017.\n[JLD+23] Jiaming Ji, Mickel Liu, Juntao Dai, Xuehai Pan, Chi Zhang, Ce Bian, Chi Zhang, Ruiyang\nSun, Yizhou Wang, and Yaodong Yang. Beavertails: Towards improved safety alignment of\nllm via a human-preference dataset, 2023.\n[JSM+23] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh\nChaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile\nSaulnier, L´elio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut\nLavril, Thomas Wang, Timoth´ee Lacroix, and William El Sayed. Mistral 7b, 2023.\n[LBE+23] Yuanzhi Li, S´ebastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, and\nYin Tat Lee.\nTextbooks are all you need II: phi-1.5 technical report.\narXiv preprint\narXiv:2309.05463, 2023.\n[LLL+24] Liangchen Luo, Yinxiao Liu, Rosanne Liu, Samrat Phatale, Harsh Lara, Yunxuan Li, Lei\nShu, Yun Zhu, Lei Meng, Jiao Sun, and Abhinav Rastogi. Improve mathematical reasoning\nin language models by automated process supervision, 2024.\n[LLX+24] Zicheng Lin, Tian Liang, Jiahao Xu, Xing Wang, Ruilin Luo, Chufan Shi, Siheng Li, Yujiu\nYang, and Zhaopeng Tu. Critical tokens matter: Token-level contrastive estimation enhances\nllm’s reasoning capability, 2024.\n[LXWZ23] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated\nby chatgpt really correct? rigorous evaluation of large language models for code generation.\narXiv preprint arXiv:2305.01210, 2023.\n[MHJ+23] Ahmed Magooda, Alec Helyar, Kyle Jackson, David Sullivan, Chad Atalla, Emily Sheng,\nDan Vann, Richard Edgar, Hamid Palangi, Roman Lutz, Hongliang Kong, Vincent Yun,\nEslam Kamal, Federico Zarfati, Hanna Wallach, Sarah Bird, and Mei Chen. A framework\nfor automated measurement of responsible AI harms in generative AI applications, 2023.\n[Ope24a] OpenAI.\nLearning to reason with language models.\nhttps://openai.com/index/\nlearning-to-reason-with-llms/, 2024. Accessed: 2024-12-08.\n[Ope24b] OpenAI. Simple evals. https://github.com/openai/simple-evals, 2024.\n[RHS+23] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang,\nJulien Dirani, Julian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-proof\nq&a benchmark, 2023.\n[RSM+23] Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon,\nand Chelsea Finn. Direct preference optimization: Your language model is secretly a reward\nmodel. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.\n[SSF+22] Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi,\nHyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei.\nLanguage models are multilingual chain-of-thought reasoners, 2022.\n[Tea24] Qwen Team. Qwq: Reflect deeply on the boundaries of the unknown, November 2024.\n22\n\n[TMH+24] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju,\nShreya Pathak, Laurent Sifre, Morgane Rivi`ere, Mihir Sanjay Kale, Juliette Love, et al.\nGemma: Open models based on gemini research and technology, 2024.\n[VSP+17] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n Lukasz Kaiser, and Illia Polosukhin.\nAttention is all you need.\nIn Advances in Neural\nInformation Processing Systems, volume 30, 2017.\n[WFM+24] Yue Wu, Yewen Fan, So Yeon Min, Shrimai Prabhumoye, Stephen McAleer, Yonatan Bisk,\nRuslan Salakhutdinov, Yuanzhi Li, and Tom Mitchell. Agentkit: Flow engineering with\ngraphs, not coding. In COLM, 2024.\n[WKC+24] Jason Wei, Nguyen Karina, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia\nGlaese, John Schulman, and William Fedus. Measuring short-form factuality in large lan-\nguage models, 2024.\n[WLS+24] Peiyi Wang, Lei Li, Zhihong Shao, R. X. Xu, Damai Dai, Yifei Li, Deli Chen, Y. Wu,\nand Zhifang Sui. Math-shepherd: Verify and reinforce llms step-by-step without human\nannotations, 2024.\n[WMZ+24] Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo,\nWeiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex\nZhuang, Rongqi Fan, Xiang Yue, and Wenhu Chen. Mmlu-pro: A more robust and chal-\nlenging multi-task language understanding benchmark, 2024.\n[YGH+24] Howard Yen, Tianyu Gao, Minmin Hou, Ke Ding, Daniel Fleischer, Peter Izsak, Moshe\nWasserblat, and Danqi Chen. Helmet: How to evaluate long-context language models effec-\ntively and thoroughly, 2024.\n[ZLM+23] Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan,\nDenny Zhou, and Le Hou. Instruction-following evaluation for large language models. arXiv\npreprint arXiv:2311.07911, 2023.\n[ZWC+23] Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J. Zico Kolter, and Matt Fredrikson.\nUniversal and transferable adversarial attacks on aligned language models, 2023.\nA\nPost-Training Dataset Details\nA.1\nRefusal to Hallucinate\nWe created post-training SFT and DPO data to mitigate hallucinations in simple settings. Without\nany mitigation, phi-4 would almost never admit to ignorance. For example, in response to too-difficult\nquestions like “Who is the 297th highest ranked tennis player?” the model would essentially act as an\nimprov-style “Yes, and. . . ” engine, inventing a superficially plausible answer.\nOur goal in pretraining was to pack as much information into the model as possible, that is, to teach\nmore to the model rather than to teach it its own limitations. Then in post-training, we can identify\nthe level of problem that is too difficult for the model, and teach it to generate refusals rather than\nhallucinations on those problems.\nWe started with seed trivia problems, such as from TriviaQA [JCWZ17]. For each question, we ran\nphi-4 multiple times to estimate its chance of accurately solving it. We also used GPT-4o to generate\n23\n\n(1) a correct answer, (2) a refusal to answer, (3) a bogus variant of the question that is impossible to\nsolve, and (4) a refusal to answer the bogus question.\nFor SFT data, we used the pair (question, correct answer) wherever the base phi-4 model was usually\ncorrect, (question, refusal) where the model was usually wrong, and (bogus question, refusal) for all bogus\nquestions. For DPO data, we used (correct > refusal) for every question that the base phi-4 sometimes\nanswered correctly, and (refusal > wrong) if phi-4 sometimes answered incorrectly. The DPO data used\nthe first 5 tokens of the response. Example synthetic generation prompts can be found below.\nTo evaluate our progress, we can use SimpleQA [WKC+24], which is a dataset mostly comprised\nof obscure facts from Wikipedia (e.g., “How many more votes did Freeman Freeman-Thomas win than\nGeorge Sandys in the 1906 Bodmin by-election?”). Small models like phi-4 or GPT-4o-mini can only\ncorrectly answer 5-10% of them. Our performance can be found in Figure 6.\nNote that SimpleQA is included in Table 1 as part of simple-evals, and our model does not have a\ngood score. This is because simple-evals uses the F1 score, which is not a good measure of quality at\nthis accuracy scale. For example, suppose we start with a model that always guesses, but almost always\nwrongly, 6% correct and 94% incorrect. Some of the 6% correct answers will be from lucky guesses, so\npost-training to limit hallucination will have fewer correct answers, and for example, the result might be\n(3% correct, 3% incorrect, 94% refusal). In this case, a model will score worse by the F1 metric compared\nto original (5.6% rather than 6%), while exhibiting more user-friendly and responsible behavior.\nA.1.1\nSynthetic Generation Prompts\nHere, we share the main synthetic generation prompts, provided to GPT-4o, to generate post-training\ndata to decrease hallucinations.\nGeneration of bogus questions\nConsider the following trivia question:\n# Question\n{{ question }}\n# Instructions\nYour job is to turn this problem into a nonsensical one, for which the\nanswer is invalid or unlikely to be known by anyone.\nFor example, you\nmight change the name from a well-known figure to a random name, or\nchange the date from a well-known event to a random date, or the place\nto a different one.\nFor example, you might change \"When did Amelia\nEarhart cross the Atlantic Ocean?\" to \"When did Edgar Greenwood cross\nthe Atlantic Ocean?\" or \"How many times did Amelia Earhart cross the\nEnglish Channel?\".\n↪\n↪\n↪\n↪\n↪\n↪\n↪\nYour goal is that the new question is *plausibly real*, but impossible to\nanswer.\nYou should not make the question obviously fake, silly, or\nfictional; for example, all country names should be real countries,\nand no names should be obvious homages to the original question.\nIt\nshould sound like a serious trivia question.\n↪\n↪\n↪\n↪\n24\n\nYou may start with a very brief discussion, then end with two markdown\nsections:\n↪\n- The section '# Response' that contains the question.\n- The section '# Quality' that rates the generated question in quality\nfrom 1-5, with 5 being the highest quality.\n↪\nA high quality question is (1) different from the given question and\n(2) plausible\n↪\nGenerations of refusals\nConsider the following question:\n# Question\n{{ question }}\n# Instructions\nYou might well know the answer, but imagine that you were an LLM that did\nnot know the correct answer. Write a plausible response to this\nquestion that the LLM might give if it did not know the answer and\nwould like to say so rather than guess incorrectly.\n↪\n↪\n↪\nThis LLM cannot look things up.\nIt could suggest relevant information\nthat it knows; it can also just say that it does not know the answer,\nif it is unlikely to know anything useful.\n↪\n↪\nYou may start with a very brief discussion, then end with a markdown\nsection '# Response' that contains the response.\n↪\nAnswer checking\nI am grading solutions to a trivia question.\nYour job is to determine\nwhether the given submission matches the answer key.\n↪\n## Original question\n{{ question }}\n## Submission\n{{ response }}\n## Answer key\n{{ answer.value }}\n{% if answer.alternates %}\n25\n\n### Alternative Answer Forms\n{% for alt in answer.alternates %}\n{{ alt }}\n{% endfor %}\n{% endif %}\n## Instructions\nYou job is **NOT to solve the question**.\nYour job is to determine\nwhether the given submission should be graded as correct *without\nneeding a protest*.\nIt does not matter if you disagree with the\nofficial answer; you should only consider whether the submission is\nequivalent to the answer key.\n(There is a separate process for\nprotests.)\n↪\n↪\n↪\n↪\n↪\nGive a freeform analysis comparing the submission to the answer key.\nYou\nshould then output a JSON dictionary in the following form:\n↪\n```json\n{\n\"matches_key\": [Answer 'True', 'False', or 'Uncertain'],\n}\n```\nA.2\nJudge-guided DPO\nFor the second round of DPO, we generate responses from GPT-4o, GPT-4t and our model. To label\nresponses as positive or negative, we use GPT-4o as a judge and use the following prompt.\nYour task is to judge which of the following reply given by an AI\nassistant is better.\n↪\n# Conversation\n{{ chat }}\n# Replies\n{{ replies }}\n# Guideline\nProduce your output in the following JSON format (without comments and\nwith correct escape characters):\n↪\n```json\n{\n\"faults\": {\n26\n\n\"Assistant 1\": \"(string) List all the problems with the assistant 1\nreply. For each problem try to determine whether this is due to\nlack of comprehension of the relevant material, a logical\nerror, a factual error, a stylistic issue. If the answer is\nperfect, write none. If the question did not ask for a specific\nlevel of detail in the explanation, do not penalize the answer\nfor being too detailed or too concise.\",\n↪\n↪\n↪\n↪\n↪\n↪\n\"Assistant 2\": ...\n...\n},\n\"faults_discussion\": \"(string) Discuss the general strengths and\nweaknesses of each assistant. What are the main differences\nbetween the answers in terms of style, accuracy and level of\ndetail?\",\n↪\n↪\n↪\n\"accuracy\": {\n\"Assistant 1\": (1-5) how would you rate assistant 1 in terms of\naccuracy?,\n↪\n...\n},\n\"style\": {\n\"Assistant 1\": (1-5) how would you rate assistant 1 in terms of\nstyle?,\n↪\n...\n},\n\"detail\": {\n\"Assistant 1\": (1-5) how would you rate assistant 1 in terms of\nlevel of detail?,\n↪\n...\n}\n}\n```\nB\nData Processing\nB.1\nDecontamination\nWe decontaminate against the ARC-Easy, MBPP, phibench, CommonsenseQA, WinoGrande, mcphi,\nMedQA, MATH, AGIEval, PIQA, OpenBookQA, HellaSwag, GPQA, mt-bench, MMLUPro, GSM8k,\nHumanEval, arena hard, ARC-Challenge, and MMLU benchmarks. We apply a hybrid n-gram algorithm\nfor decontamination which uses 13-gram and 7-gram features for removing matches to the test set, which\nis described in more detail in 1. We create a set of common 13-grams in the Wiki and train set and try\nto not remove them since these are some common phrases which are ubiquitous. Some examples include\n’a i only b ii only c iii only d ii and iii’, ’a true true b false false c true false d false true’, ’logically\nequivalent b contradictory c neither logically equivalent nor contradictory but consistent d’, ’a (ii) and\n(iv) only b (i) and (iii) only c (i) (ii)’, ’b e b a b e c c b d c e d’.\n27\n\nAlgorithm 1 Decontamination Algorithm\nRequire:\nInput training text train\nBenchmark texts tests\nAllowed 13-grams allowed 13gram\nThresholds: info 7gram threshold, contaminated 7gram threshold\nEnsure:\nA result object with contamination details\n1: procedure CheckContamination(train)\n2:\nStep 1: Extract 13-grams and Check Contamination\n3:\nfeatures 13 ←ExtractNGrams(train,13)\n4:\nfor all feature ∈features 13 do\n5:\nif feature ∈BenchmarkFeatures13 and feature ∉allowed 13gram then\n6:\nreturn Contaminated (13-gram match)\n7:\nStep 2: Extract 7-grams and Compute Overlaps\n8:\nfeatures 7 ←ExtractNGrams(train,7)\n9:\noverlap counts ←CountOverlaps(features 7,BenchmarkFeatures7)\n10:\nStep 3: Compute Overlap Ratio for Tests\n11:\nmax ratio ←0, max test ←None\n12:\nfor all test ∈BenchmarkTests do\n13:\nratio ←\noverlap counts[test]\nmin(len(features 7),len(BenchmarkFeatures7[test]))\n14:\nif ratio > max ratio then\n15:\nmax ratio ←ratio, max test ←test\n16:\nStep 4: Determine Contamination\n17:\nif max ratio > info 7gram threshold then\n18:\nif max ratio ≥contaminated 7gram threshold then\n19:\nreturn Contaminated (7-gram match)\n20:\nelse\n21:\nreturn Partial Contamination (7-gram info match)\n22:\nreturn Clean (No significant overlap)\n28\n\ncontaminated:\nTrue\nTrain:\nThere are some oarsmen in a boat.\nThe average weight is increased by 1.8 kg\nwhen one of the crew, who weighs 53 kg, is replaced by a new man who weighs 71 kg.\nHow\nmany oarsmen are there in the boat?\nTrain Dataset:\norca-math-word-problems-200k\n13gram test:\nThe average weight of 10 oarsmen in a boat is increased by 1.8 kg when\none of the crew, who weighs 53 kg is replaced by a new man.\nFind the weight of the new\nman.A. 71 B.62 C.43 D.67 E.40\nTest Dataset:\nAGIEval\n13gram segment:\none of the crew who weighs 53 kg is replaced by a new\n13gram contaminated:\nTrue\n7gram test:\nThe average weight of 10 oarsmen in a boat is increased by 1.8 kg when one\nof the crew, who weighs 53 kg is replaced by a new man.\nFind the weight of the new\nman.A. 71 B. 62 C. 43 D. 67 E. 40\n7gram overlaps:\n[’1 8 kg when one of the’, ’of the crew who weighs 53 kg’, ’the\ncrew who weighs 53 kg is’, ’increased by 1 8 kg when one’, ’crew who weighs 53 kg is\nreplaced’, ’weighs 53 kg is replaced by a’, ’8 kg when one of the crew’, ’is increased\nby 1 8 kg when’, ’kg when one of the crew who’, ’53 kg is replaced by a new’, ’when one\nof the crew who weighs’, ’by 1 8 kg when one of’, ’kg is replaced by a new man’, ’one\nof the crew who weighs 53’, ’who weighs 53 kg is replaced by’]\n7gram ratio:\n0.39473684210526316\nC\nAMC Evaluation Details\nIn this section, we fully describe our inference and grading schemes used for to obtain the November\n2024 AMC scores displayed in Figure 1. The 78 questions in these contests (4 sets of 25 questions, with\noverlaps between the 10A/12A and 10B/12B exams) were made available on or after November 6, 2024.\nAll external models we tested were published before this date, as were the datasets for all stages of phi-\n4’s training. Thus, these contests are our best attempt at conducting a completely contamination-proof\nevaluation of mathematical reasoning capabilities. We only benchmarked on this dataset after choosing\nthe hyperparameters used in post-training our final candidate models, making this dataset completely\nindependent of our final model. 8\nWe obtained the questions from the Art of Problem Solving Wiki9, and formatted them with the\nfollowing template:\nThe following question is from a 25-question, multiple choice test. Each\nquestion is followed by answers marked A, B, C, D, and E.\nOnly one of\nthese is correct.\n↪\n↪\nSCORING: You will receive 6 points for each correct answer, 1.5 points for\neach problem left unanswered, and 0 points for each incorrect answer.\n↪\nSolve the question step by step, then answer \\boxed{A}, \\boxed{B},\n\\boxed{C}, \\boxed{D}, \\boxed{E}, or \\boxed{blank}.\n↪\n# Question\n8For full disclosure, we evaluated our final three candidate models on this dataset and all three average scores exceeded\n89. We settled on our final model based on other factors, before measuring its score but after seeing the scores for the other\ntwo candidates.\n9https://artofproblemsolving.com/wiki/index.php/2024_AMC_10A (10B, 12A, 12B)\n29\n\n{{question}}\n(A) {{option_a}}\n(B) {{option_b}}\n(C) {{option_c}}\n(D) {{option_d}}\n(E) {{option_e}}\nWith each question formatted this way, we obtained 10 independent generations at temperature 0.5\nfrom each model we tested. We then followed the grading scheme described in the above prompt. We\nfound that every model we tested (including our own) frequently failed to follow the “box your final\nanswer” instruction, particularly after a long chain of thought. To stabilize the evaluations, we decided\nto count otherwise correct solutions (e.g. boxing the correct numerical expression) as correct. To do\nthis, we prompted GPT-4o to extract a final answer (A/B/C/D/E or none) from each model’s solution,\nwith temperature 1.\nD\nSynthetic generation examples\nD.1\nGeneration examples\nWe review a few examples of what our synthetic datasets look like, to give a general flavor of some of\nour techniques.\nD.1.1\nExtracting and Tagging Excerpts from Content\nTo construct a dataset focused on reasoning and complexity, we extract excerpts from sources such as\nweb pages, books, and scientific articles. Each excerpt is annotated with metadata such as complexity\nlevel, factual obscurity, and the presence of reasoning chains. These annotations help identify high-value\ncontent for synthetic data generation. Below, we provide an example of metadata we generated for\nscientific content:\nStart Line: 8, End Line: 11\nInformation Type: Empirical Result Discussion\nBrief Description: Discussion of the role of SNPs in AD development and severity.\nComplexity Level: B\nFactual Obscurity: C\nChain of Reasoning: True\nReasoning Steps:\n1. Assumption: Specific SNPs influence immune response.\nConclusion: These SNPs may affect AD severity by modulating IgE levels.\nDescription: The study links genetic variations to clinical phenotypes.\n2. Assumption: SNPs associated with AD are replicated across cohorts.\nConclusion: Replication supports their role as potential genetic markers.\nDescription: Statistical analysis confirms the robustness of the findings.\nDependencies: Previous GWAS findings, statistical methods (lines 10-15)\nThe raw content will later be filtered based on the metadata, and both will be used as seed for a variety\nof synthetic generations pipelines.\n30\n\nD.1.2\nSelf-revision\nAnother component of our synthetic data pipeline is the iterative self-revision process. This process\ninvolves multiple stages where the model generates, critiques, and revises its output to meet specific\ncriteria. Below, we give an example of this workflow, focusing on the creation of a reading comprehension\nexercise based on a scientific excerpt:\n**Excerpt:**\n\"Future studies should replicate our findings for OXTR and BDNF, but also\ninclude additional stress-related candidate genes. [...] could reverse\naberrant DNA methylation-could become an important goal in the\ndevelopment of new treatment approaches.\"\n↪\n↪\n↪\n**Revision 0:**\n*Plan:* To create an advanced reading comprehension exercise:\n- Incorporate technical terms from genetics and epigenetics.\n- Add nested counterfactuals and conditional reasoning.\n- Require logical reasoning and background knowledge.\n*Exercise:* Researchers focused on DNA methylation following psychosocial\nstress. What conclusion can be drawn from studies examining both\naversive and positive experiences, diversified cohorts, and refined\nsampling intervals?\n↪\n↪\n↪\n1. A monotonic relationship between stress and methylation is confirmed.\n2. Differential methylation patterns reveal bidirectional sensitivity\n(correct).\n↪\n3. Early-life adversities remain the primary influence.\n4. Positive experiences have negligible effects.\n**Requirements (Flavored):**\n- Exercises must require both understanding the text and external advanced\nknowledge.\n↪\n- Incorrect choices should be plausible enough to mislead without full\ncomprehension.\n↪\n- The content should challenge advanced undergraduates in genetics or\nepigenetics.\n↪\n**Critique (Agent):**\n- **External Knowledge:** Does not explicitly require concepts beyond the\nexcerpt. *Score: 1*\n↪\n- **Plausibility of Choices:** Incorrect options are plausible but not\nmisleading enough. *Score: 2*\n↪\n- **Suggestions:** Introduce external concepts like epigenetic drift or\nthe diathesis-stress model, and refine incorrect choices to address\ncommon misconceptions.\n↪\n↪\n**Revision 1:**\n31\n\n*Plan:* Add references to the hypothalamic-pituitary-adrenal (HPA) axis\nand cortisol's role in stress responses, integrating advanced\nneuroendocrinology knowledge.\n↪\n↪\n*Exercise:* Considering DNA methylation and the HPA axis's role, how could\ncortisol influence classical and non-classical epigenetic changes?\n↪\n1. Cortisol is irrelevant to the modifiers discussed.\n2. Cortisol effects are linear and align with classical models.\n3. The dynamic epigenetic role of cortisol enriches research paradigms\n(correct).\n↪\n4. Cortisol’s role is limited to downregulation of methylation.\n**Critique (Agent):**\n- **Challenge Level:** Still insufficiently difficult for advanced\nundergraduates. *Score: 1*\n↪\n- **Suggestions:** Add nuanced alternatives based on theories like\neustress vs. distress or glucocorticoid response elements.\n↪\n**Revision 2:**\n*Plan:* Refine incorrect options and add concepts like glucocorticoid\nresponse elements to deepen the challenge. Reframe exercise to compare\nclassical and non-classical pathways in epigenetics.\n↪\n↪\n---\nD.1.3\nCreating Conversations from Snippets\nAnother component of our synthetic data pipeline involves transforming factual snippets into multi-turn,\nnuanced conversations. This process is designed to produce dialogues that are contextually accurate and\nintellectually engaging, encouraging critical thinking and deeper reasoning. The process of generating\nconversations includes several iterative steps:\n1. Initial Turn: Based on the snippet, the model generates a foundational response that presents\ncore information in a clear and direct manner. This step may also include an optional curation of\na participant’s profile that guides the tone and style of dialogue throughout the generation.\n2. Subsequent Turns: The dialogue grows through a dynamic flow of agents generating alternating\nturns, directing the conversation, summarizing earlier context and injecting new scenarios and\ntopics consistent with earlier messages.\n3. Self-Revision: After each turn, the model evaluates its responses, brainstorms the best next\ncourse of action given the current context, to maximize the complexity and nuance of the discussion.\nThis includes suggestions for exploring alternative perspectives or creating connections to broader\ncontexts.\nD.2\nFill-in-the-middle exercises\nMany data generation techniques require pairs of contexts and ground-truth answers for seeding and\nrely on rejection sampling during data generation. One approach we developed creates fill-in-the-middle\n32\n\nexercises from free-form text that does not naturally translate into such pairs. This involves removing\na meaningful portion of the text (the “middle”), framing the remaining text as the context, and using\nthe removed content as the ground-truth answer. The key challenge lies in identifying portions of the\ntext where reasoning can reconstruct the removed content, ensuring a “correct” answer exists.\nFor\ninstance, we generate such pairs from public code snippets, turning them into exercises and producing\ntheir solutions (augmented with chain-of-thought tokens) via rejection sampling. We give an example of\nsuch a transcript.\n**Fill-in-the-Middle Exercise**\n**Context (Excerpt from Code Snippet):**\nfor p in [path + [n] for n in graph[node]]:\nsmalls = collections.defaultdict(lambda: 0)\nfor n in path:\nif all_c['start'] > 1 or all_c['end'] > 1:\ncontinue\nfor c in smalls.values():\nif c <= 1:\ncontinue\n<<THIS PART DELETED>>\nif not bad:\npaths.append(p)\n**Solution:**\n**Background:**\nThis snippet processes paths in a graph, tracking visits to nodes,\nparticularly \"small\" nodes identified by lowercase strings. Key\nconditions:\n↪\n↪\n- Start and end nodes cannot be revisited.\n- \"Small\" nodes may have specific limits on revisits.\n**Reasoning:**\nThe missing part handles violations of small node visit limits using two\nvariables:\n↪\n- `cused` indicates if one small node has already been revisited.\n- `bad` marks the path as invalid if a second such revisit occurs.\nThe loop iterating over `smalls.values()` likely checks whether a small\nnode is revisited for the first time (allowing it by setting `cused`\nto `True`) or violates the limit (setting `bad` to `True` and breaking\nthe loop).\n↪\n↪\n↪\n**Final Guess:**\nThe missing part is likely:\nif c > 1:\nif not cused:\ncused = True\n33\n\nelse:\nbad = True\nbreak\n**Comparison to Correct Answer:**\n- The solution captures the general logic but omits the specific condition\n`elif c == 2 and not cused`, making it broader.\n↪\n- **Correctness Discussion:** The logic is close but lacks precision, as\nthe revisits must explicitly check for exactly two visits.\n↪\n**Grading and Feedback:**\n- **Grade:** 3 (partial correctness).\n- **Hint:** Consider revisiting the specific condition for revisits. Focus\non the exact count of visits that should trigger allowances.\n↪\nD.3\nAgents\nAgent tasks that involve interactions with longer horizons may present unique challenges such as plan-\nning, reflection, and error correction. Our training data consists of trajectories collected from Agen-\ntKit [WFM+24] with detailed chain-of-thought. Specifically, we generate high-quality trajectories by\nrunning AgentKit on a wide range of environments, and rewrite the guided raw reasoning outputs from\nAgentKit into a variety of self-contained statements or thoughts that aim to capture the gist of Agen-\ntKit reasoning. Training with AgentKit data improves planning, reasoning, tool use, math, and error\ncorrection on our internal benchmark.\nIn agent tasks, phi-4 follows a characteristic chain-of-thought with explicit planning and reflections.\nWe show an example of phi-4 interacting with the tower of Hanoi below:\nAnalyzing the current situation and reflecting on past actions is crucial\nfor determining the next best step. Here's a breakdown of the thought\nprocess:\n↪\n↪\n### Analysis of Current and Past Environment\n1. **Current Configuration:**\n- Rod A: |bottom, [0], top|\n- Rod B: |bottom, [1], top|\n- Rod C: |bottom, [2], top|\n2. **Past Performance:**\n- There have been repeated unsuccessful attempts to move disks,\nparticularly from rod B to C and A to C. These failures were due to\nrule violations, such as attempting to place a larger disk on a\nsmaller one.\n↪\n↪\n↪\n3. **Environmental Patterns and Rules:**\n- Only one disk can be moved at a time.\n- A larger disk cannot be placed on a smaller disk.\n- The goal is to move all disks from rod A to rod C.\n34\n\n### Reflection on Past Performance\n- **Mistakes Identified:**\n- Repeated attempts to make illegal moves indicate a misunderstanding or\noversight of the rules.\n↪\n- The plan was not effectively followed, as seen by the repeated failed\nattempts to move disks from rod B to C and A to C.\n↪\n- **Correct Moves:**\n- Successfully moved disk 0 from C to A, which was a necessary step to\nfree rod C for subsequent moves.\n↪\n### Relevant Considerations\n- **Current Objective:**\n- The immediate goal is to move disk 1 from rod B to rod C. This move is\nlegal and aligns with the rules since disk 1 is smaller than disk 2\non rod C.\n↪\n↪\n- **Strategic Alignment:**\n- Moving disk 1 from B to C is a strategic step that aligns with the\noverall plan to eventually stack all disks on rod C in the correct\norder.\n↪\n↪\n### Additional Thoughts\n- Ensuring compliance with the rules is paramount to avoid repeated\nfailures.\n↪\n- Each move should be evaluated for legality before execution to maintain\nprogress towards the goal.\n↪\n### Updated Plan\n1. **Move Disk 1 from B to C:**\n- Completion Quantification: Disk 1 is on rod C.\n- Certainty: Known. This move is legal and necessary to progress\ntowards the goal configuration.\n↪\n2. **Move Disk 0 from A to C:**\n- Completion Quantification: Disk 0 is on rod C, on top of disk 1.\n- Certainty: Known. This move is legal once disk 1 is on rod C.\n3. **Move Disk 2 from C to B:**\n- Completion Quantification: Disk 2 is on rod B.\n- Certainty: Known. This move is necessary to free rod C for the final\nsequence.\n↪\n35\n\n### Chosen Action\nBased on the analysis and the updated plan, the next logical and legal\naction is to move disk 1 from rod B to rod C. This move adheres to the\nrules and progresses towards the goal configuration.\n↪\n↪\n<updated plan>\n1. **Move Disk 1 from B to C**:\n- Completion Quantification: Disk 1 is on rod C.\n- Certainty: Known. This move is legal and necessary to progress\ntowards the goal configuration.\n↪\n2. **Move Disk 0 from A to C**:\n- Completion Quantification: Disk 0 is on rod C, on top of disk 1.\n- Certainty: Known. This move is legal once disk 1 is on rod C.\n3. **Move Disk 2 from C to B**:\n- Completion Quantification: Disk 2 is on rod B.\n- Certainty: Known. This move is necessary to free rod C for the final\nsequence.\n↪\n</updated plan>\n<action>Move the top disk of rod B to the top of rod C</action>\n36\n"
    },
    {
      "arxiv_id": "2509.06283",
      "full_text": "SFR-DeepResearch: Towards Effective Reinforcement\nLearning for Autonomously Reasoning Single Agents\nXuan-Phi Nguyen∗\nShrey Pandit\nRevanth Gangi Reddy†\nAustin Xu\nSilvio Savarese\nCaiming Xiong∗\nShafiq Joty∗\nSalesforce AI Research\nAbstract\nEquipping large language models (LLMs) with complex, interleaved reasoning\nand tool-use capabilities has become a key focus in agentic AI research, especially\nwith recent advances in reasoning-oriented (“thinking”) models. Such capabilities\nare key to unlocking a number of important applications. One such application is\nDeep Research (DR), which requires extensive search and reasoning over many\nsources. Our work in this paper focuses on the development of native Autonomous\nSingle-Agent models for DR featuring minimal web crawling and Python tool\nintegration. Unlike multi-agent systems, where agents take up pre-defined roles and\nare told what to do at each step in a static workflow, an autonomous single-agent\ndetermines its next action dynamically based on context, without manual directive.\nWhile prior work has proposed training recipes for base or instruction-tuned LLMs,\nwe focus on continual reinforcement learning (RL) of reasoning-optimized models\nto further enhance agentic skills while preserving reasoning ability. Towards this\nend, we propose a simple RL recipe with entirely synthetic data, which we apply\nto various open-source LLMs. Our best variant, SFR-DR-20B, achieves up to\n28.7% on Humanity’s Last Exam benchmark. In addition, we conduct key analysis\nexperiments to provide more insights into our methodologies.\n1\nIntroduction\nThe ability to call functions (or tools) is a core and well-studied capability in building practical Large\nLanguage Models (LLMs) [23, 21]. By enabling models to interact with the real world—retrieving\nup-to-date, reliable information through internet search or executing complex computations via\ncode—tool use reduces hallucination and improves reliability on complex, long-horizon tasks. Among\nthe many types of tool-integrated agents, web-based research agents, often referred to as Deep\nResearch (DR) [30], have attracted notable attention in both closed- and open-source communities.\nThese agents use browsing and coding tools to answer challenging questions. Unlike agents that\nneed to follow largely irreversible, acyclic workflows of tool calls (e.g., computer-use [36] or email\nagents), DR agents can invoke tools in a flexible order. However, this flexibility demands advanced\nreasoning ability to plan and execute correct tool calls, e.g., searching for specific entities or writing\nPython code.\nDR systems are typically implemented as either single-agent or multi-agent systems. A single-agent\nsystem, such as OpenAI’s DeepResearch[30] or Kimi-Researcher [26], gives a single, tool-equipped\nLLM the user’s question and allows it to autonomously perform actions like web search, webpage\n∗Project lead & corresponding authors: {xnguyen,cxiong,sjoty}@salesforce.com\n†Work done during an internship at Salesforce AI Research.\nTechnical Report.\narXiv:2509.06283v2  [cs.AI]  9 Sep 2025\n\nbrowsing, or coding in a multi-turn format. Apart from the initial prompt, this agent receives no\nexternal directives at intermediate steps. In contrast, a multi-agent DR system (e.g., OpenManus\n[22], Open DR [16]) typically employs a complex workflow in which multiple agents—potentially\npowered by different LLMs—are assigned distinct roles and task descriptions (e.g., orchestrator,\nplanner, coder, researcher, supervisor). For instance, an orchestrator may decompose a complex\nproblem into sub-problems and dispatch them to specialized agents equipped with dedicated tools.\nIn this work, we train autonomous single-agent LLMs to perform complex tasks using a minimal\nset of tools: a web search tool, a web crawling tool, and a Python interpreter. These agents are\ntrained to process initial requirements and contextual information from tool outputs to autonomously\nplan and execute their next action. Our focus on single-agent systems stems from two beliefs: First,\nwe believe single agents can generalize better to unseen tasks, as they are not constrained by the\npredefined, heuristic-based workflows common in multi-agent systems. Second, if more complex\nmulti-agent scaffolding is used, single-agents can be seamlessly integrated as specialized sub-agents,\nthereby reducing overall system complexity by eliminating redundant deep research components.\nWhile some prior work has suggested to begin agentic training from instruction-tuned (SFT) or\nbase (pre-SFT) models with cold-start instruction-tuning and RL [39, 17], we focus on continual\nRL training on reasoning-optimized models [41, 47, 1] to further improve agentic capabilities while\nalso preserving their strong reasoning ability. Towards this end, we develop a generic RL-based\nframework to improve the agentic capabilities of pre-trained reasoning models. The framework spans\ntwo main aspects:\n• Agentic Inference Pipeline: We implement an agentic scaffolding that mirrors the way the initial\nLLMs are originally trained, closely resembling a multi-turn conversation with tools. Additionally,\nwe develop a memory management system that allows the agent to manage its own memory,\neffectively enabling a virtually unlimited context window. Specifically, we reserve a portion of\nthe fixed context length as a memory buffer and provide the model with a memory clean-up tool.\nDuring roll-out, the agent will be told if the memory exceeds the token buffer length, and tasked\nwith using the clean-up tool to select only the information it deems important. We detail how this\ngeneric method is adapted for different base LLMs to account for their specific characteristics.\n• RL Training Recipe: We developed a novel pipeline to synthesize complex search- and reasoning-\nintensive training datasets suitable for end-to-end RL, which are more difficult than existing\nopen-source datasets [48, 12] and challenge even state-of-the-art DR agents [30]. To make use of\nsuch data, we developed a reinforcement learning algorithm based on REINFORCE [43] with novel\nmodifications that stabilize the policy optimization process. In particular, we find that agentic RL\ntraining can produce very diverse rollout scenarios with varied lengths (number of tool calls/turns).\nTo mitigate these instabilities, we propose temporal advantage normalization and strategic trajectory\nfiltering.\nWe applied our recipes on three distinct reasoning models: QwQ-32B [41, 46], Qwen3-8B [47], and\nthe recent gpt-oss-20b [1]. In the experiments, we demonstrate that our RL tuned models outperform\nmany popular baselines of similar sizes. Notably, our best variant, trained from gpt-oss-20b, achieves\nup to 28.7% in the full text-only benchmark of Humanity’s Last Exam [33], as well as competitive\nscores in FRAMES [15] and GAIA[24]. We additionally analyze the impact of our proposed agentic\nworkflow and the importance of length normalization in preventing degenerate tool-calling trajectories\nin our ablation study.\n2\nBackground\n2.1\nDeep Research Agents\nProviding LLMs with Internet access to generate grounded answers for complex fact-seeking\nquestions has been an important research topic [35, 5], closely related to retrieval-augmented\ngeneration [4, 27]. Recent web-based agentic systems increasingly leverage reasoning-oriented\nLLMs [10], such as Search-R1 [14, 19]. Deep Research with o3 [30] was among the first systems to\nintegrate both web browsing and code interpretation to tackle harder problems, including not only\nchallenging short-form questions but also abstract report-writing queries. Since then, a variety of\ndeep research systems have been introduced [44, 13, 6]. While some systems remain proprietary\n2\n\n[30, 9, 32] with undisclosed architectures, many open-source systems can be broadly categorized as\neither single-agent or multi-agent. The boundary between the two is blurred and still debated.\nIn this paper, we regard a single-agent system as one where a single primary LLM autonomously\nmakes tool-calling decisions based on the current context, without external directives at intermediate\nsteps. Single-agent systems typically restrict themselves to primitive tools but not LLM-enhanced\ntools. Examples include basic LLMs with function calling [47, 28, 1], ReAct-style agents [49, 17, 39],\nor a repetitive tool-calling-then-summarizing process such as Kimi-Researcher [26].\nBy contrast, a multi-agent system involves multiple agents collaborating within a pre-defined\nworkflow, each with its own agency and specialized role (e.g., planner, reasoner, coder, researcher,\nwriter). In addition, certain tools are treated as sub-agents when they rely on LLMs to perform\ncomplex tasks, such as query-focused information extraction from web content. Many open-source\ndeep research systems adopt this paradigm, including Open Deep Research [3, 16], Miroflow [25],\nand others [51, 20, 22, 3].\nOverall, single-agent systems are simple, agile, and more likely to generalize to unseen tasks because\nof its flexible design and autonomous workflow, whereas multi-agent systems tend to specialize in\npre-defined workflows and can achieve greater performance and efficiency. Single-agents can also be\nseamlessly plugged in an multi-agent system.\n2.2\nAgentic Tool-integrated Reinforcement Learning\nReinforcement learning with verifiable rewards (RLVR) has become the standard methodology for\ntraining agentic LLMs [30, 28, 47, 26, 40]. While various RL algorithms, such as GRPO and related\nmethods [38, 50, 52, 2], have achieved success on single-turn reasoning tasks, they have not proven\nto be optimal or stable for long-horizon agentic tasks without modifications. In the realm of math\nsolving with code, techniques like trajectory filtering have been introduced to stabilize multi-turn\ntraining [21, 45, 8, 7]. For web agents, cold-start instruction-tuning followed by RL with customized\nobjectives and roll-out strategies is commonly employed [39, 17, 31, 42, 26]. Other approaches\n[20, 25] leverage preference learning [34]. Most prior work begins training from base (pre-SFT) or\ninstruction-tuned models. In contrast, we initialize from reasoning-optimized “thinking” models,\nallowing us to both leverage and preserve their strong step-by-step reasoning while endowing them\nwith new agentic capabilities. This design choice, however, introduces unique challenges, most\nnotably, the difficulty of reliably steering long-horizon chain-of-thought behavior during optimization.\n3\nSFR-DeepResearch\nIn this section, we describe the process of building SFR-DeepResearch (SFR-DR). First, we formulate\na novel yet simple agentic inference scaffolding that stabilizes multi-step rollouts with a flexible\ncontextual memory buffer that enables arbitrarily length trajectories. Then, we describe how the\ntraining data is constructed for end-to-end RL training. Finally, we explain our novel RL recipe,\nwhich helps stabilize multi-turn RL in complex deep research setups.\n3.1\nAgentic Inference Scaffolding\n3.1.1\nTools\nThe tool-set available to an agentic system plays a critical role in the system performance. There\nare many advanced tools in existence that can make the agent’s job easier, from more thorough\nsearch engines to interactive web-browsing tools and even LLM-enhanced tools (i.e., sub-agents)\n[51, 22, 25, 36]. However, when training a single-agent, the tools provided to the agent define a\ncrucial component of the RL environment. By giving an agent tools that make information extraction\ntoo easy, the agent is not challenged enough during training. For this reason, we equip and train our\nagents with a minimal set of tools that provide enough functionality to complete tasks, but do not\nrender any training tasks trivially easy, incentivizing our agents to explore more and to use their tools\neffectively and efficiently. Concretely, we use the following three tools:\n• search_internet(query:str) utilizes a bare-bone search API, such as serper.dev, and\nreturns the top-10 organic search results. Each result entry usually, but not always, contains the full\nURL, title, and a short description of the page.\n3\n\nFigure 1: An example tool calling trajectory by our SFR-DR agentic workflow, catered for QwQ-\n32B and Qwen3 models. The multi-turn interaction is framed as a single-turn contextual question\nanswering problem, where there is always only 1 user turn. The previous tool calls and responses are\npacked as memory and placed in the user turn together with the question.\n• browse_page(url:str, section_id:int) obtains readable content from the URL by\nscraping and converting the raw HTML into Markdown format. Notably, we strip all hyperlinks\nfrom the HTML content, as they typically render as extremely long strings. This makes the page\nunclickable and static. As a result, the only way for the agent to discover new URLs is through\nthe search engine. This is different from existing work [30, 1, 17, 39, 20], where agents can\ninteractively browse the content of web pages and click on hyperlinks directly. Additionally, if\na web page is longer than a pre-defined limit, it will be split into sections, which the agent may\n“scroll” to via the section_id argument.\n• code_interpreter(code:str) locally executes stateless model-written Python code on\nthe local machine, and times out after 5 minutes. Different from stateful interpreters [30], each\nstateless execution is an independent runtime and does not share variables from past executions.\nNotably, unlike remote cloud-based sandbox environments, our coding tool does not have access\nto the command line or ability to install packages. File system access and sensitive packages that\npose security and integrity risks are also prohibited.1\n3.1.2\nSingle-agent Agentic Workflow\nTraining function-calling LLMs is typically done by utilizing a multi-turn structure: Tool descriptions\nare inserted in the model system prompt, the model outputs its tool calling action in the assistant\nturn, and the tool results are presented to the model in either the user turn [47] or specialized turns\ndesigned for tool results [1, 27]. As such, when continually training models with RL to excel as DR\nagents, it is intuitive to preserve the multi-turn nature of function-calling training. However, we find\nthat specific model families have distinct model characteristics that do not allow for a one-size-fit-all\ntraining formulation. As a result, we tailor our inference setups on a per-model family basis.\nFigure 1 demonstrates an example tool calling trajectory of our SFR-DR. Formally, given\nan input question q, a multi-turn agentic trajectory is defined as an ordered set T (q)\n=\n(q, c1, o1, c2, o2, ..., cn, on, a) where ci is the model response that includes a tool call, oi is the\nresulting feedback returned from executing that tool call in the environment at agentic step i, and a is\nmodel’s proposed answer. For reasoning models, ci and a may not only include the output part, but\nalso the “thinking” tokens.\nFor QwQ-32B [41] and Qwen3 [47] models, we find that inference is more effective when we\nreformulate a typical multi-turn tool calling conversation as an iterative single-turn task (Figure\n1). We hypothesize that these models were extensively post-trained with RL to excel at typically\nsingle-step tasks, such as solving math problems or writing code.\nMore precisely, with the\ndefault multi-turn chat template at step i > 1, the prompt sent to the model is equivalent\n1Attempts to import packages like os,sys,subprocess,socket,signal,multiprocessing,\nthreading,ssl,pdb,resource,xmlrpc, etc, will receive an error message.\n4\n\nto “<user>q<assistant>c1<user>o1...<user>oi−1<assistant>”.\n2 In our agentic\nworkflow, the same prompt can be reformulated a single-turn contextual question answering prompt\nas “<user>q; [c1, o1, ..., oo−1]<assistant>”, where the question, tool call actions, and tool\nresults all reside in the first user turn. The tool results are included in the user turn as contextual\nknowledge, which the model should use to determine its next action. As more tool calls and tool\nresults accumulate during rollout, instead of a longer multi-turn conversation, the prompt always\ncontains only one “contextual question” that keeps getting longer and more complex. Additionally,\nas we are training reasoning LLMs, we must manage the long CoT “thinking” tokens. We find that\nthe most straightforward approach, interleaving the long CoT between tool calls, as recommended by\nQwen3, causes several problems. First, the long CoTs include unnecessary tokens, which quickly\nfills up the model’s context window. Second, we observe that the long CoT tokens begin to devolve\ninto highly erratic outputs as the trajectory length grows, likely because existing post-training does\nnot extend conversations to extremely long, multi-turn settings. Instead, we opt to omit previous\nlong CoTs in the current step. As a result, at each step, the model will generate a new long CoT that\nreasons about the latest contextual information. We analyze the impact of this modification in §4.2.1.\nOn the other hand, the gpt-oss model [1] exhibits significantly stronger multi-turn abilities and\nconsistently produces shorter chain-of-thoughts. Therefore, we follow the default harmony chat\ntemplate that comes with the model instead of the above single-turn proposal.\nLong-horizon Context Management. For complex problems, the long-context nature of multi-\nturn tool-calling interactions becomes a critical challenge: Naively storing all tool results and\nmodel reasoning traces quickly fills up the model’s context window (of length L tokens), whereas\nblindly truncating the conversation may inadvertently discard crucial information found in earlier\nconversation turns. As such, context management becomes a crucial skill for DR agents, especially\nfor models that output long CoT. Several multi-agent workflows have proposed using an external\nmemory bank [35, 22]. Instead, we train our agents to self-manage its own internal memory,\ni.e., the context window itself. For QwQ and Qwen models, we simply provide an internal tool\ncalled clean_memory(content:str) that replaces the current context information, such as\n[c1, o1..., co, ro] for step i, with model-generated content specified in the content argument.3\nThis clean up process is illustrated in step 5 of Figure 1. During rollout, if the memory is about\nto exceed a pre-defined limit Lmem < L, the model will be informed so and instructed to invoke\nclean_memory. In this case, any other tool call other than cleaning up the memory will yield\na “memory overflow” error until the model successfully cleans the context memory. For gpt-oss\nmodels, as we use the original multi-turn format, we instead provide them with tools to edit or delete\nindividual past tool results.\nImproving Fault Tolerance. As all LLMs are stochastic, there is a chance that the models will\nproduce responses in incorrect formats, causing parsing errors. Depending on the severity of the\nformat error, we implement protocols to either repair, retry, or inform the model about the error in the\nnext step. For example, if the model produces tool calling action but misplaces a special token and\na deterministic reparation is unsuccessful, the model will receive a syntax-error message and will\nbe asked to remedy its tool call in the next turn, as shown step 3 of Figure 1. The model would also\nreceive a similar warning if it calls a non-existent tool or an existing tool with invalid parameters.\n3.2\nTraining Data Synthesis Pipeline\nWe create a mix of challenging synthetic data to train our agent to perform two core tasks: Short-form\nQA and long-form report writing. For short-form QA, we observe that existing multi-hop training\ndatasets [12, 48] are not sufficiently challenging for our initial models, even without search; such\nquestions are likely too easy and/or already included in pre- or post-training data mixes. As such,\nwe utilize an iterative approach to construct more challenging multi-hop question-answer pairs\nprogressively. In addition to multi-hop fact-seeking questions, we also include traditional math and\ncode reasoning tasks. For long-form reports, we prompt an LLM to create both instructions and\ngrading rubrics for a curated set of open-ended questions. In all, our training data is challenging for\n2For\nbrevity,\nwe\ncondense\nthe\ntemplate\nin\nmain\ntext.\nThe\nactual\ntemplate\nis\n<|im_start|>user\\nq<|im_end|><|im_start|>assistant\\nc1<|im_end|>\n<|im_start|>user\\n<tool_response>o1</tool_response><|im_end|>...\n3If the agent has cleaned up K times, the current memory will not include tool results oj that occurred before\nthe K-th clean up as they were erased.\n5\n\neven state-of-the-art agents: OpenAI Deep Research with o3 [30] achieves less than 65% accuracy on\nour short-form dataset, while our best baseline agent scored less than 40%. These questions are also\nsearch intensive, with an o4-mini agent [29] taking up to 50 tool calls to complete a single question.\n3.3\nEnd-to-End Reinforcement Learning Recipe\nLength-normalized RL Objective. We employ a modern variant of the REINFORCE algorithm\n[43] to train our SFR-DR agents, which features clipped-surrogate losses [37, 38, 52]. Particularly,\ngiven an input question q, we perform a group of G independent rollout trajectories defined as the\nMarkov chain τi = [(si,1, ai,1), (si,2, ai,2), ..., (si,Ti, ai,Ti)] of length Ti where si,j is the Markov\nstate and ai,j is the corresponding policy action at agentic step i. All steps si,j receive the same\nreward ri which is obtained at the last step. We do not use any intermediate rewards. The step-level\nadvantage Ai,j is then determined as:\nAi,j = Ai = ri −mean(R)\nstd(R) · Ti\n(1)\nwhere R is the set of all trajectory-level rewards within the same group. The loss is then computed at\nstep level. Compared to prior work [38, 50], our advantage formulation features a normalization term\nover the trajectory length. This means that steps of longer rollouts have lower absolute advantage\nmagnitudes than those of shorter rollouts. The normalization is designed to regulate and stabilize\ntraining when the trajectory length varies significantly. Without normalization, we observe that longer\ntrajectories dominate the training loss, even if said trajectories are not necessarily of higher quality or\ncorrect. As a result, failing-but-long trajectories appear more frequently over time, even if they are\nimposed with penalties and negative rewards. This results in unintended negative learned behavior,\nsuch as repeated tool calling; We find this behavior is mitigated with length normalization (§4.2.2).\nTrajectory Filtering. We also employ a strategic trajectory filtering procedure to ensure the training\nbatch mixture is optimal. Particularly, similar to [50, 26], we filter out invalid trajectories, such\nas those ending with truncation or incorrectly-formatted responses, from the replay buffer. We\nalso maintain the ratio of positive to negative trajectories of a group within a pre-defined range by\nrandomly or heuristically dropping over-represented trajectories. We observe that, without such\nmeasures, the training process is unstable and prone to model collapse.\nPartial Rollouts. As errors compound the longer the trajectory becomes, we found it is beneficial\nto reuse partial rollouts. Unlike MoonshotAI [26] which continues the unfinished rollouts with the\nupdated policy, we treat the partial rollouts as new independent initial states, from which group-level\nMonte-Carlo rollouts begin using the same policy. This allows more exposure to and gradient updates\nfrom long-tail intermediate states.\nReward Modeling. For both types of tasks described in §3.2, we use the same baseline LLM as\nverifier but with different rewarding procedures. For short-form tasks, we prompt the LLM to decide\nif the agent’s answer is semantically consistent with the ground-truth answer. The agent receives a\nreward ri = 1 if the answer is consistent and 0 otherwise. Meanwhile, for long-form report writing\ntasks, we employ a multi-stage process where the verifier grades the generated report individually\nand produces scores for multiple criteria, such as factuality/hallucination, compliance, writing quality,\nand citation quality. Each category carries a specific scoring weight. Within a group, valid reports are\nthen ranked by the verifier and a ranking score can be derived for each report. The total reward of a\ntrajectory is the weighted sum of component scores and the ranking score.\nRL Infrastructure. We build an in-house RL training pipeline that emphasizes scalability and\nfault-tolerance. First, during rollout phase, the pipeline aggressively uses asynchronous and multi-\nprocessing programs to accelerate parallel rollouts, maximizing the throughput of the SGLang [53]\ninference engine. Second, besides the search API, the toolbox is completely local and does not ping\ndedicated external services like e2b.dev. Tool actions are all executed locally through a revamped\napproach that supports large-scale parallel execution. We also cache tool results so repeated tool-\ncalls will instead retrieve results from our local database, rather than repeating the time-consuming\nexecutions. We further optimize the model placement of our framework, co-locating policy inference\nengines, verifier models, and policy models under training on the same set of GPUs to eliminate idle\nGPU usage. This co-location approach makes better use of GPU resources and improves training\nspeed compared to other frameworks where inference models and training models are allocated to\ndifferent GPUs. Specifically, during the gradient update phase, the inference engines are offloaded\n6\n\nTable 1: Performance of SFR-DR agents across benchmarks with Pass@1. Scores for our agents are\nobtained under a contamination blocklist. † indicates reported numbers where both the provided\nopen-source code (if available) and publication do not mention or include leakage prevention efforts,\nas of September 1, 2025. ∗indicates baselines that we run using open-source code and our blocklist.\nAgent\nBase models\nFRAMES\nGAIA\nHLE/HLE-500\nProprietary Agents\nDeep Research [30]\no3\n-\n67.4\n26.6/-\nGPT-5 [28]\nGPT-5\n-\n-\n35.2/-\nGPT-5-Pro [28]\nGPT-5-Pro\n-\n-\n42.0/-\no4-mini [29]\no4-mini\n-\n-\n17.7/-\nKimi-researcher [26]\nKimi-k1.5/k2\n78.8†\n-\n26.9†/-\ngpt-oss-20b [1]\ngpt-oss-20b\n-\n-\n17.3/-\ngpt-oss-120b [1]\ngpt-oss-120b\n-\n-\n19.0/-\nMulti Agents\nOpenDeepSearch-R1 [3]\nDeepseek-R1-671B\n72.4*\n-\n10.6*/-\nOpenDeepSearch-QwQ [3]\nQwQ-32B\n54.1*\n-\n9.1*/-\nMiroThinker-8B [25]\nQwen3-8B&235B\n64.4†\n44.8†\n-\nMiroThinker-32B [25]\nQwen3-32B&235B\n71.7†\n54.1†\n-/11.8†\nWebThinker-32B [20]\nQwQ-32B\n35.5*\n48.5†\n-/15.8†\nSingle Agents\nWebSailor-32B [17]\nQwen2.5-32B\n69.78*\n44.0* (53.2†)\n10.75*/\nWebShaper-32B [39]\nQwQ-32B\n69.42*\n48.5* (53.3†)\n12.23*/\nAFM-32B [18]\nQwen2.5-32B\n55.3†\n-\n-/18.0†\nSFR-DR-8B\nQwen3-8B\n63.3\n41.7\n13.2/14.0\nSFR-DR-32B\nQwQ-32B\n72.0\n52.4\n16.2/17.1\nSFR-DR-20B\ngpt-oss-20b\n82.8\n66.0\n28.7\nto reserve space for training models, and vice versa. Toolbox failures and timeouts, CPU and GPU\nout-of-memory (OOM) errors, hanging or crashed inference engines may disrupt ongoing RL training.\nTo mitigate the damage of failed sub-components, we implement a recovery procedure that remedies\nOOM errors and restores failed components, lessening our need for human oversight during training.\nContamination Prevention. During both training and evaluation (§4), we adopt various measures\nto prevent the agent from accessing potentially contaminated content or benchmark solutions via web\nbrowsing. For example, certain sensitive domain names, such as huggingface.co, are blocked and\nautomatically return a “Unavailable” error message to the agent if access is attempted.\n4\nExperiments\nIn this section, we demonstrate the performance of SFR-DR agents across reasoning- and browsing-\nbased benchmarks. We also discuss various ablation studies to provide more insights into the\ncomponents of our method.\n4.1\nMain Evaluation\nBenchmarks and Baselines. We conduct experiments on three benchmarks: FRAMES [15], GAIA\n[24], and Humanity’s Last Exam (HLE) [33]. FRAMES and GAIA are two browsing-focused\nbenchmarks, with the former focusing on multi-hop reasoning QA and the latter focusing on general\nassistant-like tasks. HLE is reasoning focused, covering domains like math and science. For GAIA,\nwe test on the text-only evaluation set. For HLE, we conducted evaluation on the full text only subset,\nwhich includes more than 2100 questions. As some baselines have reported results on a specific\nsubset of 500 samples [20], we also report on this subset as HLE-500.\n7\n\nWe compare SFR-DR against several proprietary systems and open-source multi-agent and single-\nagent systems. In particular, our proprietary baselines include OpenAI DeepResearch with o3 [30],\nGPT-5 and GPT-5-Pro [28], o4-mini [29], and Kimi-Researcher [26]. For open-source multi-\nagent baselines, we compare against OpenDeepSearch (DeepSeek-R1 and QwQ as agents) [3],\nWebThinker [20], MiroThinker [25]. MiroThinker, or Miroflow, utilizes either Qwen3-8B or 32B as\nan orchestrator agent, but relies on Qwen3-235B sub-agents to perform reasoning tasks. Finally, for\nopen-source single-agent systems, we evaluate against the 32B variant of the recent WebSailor [17],\nand WebShaper [39] series, as well as AFM-32B [18].\nEvaluation with Contamination Blocklist. Because all benchmarks we use are publicly available on\nthe Internet, any web agent may inadvertently attempt to visit websites where the benchmark solutions\nare hosted. In such contaminated scenarios, the agent may trivially answer the question without much\nreasoning effort as intended. Recent work [11] shows that up to 3.4% of usable samples for HLE\nmay be contaminated in this manner when running evaluation. When conducting our evaluation, we\nmitigate this contamination risk by using a blocklist as described in §3.3. Specifically, if the agent\nattempts to access a blocked domain name, such as huggingface.co, we return an “Unavailable”\nerror message.\nOf our evaluated baselines, only OpenAI explicitly states that they have taken precautions with a\nblocklist [30, 28, 29]. As such, we report OpenAI numbers directly, if numbers exist for a particular\nbaseline. For all other baselines, we are unable to confirm if contamination precautions exist by\nchecking both technical reports or source code. As a result, we re-run baselines using their publicly\nreleased implementations modified to use a similar blocklist, and report Pass@1. As a result, numbers\nthat we report may differ from those reported in technical reports or online. We mark such evaluation\nruns appropriately when presenting our results.\nMain Evaluation Results. Table 1 shows the main evaluation results. Notably, our SFR-DR-20B\nsingle-agent outperforms various baselines of comparable sizes, even challenging potentially larger\nand proprietary agents such as OpenAI Deep Research with o3 [30]. In particular, SFR-DR-20B\nexcels not only at using its provided tools but also in complex reasoning settings like HLE, with 65%\nrelative improvement over gpt-oss-20b. This stems from a combination of better agentic workflow\nand effective RL fine-tuning with our synthesized data. Our 8B and 32B variants also demonstrate\nstrong performance compared to open-source baselines [20, 39, 17] trained from the same set of\ninitial models.\n4.2\nAnalysis\nIn this section, we conduct various ablation studies to provide more insights into our methods.\n4.2.1\nEffectiveness of Modified Agentic Workflow\nWe demonstrate the effectiveness of our single-agent agentic workflow for QwQ-32B and Qwen3-8B.\nIn particular, we run inference using the default multi-turn chat templates provided by the models\nand our agentic workflow as described in §3.1, which condenses all past turns into the first user turn.\nAs shown in Table 2, by carefully managing multi-turn conversations, we see significant gains in\nperformance, most notably a 10% absolute increase on FRAMES for the 32B model. To explain how\nan inference-time trick can yield such improvements, we manually inspect trajectories produced by\neach model with and without our agentic scaffolding. We find a consistent theme: The “thinking”\ntokens generated in intermediate steps degrade in quality once past the first assistant turn, resulting\nin the model either prematurely giving up or producing degenerate or repetitive outputs. While\nthese models have demonstrated strong performance in reasoning settings, such as math and code,\nsuch settings are typically conducted in single-step. Agentic research, on the other hand, requires\nlong multi-turn interactions. We hypothesize that such models have been post-trained to focus more\non single-turn reasoning tasks, and as a result, degenerate quickly as multi-turn tasks move out of\ntraining distribution. Our workflow re-casts the multi-turn interaction into a single-turn interaction,\nbringing the inference task closer to settings that the model originally excels at. This, in turn, yields\ntraining-free gains.\nOur agentic workflow also features fault tolerance, which attempts to correct model errors that arise\nout of inference stochasticity. As described in §3.1, we attempt to repair faulty tool calls, returning\nerror messages or retry if the repair is unsuccessful. These fault tolerance mechanisms help steer the\n8\n\nFigure 2: Average training trajectory lengths of SFR-DR-8B agents over the course of RL training\nwith and without our proposed length normalization (§3.3). Without the normalization term, tool\nusage rapidly increases but the performance on HLE [33] collapses. On the other hand, our length\nnormalization regulates tool usage, improving performance.\nmodel back on the right track if a misstep occurs at an intermediate step, allowing the model continue\nto run until it proposes a final answer.\n4.2.2\nMore Tool Calls Do Not Equate Better Scores\nPrior work suggests that increased tool usage can improve performance, framing this as a form of test-\ntime scaling [30, 26]. This intuition holds only when tool calls are diverse and strategically executed.\nUnder a standard RL with verifiable rewards (RLVR) objective, the assumption is that achieving\nthe correct final answer reflects effective tool use, although this outcome is more hoped for than\nguaranteed. Crucially, the training objective itself does not explicitly enforce such behavior. Figure 2\ncompares training runs with and without our length-normalized advantage modification introduced in\n§3.3 for SFR-DR-8B agents. Without normalization, tool usage rises rapidly, but both training reward\nand validation performance decline. Closer inspection shows that the agent degenerates into making\nrepetitive, identical tool calls. This occurs because long trajectories contribute disproportionately\nmore action steps to each batch, dominating the loss; as a result, they are reinforced and appear more\nfrequently, even when heavily penalized through negative rewards or length penalties. In contrast,\nwith normalization, training is more stable and performance improves, even though tool usage grows\nmore moderately.\n4.2.3\nTool Usage Analysis\nFigure 3a reports the average number of tool calls made by different SFR-DR agents before and after\nRL training on HLE. As shown in §4.2.2, even though our RL objective limits rapid increases in\ntool usage, RL training produces models that make moderately more tool calls than pre-RL variants,\nimproving overall performance. Another interesting observation is that SFR-DR-20B, which is trained\nfrom gpt-oss-20b, makes up to 10 times more tool calls than QwQ and Qwen3 variants, which tend to\ndo only internal reasoning for many samples. This behavior may be a consequence of our hypothesis\nin §4.2.1 that the Qwen-family of models have been optimized primarily for single-turn reasoning\nTable 2: Comparison between SFR-DR agentic workflow and the default multi-turn workflow\nspecified in the model chat template.\nAgent\nFRAMES\nHLE\nQwen3-8B multi-turn\n52.5\n8.8\nQwQ-32B multi-turn\n58.0\n12.3\nSFR-DR-8B (pre-RL)\n58.8\n9.9\nSFR-DR-32B (pre-RL)\n68.0\n13.9\n9\n\n(a) Average tool usage by models\n(b) Average step-level model response length\nFigure 3: Comparison of (a) average tool usage and (b) average step-level response lengths (tokens)\non HLE across different models.\ntasks. On the other hand, gpt-oss-20b appears better primed for agentic training, as indicated by its\npre-RL number of tool calls. RL training further improves this number.\n4.2.4\nResponse Length Analysis\nThe response length, primarily the length of “thinking” chain-of-thoughts (CoTs), provides another\ninsight into model behavior. Figure 3b reports the average number of generated tokens at each agentic\nstep (step-level) for different SFR-DR models on HLE. As shown, the SFR-DR-20B model generates\nless than 2,000 tokens per step, which is 4-5 times fewer than the 8B and 32B counterparts. This\nindicates that the gpt-oss-20b model is much more token-efficient than the Qwen-family models, with\nthe latter tending to overthink and generate excessively long per-step CoTs. These inherently longer\nCoTs also make these models more difficult to steer via fine-tuning. More interestingly, while the RL\ntraining leads to an increase in average response length for QwQ and Qwen3 models, it causes the\ngpt-oss-20b variant to shrink in response length, making it even more token-efficient.\n5\nConclusion\nOverall, we propose a compact synthetic-data reinforcement learning recipe that adapts reasoning-\noptimized LLMs into native Autonomous Single-Agent systems for Deep Research. Applied to\nopen-source backbones, our best variant attains 28.7% on Humanity’s Last Exam. Our analysis\nhighlights the contributions of various components of our system as well as impact of our RL training\nprocess on the agent behavior.\nReferences\n[1] Sandhini Agarwal, Lama Ahmad, Jason Ai, Sam Altman, Andy Applebaum, Edwin Arbus,\nRahul K Arora, Yu Bai, Bowen Baker, Haiming Bao, et al. gpt-oss-120b & gpt-oss-20b model\ncard. arXiv preprint arXiv:2508.10925, 2025.\n[2] Arash Ahmadian, Chris Cremer, Matthias Gallé, Marzieh Fadaee, Julia Kreutzer, Olivier\nPietquin, Ahmet Üstün, and Sara Hooker. Back to basics: Revisiting reinforce style optimization\nfor learning from human feedback in llms. arXiv preprint arXiv:2402.14740, 2024.\n[3] Salaheddin Alzubi, Creston Brooks, Purva Chiniya, Edoardo Contente, Chiara von Gerlach,\nLucas Irwin, Yihan Jiang, Arda Kaz, Windsor Nguyen, Sewoong Oh, et al. Open deep search:\nDemocratizing search with open-source reasoning agents. arXiv preprint arXiv:2503.20201,\n2025.\n[4] Muhammad Arslan, Hussam Ghanem, Saba Munawar, and Christophe Cruz. A survey on rag\nwith llms. Procedia computer science, 246:3781–3790, 2024.\n[5] Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, and\nFeng Zhao. Mindsearch: Mimicking human minds elicits deep ai searcher. arXiv preprint\narXiv:2407.20183, 2024.\n10\n\n[6] Prafulla Kumar Choubey, Xiangyu Peng, Shilpa Bhagavath, Kung-Hsiang Huang, Caiming\nXiong, and Chien-Sheng Wu. Benchmarking deep search over heterogeneous enterprise data.\narXiv preprint arXiv:2506.23139, 2025.\n[7] Guanting Dong, Hangyu Mao, Kai Ma, Licheng Bao, Yifei Chen, Zhongyuan Wang, Zhongxia\nChen, Jiazhen Du, Huiyang Wang, Fuzheng Zhang, et al. Agentic reinforced policy optimization.\narXiv preprint arXiv:2507.19849, 2025.\n[8] Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan\nJiang, Jinxin Chi, and Wanjun Zhong. Retool: Reinforcement learning for strategic tool use in\nllms. arXiv preprint arXiv:2504.11536, 2025.\n[9] Google.\nTry deep research and our new experimental model in gemini,\nyour\nai\nassistant.\n2025.\nURL\nhttps://blog.google/products/gemini/\ngoogle-gemini-deep-research/.\n[10] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\nShirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in\nllms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025.\n[11] Ziwen Han, Meher Mankikar, Julian Michael, and Zifan Wang. Search-time data contamination.\narXiv preprint arXiv:2508.13180, 2025.\n[12] Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa. Constructing\na multi-hop QA dataset for comprehensive evaluation of reasoning steps. In Donia Scott,\nNuria Bel, and Chengqing Zong, editors, Proceedings of the 28th International Conference\non Computational Linguistics, pages 6609–6625, Barcelona, Spain (Online), December 2020.\nInternational Committee on Computational Linguistics. doi: 10.18653/v1/2020.coling-main.580.\nURL https://aclanthology.org/2020.coling-main.580.\n[13] Abhinav Java, Ashmit Khandelwal, Sukruta Midigeshi, Aaron Halfaker, Amit Deshpande, Navin\nGoyal, Ankur Gupta, Nagarajan Natarajan, and Amit Sharma. Characterizing deep research: A\nbenchmark and formal definition. arXiv preprint arXiv:2508.04183, 2025.\n[14] Bowen Jin, Hansi Zeng, Zhenrui Yue, Jinsung Yoon, Sercan Arik, Dong Wang, Hamed\nZamani, and Jiawei Han. Search-r1: Training llms to reason and leverage search engines\nwith reinforcement learning. arXiv preprint arXiv:2503.09516, 2025.\n[15] Satyapriya Krishna, Kalpesh Krishna, Anhad Mohananey, Steven Schwarcz, Adam Stambler,\nShyam Upadhyay, and Manaal Faruqui. Fact, fetch, and reason: A unified evaluation of\nretrieval-augmented generation. arXiv preprint arXiv:2409.12941, 2024.\n[16] LangChain-AI.\nOpen deep research github.\n2025.\nURL https://github.com/\nlangchain-ai/open_deep_research.\n[17] Kuan Li, Zhongwang Zhang, Huifeng Yin, Liwen Zhang, Litu Ou, Jialong Wu, Wenbiao Yin,\nBaixuan Li, Zhengwei Tao, Xinyu Wang, et al. Websailor: Navigating super-human reasoning\nfor web agent. arXiv preprint arXiv:2507.02592, 2025.\n[18] Weizhen Li, Jianbo Lin, Zhuosong Jiang, Jingyi Cao, Xinpeng Liu, Jiayu Zhang, Zhenqiang\nHuang, Qianben Chen, Weichen Sun, Qiexiang Wang, et al. Chain-of-agents: End-to-end agent\nfoundation models via multi-agent distillation and agentic rl. arXiv preprint arXiv:2508.13167,\n2025.\n[19] Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, and\nZhicheng Dou. Search-o1: Agentic search-enhanced large reasoning models. arXiv preprint\narXiv:2501.05366, 2025.\n[20] Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen,\nand Zhicheng Dou. Webthinker: Empowering large reasoning models with deep research\ncapability. arXiv preprint arXiv:2504.21776, 2025.\n[21] Xuefeng Li, Haoyang Zou, and Pengfei Liu. Torl: Scaling tool-integrated rl. arXiv preprint\narXiv:2503.23383, 2025.\n11\n\n[22] Xinbin Liang, Jinyu Xiang, Zhaoyang Yu, Jiayi Zhang, Sirui Hong, Sheng Fan, and Xiao\nTang. Openmanus: An open-source framework for building general ai agents, 2025. URL\nhttps://doi.org/10.5281/zenodo.15186407.\n[23] Zuxin Liu, Thai Hoang, Jianguo Zhang, Ming Zhu, Tian Lan, Shirley Kokane, Juntao Tan,\nWeiran Yao, Zhiwei Liu, Yihao Feng, et al. Apigen: Automated pipeline for generating verifiable\nand diverse function-calling datasets. arXiv preprint arXiv:2406.18518, 2024.\n[24] Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia:\na benchmark for general ai assistants. In The Twelfth International Conference on Learning\nRepresentations, 2023.\n[25] MiroMind. Miromind open deep research. 2025. URL https://miromind.ai/blog/\nmiromind-open-deep-research.\n[26] MoonshotAI. Kimi-researcher: End-to-end rl training for emerging agentic capabilities. 2025.\nURL https://moonshotai.github.io/Kimi-Researcher/.\n[27] Xuan-Phi Nguyen, Shrey Pandit, Senthil Purushwalkam, Austin Xu, Hailin Chen, Yifei Ming,\nZixuan Ke, Silvio Savarese, Caiming Xong, and Shafiq Joty. Sfr-rag: Towards contextually\nfaithful llms. arXiv preprint arXiv:2409.09916, 2024.\n[28] OpenAI.\nGpt-5 system card.\n2025.\nURL\nhttps://cdn.openai.com/\ngpt-5-system-card.pdf.\n[29] OpenAI.\nOpenai\no3\nand\no4-mini\nsystem\ncard.\n2025.\nURL\nhttps://\ncdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/\no3-and-o4-mini-system-card.pdf.\n[30] OpenAI. Deep research system card. Technical report, OpenAI, August 2025. URL https:\n//cdn.openai.com/deep-research-system-card.pdf.\n[31] Jie Ouyang, Ruiran Yan, Yucong Luo, Mingyue Cheng, Qi Liu, Zirui Liu, Shuo Yu, and Daoyu\nWang. Training powerful llm agents with end-to-end reinforcement learning, 2025. URL\nhttps://github.com/0russwest0/Agent-R1.\n[32] Perplexity. Introducing perplexity deep research. 2025. URL https://www.perplexity.\nai/hub/blog/introducing-perplexitydeep-research.\n[33] Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin\nZhang, Mohamed Shaaban, John Ling, Sean Shi, et al. Humanity’s last exam. arXiv preprint\narXiv:2501.14249, 2025.\n[34] Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and\nChelsea Finn. Direct preference optimization: Your language model is secretly a reward model.\narXiv preprint arXiv:2305.18290, 2023.\n[35] Revanth Gangi Reddy, Sagnik Mukherjee, Jeonghwan Kim, Zhenhailong Wang, Dilek Hakkani-\nTur, and Heng Ji. Infogent: An agent-based framework for web information aggregation. arXiv\npreprint arXiv:2410.19054, 2024.\n[36] Pascal J Sager, Benjamin Meyer, Peng Yan, Rebekka von Wartburg-Kottler, Layan Etaiwi, Aref\nEnayati, Gabriel Nobel, Ahmed Abdulkadir, Benjamin F Grewe, and Thilo Stadelmann. Ai\nagents for computer use: A review of instructionbased computer control, gui automation, and\noperator assistants. arXiv preprint arXiv:2501.16150, 2025.\n[37] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal\npolicy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.\n[38] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang,\nMingchuan Zhang, YK Li, Yang Wu, et al. Deepseekmath: Pushing the limits of mathematical\nreasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.\n12\n\n[39] Zhengwei Tao, Jialong Wu, Wenbiao Yin, Junkai Zhang, Baixuan Li, Haiyang Shen, Kuan Li,\nLiwen Zhang, Xinyu Wang, Yong Jiang, et al. Webshaper: Agentically data synthesizing via\ninformation-seeking formalization. arXiv preprint arXiv:2507.15061, 2025.\n[40] Kimi Team, Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen,\nYanru Chen, Yuankun Chen, Yutian Chen, et al. Kimi k2: Open agentic intelligence. arXiv\npreprint arXiv:2507.20534, 2025.\n[41] Qwen Team. Qwq-32b: Embracing the power of reinforcement learning, March 2025. URL\nhttps://qwenlm.github.io/blog/qwq-32b/.\n[42] Zhepei Wei, Wenlin Yao, Yao Liu, Weizhi Zhang, Qin Lu, Liang Qiu, Changlong Yu, Puyang\nXu, Chao Zhang, Bing Yin, et al. Webagent-r1: Training web agents via end-to-end multi-turn\nreinforcement learning. arXiv preprint arXiv:2505.16421, 2025.\n[43] Ronald J Williams.\nSimple statistical gradient-following algorithms for connectionist\nreinforcement learning. Machine learning, 8(3):229–256, 1992.\n[44] Renjun Xu and Jingwen Peng.\nA comprehensive survey of deep research:\nSystems,\nmethodologies, and applications. arXiv preprint arXiv:2506.12594, 2025.\n[45] Zhenghai Xue, Longtao Zheng, Qian Liu, Yingru Li, Zejun Ma, and Bo An. Simpletir: End-to-\nend reinforcement learning for multi-turn tool-integrated reasoning. https://simpletir.\nnotion.site/report, 2025. Notion Blog.\n[46] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan\nLi, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang,\nJianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin\nYang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li,\nTianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang,\nYu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report.\narXiv preprint arXiv:2412.15115, 2024.\n[47] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu,\nChang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint\narXiv:2505.09388, 2025.\n[48] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan\nSalakhutdinov, and Christopher D. Manning. HotpotQA: A dataset for diverse, explainable\nmulti-hop question answering. In Conference on Empirical Methods in Natural Language\nProcessing (EMNLP), 2018.\n[49] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\nReact: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629,\n2022.\n[50] Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Weinan Dai,\nTiantian Fan, Gaohong Liu, Lingjun Liu, et al. Dapo: An open-source llm reinforcement\nlearning system at scale. arXiv preprint arXiv:2503.14476, 2025.\n[51] Wentao Zhang, Ce Cui, Yilei Zhao, Rui Hu, Yang Liu, Yahui Zhou, and Bo An. Agentorchestra:\nA hierarchical multi-agent framework for general-purpose task solving.\narXiv preprint\narXiv:2506.12508, 2025.\n[52] Chujie Zheng, Shixuan Liu, Mingze Li, Xiong-Hui Chen, Bowen Yu, Chang Gao, Kai Dang,\nYuqiong Liu, Rui Men, An Yang, et al. Group sequence policy optimization. arXiv preprint\narXiv:2507.18071, 2025.\n[53] Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Chuyue Livia Sun, Jeff Huang, Cody Hao Yu,\nShiyi Cao, Christos Kozyrakis, Ion Stoica, Joseph E Gonzalez, et al. Sglang: Efficient execution\nof structured language model programs. Advances in neural information processing systems,\n37:62557–62583, 2024.\n13\n"
    },
    {
      "arxiv_id": "2509.05975",
      "full_text": "ConstStyle: Robust Domain Generalization with Unified Style Transformation\nNam Duong Tran 1\nNam Nguyen Phuong 1\nHieu H. Pham 2\nPhi Le Nguyen 1*\nMy T. Thai 3*\n1 Institute for AI Innovation and Societal Impact, Hanoi University of Science and Technology\n2 VinUniversity\n3 University of Florida\nAbstract\nDeep neural networks often suffer performance drops when\ntest data distribution differs from training data. Domain\nGeneralization (DG) aims to address this by focusing on\ndomain-invariant features or augmenting data for greater\ndiversity. However, these methods often struggle with lim-\nited training domains or significant gaps between seen\n(training) and unseen (test) domains. To enhance DG ro-\nbustness, we hypothesize that it is essential for the model\nto be trained on data from domains that closely resemble\nunseen test domains—an inherently difficult task due to the\nabsence of prior knowledge about the unseen domains. Ac-\ncordingly, we propose ConstStyle, a novel approach that\nleverages a unified domain to capture domain-invariant fea-\ntures and bridge the domain gap with theoretical analysis.\nDuring training, all samples are mapped onto this unified\ndomain, optimized for seen domains. During testing, un-\nseen domain samples are projected similarly before predic-\ntions. By aligning both training and testing data within this\nunified domain, ConstStyle effectively reduces the impact\nof domain shifts, even with large domain gaps or few seen\ndomains. Extensive experiments demonstrate that Const-\nStyle consistently outperforms existing methods across di-\nverse scenarios. Notably, when only a limited number of\nseen domains are available, ConstStyle can boost accuracy\nup to 19.82% compared to the next best approach. 1\n1. Introduction\nDeep neural networks (DNNs) often experience significant\nperformance degradation when deployed on unseen test do-\nmains, which differ in distribution from the training data.\nThis issue, known as domain shift, poses a fundamental\nchallenge in real-world applications where data distribu-\ntions are inherently diverse and unpredictable. Since it is\nimpractical to collect data representative of all possible do-\nmains, bridging the gap between training (seen) and test-\ning (unseen) domains is crucial for achieving robust perfor-\nmance—yet remains a major hurdle.\n*Corresponding Authors\n1Source code: https://github.com/nduongw/ConstStyle\nDomain generalization (DG) addresses this issue by\ntraining models that generalize well to unseen domains\nwithout relying on their data during training [20, 30]. Ex-\nisting DG methods primarily focus on two strategies: (1)\nlearning domain-invariant features, and (2) augmenting\ntraining data to enhance domain diversity. Invariant rep-\nresentation learning methods extract shared features across\ndomains, minimizing the impact of domain-specific varia-\ntions [2, 3, 11, 15]. However, these approaches typically\nrequire numerous diverse domains to effectively capture in-\nvariance, making them costly and often impractical. Alter-\nnatively, data augmentation methods increase domain diver-\nsity [10, 13, 26, 29], fundamentally based on the assumption\nthat training with more data from diverse domains will pro-\nduce better performance. Yet, our empirical analysis shows\nthat increasing the number of seen domains does not always\nimprove performance on unseen domains. In fact, train-\ning on fewer but carefully selected domains can sometimes\nyield better generalization, such as resulting in higher accu-\nracy, as shown in Figure 1 or having greater class separa-\ntion, as shown in Figure 2.\nFurthermore, existing methods typically emphasize the\ntraining process, focusing on seen domains while neglect-\ning the testing phase, where the domain gap becomes most\npronounced. This oversight reveals another key limitation\nin current approaches, as they do not adequately address\nthe unseen domain at inference time. This leads to a criti-\ncal question: How can we enhance model generalization on\nunseen domains that are unknown during training but must\nbe handled effectively during inference?\nTo overcome these challenges, we propose ConstStyle,\na novel DG framework that unifies the treatment of both\ntraining and testing processes.\nConstStyle leverages our\nnewly introduced concept of unified domain, which acts as a\ncommon representation space that minimizes style discrep-\nancies between different domains, both seen and unseen.\nSpecifically, during training, all samples are aligned with\nthis unified domain to extract consistent features. At infer-\nence, test samples undergo a style transformation to match\nthe unified domain. By aligning data in this manner, Const-\nStyle reduces the impact of domain shifts, even when there\narXiv:2509.05975v1  [cs.CV]  7 Sep 2025\n\n(a) Digits5 dataset.\n(b) VLCS dataset.\nFigure 1.\nAccuracy of ConvNet with varying\nnumbers of seen domains during training.\nIn\nsome cases, using fewer seen domains leads to\nimproved performance.\n(a) Training ConvNet with 4 seen do-\nmains (left) vs single seen domain (right)\non Digits5 dataset.\n(b) Training ResNet18 with 3 seen do-\nmains (left) vs single seen domain (right)\non VLCS dataset.\nFigure 2. The illustrations indicate that training on a single seen domain can\nsometimes produce more defined class boundaries than training across multiple\ndomains. Each dot represents an instance, with colors signifying the labels.\nis a significant gap between seen and unseen domains. Our\napproach is grounded in a theoretical framework that guides\nthe selection of the unified domain to optimize generaliza-\ntion, providing a robust solution to the DG problem.\nThe main contributions of this paper are as follows:\n• We propose ConstStyle, a novel domain generalization\nframework that projects all data into a unified domain, ad-\ndressing both training and testing phases to improve gen-\neralization on unseen domains.\n• We present a theoretically grounded algorithm for defin-\ning such the unified domain, ensuring its reliability and\neffectiveness in reducing domain shifts.\n• We introduce an alignment algorithm that projects unseen\nsamples onto the unified domain during testing, with the\ngoal of reducing information loss and closing the domain\ngap between the testing and training domains. This algo-\nrithm is backed by a theoretical analysis that establishes\nperformance bounds for the model on unseen domains.\n• Extensive experiments in various scenarios with bench-\nmark datasets: PACS, Digit5, and Duke-Market101, show\nthat ConstStyle improves precision up to 19.82%.\n2. Related works\nDomain Generalization (DG) is a pivotal research area\naimed at enhancing model robustness and reliability, es-\npecially in high-stakes applications. DG focuses on out-\nof-distribution generalization, enabling models to perform\nwell on unseen domains by training on one or more source\ndomains. Various methods have been proposed to address\ndomain shifts, generally categorized into the following ap-\nproaches.\nInvariant Representation Learning. Invariant represen-\ntation learning seeks to extract features consistent across\ndomains.\nDomain alignment methods, such as CIDDG\n[11], minimize distributional differences across domains.\nRather than enforcing invariance across all features, dis-\nentangled feature learning approaches [1, 15] separate fea-\ntures into domain-specific and domain-invariant compo-\nnents, then learn them simultaneously. To further enhance\nthis, authors in [2] introduce RIDG, a method that learns\nto ensure representations for samples within the same class\nremain consistent across domains by utilizing a rationale\nmatrix and rationale invariant loss function, fostering im-\nproved generalization.\nAdditionally, normalization tech-\nniques [3, 14] remove style information to produce invari-\nant representations. Despite their promising results, these\nmethods require a large number of domains to effectively\nextract invariant features, posing challenges when deploy-\ning the model in real-world environments.\nData Augmentation. Numerous strategies, based on im-\nage level, such as AugMix [7] and CutMix [23] are de-\nveloped to achieve robust augmentation. Mixup [24] goes\nfurther by using pairwise linear interpolation in both image\nand label spaces, while Manifold Mixup [18] extends this\nto the feature level, boosting generalization. Additionally,\n[19] enhances the robustness by generating adversarial ex-\namples from hypothetical target domains, thereby strength-\nening the robustness of the model. Taking a different ap-\nproach based on the observation that style statistics (mean\nand covariance) capture essential style information specific\nto each domain, style augmentation increases the training\ndata quantity. For instance, StyDeSty [12] uses the styl-\nization module to generate various style versions given a\nsource domain. TF-Cal [27] utilizes linear combinations\nof two seen styles and combinations of a seen style with\nthe representative style, while MixStyle [29] mixes the seen\nstyle within batches to increase the diversity of the source\ndomain. DSU [10] further estimates feature statistic un-\ncertainty to sample new style features, simulating out-of-\ndistribution domains, while CSU [26] incorporates feature\ncorrelation in style mixing to retain semantic consistency,\nand Style Neophile [9] selects style prototypes from a style\nqueue based on Maximum Mean Discrepancy, capturing\nsource style distributions. However, as shown in our anal-\nysis 4.2.5, training with numerous domains does not al-\nways enhance model performance due to the dissimilarity\nbetween source and unseen domains.\nTo address the aforementioned challenges, we introduce\nConstStyle, a novel approach that alleviates the domain\nshift problem by projecting all domains into a unified space.\nThis reduces the impact of domain limitations while en-\n\nFigure 3. Overview of ConstStyle.\nabling the model to learn consistent features, thereby en-\nhancing its generalizability.\n3. Our Proposed ConstStyle\n3.1. Preliminaries\nNotations and Definitions. Throughout this paper, we as-\nsume that there are N seen domains S1, ..., SN and M un-\nseen domains U1, ..., UM (where N and M are not known in\nadvance). We focus on the classification task. Let ω denote\nthe model of interest, which consists of two components: a\nrepresentation learning module, denoted by θ, and a classi-\nfier head, denoted by ζ. As noted in previous studies [29],\nthe intermediate layers of θ often capture domain-specific\nstyle information. Thus, θ can be decomposed into two\nparts: θ = θf(θs(x)), where θs serves as the style extractor,\nand θf generates the final representation of the image [8].\nDefinition 1 (Instance Style) Given an input image x, let\nzx ∈RC×H×W be the style feature of x, i.e., zx = θs(x).\nWe define by ϵx the style statistic of x, which captures the\nchannel-wise mean and variance of zx. Specifically, we ex-\npress ϵx as ϵx = concat(µx, σx), where µx ∈RC and\nσx ∈RC are defined as follows:\n  \\ n\no\nnu\nm\nb\ner \n\\\nm\nu _\n{x_c} &=\n \\f r\na\nc\n \n{\n1\n}{\nH\nW\n}\\s\nu\nm\n _{\nh=1}^H \\ s um _{w=1}^W z_{x_{c, h, w}}, \\\\ \\nonumber \\sigma _{x_c} &= \\sqrt {\\frac {1}{HW}\\sum _{h=1}^H \\sum _{w=1}^W (z_{x_{c, h,w}}-\\mu _{x_c})^2}.\nDefinition 2 (Domain Style) Let S\nbe a domain and\nDS a set of data samples belonging to S, DS\n=\n{(x1, y1), ..., (x|DS|, y|DS|)}, and let ϵxi be the style statis-\ntic of instance xi. We define the style of domain DS, denoted\nas PS as multivariate normal distribution representing the\nstyle statistics of DS’s elements, i,e,., {ϵxi}|DS|\ni=1 . The mean\nϵS and variance ΣS of PS is calculated as follows:\n  \\\ne\npsil\non _\n{\n\\ma\nthca l {\nS\n}} =\n \\fr\na\nc {\n1}{| D _\\ma thca l  {S}|} \\sum _{i=1}^{|D_\\mathcal {S}|} \\epsilon _{x_i},\\Sigma _\\mathcal {S} = \\frac {1}{|D_\\mathcal {S}|}\\sum _{i=1}^{|D_\\mathcal {S}|} (\\epsilon _{x_i} - \\epsilon _{\\mathcal {S}})^T (\\epsilon _{x_i} - \\epsilon _{\\mathcal {S}}).\nProblem Formulation. Let (X, Y) denote the space of in-\nputs and labels. The DG problem asks us to identify a model\nω∗, which is trained on all seen domains {Sk}N\nk=1, and per-\nforms well on both seen domains {Sk}N\nk=1 and unseen do-\nmains {Uj}M\nj=1 (j = 1, ...M). This can be formulated as\nfollows:\n \\ n onu mbe\nr\n \n\\\no\nm\nega\n \n^* = \\ar\ng \\min _ {\\o\nm\ne\ng\na }\n \n\\left ( \n\\sum _{j =1}\n^\nM \\mathop {\\mathbb {E}}_{(u,y) \\in \\mathcal {U}_j}\\left [ l(\\omega (u), y) \\right ] \\right . \\\\ \\left . + \\sum _{k=1}^N \\mathop {\\mathbb {E}}_{(x,y) \\in \\mathcal {S}_k}\\left [ l(\\omega (x), y) \\right ] \\right ), \\label {formulation2}\nwhere l is the loss function, which is varied depending on\nthe task (e.g. cross entropy loss for the classification task).\n3.2. Overview\nFigure 3 presents the workflow of ConstStyle, designed to\nenhance accuracy across both seen and unseen domains by\naddressing both training and testing phases. In the training\nphase, ConstStyle follows three main steps: (i) determining\nthe style of the unified domain; (ii) transforming the style\nof all samples in the training data set (from the seen do-\nmains) to match the unified domain’s style; and (iii) training\nthe model using these style-aligned samples. In the testing\nphase, samples from the unseen domain are first adjusted to\nalign with the unified domain style before being processed\nby the trained model for inference.\nA central challenge is defining an appropriate unified do-\nmain, especially since unseen domains are unknown during\ntraining. To tackle this, we introduce an algorithm that con-\nstructs the unified domain using only information from seen\ndomains, optimizing its selection for better performance on\nseen data. However, since the unified domain is defined\nsolely using information from seen domains, a significant\ngap may exist between the unified and unseen domains.\nThis can lead to substantial data distortion when mapping\nunseen samples to the unified domain, potentially decreas-\ning model performance. To address this issue, we propose\na partial alignment algorithm that efficiently aligns the test\nsamples to the unified domain. This solution balances the\nalignment of the testing sample style with the trained style\n(thus addressing the domain shift) while preserving the es-\nsential information of the testing data (thus avoiding perfor-\nmance degradation due to excessive data distortion).\nThe details of the algorithm for determining the style of\nthe unified domain are presented in Section 3.3, while the\nalgorithms for the training and testing process are detailed\nin Sections 3.4 and 3.5.\n3.3. Unified Domain Determination\nThe unified domain is designed to maximize the model’s\nperformance on seen domains. To this end, our unified do-\nmain is defined as follows.\n\nDefinition 3 (Unified Domain) Given N\nseen domains\n{Sk}N\nk=1, each Sk has an associated domain style PSk fol-\nlows a distribution N(ϵSk, ΣSk). The unified domain T is\nthe one with the domain style that serves as the Barycenter\nof {PSk}N\nk=1 (denoted as B). Specifically, the Barycenter\n[31] is a distribution, i.e., B ∼N(ϵB, ΣB), that intuitively\nminimizes the total distance to {Pk}N\nk=1, where ϵB is deter-\nmined as follows:\n  \\ n\no\nn\nu\nmbe\nr \\epsilon _B = \\frac {1}{N} \\sum _{k=1}^N \\epsilon _{S_k}. \nThe covariance matrix ΣB is obtained by solving an itera-\ntive optimization problem. Starting with an initial covari-\nance matrix ΣB0 =\n1\nN\nPN\nk=1 ΣSk, the update formula at\neach iteration i is given by:\n  \\no n u\nm\nb\ne\nr \\\nS\ni\ng\nm\na _{B_\n{\ni\n +\n 1\n} } = \\frac {1}{N} \\sum _{k=1}^N \\left ( \\Sigma _{B_i}^{\\frac {1}{2}} \\Sigma _{S_k} \\Sigma _{B_i}^{\\frac {1}{2}} \\right )^{\\frac {1}{2}}. \nNext, we explain the rationale behind our unified domain\nand present a theoretical analysis of the model’s perfor-\nmance when trained with data projected onto this domain.\nTheoretical Analysis. Let Dk denote the dataset from do-\nmain Sk, and DT\nk represent Dk after it has been mapped to\nthe unified domain. Naturally, the model ω often achieves\noptimal performance on the seen domain Sk when trained\ndirectly on the original dataset Dk. Therefore, we aim at\ndesigning a unified domain such that training ω on DT\nk\nachieves performance comparable to training on Dk.\nLemma 1 Let ω∗and ωT be the models trained using Dk\nand DT\nk , respectively. Let us denote by LSk and LST\nk the\nempirical losses of ω∗and ωT calculated over Dk and\nDT\nk , respectively. Then, the gap between LSk and LST\nk is\nbounded as follows:\n  L\n^ { \\ma t h c al {S } _k^ { T}} -  L^{ \\mathcal {S}_k} \\leq \\beta \\times \\left (\\mathcal {D}_\\mu (\\mathcal {T}, \\mathcal {S}_k) +\\mathcal {D}_\\sigma (\\mathcal {T},\\mathcal {S}_k) \\right ), \n(1)\nwhere Dµ(T , Sk) and Dσ(T , Sk) denote the distances be-\ntween the means and standard deviations of distributions of\nunified domain T and seen domain Sk, respectively; β is\nthe upper bound of Lipschitz coefficient of the loss function\non all seen domains. (The proof is shown in Suppl. B.1).\nTheorem 1 The disparity in empirical losses computed\nacross all the seen data, between the model trained on data\nprojected onto the unified domain and those trained on the\noriginal data from the seen domains \\ifmm\node \\lbrace \\else \\textbraceleft \\fi S_k\\}_{k=1}^{N}, is bound by\nthe following inequality:\n \n \n\\la\nb\nel \n{ e q:d\ni\ns t a\nn\nc\ne o\nptim}  \\su m  _{k = 1}^N  \\left ( L^{\\mathcal {S}_k^{T}} - L^{\\mathcal {S}_k} \\right ) \\leq \\beta \\times \\sum _{k=1}^N \\left ( \\mathcal {D}_\\mu (\\mathcal {T}, \\mathcal {S}_k) +\\mathcal {D}_\\sigma (\\mathcal {T},\\mathcal {S}_k) \\right ). \n(2)\n(The proof is presented in Suppl. B.2)\nTheorem 1 suggests that the unified domain should be se-\nlected to minimize the distance on the right side of (2).\nPractical Algorithm. Now, assuming that we have n train-\ning samples: {(xi, yi)}n\ni=1, with each xi associated with a\nstyle statistic ϵxi. If the seen domains {Sk}N\nk=1 related to\nthese samples are known, Definition 3 could be applied di-\nrectly to determine the unified domain style.\nIn practical scenarios, however, we usually have only\nthe training samples without specific domain labels.\nTo\naddress this, we introduce an efficient algorithm to esti-\nmate the style statistics of the seen domains before applying\nDefinition 3. Specifically, we utilize a Gaussian Mixture\nModel (GMM) to capture the distribution of the style statis-\ntics {ϵxi}n\ni=1. The GMM Expectation-Maximization Algo-\nrithm is then employed to cluster {ϵxi}n\ni=1 into N ′ distinct\ngroups. The number of clusters N ′ is treated as a hyperpa-\nrameter (which can be set to the number of seen domains\nif this information is known). Since samples from the same\ndomain typically exhibit similar style statistics, each clus-\nter approximately represents style statistics from the same\ndomain. Consequently, the distribution of each cluster can\nbe considered as an approximate style statistic for that do-\nmain. Finally, Definition 3 is applied to the normal distribu-\ntions associated with these clusters to establish the unified\ndomain’s style statistic.\nIn practice, calculating the exact Barycenter can be com-\nputationally intensive. Thus, a straightforward yet effective\napproximation involves defining domain style of the unified\ndomain, i.e., PT = N(ϵT , ΣT ), by averaging the style dis-\ntribution of the clusters as follows:\n  \\ e\np s\ni l\no\nn ^\n{T} = \\ f\nr a\nc \n{\n1}{\nN'} \\sum _{k=1}^{N'} \\epsilon _{\\mathcal {C}_k}, \\Sigma ^{T} = \\frac {1}{N'} \\sum _{k=1}^{N'} \\Sigma _{\\mathcal {C}_k},\n(3)\nwhere N ′ is the number of clusters, and ϵCk, ΣCk are mean\nand covariance matrix of the Gaussian distribution associ-\nated with cluster Ck, respectively. Details of the unified\ndomain determination is provided in Algorithm 2 (Supple-\nmentary).\n3.4. Training Process\nStyle transformation involves adapting the original style of\ntraining samples to match the style of the unified domain.\nThis process relies on a trained model to extract the style\nfeatures from the samples. To achieve this, we split the\nConstStyle training process into two stages: Initial Train-\ning and Unified-Style Training. In the initial training phase,\nwe train a model using the original training data to develop\na feature extractor capable of capturing the style features of\nthe samples. In the subsequent phase, the feature extractor\nis used to transform all training data to match the style of\nthe unified domain. The model is then trained using these\nstyle-aligned samples. To save training costs, we perform\n\nthe initial training phase for only a few epochs (instead of\ntraining until convergence), to establish the initial unified\ndomain. Afterward, we utilize the feature extractor from\nunified-style training.\nInitial Training. Initially, the model ω is trained on the\noriginal training dataset using the traditional Empirical Risk\nMinimization (ERM) approach. Assume that the model ob-\ntained after the first training epoch is ωo = ζo(θo\nf(θo\ns)),\nwhere θo\ns denotes the style feature extractor, θo\nf the re-\nmaining encoder component, and ζo the classification head.\nThen, each training sample xi is fed through θo\ns(.) to get\nits original style feature zo\nxi = θo\ns(xi). These style features\nare used to determine the initial unified domain T o as de-\nscribed in Section 3.3. Once the unified domain is acquired,\nthe training process shifts to the second phase, where the\nmodel is trained with data transformed to the unified do-\nmain through a style transformation procedure.\nUnified-Style Training. ωo and T o are used as the ini-\ntial points for this training process. At each training epoch\nduring this phase, each image xi in the training batch is\nfed through the current style extractor θs(.) to get its orig-\ninal style feature zxi = θs(xi). This original style statistic\nis then aligned with a random style statistic ϵs = (µs, σs)\nsampled from the unified domain’s style distribution PT =\nN(ϵT , ΣT ) as follows:\n  \nz^ T _{ x _i}  = \n\\s\ni gma _s \\times \\frac {z_{x_i}-\\mu _x}{\\sigma _x} + \\mu _s. \\vspace {-5pt} \n(4)\nAfter transformation, the new style feature zT\nxi is fed into the\nmodel ω for further training, i.e., ω = ζ(θf(zT\nxi)). Back-\npropagation is performed across all components of ω, in-\ncluding the feature extractor θs(.). The unified domain T\nis periodically updated every γ epochs, a strategy that im-\nproves unified domain quality while preserving training sta-\nbility. It is worth noting that, through this projection pro-\ncess, the model is trained on E ∗D different variations of\nstyle features (where E is the number of training epochs\nand D is the total seen data), all aligned with the unified\ndomain. This strategy not only expands the training dataset\nbut also enriches the diversity of style features specific to\nthe unified domain, thereby enhancing the model’s adapt-\nability to it. Details of the training process are presented in\nAlgorithm 1 in Supplementary.\n3.5. Inference Process\nTo bridge the domain gap between test and training data,\nwe introduce a novel approach that aligns the style of test\nsamples with the unified domain prior to inference. The\nchallenge here is that since the unified domain is entirely\ndefined based on the seen domains, the gap between the uni-\nfied domain and the test domains (unseen domains) can be\nquite large, leading to the potential loss of original charac-\nteristics in the data after being aligned with the unified do-\nmain2. To address this issue, we employ a partial projection\nstrategy that balances transforming the style of test samples\nto match the unified domain while preserving their original\ncharacteristics.\nSpecifically, let ω∗= ζ∗(θ∗\nf(θo\ns)) be the model obtained\nafter the training phase. In the inference phase, each testing\nsample u is firstly fed into θo\ns to get the style feature zo\nu.\nThis style feature is then partially aligned with the unified\ndomain’s style to generate a new style feature, denoted as\nzT\nu . This zT\nu is subsequently input into ζ∗(θ∗\nf(.)) to yield\nthe final prediction result. The formula below is used to\nalign the style zo\nu of a test sample u:\n z\n^ T _{ u } =  \\ l ef t  (  \\a\nl p ha\n \\\nt im e s \\ si g ma  _u  + (1 - \\alpha ) \\times \\sigma _T \\right ) \\frac {z^o_{u} - \\mu _u}{\\sigma _u} \\\\ + \\left ( \\alpha \\times \\mu _u + (1 - \\alpha ) \\times \\mu _T \\right ),\n(5)\nwhere (µu, σu) is the original style statistic of u, and ϵT =\n(µT , σT ) is the mean; α is a hyperparameter in the range\nof (0, 1) controlling the extent to which the original feature\nis preserved. Specifically, α = 0 indicates that the test-\ning data is completely mapped to the unified domain, while\nα = 1 keeps the test data in its original state. We perform\nan ablation study with different values of α to examine its\neffects and assess our alignment algorithm (see Supplemen-\ntary E.4). Additionally, we present below a theorem that\nestablishes a bound on the distance between the empirical\nlosses of the model on unseen and seen domains.\nTheorem 2 Let S and U be the set of data from all seen and\nunseen domains, respectively; DST and DU T be the set of\nseen data and unseen data after projected onto the unified\ndomain using our algorithm; LUT and LST be the empir-\nical losses of models trained by DST and DU T calculated\nover the seen and unseen data, respectively. The difference\nof LUT and LST is bounded by the following inequality:\n  L ^ {\\m a t h c a l {U}^ { T } } - L ^ {\\\nmat\nh c a\nl\n {S}^{T}} & \\leq \\alpha \\times \\beta \\times (\\mathcal {D}_\\mu (\\mathcal {U, \\mathcal {T}})+\\mathcal {D}_\\sigma (\\mathcal {U}, \\mathcal {T})) \\\\ \\nonumber & + \\epsilon \\times \\sqrt {2.Tr(I)},\nwhere Dµ(T , U) and Dσ(T , U) represent the distances be-\ntween the mean and variance of the distributions of T and\nU. Tr(I) represents the trace of the identity matrix I, which\nis the sum of the diagonal elements of the matrix. I is the\nidentity matrix with dimensions C×H×W, where C, H, W\nare the channel, height, and width dimensions of the output\nof θs. (The proof is provided in Suppl. B.3).\nWe provide details of the inference process in Algorithm 3\nin Supplementary.\n\nMethod\nVenue\nIn-domain combinations\nAvg\nA, C, S\nP, C, S\nP, A, S\nP, A, C\nERM\n-\n95.02\n95.91\n95.75\n97.08\n95.94\nMixStyle [29]\nICLR 2021\n94.66\n95.78\n96.01\n96.59\n95.76\nDSU [10]\nICLR 2022\n94.78\n96.65\n96.39\n97.40\n96.30\nCSU [26]\nWACV 2024\n94.78\n96.52\n96.13\n97.07\n96.12\nConstStyle\nOurs\n95.37\n97.02\n96.39\n97.24\n96.50\nTable 1. In-domain performance of ConstStyle compared with\nbaselines on PACS datasets. P, A, C, S denote Photo, Art, Car-\ntoon, Sketch. The best result is colored purple and the second\nbest result is colored blue.\n4. Experimental Evaluation\nWe conducted a series of experiments to assess ConstStyle’s\neffectiveness across various scenarios. The evaluation cov-\nered three primary tasks: image classification, image cor-\nruption, and instance retrieval, offering a thorough analysis\nof the method’s robustness under different conditions.\n4.1. Settings\nImage Classification. We address the style-shift problem\nand evaluate our method on the PACS dataset [4], a Do-\nmain Generalization benchmark with four styles (Photo,\nArt, Cartoon, Sketch). Following [22], we conduct exper-\niments under two scenarios: (1) a single unseen domain,\nwhere the model trains on three domains and tests on the\nfourth [10, 26, 29], and (2) multiple unseen domains, where\ntraining is further restricted to assess generalization. Ad-\nditionally, we evaluate the Digits5 dataset [21] to improve\nrobustness across five domains.\nImage Corruption. We further assess the robustness of\nour method against image corruption using the CIFAR10-\nC dataset [6], which includes 19 types of corruption at five\nseverity levels. Higher levels indicate stronger corruption.\nCIFAR10 serves as the source domain and CIFAR10-C as\nthe target domain.\nInstance Retrieval.\nFor the instance retrieval task, we\nevaluate re-ID methods, matching individuals across cam-\nera views. Market1501 [28] and Duke [16] are used in-\nterchangeably for training and testing. Performance is as-\nsessed using the ranking accuracy and mean average preci-\nsion (mAP). In all experiments, we set α = 0.6 for PACS\ndataset and α = 0.5 for Digit5 dataset and report the results\nwith ERM refers to the approach that trains the model using\nEmpirical Risk Minimization loss. Details of experimental\nsettings are provided in Suppl. C.\n4.2. Image Classification\n4.2.1. In-domain Performance\nWe first evaluate ConstStyle’s performance on the seen do-\nmains. As shown in Table 1, ConstStyle outperforms ex-\n2This issue does not arise with data from seen domains, as the unified\ndomain is designed to closely align with them.\nMethod\nVenue\nDomains\nAvg\nArt\nCartoon\nPhoto\nSketch\nERM\n-\n77.10\n77.77\n96.40\n68.17\n79.86\nCrossgrad [17]\nICLR 2018\n78.12\n77.90\n96.64\n70.64\n80.82\nMixup [24]\nICLR 2018\n78.71\n74.53\n96.16\n66.24\n78.91\nCutmix [23]\nICCV 2019\n77.49\n73.33\n96.34\n69.80\n79.24\nEDFMix [25]\nCVPR 2022\n83.05\n81.05\n96.64\n76.50\n84.31\nRIDG [2]\nICCV 2023\n80.17\n78.32\n96.82\n72.32\n81.90\nMixStyle [29]\nICLR 2021\n81.25\n80.03\n96.82\n72.17\n82.57\nDSU [10]\nICLR 2022\n83.94\n81.10\n96.23\n79.05\n85.08\nCSU [26]\nWACV 2024\n84.62\n82.21\n96.41\n78.11\n85.33\nConstStyle\nOurs\n85.45\n82.42\n96.89\n82,32\n86,77\nTable 2. Performance of ConstStyle compared with baselines on\nPACS datasets.The best result is colored purple and the second\nbest result is colored blue.\nMethod\nVenue\nDomains\nAvg\nMNISTM\nSVHN\nSYN\nUSPS\nMNIST\nERM\n-\n67.45\n77.16\n86.43\n96.90\n98.30\n85.24\nCrossgrad[17]\nICLR 2018\n69.03\n77.20\n86.93\n96.9\n69.03\n85.65\nMixup [24]\nICLR 2018\n64.08\n79.32\n81.34\n94.51\n98.30\n83.50\nCutmix[23]\nICCV 2019\n65.45\n79.55\n84.60\n95.90\n98.30\n84.36\nEDFMix[25]\nCVPR 2022\n70.95\n77.55\n86.94\n96.98\n98.30\n86.14\nRIDG[2]\nICCV 2023\n67.35\n79.18\n86.86\n97.04\n98.30\n85.95\nMixStyle[29]\nICLR 2021\n61.48\n57.18\n64.17\n87.58\n96.90\n73.06\nDSU[10]\nICLR 2022\n67.84\n77.01\n87.21\n96.55\n98.30\n85.38\nCSU[26]\nWACV 2024\n68.25\n78.60\n86.70\n96.40\n98.30\n85.65\nConstStyle\nOurs\n71.51\n79.9\n87.90\n96.80\n98.30\n86.88\nTable 3. Performance of ConstStyle compared with baselines on\nDigits5 datasets. The best result is colored purple and the second\nbest result is colored blue.\nisting methods in three out of four cases and achieves the\nhighest overall accuracy. Compared to the standard ERM\napproach, ConstStyle improves performance by 0.56% and\nfurther exceeds the second-best method by an additional\n0.2% in accuracy.\n4.2.2. Generalization on Multi-domain Classification\nTables 2 and 3 provide a summary of the comparison be-\ntween ConstStyle and existing approaches on the image\nclassification task. As shown, ConstStyle surpasses all other\nmethods on the PACS dataset and achieves the highest per-\nformance on four out of five unseen domains in the Dig-\nits5 dataset. Regarding the average accuracy across unseen\ndomains, ConstStyle leads on both datasets. For particu-\nlarly challenging domains such as Art, Cartoon, and Sketch,\nConstStyle improves performance by 0.21% to 4.21% over\nthe second-best method. In the Sketch domain specifically,\nwhere the unseen domain style statistics vary significantly\nfrom the training domains, ConstStyle achieves the largest\nimprovement over other methods, underscoring its capa-\nbility to handle substantial domain gaps. On the Digits5\ndataset, ConstStyle also shows superior performance over\nbaseline methods, with the greatest improvement observed\nin the MNISTM domain, which presents the greatest chal-\nlenge. These results highlight ConstStyle’s strong adapt-\nability and robustness in diverse, difficult settings.\n\nFigure 4. Effect of domain gap. ConstStyle achieves significantly\nbetter performance than other methods in handling severe domain\ngaps.\n4.2.3. Robustness Against the Numbers of Unseen Do-\nmains\nPrevious studies have generally evaluated their methods\nwith limited setups, often using scenarios with only a single\nunseen domain. To offer a more thorough evaluation, we\nconduct experiments with various numbers of unseen do-\nmains. Specifically, we incrementally increase the number\nof unseen domains to two for the PACS dataset and three for\nthe Digits5 dataset. Detailed results for the PACS dataset\nare shown in Table 4, while those for the Digits5 dataset\nare provided in the Suppl. D.1. As shown, ConstStyle con-\ntinues to achieve the highest accuracy even when the num-\nber of seen domains is reduced and the number of unseen\ndomains is increased, demonstrating its strong generaliza-\ntion capability. Specifically, ConstStyle improves accuracy\nby 1.36% when the test domains are Art and Cartoon, and\nachieves a notable 5.91% increase over the state of the art\nwhen Cartoon and Sketch are the unseen domains. On av-\nerage, ConstStyle increases overall performance by 2.43%,\nunderscoring its consistent effectiveness as the number of\ntraining domains varies.\n4.2.4. Impacts of Domain Gap\nWe conduct experiments to evaluate the performance of\nConstStyle when confronted with unseen domains that may\nexhibit varying degrees of distance from the seen domains.\nSpecifically, we train the model on a specific seen domain,\nthen perform inference on various unseen domains, and in-\nvestigate how the model’s accuracy changes. We utilize the\nFr´echet distance [5] (also known as the 2-Wasserstein dis-\ntance) to model the gap between domains’ style distribu-\ntions. The results are shown in Figure 4. In general, as\nthe distance between domains increases, the performance\nMethod\nVenue\nA,P\nC,P\nP,S\nA,C\nA,S\nC,S\nAvg\nERM\n-\n74.50\n84.92\n76.27\n64.79\n69.31\n52.18\n70.32\nCrossgrad[17]\nICLR 2018\n74.26\n85.12\n76.92\n64.16\n69.96\n51.27\n70.28\nMixup[24]\nICLR 2018\n76.46\n82.78\n73.24\n64.34\n66.23\n51.27\n68.51\nCutmix[23]\nICCV 2019\n73.66\n82.63\n76.38\n64.43\n69.76\n49.09\n69.32\nEFDMix[25]\nCVPR 2022\n78.56\n86.72\n80.90\n71.10\n76.28\n54.28\n74.64\nRIDG[2]\nICCV 2023\n75.49\n84.57\n77.00\n67.75\n70.03\n53.42\n71.37\nMixStyle[29]\nICLR 2021\n75.60\n86.79\n80.54\n72.10\n73.34\n55.58\n73.99\nDSU[10]\nICLR 2022\n80.36\n86.14\n83.56\n73.49\n77.49\n62.40\n77.24\nCSU[26]\nWACV 2024\n82.92\n87.49\n83.52\n74.59\n77.42\n64.30\n78.38\nConstStyle\nOurs\n84.64\n87.49\n85.28\n75.95\n81.29\n70.21\n80.81\nTable 4. Performance comparison on the PACS dataset across six\nscenarios with different combinations of unseen domains. The best\nresult is colored purple and the second best result is colored blue.\nof the methods tends to decrease.\nHowever, ConstStyle\nconsistently delivers the highest accuracy and the slowest\nrate of performance decline across all scenarios. Specifi-\ncally, when the training domain is Photo, ConstStyle outper-\nforms CSU, with the performance gap ranging from 0.14%\nto 15.03% as the distance between seen and unseen domains\ngrows. Additionally, ConstStyle shows a performance gap\nof up to 4.54% when the training domain is Art and 3.95%\nwhen the training domain is Cartoon. These results high-\nlight the importance of projecting data onto a common do-\nmain, which helps mitigate domain gaps and enables the\nextraction of the most relevant cross-domain features.\n4.2.5. Impacts of the Number of Seen Domains\nPerformance comparison between the models. We com-\npare the performance of the methods with the varying num-\nber of seen domains (Figure 5). As shown, reducing the\nnumber of training domains tends to negatively impact the\nmodels’ generalizability due to the less diverse features\nlearned from the data.\nHowever, there are some special\ncases where training the model with fewer domains is more\neffective compared with more domains, which will be dis-\ncussed later. Despite the significant decline in performance\nacross methods, ConstStyle exhibits the slowest degrada-\ntion, which can be observed when comparing with the\nsecond-best method, CSU. Specifically, ConstStyle main-\ntains an accuracy advantage of up to 19.82% when trained\non Sketch and tested on Art, and up to 15.02% when trained\non Cartoon and tested on Sketch, outperforming CSU. In\nthe Digit5 dataset, ConstStyle achieves a performance gap\nof up to 2.77% when the test domain is SVHN and up to\n3.19% when the test domain is SYN, compared to CSU.\nWhen does training with fewer domains result in bet-\nter performance? As previously discussed, training with\na wide range of domains does not necessarily yield better\nperformance. To explore this further, we conducted experi-\nments on PACS dataset, varying the number of training do-\nmains. In each experiment, we set Sketch as the test do-\nmain and began by training the model with Art as the only\nseen domain. We then gradually added more domains to the\ntraining set, calculating the distance between the seen and\n\n(a) PACS dataset with Test domains are Art (left) and Sketch (right).\n(b) Digit5 dataset with Test domains are SVHN (left) and SYN (right).\nFigure 5. Effects of the number of training domains. ConstStyle\nconsistently delivers the best performance across all scenarios.\nFigure 6. Style statistics for different domain combinations when\ntraining ResNet18 with Sketch as the test domain. Accuracies for\neach domain combination are 67.44%, 44.57%, and 46.23%.\nunseen domains after each addition. These results, illus-\ntrated in Figure 6, reveal that model performance improves\nonly when the added domains decrease the domain gap to\nthe unseen domain.\n4.3. Robustness Against Image Corruption\nTable 5 presents the results, revealing that as corruption lev-\nels increase, the performance advantage of ConstStyle over\nexisting methods becomes more pronounced. ConstStyle\nsecures the top performance in four out of five cases, with\nthe only exception occurring at the lowest corruption level,\nwhere unseen domains closely match the seen domains. On\naverage, ConstStyle achieves the highest performance with\na 1.04% improvement over the second-best method. Com-\npared to the ERM method, which performs best at the low-\nest corruption level, ConstStyle surpasses it by 0.36% to\n15.83% across higher corruption levels. Moreover, Const-\nStyle outperforms other style-based methods with improve-\nments ranging from 0.75% to 4.96%, emphasizing its re-\nsilience in handling heavily corrupted datasets. These re-\nsults underscore ConstStyle’s robustness in handling highly\ncorrupted datasets.\nMethod\nLevel of corruption\nAvg\nlevel 1\nlevel 2\nlevel 3\nlevel 4\nlevel 5\nERM\n87.33\n80.29\n70.57\n64.81\n47.80\n70.16\nMixStyle[29]\n87.32\n79.90\n71.83\n66.54\n58.67\n73.13\nDSU[10]\n86.91\n79.40\n68.68\n64.14\n49.44\n69.71\nCSU[26]\n86.73\n79.87\n70.66\n65.51\n60.88\n72.73\nConstStyle\n86.59\n80.65\n72.03\n67.96\n63.63\n74.17\nTable 5. Comparison of methods under different corruption levels,\nconducted on the CIFAR10-C datasets. The best result is colored\npurple and the second best result is colored blue.\nMethod\nMarket →Duke\nDuke →Market\nmAP\nR1\nR5\nR10\nmAP\nR1\nR5\nR10\nERM\n13.8\n27.1\n40.5\n46.9\n21.9\n45.9\n65.6\n72.7\nMixStyle[29]\n19.5\n37.0\n52.0\n58.5\n24.6\n52.2\n70.9\n78.4\nDSU[10]\n21.6\n40.2\n54.0\n59.8\n25.5\n55.7\n73.0\n79.2\nCSU[26]\n24.1\n44.2\n59.2\n65.1\n24.9\n55.0\n72.2\n78.2\nConstStyle\n26.1\n44.7\n61.1\n67.6\n27.0\n56.5\n75.0\n81.1\nTable 6. Performance of the methods on Instance retrieval task.\nThe best result is colored purple and the second best result is col-\nored blue.\n4.4. Generalization in Instance Retrieval\nThe results shown in Table 6 highlight that ConstStyle sub-\nstantially outperforms all other methods in both settings.\nWhile other methods encounter difficulties with new do-\nmains due to their dependence on generating instances from\nthe existing dataset, ConstStyle addresses this challenge\nthrough its unified domain approach.\nCompared to the\nsecond-best method, ConstStyle achieves improvements in\nmean average precision (mAP) ranging from 0.1% to 2.8%.\n5. Conclusion\nThis paper introduces ConstStyle, a novel approach for ad-\ndressing the domain shift problem.\nThe key concept of\nConstStyle is to align data to a unified domain prior to\nboth training and testing, enabling the capture of domain-\ninvariant features and reducing discrepancies with unseen\ndomains. This alignment approach mitigates domain shift\neffects and maintains performance stability, even with fewer\ntraining domains. ConstStyle consistently outperforms ex-\nisting methods on style-shift datasets, achieving up to a\n19.82% accuracy improvement over the next best approach.\nAdditionally, we provide a theoretical analysis on the per-\nformance bounds for both seen and unseen domains. Future\nwork will explore addressing other types of domain shift,\nsuch as feature shift.\n6. Acknowledgement\nThis research is funded by Hanoi University of Science and\nTechnology (HUST) under grant number T2024-TD-002.\n\nReferences\n[1] Prithvijit Chattopadhyay, Yogesh Balaji, and Judy Hoffman.\nLearning to balance specificity and invariance for in and\nout of domain generalization. In Computer Vision–ECCV\n2020: 16th European Conference, Glasgow, UK, August 23–\n28, 2020, Proceedings, Part IX 16, pages 301–318. Springer,\n2020. 2\n[2] Liang Chen, Yong Zhang, Yibing Song, Anton van den Hen-\ngel, and Lingqiao Liu. Domain generalization via rationale\ninvariance. In ICCV, 2023. 1, 2, 6, 7\n[3] Sungha Choi, Sanghun Jung, Huiwon Yun, Joanne T Kim,\nSeungryong Kim, and Jaegul Choo. Robustnet: Improving\ndomain generalization in urban-scene segmentation via in-\nstance selective whitening. In Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition,\n2021. 1, 2\n[4] Li Da, Yang Yongxin, Song Yi-Zhe, and M. Hospedales Tim-\nothy. Deeper, broader and artier domain generalization. In\nProceedings of the IEEE International Conference on Com-\nputer Vision (ICCV), 2017. 6\n[5] DC Dowson and BV666017 Landau. The fr´echet distance\nbetween multivariate normal distributions. Journal of multi-\nvariate analysis, 1982. 7\n[6] Dan Hendrycks and Thomas Dietterich. Benchmarking neu-\nral network robustness to common corruptions and perturba-\ntions. In International Conference on Learning Representa-\ntions, 2019. 6\n[7] Dan Hendrycks*, Norman Mu*, Ekin Dogus Cubuk, Barret\nZoph, Justin Gilmer, and Balaji Lakshminarayanan. Aug-\nmix: A simple method to improve robustness and uncertainty\nunder data shift. In International Conference on Learning\nRepresentations, 2020. 2\n[8] Xun Huang and Serge Belongie. Arbitrary style transfer in\nreal-time with adaptive instance normalization.\nIn ICCV,\n2017. 3\n[9] Juwon Kang, Sohyun Lee, Namyup Kim, and Suha Kwak.\nStyle neophile: Constantly seeking novel styles for domain\ngeneralization. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pages 7130–\n7140, 2022. 2\n[10] Xiaotong Li, Yongxing Dai, Yixiao Ge, Jun Liu, Ying Shan,\nand LINGYU DUAN.\nUncertainty modeling for out-of-\ndistribution generalization. In International Conference on\nLearning Representations, 2022. 1, 2, 6, 7, 8\n[11] Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang\nLiu, Kun Zhang, and Dacheng Tao.\nDeep domain gener-\nalization via conditional invariant adversarial networks. In\nProceedings of the European conference on computer vision\n(ECCV), pages 624–639, 2018. 1, 2\n[12] Songhua Liu, Xin Jin, Xingyi Yang, Jingwen Ye, and Xin-\nchao Wang. Stydesty: Min-max stylization and destylization\nfor single domain generalization. In Forty-first International\nConference on Machine Learning, 2024. 2\n[13] Oren Nuriel, Sagie Benaim, and Lior Wolf. Permuted adain:\nReducing the bias towards global statistics in image clas-\nsification. In Proceedings of the IEEE/CVF conference on\ncomputer vision and pattern recognition, pages 9482–9491,\n2021. 1\n[14] Xingang Pan, Ping Luo, Jianping Shi, and Xiaoou Tang. Two\nat once: Enhancing learning and generalization capacities\nvia ibn-net. In Proceedings of the european conference on\ncomputer vision (ECCV), 2018. 2\n[15] Vihari Piratla, Praneeth Netrapalli, and Sunita Sarawagi.\nEfficient domain generalization via common-specific low-\nrank decomposition. In International conference on machine\nlearning, 2020. 1, 2\n[16] Ergys Ristani, Francesco Solera, Roger Zou, Rita Cucchiara,\nand Carlo Tomasi. Performance measures and a data set for\nmulti-target, multi-camera tracking. In European conference\non computer vision, 2016. 6\n[17] Shankar Shiv, Piratla Vihari, Chakrabarti Soumen, Chaud-\nhuri Siddhartha, Jyothi Preethi, and Sarawagi Sunita. Gener-\nalizing across domains via cross-gradient training. In ICLR,\n2018. 6, 7\n[18] Vikas Verma, Alex Lamb, Christopher Beckham, Amir Na-\njafi, Ioannis Mitliagkas, David Lopez-Paz, and Yoshua Ben-\ngio. Manifold mixup: Better representations by interpolating\nhidden states. In International conference on machine learn-\ning, pages 6438–6447. PMLR, 2019. 2\n[19] Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John C\nDuchi, Vittorio Murino, and Silvio Savarese. Generalizing\nto unseen domains via adversarial data augmentation. Ad-\nvances in neural information processing systems, 2018. 2\n[20] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang,\nTao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and S Yu\nPhilip. Generalizing to unseen domains: A survey on do-\nmain generalization. IEEE transactions on knowledge and\ndata engineering, 2022. 1\n[21] LeCun Yann, Bottou L´eon, Bengio Yoshua, and Haffner\nPatrick. Gradient-based learning applied to document recog-\nnition. In Proceedings of the IEEE, pages 2278–2324, 1998.\n6\n[22] Han Yu, Xingxuan Zhang, Renzhe Xu, Jiashuo Liu, Yue He,\nand Peng Cui. Rethinking the evaluation protocol of domain\ngeneralization. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition (CVPR), pages\n21897–21908, 2024. 6\n[23] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk\nChun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regu-\nlarization strategy to train strong classifiers with localizable\nfeatures. In Proceedings of the IEEE/CVF international con-\nference on computer vision, pages 6023–6032, 2019. 2, 6, 7\n[24] Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and\nDavid Lopez-Paz. mixup: Beyond empirical risk minimiza-\ntion. In International Conference on Learning Representa-\ntions, 2018. 2, 6, 7\n[25] Yabin Zhang, Minghan Li, Ruihuang Li, Kui Jia, and Lei\nZhang. Exact feature distribution matching for arbitrary style\ntransfer and domain generalization. In CVPR, 2022. 6, 7\n[26] Zheyuan Zhang, Bin Wang, Debesh Jha, Ugur Demir, and\nUlas Bagci. Domain generalization with correlated style un-\ncertainty. In Proceedings of the IEEE/CVF Winter Confer-\nence on Applications of Computer Vision, 2024. 1, 2, 6, 7,\n8\n\n[27] Xingchen Zhao, Chang Liu, Anthony Sicilia, Seong Jae\nHwang, and Yun Fu. Test-time fourier style calibration for\ndomain generalization.\narXiv preprint arXiv:2205.06427,\n2022. 2\n[28] Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jing-\ndong Wang, and Qi Tian. Scalable person re-identification:\nA benchmark. In Proceedings of the IEEE international con-\nference on computer vision, 2015. 6\n[29] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do-\nmain generalization with mixstyle. In International Confer-\nence on Learning Representations, 2021. 1, 2, 3, 6, 7, 8\n[30] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and\nChen Change Loy. Domain generalization: A survey. IEEE\nTransactions on Pattern Analysis and Machine Intelligence,\npages 4396–4415, 2022. 1\n[31] P.C. ´Alvarez Esteban, E. del Barrio, J.A. Cuesta-Albertos,\nand C Matr´an.\nA fixed-point approach to barycenters in\nwasserstein space.\nJournal of Mathematical Analysis and\nApplications, 2016. 4\n\nConstStyle: Robust Domain Generalization with Unified Style Transformation\nSupplementary Material\nA. Details of the Training Process\nDetails of unified domain determination algorithm, training\nand inference processes are presented in Algorithms 1, 2\nand 3, respectively.\nB. Proofs\nB.1. Proof of Lemma 1.\nLet us start with LSk, we have:\n  L ^\n{\n\\mat\nh\ncal {S}_\nk} & =\\f rac\n \n{\n1}{|\n\\\nmathcal \n{S}_k|}\\sum _{\n(\nx\n, y)\n \n\\in \\mat\nhcal {S}_ k }[ l (\\\nom\ne ga (x ),\n \ny\n)] \\\nn\nonumber \n\\\\ & = \\ fr a c \n{1\n} {|\\mathcal {S}_k|}\\sum _{(x, y) \\in \\mathcal {S}_k}l(\\zeta (\\theta _f(z_x)), y) \\nonumber \\\\ & = \\frac {1}{|\\mathcal {S}_k|}\\sum _{(x, y) \\in \\mathcal {S}_k} l(\\zeta (\\theta _f(\\sigma _x*\\frac {z_x - \\mu _x}{\\sigma _x}+\\mu _x)),y) \\nonumber \\\\ & = \\frac {1}{|\\mathcal {S}_k|}\\sum _{(x, y) \\in \\mathcal {S}_k}f(\\mu _x, \\sigma _x,\\frac {z_x - \\mu _x}{\\sigma _x}, y). \\label {loss:l_S}\n(7)\nSimilarly, we have:\n  L\n^ { \\\nmath\nc\nal {S}^T\n_k} = & \\f rac\n {\n1}{|\n\\\nmathcal \n{S}_k|}\\s\nu m _ {(\nx ,\n y) \n\\\nin \\math\ncal {S}_k } [l ( \\o\nme\ng a ^T( x)\n,  \ny)] \n\\\nnonumber\n \\\\ = & \\ fr a c \n{1\n} {|\\mathcal {S}_k|}\\sum _{(x, y) \\in \\mathcal {S}_k}l(\\zeta (\\theta _f(z_x^T)), y) \\nonumber \\\\ =& \\frac {1}{|\\mathcal {S}_k|}\\sum _{(x, y) \\in \\mathcal {S}_k} l(\\zeta (\\theta _f(\\sigma ^T*\\frac {z_x - \\mu _x}{\\sigma _x}+\\mu ^T)),y) \\nonumber \\\\ =& \\frac {1}{|\\mathcal {S}_k|}\\sum _{(x, y) \\in \\mathcal {S}_k}f(\\mu ^T, \\sigma ^T,\\frac {z_x - \\mu _x}{\\sigma _x}, y). \\label {loss:l_S_delta}\n(8)\nBy subtracting 8 from 7, we obtain:\n  L\n^ { \\ma t\nh\ncal \n{\nS}^T_k} \n-\n L^{ \\ ma t hc a l \n{S\n} _k\n}  &= \\ fra c { 1}\n{|\n\\ ma\nt\nhcal {S}_k|} \\sum _{(x,y) \\in \\mathcal {S}_k} \\Big ( f(\\mu ^T, \\sigma ^T, \\frac {z_x - \\mu _x}{\\sigma _x}, y) \\notag \\\\ &\\quad - f(\\mu _{x}, \\sigma _{x}, \\frac {z_x - \\mu _x}{\\sigma _x}, y) \\Big ).\n(9)\nUsing the Taylor approximation for a function with two\nvariables, we derive:\n f(\\ m u ^ T,  \\s\nig\nm a ^ T, \\f rac  { z _x\n -\n \\m\nu  _x } {\\s i gma \n_ x},  y) -  f(\\mu _{x}, \\sigma _{x}, \\frac {z_x - \\mu _x}{\\sigma _x}, y) \\\\ \\approx (\\mu ^T - \\mu _{x}) \\cdot \\nabla _{\\mu _{x}} f \\quad + (\\sigma ^T - \\sigma _{x}) \\cdot \\nabla _{\\sigma _{x}} f.\n(10)\nLet Dµ(T , Sk) denote the distance between means of\nthe unified instance style T and seen instance style Sk,\nwhile Dσ(T , Sk) represents the distance between stan-\ndard deviations.\nLet ||v|| denote the L2-norm of vector\nv. Assume f is a β-Lipschitz function, we can suppose\nsupx∈Sk ||∇µxf|| = βµ, supx∈Sk ||∇σxf|| = βσ, we have:\n  \\\nb e gin  {\nspli\nt\n} L^{\\ma\nthc a l {S } _k^T}\n -  L^{\\ m athca\nl { S\n}\n_k} \n\\\nleq & \\f\nrac { 1}{|\\\nma t\nh\ncal \n{\nS}_k|}\\s\num _ { (x, \ny) \\ in \\ m ath c al  {S}_ k } (\\beta _\\mu *||\\mu ^T - \\mu _x|| + \\\\ & \\beta _\\sigma *||\\sigma ^T - \\sigma _x||) \\end {split} \\\\ \\begin {split} = & \\beta _\\mu *\\frac {1}{|\\mathcal {S}_k|}\\sum _{(x, y) \\in \\mathcal {S}_k} ||\\mu ^T - \\mu _x|| + \\\\ & \\beta _\\sigma *\\frac {1}{|\\mathcal {S}_k|}\\sum _{(x, y) \\in \\mathcal {S}_k} ||\\sigma ^T - \\sigma _x|| \\end {split} \\\\ \\begin {split} = & \\beta _\\mu * \\mathcal {D}_\\mu (\\mathcal {T}, \\mathcal {S}_k) + \\beta _\\sigma *\\mathcal {D}_\\sigma (\\mathcal {T},\\mathcal {S}_k) \\end {split}\nLet β = max(βµ, βσ), then:\n  \\\nb e gin  { s plit}  L^{ \\ math c al {S}_k^T} - L^{\\mathcal {S}_k} \\leq \\beta \\times (\\mathcal {D}_\\mu (\\mathcal {T}, \\mathcal {S}_k) +\\mathcal {D}_\\sigma (\\mathcal {T},\\mathcal {S}_k)) \\end {split}\n(11)\nB.2. Proof of Theorem 1\nAccording to B.1, for the seen domains {Sk}N\nk=1, the total\nempirical loss across N seen domains is bounded as fol-\nlows:\n \n\\\nsum\n _{\nk =\n1\n}\n^N \nL^{{\\m\na\nt\nhca\nl {S} _ k}^T} \\l e q \\sum _{k=1}^N L^{\\mathcal {S}_k} + \\beta *\\sum _{k=1}^N(\\mathcal {D}_\\mu (\\mathcal {T},\\mathcal {S}_k) + \\mathcal {D}_\\sigma (\\mathcal {T},\\mathcal {S}_k))\n(12)\nIt can be observed that the upper bound of this loss de-\npends on the total distance from the unified domain to N\nseen domains Sk. Therefore, to minimize the loss over the\nseen domains, we aim to reduce the distance between the\nunified domain T and N seen domains Sk. Consequently,\nthe unified domain style N T = (µT , ΣT ) is the barycenter\nof N seen domain styles.\nB.3. Proof of Theorem 2\nThe loss function of the model trained on seen domains,\nobtained by ConstStyle, and test on unseen domain is given\nby:  L^{\\mathcal {U}^T} & =\\frac {1}{|\\mathcal {U}|}\\sum _{(u, y) \\in \\mathcal {U}}[l(\\omega ^T(u), y)] \\nonumber \\\\ & = \\frac {1}{|\\mathcal {C}|}\\sum _{c \\in \\mathcal {C}} \\frac {1}{|\\mathcal {U}_c|} \\sum _{u \\in \\mathcal {U}_c}[l(\\zeta (\\theta _f(z_u^T))), y_c] \\nonumber \\\\ & = \\frac {1}{|\\mathcal {C}|}\\sum _{c \\in \\mathcal {C}}\\frac {1}{|\\mathcal {U}_c|}\\sum _{u \\in \\mathcal {U}_c}[l(\\zeta (\\theta _f(\\sigma _u^T*\\frac {z_u - \\mu _u}{\\sigma _u}+\\mu _u^T),y_c] \\nonumber \\\\ & = \\frac {1}{|\\mathcal {C}|}\\sum _{c \\in \\mathcal {C}}\\frac {1}{|\\mathcal {U}_c|}\\sum _{u \\in \\mathcal {U}_c}[f(\\mu _u^T,\\sigma _u^T,\\frac {z_u - \\mu _u}{\\sigma _u},y_c)] \\label {loss:l_u}\n\nAlgorithm 1: ConstStyle Training Process\n1 Input: Seen data S = {(x, y)}, Model ω = ζ(θf(θs(.)), the update interval γ, the number of epochs E, the learning\nrate η, and the number of clusters N ′;\n2 Output: Optimal model ω∗, the final unified domain N T ;\n3 Algorithm:\n4 for epoch ≤E do\n5\nε ←∅;\n// Set of style features\n6\nfor x ∈S do\n7\nif epoch ≤ξ then\n8\nzx = θs(x);\n9\np(x) = ζ(θf(zx));\n10\nelse\n11\nzx = θs(x);\n12\nϵs ∼N T ;\n// sample style features\n13\nµs, σs = split(ϵs);\n14\nzT\nx = σs ∗zx−µx\nσx\n+ µs ;\n// project to the unified domain\n15\np(x) = ζ(θf(zT\nx ));\n16\nl = P\nc∈C yc. log(pc(x));\n17\nω = ω −η.∇ωl;\n// Update model\n18\nif epoch % γ == 0 then\n19\nµxc =\n1\nHW\nPH\nh=1\nPW\nw=1 zxc,h,w, σxc =\nq\n1\nHW\nPH\nh=1\nPW\nw=1(zxc,h,w −µxc)2;\n20\nϵx = concat(µx, σx) ;\n// extract style features\n21\nε = ε ∪ϵx ;\n// store style features\n22\nif epoch % γ == 0 then\n23\nN(ϵT , ΣT ) =Unified Domain Determination(ε, N ′);\n24\nN T ←N(ϵT , ΣT ) ;\n// get unified domain style\n25\nω∗= ω;\n26 return ω∗, N T\nAlgorithm 2: Unified Domain Determination\n1 Input: Set of all style features ε = {ϵx|x ∈S},\nNumber of clusters N ′;\n2 Output: Unified Domain Style N(ϵT , ΣT );\n3 Algorithm:\n4 {Ck ∼N(ϵCk, ΣCk)|k = 1..N ′} ←\nBayesGMM(ε, N ′) ϵT =\n1\nN ′\nPN ′\nk=1 ϵCk;\n5 ΣT =\n1\nN ′\nPN′\nk=1 ΣCk;\n6 N T = N(ϵT , ΣT );\n7 return N T\nLUT = 1\n|U|\nX\n(u,y)∈U\n[l(ωT (u), y)]\n= 1\n|C|\nX\nc∈C\n1\n|Uc|\nX\nu∈Uc\n[l(ζ(θf(zT\nu ))), yc]\n= 1\n|C|\nX\nc∈C\n1\n|Uc|\nX\nu∈Uc\n[l(ζ(θf(σT\nu ∗zu −µu\nσu\n+ µT\nu ), yc]\n= 1\n|C|\nX\nc∈C\n1\n|Uc|\nX\nu∈Uc\n[f(µT\nu , σT\nu , zu −µu\nσu\n, yc)]\n(13)\nSimilarly, We have:\n  L ^ {\n\\ma\nt\nhcal {S\n}^T} & =\\ fra\nc  \n{1}\n{\n|\\m\na\nthca\nl\n {S}\n|}\\sum _{(\nx , y)  \\i\nn  \n\\ma\nt\nhca\nl\n {S}\n}\n[l(\\\nomega ^T(x ) , y )]\n \\\nn on um ber\n \\\n\\ &\n \n= \\\nf\nrac \n{\n1}{|\n\\math c al  {C } |}\n\\s\nu m _{c \\in \\mathcal {C}}\\frac {1}{|\\mathcal {S}_c|}\\sum _{x \\in S_c}[l(\\zeta (\\theta _f(z^T_x))),y_c] \\nonumber \\\\ & = \\frac {1}{|\\mathcal {C}|}\\sum _{c \\in \\mathcal {C}}\\frac {1}{|\\mathcal {S}_c|}\\sum _{x \\in \\mathcal {S}_c}[l(\\zeta (\\theta _f(\\sigma ^T*\\frac {z_x - \\mu _x}{\\sigma _x}+\\mu ^T),y_c] \\nonumber \\\\ & = \\frac {1}{|\\mathcal {C}|}\\sum _{c \\in \\mathcal {C}}\\frac {1}{|\\mathcal {S}_c|}\\sum _{x \\in \\mathcal {S}_c}[f(\\mu ^T,\\sigma ^T,\\frac {z_x - \\mu _x}{\\sigma _x},y_c)]. \\label {loss:l_u_delta} (14)\nAssume that the cardinality of seen domain S and unseen\ndomain U are the same for all classes, i.e, |Sc| = |Uc| =\nd = |U|\n|C| = |S|\n|C| , ∀c ∈C . From Equations 13 and 14, we\nhave: L^{\\mathcal {U}^T} - L^{\\mathcal {S}^T} = \\frac {1}{|\\mathcal {C}|}\\sum _{c\\in \\mathcal {C}}\\frac {1}{d}\\sum _{u \\in U_c, x \\in S_c} [f(\\mu _u^T,\\sigma _u^T,\\frac {z_u - \\mu _u}{\\sigma _u},y_c)\\\\ -f(\\mu ^T, \\sigma ^T, \\frac {z_x - \\mu _x}{\\sigma _x},y_c)]\n\nAlgorithm 3: ConstStyle Inference Process\n1 Input: Unseen data U = {u|u ∼U}, Optimal\nmodel ω∗, Unified domain N T ;\n2 Output: Prediction set LU;\n3 Algorithm:\n4 LU = ∅;\n5 for u ∈U do\n6\nzu = θs(u);\n7\nµT , σT = split(ϵT );\n8\nzT\nu = (α.σu + (1 −α).σT ). zu−µu\nσu\n+ (α.µu +\n(1 −α).µT );\n9\np(u) = ζ(θf(zT\nu ));\n10\nyu = arg max(softmax(p(u));\n11\nLU = LU ∪yu;\n12 return LU\nLUT −LST = 1\n|C|\nX\nc∈C\n1\nd\nX\nu∈Uc,x∈Sc\n[f(µT\nu , σT\nu , zu −µu\nσu\n, yc)\n−f(µT , σT , zx −µx\nσx\n, yc)]\n(15)\nBy applying the Taylor approximation for three variables,\nwe obtain:\n  &f\n( \\ mu\n _ u^ T , \n\\s\ni gma  _u^T ,  \\ f ra c  {\nz_\nu  - \n\\ mu \n_ u }{ \\sig m a  _u\n} ,  y _c) -\n f(\\ m u \n^T\n,  \\ s ig\nma\n ^ T, \\f\nra\nc\n {z _ x -  \\ m u _ x} { \\s igma  \n_ x} ,  y _ c)  \\n o nu m be r \\\\  \n& \\ap p ro\nx \n( \\m u  _\nu^\nT - \\mu\n \n^\nT ) \\ nab l a _ { \\mu  ^ T }  f +  ( \\ s igm a\n _u^ T  -\n \\\ns ig m a \n^\nT) \\nabl\na\n _{\\sigma ^T}f \\nonumber \\\\ &\\quad + (\\frac {z_u - \\mu _u}{\\sigma _u}-\\frac {z_x - \\mu _x}{\\sigma _x})\\nabla _{\\frac {z_x - \\mu _x}{\\sigma _x}}f \\nonumber \\\\ &= (\\alpha * \\mu _u + (1 - \\alpha ) * \\mu ^T - \\mu ^T)\\nabla _{\\mu ^{T}} f \\nonumber \\\\ &\\quad + (\\alpha * \\sigma _u + (1 - \\alpha ) * \\sigma ^T - \\sigma ^T)\\nabla _{\\sigma ^T} f \\nonumber \\\\ &\\quad + (\\frac {z_u - \\mu _u}{\\sigma _u}-\\frac {z_x - \\mu _x}{\\sigma _x})\\nabla _{\\frac {z_x - \\mu _x}{\\sigma }}f \\nonumber \\\\ &= \\alpha * (\\mu _u - \\mu ^T)*\\nabla _{\\mu ^T} f + \\alpha * (\\sigma _u - \\sigma ^T)*\\nabla _{\\sigma ^T} f \\nonumber \\\\ &\\quad + (\\frac {z_u - \\mu _u}{\\sigma _u}-\\frac {z_x - \\mu _x}{\\sigma })\\nabla _{\\frac {z_x - \\mu _x}{\\sigma }}f \\label {long_equation}\n(16)\nDenote ||v|| as the L2-norm of tensor v. Suppose that\nsupx∈S(||∇µT f||, ||∇σT f||) = β and supx∈S ∇zx−µx\nσ\nf =\nξ, then we have:\n  \\ l abe\nl  \n{lo\ns\ns:n\no\nt\nd\none} \\non\num b er  & L^ { \\mat\nh c a l {U } ^T} -  L ^ {\\ma t hc\nal\n {S } ^T\n}\n \\\\\n \\ n o n u\nmbe\nr\n &\\\nleq \\ f rac { 1}{| \\ mathc\na l  {\nC}|\n}\n\\sum _{\nc \\i n  \\\nma\nt hc a l \n{\nC}}\n\\frac {1}{d}\\sum _{u \\in \\mathcal {U}_c, x \\in \\mathcal {S}_c} (\\alpha \\times (\\beta \\times ||\\mu ^T - \\mu _u|| \\\\ \\nonumber & \\quad + \\beta \\times ||\\sigma ^T - \\sigma _u||)+\\xi \\times ||\\frac {z_u - \\mu _u}{\\sigma _u}-\\frac {z_x - \\mu _x}{\\sigma }||) \\\\ \\nonumber & \\leq \\alpha \\times \\beta \\times \\frac {1}{|\\mathcal {U}|}\\sum _{u \\in \\mathcal {U}} ( ||\\mu ^T - \\mu _u||+||\\sigma ^T - \\sigma _u||) \\\\ & \\quad + \\xi \\times \\frac {1}{|\\mathcal {U}|}\\sum _{u \\in \\mathcal {U}, x \\in \\mathcal {S}}||\\frac {z_u - \\mu _u}{\\sigma _u}-\\frac {z_x - \\mu _x}{\\sigma }||.\\\\ \\nonumber\nObserved that, zu−µu\nσu\n, zx−µx\nσ\n∼N(0, I), where I is the\nidentity matrix size C × H × W, where C, H, W are the\nchannel, height, and width dimensions of zx. When the car-\ndinality of seen domains S, unseen domain U is sufficiently\nlarge, we can approximate:\n \n \\f\nr\nac {1}{\n|\\ma t hc\nal\n {U } |}\n\\\nsu m  _{u \\in \\mathcal {U}, x \\in \\mathcal {S}}||\\frac {z_u - \\mu _u}{\\sigma _u}-\\frac {z_x - \\mu _x}{\\sigma }|| = \\mathbb {E}[||U-X||], (18)\nwhere U and X are two random multivariate variables\nover RC×H×W drawn from standard Gaussian distribution,\nU, X ∼N(0, I). We have:\n  &\\qua d  \\qu a d 0 \\ l eq \\m a thbb  {V}[\n| |U -  X |\n|\n] = \\ m athbb  \n{\nE}[||U\n- X\n||^\n2\n] - (\\m\nathb b  {\nE}\n[ U -  X\n]\n)^ 2\n \n\\\\ & \\rightarrow \\mathbb {E}[U-X] \\leq \\sqrt {\\mathbb {E}[||U-X||^2]} = \\sqrt {Tr(2I)} \\\\ & \\rightarrow \\frac {1}{|\\mathcal {U}|}\\sum _{u \\in \\mathcal {U}, x \\in \\mathcal {S}}||\\frac {z_u - \\mu _u}{\\sigma _u}-\\frac {z_x - \\mu _x}{\\sigma }|| \\leq \\sqrt {Tr(2I)}\nLet Dµ(T , U) and Dσ(T , U) be the distance between\nmean and standard deviation of unified domain T and un-\nseen domain U, respectively. From Equation (17), we ob-\ntain:\n  L ^ {\\m a t h c a l {U}^ T } - L^{\\m a th\nc a l\n \n{S}^T}& \\leq \\alpha \\times \\beta \\times (\\mathcal {D}_\\mu (\\mathcal {U}, \\mathcal {T})+\\mathcal {D}_\\sigma (\\mathcal {\\mathcal {U}, \\mathcal {T}})) \\\\ & \\quad +\\xi \\times \\sqrt {2.Tr(I)}\nC. Experiment Setup\nImage classification: We train a ResNet18 pretrained on\nImageNet for 200 epochs with learning rate of 0.001. Batch\nsize is set to 32 for PACS dataset with 3 integrated Con-\nstStyle layers, and 128 with 1 ConstStyle layer for Digit5\ndataset.\nImage Corruption: We use WideResNet with a single\nConstStyle layer as a backbone, training for 200 epochs\nwith a learning rate of 0.05 and batch size of 512.\nInstance Retrieval: We train a model with ResNet50 pre-\ntrained on ImageNet as the backbone for 80 epochs with a\nlearning rate of 0.0035. We integrate 3 ConstStyle layers\n\nMethod\nVenue\nM,MM\nM,S\nM,SY\nM,U\nMM,S\nMM,SY\nMM,U\nS,SY\nS,U\nSY,U\nAvg\nERM\n-\n80.22\n82.77\n92.34\n97.46\n77.60\n74.83\n71.67\n52.49\n77.70\n87.86\n79.49\nCrossgrad\nICLR 2018\n79.24\n82.95\n92.01\n97.68\n76.64\n75.01\n73.00\n50.77\n78.77\n84.8\n77.02\nMixup\nICLR 2018\n75.92\n84.88\n90.81\n96.75\n75.87\n70.71\n67.49\n44.03\n80.51\n82.58\n76.95\nCutmix\nICCV 2019\n74.86\n85.16\n91.61\n97.02\n77.78\n70.04\n68.87\n45.51\n80.75\n85.59\n77.71\nEFDMix\nCVPR 2022\n76.29\n82.87\n92.53\n97.52\n77.65\n76.14\n73.33\n52.34\n78.57\n85.87\n78.88\nRIDG\nICCV 2023\n79.75\n84.48\n91.97\n97.23\n77.8\n73.77\n71.05\n50.73\n79.74\n86.33\n79.28\nMixStyle\nICLR 2021\n77.96\n72.69\n83.37\n86.82\n75.09\n62.18\n68.15\n41.53\n58.5\n71.88\n69.81\nDSU\nICLR 2022\n78.77\n83.83\n92.1\n97.81\n78.53\n74.78\n71.89\n53.66\n78.14\n87.62\n79.71\nCSU\nWACV 2024\n78.64\n84.29\n92.72\n97.39\n77.27\n75.61\n72.67\n57.28\n78.56\n88.08\n80.25\nConstStyle\nOurs\n80.22\n84.69\n92.92\n97.33\n78.73\n76.27\n74.19\n57.58\n80.29\n88.24\n81.04\nMethod\nVenue\nM,MM,S\nM,MM,SY\nM,MM,U\nM,S,SY\nM,S,U\nM,SY,U\nMM,S,SY\nMM,S,U\nMM,SY,U\nS,SY,U\nAvg\nERM\n-\n80.12\n76.39\n71.41\n61.89\n83.47\n91.07\n44.49\n77.63\n76.87\n48.47\n71.18\nCrossgrad\nICLR 2018\n79.59\n76.32\n71.31\n60.37\n83.21\n91.47\n36.57\n77.71\n74.26\n46.55\n70.34\nMixup\nICLR 2018\n78.35\n74.19\n69.51\n57.22\n85.78\n91.16\n34.45\n77.11\n71.34\n41.29\n68.04\nCutmix\nICCV 2019\n79.82\n73.12\n68.92\n58.28\n85.64\n91.32\n32.52\n78.3\n72.57\n39.92\n68.04\nEFDMix\nCVPR 2022\n80.38\n76.04\n70.13\n63.48\n83.62\n91.96\n43.46\n77.61\n73.94\n50.43\n71.10\nRIDG\nICCV 2023\n80.51\n74.71\n70.45\n61.76\n84.78\n91.41\n35.02\n78.28\n75.74\n45.53\n69.81\nMixStyle\nICLR 2021\n78.91\n74.97\n61.48\n57.95\n71.44\n81.43\n42.92\n71.44\n62.3\n40.99\n64.38\nDSU\nICLR 2022\n80.71\n76.25\n70.54\n62.35\n83.25\n91.47\n42.87\n77.84\n76.29\n48.31\n70.98\nCSU\nWACV 2024\n80.63\n76.26\n69.50\n64.68\n85.09\n91.53\n47.31\n77.64\n75.61\n52.73\n72.09\nConstStyle\nOurs\n80.32\n77.93\n70.89\n64.68\n84.88\n92.10\n48.88\n79.08\n77.27\n53.55\n72.95\nTable 7. Multiple unseen domain generalization (2 and 3 unseen domains) on Digits5 dataset. Abbrevations: (M: MNIST, MM: MNISTM,\nS: SVHN, SY: SYN, U: USPS). The best result is colored purple and the second best result is colored blue.\nFigure 7. Style statistics of ERM and ConstStyle.\nMethod\nDataset\nPACS\nDigit5\nConstStyle w/ Pretrained features\n86.31\n76.61\nConstStyle w/ Domain label\n86.73\n86.37\nConstStyle\n86.77\n86.88\nTable 8. Different variants of ConstStyle.\ninto the model.\nAcross all experiment scenarios, the number of clusters is\nfixed to 4. All methods are optimized using SGD optimizer.\nOptimal hyperparameters are selected based on the perfor-\nmance on the validation dataset.\nD. Additional Results\nD.1. Multiple Unseen Domains on Digit5 dataset\nWe perform additional experiment with multiple unseen do-\nmains on the Digit5 dataset. The results are shown in Table\n# of clusters\n1\n2\n3\n4\n5\nPACS\n86.07\n86.51\n86.61\n86.77\n86.61\nDigit5\n85,80\n85,60\n85,54\n86.88\n85.93\nTable 9. Impacts of the number of clusters.\nBatchsize\n8\n16\n32\n64\n128\n256\nAccuracy\n85.43\n86.22\n86.77\n86.33\n85.91\n85.10\nTable 10. Impacts of the batch size on accuracy (PACS dataset).\n7. It can be observed that ConstStyle achieves the best per-\nformance in most of the scenarios, and obtains the highest\naverage accuracy.\nE. Ablation Studies\nIn this section, we conduct a more in-depth analysis con-\ncerning the impacts hyperparameters in ConstStyle’s, which\nis the number of clusters used during the unified domain de-\ntermination phase, we additionally perform experiments to\nexplore the influence of training batch size and impact of α\nin the inference process.\nE.1. In-depth analysis of ConstStyle\nWe first conduct additional experiments to further analyze\nthe behaviors of ConstStyle. Figure 7 illustrates the style\nstatistics for both seen and unseen domains, demonstrating\nthat ConstStyle effectively aligns training and test samples\nwithin a unified domain, thereby enhancing performance\nunder distribution shift. Additionally, we evaluate Const-\n\nα\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nPACS\n86.00\n85.08\n85.76\n86.34\n86.33\n86.34\n86.77\n86.46\n86.22\n86.03\n85.86\nDigit5\n85.96\n85.62\n85.77\n85.91\n85.95\n86.88\n86.01\n85.99\n85.98\n86.01\n85.96\nTable 11.\nImpact of α to the model performance on different\ndatasets.\nStyle with two alternative approaches: 1. Clustering us-\ning domain label and 2. Utilizing pretrained style statis-\ntics with results shown in Table 8. We can observe that\nwhile domain labels can produce good performance, they\nare not always optimal, as some samples have style statistics\nbelonging to other domains; thus, clustering using GMM\ncan form appropriate domain clusters, yielding better per-\nformance. Furthermore, using pretrained features for clus-\ntering can achieve comparable results if style features are\npreviously learned by the pretrained model, as shown in the\nPACS dataset in Table 8. However, if the pretrained model\nhas not learned style features, relying on them can signif-\nicantly degrade ConstStyle’s accuracy, as observed in the\nDigit5 dataset.\nE.2. Impacts of the Number of Clusters\nWe first investigate the impact of the number of clusters dur-\ning the clustering phase, ranging from one to five. Figure 9\ndemonstrates that ConstStyle performs consistently across\ndomains, regardless of the number of clusters. This con-\nsistency demonstrates ConstStyle’s robustness, as the major\ngoal is to construct a single domain by averaging all of the\nclusters in the visible domains.\nE.3. Impacts of the Batch Size\nIn this section, we investigate the impacts of the batch size\non ConstStyle’s performance. Experiments are conducted\nwith batch size ranging from 8 to 256, and the results are\npresented in Table 10. The results suggest that using either\nvery small or very large batch sizes can lead to suboptimal\nperformance, as too few or too many style modifications\nmay disrupt learning stability. The optimal strategy is to\nuse a moderate batch size (about 32), ensuring balanced and\nsteady learning for the model.\nE.4. Impacts of Partial Projection\nWe study the impacts of α on the performance of the pro-\nposed method by varying this parameter from 0 to 1, with\nthe results presented in Table 11.\nIt is evident that the\nimpact of α varies significantly across different values,\nhighlighting its important role in achieving optimal perfor-\nmance. When an appropriate value of α is selected, overall\nperformance can improve by up to 0.56% for PACS dataset\nand up to 0.87% for Digit5 dataset, compared to when no α\nvalue is used. This results also highlights the effects of our\nproposed partial style alignment algorithm (Section 3.5).\nData size\n32892\n65787\n98680\n131575\nAverage training time per epoch (s)\n249.2\n568.4\n857.3\n1076.4\nTable 12. Scalability of ConstStyle with different number of train-\ning data size.\nE.5. Scalability against larger datasets\nConstStyle has three components: style statistics distribu-\ntion estimation, unified style determination, and style alig-\nment. The computational complexity of all three compo-\nnents scales linearly with the training data size. As a result,\nConstlyle is inherently scalable to large datasets. This scal-\nability is also empirically demonstrated in Table 12, which\nreports the average training time per epoch when varying\nthe training data size.\n"
    },
    {
      "arxiv_id": "2509.04033",
      "full_text": "Single spin asymmetry Asin(3ϕh−ϕR)\nUL\nin dihadron production in SIDIS\nLei Tan,1 Gang Li,1 Mao Song,1 and Xuan Luo1, ∗\n1School of Physics and Optoelectronics Engineering,\nAnhui University, Hefei 230601, People’s Republic of China\nIn the field of particle physics, the phenomenon of dihadron production in semi-inclusive deep\ninelastic scattering (SIDIS) process has always been a significant focus. This paper focuses on the\nsingle longitudinal spin asymmetry Asin(3ϕh−ϕR)\nUL\nin the dihadron production during this process\nand combines the transverse-momentum-dependent dihadron fragmentation function (DiFF) H⊥\n1 to\ndeeply analyze its underlying mechanism. Here, the involved DiFF H⊥\n1 is the analogue of the Collins\nfunction for single-hadron production and it describes the fragmentation of a transversely polarized\nquark at leading twist. Recent studies have shown that the azimuthal asymmetry signal observed\nby the COMPASS collaboration in the dihadron SIDIS is weak. To reveal the reason for this small\nsignal and to study the asymmetry, we calculate the unknown T-odd DiFF H⊥\n1 using the spectator\nmodel. The spectator model, widely used in SIDIS, describes the internal structure of hadrons and\nthe hadronization mechanism. This model has successfully explained dihadron production in unpo-\nlarized and single-polarized processes. During the research process, while maintaining the transverse\nmomentum dependence of the hadron pair, we employ the transverse momentum dependent(TMD)\nfactorization framework, using this method and the model, we first simulate the asymmetry in the\nCOMPASS energy region and compare it with experimental data.\nFurthermore, we predict the\nsame asymmetry at the HERMES, expecting to provide valuable theoretical references for relevant\nexperimental studies.\nI.\nINTRODUCTION\nThe\nstudy\nof\ndihadron\nfragmentation\nfunctions\n(DiFFs) is a focal point in both theoretical and experi-\nmental aspects. DiFFs describe the probability distribu-\ntion of the transformation of a quark or an antiquark into\ntwo hadrons and everything else through strong interac-\ntions. They were first mentioned in Ref. [1]. The evolu-\ntion equations of DiFFs have been successively examined\nin Refs. [2, 3], with more in-depth study in Refs. [4, 5].\nRef. [6] extended the research perspective by analyzing\nfor the first time the evolution kernel as the functions of\nthe hadron pair invariant mass Mh. Ref. [7] introduced\nthe transversely polarized dihadron fragmentation func-\ntion for spin analysis of transversely polarized fragmen-\ntation quarks, leading to the definition of H∢\n1 . Ref. [8]\ncomprehensively probed the leading order distortion in\ndihadron fragmentation and clarified the definition of the\nrelevant function.\nRef. [9] started the whole business\non dihadron fragmentation to access the quark transver-\nsity distributions. Regarding the exploration of nucleon\ntransverse spin, DiFFs [10] have played an important role\nin the study of nucleon spin structure. Ref. [11] intro-\nduced the partial-wave analysis and provided new posi-\ntive qualitative conditions, offering a clearer understand-\ning of the hadron-pair system. Ref. [12] went one step\nfurther by extending the analysis to the subleading twist,\nintegrating over the transverse component of hadron pair\nmomentum, and seamlessly connecting to the transverse\nmomentum dependent case. The cross section expression\nfor production of two hadrons in SIDIS within TMD fac-\n∗xuanluo@ahu.edu.cn\ntorization is presented in Ref. [13]. The Collins effect [14]\nand back-to-back dihadron production in e+e−annihila-\ntion [15] are commonly used techniques for extracting the\nchiral-odd transversity distribution. The in-depth study\nof the dihadron DiFFs has provided additional possibili-\nties for such analyses. Recently, Refs. [16–18] presented\na series of valuable research results on DiFFs. The trans-\nverse spin distributions were initially extracted by relying\non the convolution of single hadron SIDIS data h1 ⊗H⊥\n1 ,\nwhich can not be separated from the transverse momen-\ntum of quarks involved in the chiral-odd Collins fragmen-\ntation function. The chiral-odd dihadron fragmentation\nfunction H∢\n1 [11, 19] couples with a specific function h1\nand plays a crucial role at the leading twist level. The\nBELLE collaboration’s measurements of the azimuthal\nasymmetry in the distribution of charged pion pairs in\nannihilation of e+e−[20] have motivated the parameter-\nization of H∢\n1 for up and down quarks [21]. Recent stud-\nies [22–26] have extracted h1 from SIDIS and proton-\nproton collision data.\nIn the mean time, the specta-\ntor model [27–29], and Nambu-Jona-Lasinio (NJL) quark\nmodel [30–32] are used to make predictions for the DiFFs.\nIn particle physics research, the hadron pair produc-\ntion in SIDIS has attracted much attention, especially\nwith respect to its azimuthal asymmetry. The HERMES\ncollaboration [33] and COMPASS collaboration [34, 35]\nhave begun to measure such asymmetries in the hadron\npair production with unpolarized or transversely polar-\nized targets. In addition, the BELLE collaboration has\nmeasured the azimuthal asymmetry for the production of\nback-to-back hadron pair. More recently, the COMPASS\ncollaboration [36] has measured the azimuthal asymme-\ntry results for dihadron production using the longitudi-\nnally polarized proton target. When the incident lepton\nbeam is unpolarized or longitudinally polarized, one of\narXiv:2509.04033v1  [hep-ph]  4 Sep 2025\n\n2\nthe many modulations sin(3ϕh−ϕR) modulation appears\nin our field of view [11]. Other modulations under the\nsame experimental conditions, involving different under-\nlying mechanisms, are discussed in Refs. [37–39]. Here\nϕh is the azimuthal angle of the hadron pair system, and\nϕR is the angle between the lepton and dihadron plane.\nExperimentally, COMPASS measurements show that the\nsin(3ϕh−ϕR) asymmetry is near zero at the current accu-\nracy. Theoretically, in the parton model, this asymmetry\narises mainly from the coupling of the function h1L and\nthe T-odd DiFF H⊥\n1 .\nIn this paper, we investigate the sin(3ϕh−ϕR) asymme-\ntry in the SIDIS process for dihadron production. After\nperforming partial waves expansion, this asymmetry is\nfound to arise from the contribution of h1LH⊥\n1,OT where\nH⊥\n1,OT arises from the interference of s- and p-waves. In\nthe Amsterdam notations, h1L describes a transversely\npolarized quark in a longitudinally polarized proton, ap-\npearing at leading twist. We use the spectator model [28]\nto calculate H⊥\n1,OT and find that the loop contributions\nhave to be considered to obtain a non-vanishing result.\nUsing these results, the sin(3ϕh −ϕR) asymmetry is the-\noretically predicted at the COMPASS kinematics and\ncompared with the COMPASS preliminary data.\nThe remainder of the article is structured as follows.\nThe basic framework of the dihadron fragmentation func-\ntion is introduced in Chapter II. In Chapter III, the cal-\nculation of the sin(3ϕh −ϕR) azimuthal asymmetry in\nthe SIDIS process of dihadron production is presented,\nwhere an unpolarized lepton beam is scattered with a lon-\ngitudinally polarized proton target. Chapter IV applies\nthe spectator model to calculate the dihadron fragmenta-\ntion function H⊥\n1,OT for T-odd functions. Chapter V pro-\nvides numerical results for the sin(3ϕh −ϕR) azimuthal\nasymmetry under the kinematics of the COMPASS and\nHEMERS measurements. The present work is summa-\nrized in Chapter VI.\nII.\nTHE BASIC FRAMEWORK\nConsider the dihadron fragmentation function process\nq →π+π−X, in which a quark with momentum k frag-\nments into two unpolarized pions with masses M1, M2,\nand momenta P1, P2. For convenience, we introduce two\nvectors Ph = (P1 + P2) and R = (P1 −P2)/2, with Ph\nand R representing the total momentum and the rela-\ntive momentum of the dihadron. In addition, Mh rep-\nresents the invariant mass of the dihadron. We describe\na four-dimensional vector ⃗a as [a−, a+, ⃗aT ] in terms of\nthe longitudinal light-cone coordinates a± = a0±a3\n√\n2\nand\nthe transversal light-cone coordinates ⃗aT = (a1, a2). We\nalso introduce x which represents the longitudinal mo-\nmentum fraction of the final state quark. And zi is the\nlongitudinal component of the hadron hi found in the\nfragmentation of the quark. The ratio of the light-cone\nmomentum fraction carried by the hadron pair with re-\nspect to the fragmentation quark is defined as z. For con-\nvenience, the axes are chosen by virtue of the condition\n⃗PhT = 0. In order to perform the partial wave expansion\nof the dihadron fragmentation function, we need to give\nthe following dynamical quantities in the center of mass\nsystem of the dihadron. Here the momentum P µ\nh , kµ and\nRµ can be written as [28]\nP µ\nh =\n\u0014\nP −\nh , M 2\nh\n2P −\nh\n,⃗0T\n\u0015\n,\n(1)\nkµ =\n\"\nP −\nh\nz , z(k2 + ⃗k2\nT )\n2P −\nh\n,⃗kT\n#\n,\n(2)\nRµ =\n\u0014\n−|⃗R|P −\nh\nMh\ncos θ, |⃗R|Mh\n2P −\nh\ncos θ,\n|⃗R| sin θ cos ϕR, |⃗R| sin θ sin ϕR\n\u0015\n=\n\"\n−|⃗R|P −\nh\nMh\ncos θ, |⃗R|Mh\n2P −\nh\ncos θ, ⃗Rx\nT , ⃗Ry\nT\n#\n,\n(3)\nwhere\n|⃗R| =\nr\nM 2\nh\n4\n−m2π.\n(4)\nIn this physical context, mπ represents the mass of the\nπ meson and θ is defined as the polar angle between the\ndirection of P1 in the dihadron center of mass system and\nthe direction of Ph in the laboratory system [11]. With\nthe help of these four momenta, we are able to derive\nsome practical relations\nPh · k = M 2\nh\n2z + z k2 + ⃗k2\nT\n2\n,\n(5)\nPh · R = 0,\n(6)\nR · k =\n\u0012Mh\n2z −z k2 + ⃗k2\nT\n2Mh\n\u0013\n|⃗R| cos θ −⃗kT · ⃗RT .\n(7)\n\n3\nIII.\nTHE sin(3ϕh −ϕR) ASYMMETRY OF\nDIHADRON PRODUCTION IN SIDIS\nFIG. 1: Angle definitions involved in the measurement\nof the single longitudinal spin asymmetry in SIDIS\nproduction of two hadrons.\nThe SIDIS process shown in Fig.1, in which an unpo-\nlarized lepton µ collides with a longitudinally polarized\nnucleon target to produce dihadrons h+ and h−where\nthe incoming and outgoing four-momenta of the lepton\nare denoted as ℓand ℓ\n′, and the momentum of the proton\ntarget is P, with mass M and polarization S. In this pro-\ncess, the parton momentum is p, and the virtual photon\nmomentum q = ℓ−ℓ\n′. The final state quark momentum\nis k = p + q, which subsequently fragments up into two\nunpolarized hadrons with masses M1, M2 and momenta\nP1, P2, respectively, along with some unobservable states\nX. In order to clarify the relation between the differential\ncross section of the process and the structure function on\nwhich the dihadron fragmentation function depends, we\nuse the following kinematic variables\nx = p+\nP + , y = P · q\nP · ℓ, z = P −\nh\nk−= z1 + z2,\n(8)\nzi = P −\ni\nk−, Q2 = −q2, s = (P + ℓ)2,\n(9)\nPh = P1 + P2, R = R1 −R2\n2\n, M 2\nh = P 2\nh.\n(10)\nThe DiFFs D1 and H⊥\n1\ncan be extracted from the\nquark-quark correlation function ∆(k; Ph; R)\n∆(k, Ph, R) =\nX\nZ\nX\nd4ξ\n(2π)4 eik·ξ⟨0|ψ(ξ)|Ph, R; X⟩\n⟨X; Ph, R|ψ(0)|0⟩|ξ−=⃗ξT =0\n=\n1\n16π\n\u001a\nD1/n−+ G⊥\n1 γ5\nεµν\nT RT µkT ν\nM 2\nh\n/n−\n+H⊥\n1\nσµνkµ\nT nν\n−\nMh\n+ H∢\n1\nσµνRµ\nT nν\n−\nMh\n\u001b\n,\n(11)\nwhere n−=\n1\n√\n2[1, 0, 0, −1], similarly, we need to repre-\nsent the quark-quark correlation function in the leading\ntwist form in the center-of-mass system. There is a spe-\ncific relation between the correlation function under these\ntwo different representations, which reads as follows\n∆(z, k2\nT , cos θ, M 2\nh, ϕR, ϕk) =\n|⃗R|\n16zMh\nZ\ndk+∆(k, Ph, R).\n(12)\nBy first decomposing the correlation function of the\ncenter-of-mass system according to the generally possible\nDirac structure, and then projecting the desired scalar\nfunction, the following relation can be obtained\n4πTr\n\u0002\n∆(z, k2\nT , cos θ, M 2\nh, ϕR, ϕk)iσα−γ5\n\u0003\n= εαβ\nT kβ\nT\nMh\nH⊥\n1 + εαβ\nT Rβ\nT\nMh\nH∢\n1 ,\n(13)\nwhere iσα−= −1\n2(γαγ−−γ−γα), and γ−is the negative\nlight-cone Dirac function.\nThe DiFFs D1 and H⊥\n1 can be expanded into the par-\ntial waves form associated with the corresponding di-\nhadron system [11]. The dependence on ⃗kT · ⃗RT makes\nthe expansion more complicated\nD1(z, k2\nT , cos θ, M 2\nh, ϕR, ϕk) = D1,OO(z, M 2\nh) + D1,OL(z, M 2\nh) cos θ + D1,LL(z, M 2\nh)1\n4(3 cos2 θ −1)\n+ cos(ϕk −ϕR) sin θ(D1,OT + D1,LT cos θ) + cos(2ϕk −2ϕR) sin2 θD1,T T ,\n(14)\nH⊥\n1 (z, k2\nT , cos θ, M 2\nh, ϕR, ϕk) = H⊥\n1,OO(z, M 2\nh) + H⊥\n1,OL(z, M 2\nh) cos θ + H⊥\n1,LL(z, M 2\nh)1\n4(3 cos2 θ −1)\n+ 2 cos(ϕk −ϕR) sin θ(H⊥\n1,OT + H⊥\n1,LT cos θ).\n(15)\nH⊥\n1,OT originates from the interference of s- and p-\nwaves, H⊥\n1,OO is the sum of the pure contributions from\nthe s- wave ( 1\n4H⊥\n1,OO,s) and p- wave ( 3\n4H⊥\n1,OO,p). We then\nconsider the azimuthal asymmetry of the SIDIS process,\nin which the unpolarized muon and longitudinally polar-\n\n4\nized nucleon targets scatter. Within the TMD framework\nusing the defining A(y) = 1−y+ y2\n2 , the differential cross\nsection of the process is [19]\nd8σUL\ndxdydzdϕhdϕRd cos θd⃗P 2\nh⊥dM 2\nh\n=\nα2\n2πsxy2 A(y)\nX\nq\ne2\nqI\n\"\nf q\n1 ×\n(\nDq\n1,OO + Dq\n1,OL cos θ+\nDq\n1,LL\n1\n4(3 cos2 θ −1) + sin θ cos(ϕh −ϕR)\n\u0010\nDq\n1,OT + Dq\n1,LT cos θ\n\u0011\n+ sin2 θ cos[2(ϕh −ϕR)] Dq\n1,T T\n)#\n,\n(16)\nand Ref. [11] presented a complete formula for the longitudinally polarized nucleon, we can get\nd8σUL\ndxdydzdϕhdϕRd cos θd⃗P 2\nh⊥dM 2\nh\n=\nα2\n2πsxy2 A(y)\nX\nq\ne2\nq{sin θ sin(3ϕh −ϕR)×\n(−I\n\"\n4(⃗pT · ˆPh⊥)(⃗kT · ˆPh⊥)2 −2(⃗pT · ⃗kT )(⃗kT · ˆPh⊥) −⃗k2\nT (⃗pT · ˆPh⊥)\n2MM 2\nh\n#\nh⊥\n1L(−2Mh\n|⃗kT |\nH⊥\n1,OT ))}.\n(17)\nThe structure functions appearing in Eq. (17) are con-\nvolutional forms with specific weights\nI [f] =\nZ\nd2⃗pT d2⃗kT δ(⃗pT −⃗kT −\n⃗Ph⊥\nz ) [f] .\n(18)\nwhere ϕR and ϕS are the azimuthal angles of the trans-\nverse vectors ⃗RT and ⃗ST with respect to the lepton\nscattering plane, respectively. The ˆPh⊥satisfies ˆPh⊥=\n⃗Ph⊥/|⃗Ph⊥|. For convenience the unpolarized or longitu-\ndinally polarized states are denoted by the labels U and\nL.\nIn Eq. (16), f q\n1 and Dq\n1,OO are the unpolarized PDF\nand the unpolarized DiFF with flavor q, respectively. In\nEq. (17), h⊥\n1L is a distribution function of twist-2 which\ncouples to the T-odd DiFF H⊥\n1,OT . To obtain the asym-\nmetry we need to integrate over the cos θ and the result\nis as follows\nAsin(3ϕh−ϕR)\nUL\n= π\n4\nΣqe2\nq\nR\nI\n\u0002\n−[ 4(⃗pT · ˆ\nPh⊥)(⃗kT · ˆ\nPh⊥)2−2(⃗pT ·⃗kT )(⃗kT · ˆ\nPh⊥)−⃗k2\nT (⃗pT · ˆ\nPh⊥)\n2MM 2\nh\n]h⊥\n1L(−2Mh\n|⃗kT | H⊥\n1,OT )\n\u0003\nΣqe2q\nR\nI[f q\n1 D1,OO]\n.\n(19)\nIV.\nTHE MODEL CALCULATION OF H⊥\n1,OT\nIn this section, we need to calculate the DiFF H⊥\n1,OT\nunder the spectator model. Theoretically, the absence of\nimaginary phases leads to a vanishing H⊥\n1,OT for the tree\ndiagram correlation function.\nHowever, in the case of\nthe DiFF, the quark-dihadron interaction vertex F s∗F p\nis defined in complex form as a way of generating this\nimaginary phase. Thus, a correlation function similar to\nthe Ref. [28] can be obtained\n∆q(k, Ph, R) =\n1\n(2π)4\n(/k + m)\n(k2 −m2)2\n× (F s∗e\n−k2\nΛ2s + F p∗e\n−k2\nΛ2p /R)\n× (/k −/P h + Ms) × (F se\n−k2\nΛ2s + F pe\n−k2\nΛ2\nP /R)\n× (/k + m) · 2πδ((k −Ph)2 −M 2\ns ),\n(20)\nwhere m and Ms represent the masses of the fragmented\nquark as well as the spectator quark, respectively. The\ns-wave and p-wave vertex structures F s, F p are usually\nwritten in the following form [28]\nF s = fs,\nF p = fρ\nM 2\nh −M 2\nρ −iΓρMρ\n(M 2\nh −M 2ρ)2 + Γ2ρM 2ρ\n+ fω\nM 2\nh −M 2\nω −iΓωMω\n(M 2\nh −M 2ω)2 + Γ2ωM 2ω\n−if ′\nω\np\nλ(M 2ω, M 2\nh, m2π)Θ(Mω −mπ −Mh)\n4πΓM 2ω[4M 2ωm2π + λ(M 2ω, M 2\nh, m2π)]\n1\n4 .\n(21)\nwhere λ(M 2\nω,M 2\nh, m2\nπ) = (M 2\nω−(Mh+mπ)2)(M 2\nω−(Mh−\nmπ)2), Θ denotes the unit step function. The first two\nterms of F p can be identified with the contributions of\nthe ρ and the ω resonances decaying into two pions. The\n\n5\nmasses and widths of the two resonances are adopted\nfrom the PDG [40]: Mρ = 0.776 GeV, Γρ = 0.150 GeV,\nMω = 0.783 GeV and Γω = 0.008 GeV.\nSubstituting Eq. (20) into Eq. (12) yields\n∆q(z, k2\nT , cos θ, M 2\nh, ϕR, ϕk) =\n|⃗R|\n256π3z(1 −z)Mhk−\n×\n\u0014\n|F s|2e\n−2k2\nΛ2s (/k + m)(/k −/P h + MS)(/k + m)\n(k2 −m2)2\n+ |F p|2e\n−2k2\nΛ2p (/k + m)/R(/k −/P h + MS)/R(/k + m)\n(k2 −m2)2\n+ F s∗F pe\n−2k2\nΛ2sp (/k + m)(/k −/P h + MS)/R(/k + m)\n(k2 −m2)2\n+ F s∗F pe\n−2k2\nΛ2sp (/k + m)/R(/k −/P h + MS)(/k + m)\n(k2 −m2)2\n\u0015\n.\n(22)\nHere z-dependent Λ truncates Λsp and Λs,p to satisfy the\nfollowing relation\n2\nΛ2sp\n= 1\nΛ2s\n+ 1\nΛ2p\n,\n(23)\nwhere Λs,p satisfies the following structure and a,β and γ\nare the model parameters that will be given afterwards,\nand the k2 is fixed by the on-shell condition of the spec-\ntator\nΛs,p = as,pzβs,p(1 −z)γs,p,\n(24)\nk2 =\nz\n1 −z\n⃗k2\nT + M 2\ns\n1 −z + M 2\ns\nz .\n(25)\nIn Eq. (22), the terms of the |F s|2 and |F p|2 couplings are\npure s-wave and p-wave contributions, respectively, and\ntherefore they do not contribute to H⊥\n1,OT . H⊥\n1,OT orig-\ninates exclusively from the s- and p-wave interferences,\ndescribed by the last two terms in Eq. (22), where the\nrequired imaginary phase originates in the p-wave vertex\nF p. Following the approach of Ref. [28], for the tree di-\nagram results of H⊥\n1,OT , the mass of the input quark can\nbe set to be zero GeV. We have verified that even if the\ninput quark is given a small mass, they have essentially\nno effect on the model predictions of the DiFF and the\nresulting asymmetry. Therefore, the tree diagram con-\ntribution of H⊥\n1,OT vanishes, and it is then necessary to\nconsider the one-loop diagram contribution.\nWrite the one-loop contribution of the correlation func-\ntion in the Fig. 2 according to Feynman rule\n∆q\na(z, k2\nT , cos θ, M 2\nh, ϕR, ϕk) = i\nCF αs\n32π2(1 −z)P −\nh\n· |⃗R|\nMh\n·\n(/k + m)\n(k2 −m2)3 (F s∗e\n−k2\nΛ2s + F p∗e\n−k2\nΛ2p /R)(/k −/P h + Ms)\n× (F se\n−k2\nΛ2s + F pe\n−k2\nΛ2p /R)(/k + m)\nZ\nd4ℓ\n(2π)4\nγµ(/k −/ℓ+ m)γµ(/k + m)\n((k −ℓ)2 −m2 + iε)(ℓ2 + iε),\n(26)\n∆q\nb(z, k2\nT , cos θ, M 2\nh, ϕR, ϕk) = i\nCF αs\n32π2(1 −z)P −\nh\n|⃗R|\nMh\n(/k + m)\n(k2 −m2)2 (F s∗e\n−k2\nΛ2s + F p∗e\n−k2\nΛ2p /R)(/k −/P h + Ms)\nZ\nd4ℓ\n(2π)4\nγµ(/k −/P h −/l + Ms)(F se\n−k2\nΛ2s + F pe\n−k2\nΛ2p /R)(/k −/ℓ+ m)γµ(/k + m)\n(k −Ph −ℓ)2 −M 2s + iε)((k −ℓ)2 −m2 + iε)(ℓ2 + iε)\n,\n(27)\n\n6\nFIG. 2: One loop order corrections to the fragmentation function of a quark into a meson pair in the spectator\nmodel. Where h.c. represents the hermitian conjugations of these diagrams.\n∆q\nc(z, k2\nT , cos θ, M 2\nh, ϕR, ϕk) = i\nCF αs\n32π2(1 −z)P −\nh\n· |⃗R|\nMh\n·\n(/k + m)\n(k2 −m2)2 (F s∗e\n−k2\nΛ2s + F p∗e\n−k2\nΛ2p /R)(/k −/P h + Ms)\n× (F se\n−k2\nΛ2s + F pe\n−k2\nΛ2p /R)\nZ\nd4ℓ\n(2π)4\n(/k + m)γ−(/k −/ℓ+ m)\n((k −ℓ)2 −m2 + iε)(−ℓ−± iε)(ℓ2 + iε),\n(28)\n∆q\nd(z, k2\nT , cos θ, M 2\nh, ϕR, ϕk) = i\nCF αs\n32π2(1 −z)P −\nh\n· |⃗R|\nMh\n· (/k + m)\nk2 −m2 (F s∗e\n−k2\nΛ2s + F p∗e\n−k2\nΛ2p /R)(/k −/P h + Ms)\nZ\nd4ℓ\n(2π)4\nγ−(/k −/P h −/ℓ+ ms)((F se\n−k2\nΛ2s + F pe\n−k2\nΛ2p /R))(/k −/ℓ+ m)\n(k −Ph −ℓ)2 −M 2s + iε)((k −ℓ)2 −m2 + iε)(−ℓ−± iε)(ℓ2 + iε).\n(29)\nIn Eqs. (26–29), we use the Feynman rule 1/(−ℓ−±iξ)\nfor the eikonal propagator, and this Feynman rule is also\napplicable to the vertex formed between the eikonal line\nand the gluon. As a matter of principle, the Gaussian\nform factors in these formulas should depend on the loop\nmomentum ℓ. In order to simplify the integrals, we follow\nthe choice made in Ref. [41], where the dependence on ℓ\nis discarded and only these Gaussian form factors are\nassumed to have a k2 dependence. Similar choices are\nmade in Ref. [42–44], which also lead to reasonable final\nresults.\nHere we apply the Cutkosky cutting rules\n1\nℓ2 + iε →−2πiδ(ℓ2),\n1\n(k −ℓ)2 + iε →−2πiδ((k −ℓ)2).\n(30)\nUsing the above convention, the final result of H⊥\n1,OT\nis obtained:\nH⊥a\n1,OT = 0,\n(31)\nH⊥b\n1,OT =\n1\n2π3\n\"\nCF αs|⃗R|2\n1 −z\n· |F s∗F p|e\n−2k2\nΛ2sp\n#\n×\n1\n(k2 −m2)2 kT Cb,\n(32)\nH⊥c\n1,OT = 0,\n(33)\nH⊥d\n1,OT = −1\n2π3\n\"\nCF αs|⃗R|2\n1 −z\n· |F s∗F p|e\n−2k2\nΛ2sp\n#\n×\n1\n(k2 −m2)((I2 −A)kT ),\n(34)\nwith\nCb = A(2k2 + 2m2 + 2mMs) + B(2m2 + 2M 2\nh −2M 2\ns )\n+A0(−k2 −m2) + B0(M 2\ns −m2 −M 2\nh) + I2(m2 −k2).\n(35)\n\n7\nThe coefficients A and B denote the following functions\nA =\nI1\nλ(k, Mh, Ms)[2k2(k2 −M 2\ns −M 2\nh)I2\nπ\n+ (k2 + M 2\nh −M 2\ns )],\n(36)\nB = −\n2k2\nλ(k, Mh, Ms)I1\n\u0012\n1 + k2 + M 2\ns −M 2\nh\nπ\nI2\n\u0013\n,\n(37)\nwhich originate from the decomposition of the following\nintegral [45]\nZ\nd4ℓℓµδ(ℓ2)δ\n\u0002\n(k −ℓ)2 −m2\u0003\n(k −Ph −ℓ)2 −M 2s\n= Akµ + BP µ\nh .\n(38)\nThe functions Ii represent the results of the following\nintegrals\nI1 =\nZ\nd4ℓδ(ℓ2)δ\n\u0002\n(k −ℓ)2 −m2\u0003\n=\nπ\n2k2 (k2 −m2),\n(39)\nI2 =\nZ\nd4ℓδ(ℓ2)δ\n\u0002\n(k −ℓ)2 −m2\u0003\n(k −ℓ−Ph)2 −M 2s\n=\nπ\n2\np\nλ(k, Mh, Ms)\nln\n\u0012\n1 −\n2\np\nλ(k, Mh, Ms)\nk2 −M 2\nh + M 2s +\np\nλ(k, Mh, Ms)\n\u0013\n,\n(40)\nwhere λ(k, Mh, Ms) = [k2−(Mh+Ms)2][k2−(Mh−Ms)2].\nFurthermore, we have to calculate the following integrand\nZ\nd4ℓℓµℓνδ(ℓ2)δ((k −ℓ)2 −m2)\n(k −p −ℓ)2 −M 2s\n= kµkνA0 + kµpνB0 + pµkνC0 + pµpνD0 + gµνE0,\n(41)\nwhere the coefficients A0, B0, C0, D0 and E0 are defined as:\nA0 = (k2 −m2)(Ak4 −Bk4 −4Ak2M 2\nh −2Bk2M 2\nh + AM 4\nh + BM 4\nh −2Ak2M 2\ns + 2Bk2M 2\ns −2AM 2\nhM 2\ns + AM 4\ns −BM 4\ns )\n2k2(k4 −2k2M 2\nh −2k2M 2s + M 4\nh −2M 2\nhM 2s + M 4s )\n,\n(42)\nB0 = C0 = 1\n2\n(k2 −m2)(Ak2 + 3Bk2 + AM 2\nh −BM 2\nh −AM 2\ns −3BM 2\ns )\nk4 −2k2M 2\nh −2k2M 2s + M 4\nh −2M 2\nhM 2s + M 4s\n,\n(43)\nD0 = −\n(k2 −m2)(Ak2 + 2Bk2 −BM 2\nh + BM 2\ns )\nk4 −2k2M 2\nh −2k2M 2s + M 4\nh −2M 2\nhM 2s + M 4s\n,\n(44)\nE0 = −1\n4(k2 −m2)(A −B),\n(45)\nand B0 = C0 because of the symmetry of the integrand under the exchange of the Lorentz indices µ and ν.\nV.\nNUMERICAL RESULTS\nTo determine the parameters of the spectator model,\nthe authors of Ref. [28] conduct a comparison between\nthe model and the output of the PYTHIA event gen-\nerator [46] that is employed for the HERMES experi-\nment. The parameter values acquired through the fitting\nprocess are as follows: as = 2.60 GeV, βs = −0.751,\nγs = −0.193, ap = 7.07 GeV, βp = −0.038, γp = −0.085,\nfs = 1197 GeV−1, fρ = 93.5, fω = 0.63, f ′\nω = 75.2,\nMs = 2.97 Mh.\nIn this study, as chosen in Ref. [28],\nthe input quark mass is set to zero GeV.\nIt is worth\nemphasizing that the model parameters are obtained by\ncomparing the theoretical predictions with simulations\ngenerated from PYTHIA events under HERMES kine-\nmatics. Subsequent predictions of the asymmetry will be\nmade under the kinematic conditions of COMPASS and\nEIC. Since this prediction is based on model parameters\nobtained under HERMES dynamics, there is necessarily\na degree of uncertainty in these parameters. However, in\nthe current work, this uncertainty is neglected and the\nstrong coupling is chosen to be αs ≈0.3.\nIn the left and right panels of Fig. 3, we plot the ratio\nof H⊥\n1,OT relative to D1,OO as a function of z and Mh,\nobtained after integrating over the azimuthal angle ϕk\nand the magnitude kT of the transverse momentum. For\nthe z-dependent plot (left panel), we integrate over Mh\nin the range 0.3 GeV < Mh < 1.6 GeV; conversely, for\nthe Mh-dependent plot (right panel), we integrate over z\nin the range 0.2 GeV < z < 0.9 GeV. The comparison\nshows that H⊥\n1,OT is numerically three orders of magni-\ntude smaller compared to the unpolarized dihadron frag-\n\n8\nmentation function D1,OO. At the same time, it is found\nthat there exists a zero point at Mh = 0.74 GeV.\nIn the following, we present the numerical results for\nthe azimuthal asymmetry of sin(3ϕh −ϕR) in the SIDIS\nprocess. This process is defined as the scattering between\nan unpolarized muon and a longitudinally polarized nu-\ncleon target. Based on the principle of isospin symme-\ntry, we find that the fragmentation correlators associ-\nated with the processes of u →π+π−X, ¯d →π+π−X,\nd →π−π+X, and ¯u →π−π+X are similar to one an-\nother. Regarding vector transformation, when the sign\nreversal operation is applied to ⃗R, this operation is math-\nematically equivalent to performing the angular transfor-\nmations θ →π −θ and ϕ →ϕ + π respectively. The pro-\ncesses originating from d →π−π+X and ¯u →π−π+X,\nwhich show a linear dependence on ⃗R for the DiFF\nH⊥\n1,OT , produce a negative sign compared to the pro-\ncess originating from u →π+π−X.\nWhen expanding\nthe flavor sum in the numerator of Eq. (19), we utilize\nthe isospin symmetry on the DiFF H⊥\n1 . In addition, the\nsea quark distributions should be generated by the evolu-\ntion of perturbative QCD and they are zero at the model\nscale. In the present work, we decide to ignore the QCD\nevolution which causes the antiquark PDFs f1 and h1L\nto take zero values. The expressions for the distribution\nfunction of (3ϕh−ϕR) azimuthal asymmetry with respect\nto the independent variables x, z, and Mh below can be\naccurately derived using Eq. (19).\nAsin(3ϕh−ϕR)\nUL\n(x) =\n\u0012 Z\ndydz2MhdMhd cos θd2 ⃗kT d2 ⃗pT d2 ⃗Ph⊥(kT pT π\n4\n)δ(⃗pT −⃗kT −\n⃗Ph⊥\nz\n)(−\n\"\n4(⃗pT · ⃗Ph⊥)(⃗kT · ⃗Ph⊥)2 −2|⃗Ph⊥|2(⃗pT · ⃗kT )(⃗kT · ⃗Ph⊥) −|⃗Ph⊥|2⃗k2\nT (⃗pT · ⃗Ph⊥)\n2|⃗Ph⊥|3MM 2\nh\n#\n(4h⊥u\n1L −h⊥d\n1L)(−2Mh\n|⃗kT |\nH⊥\n1,OT )\n\u0013\u000e\n\u0012 Z\ndydz2MhdMhd cos θd2 ⃗kT d2 ⃗pT d2 ⃗Ph⊥δ(⃗pT −⃗kT −\n⃗Ph⊥\nz\n)(4f u\n1 (p2\nT ) + f d\n1 (p2\nT ))D1,OO(k2\nT )\n\u0013\n,\n(46)\nAsin(3ϕh−ϕR)\nUL\n(z) =\n\u0012 Z\ndxdy2MhdMhd cos θd2 ⃗kT d2 ⃗pT d2 ⃗Ph⊥(kT pT π\n4\n)δ(⃗pT −⃗kT −\n⃗Ph⊥\nz\n)(−\n\"\n4(⃗pT · ˆPh⊥)(⃗kT · ˆPh⊥)2 −2|⃗Ph⊥|2(⃗pT · ⃗kT )(⃗kT · ⃗Ph⊥) −|⃗Ph⊥|2⃗k2\nT (⃗pT · ⃗Ph⊥)\n2|⃗Ph⊥|3MM 2\nh\n#\n(4h⊥u\n1L −h⊥d\n1L)(−2Mh\n|⃗kT |\nH⊥\n1,OT )\n\u0013\u000e\n\u0012 Z\ndxdy2MhdMhd cos θd2 ⃗kT d2 ⃗pT d2 ⃗Ph⊥δ(⃗pT −⃗kT −\n⃗Ph⊥\nz\n)(4f u\n1 (p2\nT ) + f d\n1 (p2\nT ))D1,OO(k2\nT )\n\u0013\n,\n(47)\nAsin(3ϕh−ϕR)\nUL\n(Mh) =\n\u0012 Z\ndxdydz2Mhd cos θd2 ⃗kT d2 ⃗pT d2 ⃗Ph⊥(kT pT π\n4\n)δ(⃗pT −⃗kT −\n⃗Ph⊥\nz\n)(−\n\"\n4(⃗pT · ˆPh⊥)(⃗kT · ˆPh⊥)2 −2|⃗Ph⊥|2(⃗pT · ⃗kT )(⃗kT · ⃗Ph⊥) −|⃗Ph⊥|2⃗k2\nT (⃗pT · ⃗Ph⊥)\n2|⃗Ph⊥|3MM 2\nh\n#\n(4h⊥u\n1L −h⊥d\n1L)(−2Mh\n|⃗kT |\nH⊥\n1,OT )\n\u0013\u000e\n\u0012 Z\ndxdydz2Mhd cos θd2 ⃗kT d2 ⃗pT d2 ⃗Ph⊥δ(⃗pT −⃗kT −\n⃗Ph⊥\nz\n)(4f u\n1 (p2\nT ) + f d\n1 (p2\nT ))D1,OO(k2\nT )\n\u0013\n,\n(48)\nwhere the results for D1,OO can be obtained with the\nhelp of a similar tree diagram order calculation\nD1,OO(z,⃗k2\nT , Mh) =\n4π|⃗R|\n256π3Mhz(1 −z)(k2 −m2)2\n(\n4|F s|2e\n−2k2\nΛ2s (zk2 −M 2\nh −m2z + m2 + 2mMs + M 2\ns )−\n4|F p|2e\n−2k2\nΛ2p |⃗R|2(−zk2 + M 2\nh + m2(z −1) + 2mMs −M 2\ns )\n+ 4\n3|F p|2e\n−2k2\nΛ2\nP |⃗R|2\n\u0014\n4\n\u0012Mh\n2z −z k2 + ⃗k2\nT\n2Mh\n\u00132\n+ 2z k2 −m2\nMh\n\u0012Mh\n2z −z k2 + ⃗k2\nT\n2Mh\n\u0013\u0015)\n.\n(49)\nRegarding the PDFs f1 and h⊥\n1L, we use the same spec-\ntator model results [47] for uniformity. In order to cal-\nculate the value of the sin(3ϕh −ϕR) asymmetry in the\nprocess of SIDIS produced by dihadron under the COM-\nPASS kinematics, the following kinematics truncation is\nused [36]\n• Cut1 at the COMPASS: √s = 17.4 GeV, 0.003 <\nx < 0.4, 0.1 < y < 0.9, 0.2 < z < 0.9, 0.3 GeV <\nMh < 1.6 GeV, Q2 > 1 GeV2, W > 5 GeV.\n\n9\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nz\n0.02\n0.01\n0.00\n0.01\n0.02\nH1, OT/D1, oo\nspectator medel prediction\n0\n1\n2\nMh[GeV]\n0.02\n0.01\n0.00\n0.01\n0.02\nH1, OT/D1, oo\nspectator medel prediction\nFIG. 3: The DiFF H⊥\n1,OT as functions of z (left panel) and Mh (right panel) in the spectator model, normalized by\nthe unpolarized DiFF D1,OO.\n10\n2\n10\n1\nx\n0.05\n0.04\n0.03\n0.02\n0.01\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\nASin(3\nh\nR)\nUL\nspectator model prediction\nCOMPASS measurement\n(a)\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nz\n0.05\n0.04\n0.03\n0.02\n0.01\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\nASin(3\nh\nR)\nUL\nspectator model prediction\nCOMPASS measurement\n(b)\n0.0\n0.5\n1.0\n1.5\n2.0\nMh[GeV]\n0.05\n0.04\n0.03\n0.02\n0.01\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\nASin(3\nh\nR)\nUL\nspectator model prediction\nCOMPASS measurement\n(c)\nFIG. 4: The sin(3ϕh −ϕR) azimuthal asymmetry in the SIDIS process of unpolarized muons off longitudinally\npolarized nucleon target as a functions of x (Fig. 4a), z (Fig. 4b) and Mh (Fig. 4c) at COMPASS. The full circles\nwith error bars show the preliminary COMPASS data [28] for comparison. The dashed curves denote the model\nprediction.\nhere W is the invariant mass of photon-nucleon system\nwith W 2 = (P + q)2 ≈1−x\nx Q2.\nAfter performing numerical operations, under the\nCOMPASS dynamics conditions, our main results are\npresented in Fig. 4. This figure shows both the model pre-\ndictions and experimental measurements of the sin(3ϕh−\nϕR) azimuthal asymmetry.\nThe distributions with re-\nspect to x (Fig. 4a), z (Fig. 4b), and Mh (Fig. 4c) are\ndepicted respectively.\nThe dashed line represents our\nmodel predictions, while the solid circles with error bars\nrepresent the preliminary data from the COMPASS col-\nlaboration.\nThrough comparison, we observe that the\nmodel predictions effectively characterize the preliminary\nCOMPASS data, which are consistent with zero. Based\non the model calculations for H⊥\n1,OT , its relatively small\nvalue might be the primary cause of this small magnitude\nasymmetry.\nIn addition, for further comparison, we have predicted\nthe same asymmetry on HERMES using the following\nkinematics truncations.\nThe x, z, and Mh dependent\nasymmetries are plotted in Fig. 5. As shown, we believe\nthat the overall trend of asymmetry for HERMES is sim-\nilar to that of COMPASS. The size of the asymmetry is\nslightly smaller than the size at COMPASS and can still\nbe commensurate with zero in the kinematics of HER-\nMES.\n• Cut2 [48] at the HERMES: √s = 7.2 GeV, 0.023 <\nx < 0.4, 0.1 < y < 0.95, 0.2 < z < 0.7, 0.3 GeV <\nMh < 1.6 GeV, Q2 > 1 GeV2, W 2 > 10 GeV2,\nVI.\nCONCLUSION\nIn this research, we investigate the single spin asym-\nmetry with a sin(3ϕh −ϕR) modulation in the dihadron\nproduction process of SIDIS. With the spectator model\nresults for D1,OO, we calculate the T-odd DiFF H⊥\n1,OT by\nconsidering loop contributions to obtain a nonvanishing\nH⊥\n1,OT . We present the prediction for the sin(3ϕh −ϕR),\ncomparing the prediction with the COMPASS measure-\nments by using the numerical results of the DiFFs and\nPDFs.\nThe results describe the vanishing data in the\nCOMPASS measurements very well. In addition, we ob-\ntain particularly small asymmetries in the dynamics con-\nditions of HERMES. Under the predictions of COMPASS\nand HERMES, the Mh distribution of the asymmetry\nexhibits a distinct characteristic structure.\nThe result\n\n10\n10\n3\n10\n2\n10\n1\nx\n0.05\n0.04\n0.03\n0.02\n0.01\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\nASin(3\nh\nR)\nUL\nHEMERS\nspectator model prediction\n(a)\n0.2\n0.4\n0.6\nz\n0.05\n0.04\n0.03\n0.02\n0.01\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\nASin(3\nh\nR)\nUL\nHEMERS\nspectator model prediction\n(b)\n0\n1\n2\nMh[GeV]\n0.05\n0.04\n0.03\n0.02\n0.01\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\nASin(3\nh\nR)\nUL\nHEMERS\nspectator model prediction\n(c)\nFIG. 5: The sin(3ϕh −ϕR) azimuthal asymmetry in the SIDIS process of unpolarized muons off longitudinally\npolarized nucleon target as a functions of x (Fig. 5a), z (Fig. 5b) and Mh (Fig. 5c) at the HERMES(√s = 7.2 GeV).\nprovides us important clues to get an in-depth under-\nstanding of the interference mechanism between s−and\np- waves during the hadronization process.\nVII.\nACKNOWLEDGMENTS\nThis work is supported in part by the National Natural\nScience Foundation of China under Grants No. 12205002,\nin part by the the Natural Science Foundation of Anhui\nProvince (2108085MA20,2208085MA10), and in part by\nthe key Research Foundation of Education Ministry of\nAnhui Province of China (KJ2021A0061).\n[1] K. Konishi, A. Ukawa, and G. Veneziano, Nucl. Phys. B\n157, 45 (1979).\n[2] I. Vendramin, Nuovo Cim. A 62, 21 (1981).\n[3] I. Vendramin, Nuovo Cim. A 66, 339 (1981).\n[4] D. de Florian and L. Vanni, Physics Letters B 578, 139\n(2004).\n[5] A. Majumder, B. M¨uller, and X.-N. Wang, Physical Re-\nview Letters 99 (2007), 10.1103/physrevlett.99.192301.\n[6] F. A. Ceccopieri, M. Radici, and A. Bacchetta, Physics\nLetters B 650, 81–89 (2007).\n[7] J. C. Collins and G. A. Ladinsky,\n(1994), arXiv:hep-\nph/9411444.\n[8] A. Bianconi, S. Boffi, R. Jakob, and M. Radici, Physical\nReview D 62 (2000), 10.1103/physrevd.62.034008.\n[9] R. L. Jaffe, X. Jin, and J. Tang, Physical Review Letters\n80, 1166–1169 (1998).\n[10] J. C. Collins, S. F. Heppelmann,\nand G. A. Ladinsky,\nNuclear Physics B 420, 565–582 (1994).\n[11] A. Bacchetta and M. Radici, Physical Review D 67\n(2003), 10.1103/physrevd.67.094002.\n[12] A. Bacchetta and M. Radici, Phys. Rev. D 69, 074026\n(2004), arXiv:hep-ph/0311173.\n[13] S. Gliske, A. Bacchetta,\nand M. Radici, Phys. Rev. D\n90, 114027 (2014), [Erratum:\nPhys.Rev.D 91, 019902\n(2015)], arXiv:1408.5721 [hep-ph].\n[14] J. C. Collins, Nucl. Phys. B 396, 161 (1993), arXiv:hep-\nph/9208213.\n[15] M. Anselmino, M. Boglione, U. D’Alesio, A. Kotzinian,\nF. Murgia, A. Prokudin,\nand S. Melis, Nucl. Phys. B\nProc. Suppl. 191, 98 (2009), arXiv:0812.4366 [hep-ph].\n[16] D. Pitonyak, C. Cocuzza, A. Metz, A. Prokudin,\nand\nN. Sato, “Number density interpretation of dihadron\nfragmentation functions,”\n(2023), arXiv:2305.11995\n[hep-ph].\n[17] C. Cocuzza, A. Metz, D. Pitonyak, A. Prokudin, N. Sato,\nand R. Seidl, Physical Review Letters 132 (2024),\n10.1103/physrevlett.132.091901.\n[18] C. Cocuzza, A. Metz, D. Pitonyak, A. Prokudin, N. Sato,\nand R. Seidl (Jefferson Lab Angular Momentum (JAM)),\nPhys. Rev. D 109, 034024 (2024), arXiv:2308.14857 [hep-\nph].\n[19] M. Radici, R. Jakob, and A. Bianconi, Phys. Rev. D 65,\n074031 (2002), arXiv:hep-ph/0110252.\n[20] A. Vossen et al. (Belle), Physical Review Letters 107,\n072004 (2011).\n[21] A. Courtoy, A. Bacchetta, M. Radici, and A. Bianconi,\nPhys. Rev. D 85, 114023 (2012), arXiv:1202.0323 [hep-\nph].\n[22] A. Bacchetta, A. Courtoy,\nand M. Radici, Phys. Rev.\nLett. 107, 012001 (2011), arXiv:1104.3855 [hep-ph].\n[23] A. Bacchetta, A. Courtoy, and M. Radici, JHEP 03, 119\n(2013), arXiv:1212.3568 [hep-ph].\n[24] M. Radici, A. Courtoy, A. Bacchetta, and M. Guagnelli,\nJHEP 05, 123 (2015), arXiv:1503.03495 [hep-ph].\n[25] M. Radici, A. M. Ricci, A. Bacchetta, and A. Mukherjee,\nPhys. Rev. D 94, 034012 (2016), arXiv:1604.06585 [hep-\nph].\n[26] M. Radici and A. Bacchetta, Phys. Rev. Lett. 120,\n192001 (2018), arXiv:1802.05212 [hep-ph].\n[27] A. Bianconi, S. Boffi, R. Jakob,\nand M. Radici, Phys.\nRev. D 62, 034009 (2000), arXiv:hep-ph/9907488.\n[28] A. Bacchetta and M. Radici, Phys. Rev. D 74, 114007\n(2006), arXiv:hep-ph/0608037.\n[29] A.\nBacchetta,\nF.\nA.\nCeccopieri,\nA.\nMukherjee,\nand M. Radici, Phys. Rev. D 79, 034029 (2009),\narXiv:0812.0611 [hep-ph].\n[30] H. H. Matevosyan, A. Kotzinian,\nand A. W. Thomas,\nPhysics Letters B 731, 208–216 (2014).\n\n11\n[31] H. H. Matevosyan, A. W. Thomas, and W. Bentz, Phys-\nical Review D 88 (2013), 10.1103/physrevd.88.094022.\n[32] H. H. Matevosyan, A. Kotzinian,\nand A. W. Thomas,\nPhys. Rev. Lett. 120, 252001 (2018).\n[33] A. Airapetian et al. (HERMES), JHEP 06, 017 (2008),\narXiv:0803.2367 [hep-ex].\n[34] C. Adolph et al. (COMPASS), Phys. Lett. B713, 10\n(2012), arXiv:1202.6150 [hep-ex].\n[35] C. Adolph et al. (COMPASS), Phys. Lett. B736, 124\n(2014), arXiv:1401.7873 [hep-ex].\n[36] S. Sirtl, in 22nd International Symposium on Spin Physics\n(2017) arXiv:1702.07317 [hep-ex].\n[37] X. Luo, H. Sun, J. Li, Y.-L. Xie,\nand Tichouk, Phys.\nRev. D 100, 094036 (2019), arXiv:1906.05674 [hep-ph].\n[38] X. Luo and H. Sun, Phys. Rev. D 102, 014044 (2020),\narXiv:2004.13507 [hep-ph].\n[39] X. Luo, H. Sun, and Y.-L. Xie, Phys. Rev. D 101, 054020\n(2020), arXiv:2003.03770 [hep-ph].\n[40] S. Eidelman et al. (Particle Data Group), Phys. Lett. B\n592, 1 (2004).\n[41] G. Marcel et al., Astron. Astrophys. 659, A194 (2022),\narXiv:2109.13592 [astro-ph.HE].\n[42] A. Bacchetta, R. Kundu, A. Metz,\nand P. J. Mulders,\nPhys. Rev. D 65, 094021 (2002), arXiv:hep-ph/0201091.\n[43] A. Bacchetta, A. Metz,\nand J.-J. Yang, Phys. Lett. B\n574, 225 (2003), arXiv:hep-ph/0307282.\n[44] D. Amrath, A. Bacchetta,\nand A. Metz, Phys. Rev. D\n71, 114018 (2005), arXiv:hep-ph/0504124.\n[45] Z. Lu and I. Schmidt, Phys. Lett. B 747, 357 (2015),\narXiv:1501.04379 [hep-ph].\n[46] T. Sjostrand, P. Eden, C. Friberg, L. Lonnblad, G. Miu,\nS. Mrenna,\nand E. Norrbin, Comput. Phys. Commun.\n135, 238 (2001), arXiv:hep-ph/0010017.\n[47] A. Bacchetta, F. Conti,\nand M. Radici, Phys. Rev. D\n78, 074010 (2008), arXiv:0807.0323 [hep-ph].\n[48] A. Airapetian et al. (HERMES Collaboration), Phys.\nRev. Lett. 103, 152002 (2009).\n"
    },
    {
      "arxiv_id": "1412.3460",
      "full_text": "CERN PH-TH/2014-254\nHamiltonian Truncation Study of the φ4 Theory\nin Two Dimensions\nSlava Rychkova,b,c, Lorenzo G. Vitaled\na CERN, Theory Division, Geneva, Switzerland\nb Laboratoire de Physique Th´eorique de l’´Ecole normale sup´erieure, Paris, France\nc Facult´e de Physique, Universit´e Pierre et Marie Curie, Paris, France\nd Institut de Th´eorie des Ph´enom`enes Physiques, EPFL, CH-1015 Lausanne, Switzerland\nAbstract\nWe defend the Fock-space Hamiltonian truncation method, which allows to calculate nu-\nmerically the spectrum of strongly coupled quantum ﬁeld theories, by putting them in a ﬁnite\nvolume and imposing a UV cutoﬀ. The accuracy of the method is improved via an analytic\nrenormalization procedure inspired by the usual eﬀective ﬁeld theory. As an application, we\nstudy the two-dimensional φ4 theory for a wide range of couplings.\nThe theory exhibits a\nquantum phase transition between the symmetry-preserving and symmetry-breaking phases.\nWe extract quantitative predictions for the spectrum and the critical coupling and make contact\nwith previous results from the literature. Future directions to further improve the accuracy of\nthe method and enlarge its scope of applications are outlined.\nDecember 2014\narXiv:1412.3460v6  [hep-th]  20 Aug 2018\n\nContents\n1\nIntroduction\n2\n2\nThe problem and the method\n4\n2.1\nHamiltonian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n2.2\nTruncation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n3\nUV cutoﬀdependence and renormalization\n8\n3.1\nGeneral remarks\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n3.2\nComputation of ∆H . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n3.3\nRenormalization procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.4\nA test for the φ2 perturbation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.5\nComparison to Ref. [1] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4\nStudy of the φ4 theory\n19\n4.1\nVarying g . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4.2\nThe critical point . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.3\nL dependence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4\nEmax dependence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n4.5\nComparison to the TCSA methods . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n5\nComparison with prior work\n29\n5.1\nDLCQ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.2\nQSE diagonalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n5.3\nDMRG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n5.4\nLattice Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n5.5\nUniform matrix product states\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6\nDiscussion\n35\nA Speeding up the Hamiltonian matrix computation\n36\nB Perturbation theory checks\n38\n1\nIntroduction\nHow do we extract predictions about a strongly coupled quantum ﬁeld theory (QFT) which is not\nexactly solvable? The lattice would be one answer, but it’s not the only one. Hamiltonian trun-\ncation techniques, which generalize the Rayleigh-Ritz method familiar from quantum mechanics,\nare a viable deterministic alternative to the lattice Monte Carlo simulations, at least for some\ntheories. These techniques remain insuﬃciently explored, compared to the lattice, and their true\nrange of applicability may be much wider than what is currently believed. There exist several\nincarnations of Hamiltonian truncation, some better known than others, diﬀering by the choice of\nbasis and of the quantization frame. For example, Discrete Light Cone Quantization (DLCQ) [2]\nand Truncated Conformal Space Approach (TCSA) [3] are two representatives of this family of\nmethods.\n2\n\nHere we will be concerned with what is perhaps the simplest setting for the Hamiltonian\ntruncation—the φ4 theory in two spacetime dimensions.\nMoreover, we will consider the most\nstraightforward realization of the method—we will quantize at ﬁxed time rather than on the\nlight cone, and use the Fock space basis for the Hilbert space rather than the abstruse conformal\nbases.1 We will expand the φ4 Hamiltonian into ladder operators, as on the ﬁrst page of every QFT\ntextbook. We will however take this Hamiltonian more seriously than in most textbooks. Namely,\nwe will use it to extract non-perturbative predictions, rather than as a mere starting point for\nthe perturbative calculations. Concretely, we will (1) put the theory into a (large) ﬁnite volume,\nto make the spectrum discrete, (2) truncate the Hilbert space to a ﬁnite dimensional subspace of\nlow-energy states, and (3) diagonalize the truncated Hamiltonian numerically.\nIn spite or perhaps because of its extreme simplicity, this concrete idea has so far received even\nless attention than its more sophisticated cousins mentioned above. The only prior works known\nto us are [5, 6].2 Here, we will follow up on these early explorations with our own detailed study.\nWhile the basic idea and the qualitative conclusions of our work will be similar to [5, 6], our\nimplementation contains several conceptual and technical novelties. In particular, we will pay\nspecial attention to the convergence rate of the method, and will develop analytical tools allowing\nto accelerate the convergence, improve the accuracy, and better understand the involved systematic\nerrors.\nThe advances reported in this paper, as well as the ongoing progress in developing the other\nvariants of the Hamiltonian truncation [10–12], [13, 14, 1] make us hopeful that in a not too distant\nfuture these methods will turn into precision tools for studying strongly coupled QFTs.\nThe structure of the paper is clear from the table of contents. In section 2 we present the\nproblem and the basic methodology used to study the spectrum numerically.\nSection 3 elucidates the ideas behind the renormalization procedure, its implementations\nadopted in the numerical study, and provides some tests of the analytical results. The reader\nafraid of the technicalities may skip it. Yet it is precisely this section which is the theoretical heart\nof the paper.\nSection 4 contains the main numerical application of the work, i.e. the calculation of the\nspectrum of the two-dimensional φ4 theory.\nThe dependence of the numerical results on the\nphysical and unphysical parameters is analyzed carefully, and an estimate of the critical coupling is\nprovided. Computations were performed using a python code included with the arXiv submission.\nIn section 5 we compare our method to the existing ones in the literature. Most of these prior\nstudies focused in particular on the critical coupling estimates.\nWe conclude in section 6. Appendix A presents some technical details useful for the practical\nimplementation of the procedure. Appendix B provides the perturbative checks of our method,\nalongside a discussion of the Borel-summability of the model.\nWe would like to mention right away that this paper was developed in parallel with Ref. [1]\npublished three months ago and devoted to the TCSA approach in d > 2 dimensions. The concrete\nexample treated in [1] was the φ4 theory in d = 2.5 dimensions, which has the same phase structure\n1The use of a conformal basis in two dimensions requires compactifying the scalar ﬁeld [4], see the discussion in\nsection 4.5.\n2A more extensive description of this work can be found in [7] and [8].\nAnother paper [9] studied the two-\ndimensional Yukawa model without scalar self-interaction.\n3\n\nas the d = 2 case studied here.\nThe attentive reader will notice many similarities in section\n4 regarding the physics discussion, and in section 3 regarding the renormalization procedure.\nHowever, concerning the latter, there is also a diﬀerence of principle which will be stressed in\nsection 3.5 below.\n2\nThe problem and the method\n2.1\nHamiltonian\nWe will be studying the two-dimensional φ4 theory, deﬁned by the following Euclidean action:\nS = S0 + g\nZ\nd2x :φ4 : ,\n(2.1)\nS0 = 1\n2\nZ\nd2x :(∂φ)2 + m2φ2 : .\n(2.2)\nHere : : denotes normal ordering. Normal ordering of the free massive scalar action S0 simply means\nthat we set to zero the ground state energy density (in inﬁnite ﬂat space, and before adding the\nquartic perturbation). The quartic interaction term is then assumed normal-ordered with respect\nto the mass m appearing in the free action. In perturbation theory this simply corresponds to\nforbidding the diagrams with lines beginning and ending inside the same quartic vertex. In terms\nof operators, this means that we are adding counterterms [15]:\n:φ4 : = φ4 −6Zφ2 + 3Z2 .\n(2.3)\nHere\nZ =\nZ\nd2k\n(2π)2\n1\nk2 + m2\n(2.4)\nis a logarithmically UV-divergent quantity.\nAlthough absent in (2.1), below we will also need to consider perturbations given by the\nnormal-ordered φ2 operator:\n:φ2 : = φ2 −Z.\n(2.5)\nThe above equations specify what we mean by the theory in inﬁnite ﬂat space, and also deﬁne\nthe mass parameter m and the quartic coupling g in terms of which we will parametrize the theory.\nAll physical quantities (such as particles masses and S-matrix elements) are then ﬁnite functions\nof m and g. Also the change of the ground state energy density due to turning on the coupling g\nis ﬁnite and observable in this theory. This change can be thought of as the contribution of the\ntheory (2.1) to the cosmological constant.\nSince both m and g are dimensionful, physics depends on their dimensionless ratio ¯g = g/m2,\nwhile m (or g) sets the overall mass scale. We will assume g > 0 to have a stable vacuum. Both\nsigns of m2 are interesting, but in this paper we will only consider the case m2 > 0. Notice that\nthis does not mean that we will always be in the phase of preserved Z2 symmetry φ →−φ, since\nthe mass parameter undergoes renormalization. In fact, as we will see below, for m2 > 0 and\n¯g > ¯gc = O(1) the theory ﬁnds itself in the phase where the Z2 symmetry is spontaneously broken.\nThis is a nonperturbative phenomenon. For ¯g ≪1, the fate of the Z2 symmetry is of course\ndetermined by the sign of m2.\n4\n\nIn this paper we will study the above theory not in inﬁnite space but on a cylinder of the\nform S1\nL × R, where S1\nL is the circle of length L and R will be thought of as Euclidean time. We\nwill impose the periodic boundary conditions around the circle. We will describe the theory on\nthis geometry in the Hamiltonian formalism, taking advantage of the fact that the ﬁnite volume\nspectrum is discrete.\nNow, what is the Hamiltonian which describes the theory (2.1) on S1\nL ×R? The correct answer\nto this question involves a subtlety, so let us proceed pedagogically.\nWe ﬁrst discuss the Hamiltonian which describes the free massive scalar. In canonical quanti-\nzation, the ﬁeld operator is expanded into modes:\nφ(x) =\nX\nk\n1\n√2Lωk\n\u0010\nakeikx + a†\nke−ikx\u0011\n,\n(2.6)\nwhere the momenta k take discrete values k = 2πn/L, n ∈Z, ωk =\n√\nm2 + k2, and the ladder\noperators satisfy the usual commutation relations:\n[ak, ak′] = 0,\n[ak, a†\nk′] = δnn′ .\n(2.7)\nThe Hilbert space H of the theory is the Fock space of these ladder operators, spanned by the\nstates\n|ψ⟩= |k1, . . . , km⟩= Na†\nk1 . . . a†\nkm|0⟩,\n(2.8)\nwhere N is the normalization factor to get a unit-normalized state. The free scalar Hamiltonian\nis then given by:\nHfree = H0 + E0(L),\nH0 =\nX\nk\nωka†\nkak .\n(2.9)\nThe only subtlety here is the c-number term E0(L). The point is that we want the oscillator\npart H0 of the ﬁnite volume Hamiltonian to be normal-ordered. However, the normal ordering\ncounterterm in inﬁnite space and for ﬁnite L is slightly diﬀerent, and E0(L) compensates for this\nmismatch. It is nothing but the Casimir energy of the scalar ﬁeld, and is given by (see [16]):\nE0(L) = −1\nπL\nZ ∞\n0\ndx\nx2\n√\nm2L2 + x2\n1\ne\n√\nm2L2+x2 −1\n.\n(2.10)\nThis expression can be derived in many equivalent ways. One method is to regulate the diﬀerence\nof the zero-point energies:\nX\nn\nωkn/2 −L\nZ +∞\n−∞\ndk\n2πωk/2 .\n(2.11)\nAnother method is to compute the partition function of the theory on the torus S1\nL1 × S1\nL2, which\ncan be done from the path integral formulation of the theory. The partition function deﬁned in\nthis way enjoys the property of modular invariance. This method naturally produces a term in\nthe free energy of the form (2πL2) × E0(L1).\nWe next discuss the ﬁnite-volume Hamiltonian for the interacting theory. It will have the form:\nH = E0(L) + H0 + gV4 + . . . ,\n(2.12)\nV4 =\nZ L\n0\ndx :φ4 :L .\n(2.13)\n5\n\nThe normal ordering here is deﬁned on the circle of length L in the Hamiltonian sense, just putting\nall creation operators to the left. Thus:\nV4 = gL\nX\nk1+k2+k3+k4=0\n1\nQ √2Lωi\nh\nak1ak2ak3ak4 + 4a†\n−k1ak2ak3ak4\n+ 6a†\n−k1a†\n−k2ak3ak4 + 4a†\n−k1a†\n−k2a†\n−k3ak4 + a†\n−k1a†\n−k2a†\n−k3a†\n−k4\ni\n.\n(2.14)\nThe origin of the . . . terms in (2.12) lies again in the fact that the normal-ordering counterterms\nadded when deﬁning V ,\n:φ4 :L = φ4 −6ZLφ2 + 3Z2\nL ,\nZL =\nX\nn\n1\n2Lωkn\n,\n(2.15)\nare not exactly the same as in the inﬁnite space deﬁnition (2.3). The diﬀerence is\n:φ4 : −:φ4 :L = −6(Z −ZL)φ2 + 3(Z2 −Z2\nL) = 6(ZL −Z):φ2 :L + 3(ZL −Z)2 ,\n(2.16)\nwhere in the second equality we used φ2 = :φ2 :L + ZL.\nTo compute ZL −Z we rewrite Z in the form adapted to the Hamiltonian quantization:\nZ =\nZ dk\n4π\n1\n√\nk2 + m2 .\n(2.17)\nThe diﬀerence ZL −Z is ﬁnite and is readily calculated using the Abel-Plana formula:\nz(L) ≡ZL −Z = 1\nπ\nZ ∞\n0\ndx\n√\nm2L2 + x2\n1\ne\n√\nm2L2+x2 −1\n.\n(2.18)\nThis allows us to complete the . . . terms in (2.12). Thus, the Hamiltonian on a circle of ﬁnite\nlength L corresponding to the inﬁnite space theory (2.3) is given by:\nH = H0 + g[V4 + 6z(L)V2] + [E0(L) + 3z(L)2gL],\n(2.19)\nV2 =\nZ L\n0\ndx :φ2 :L =\nX\nk\n1\n2ωk\n(aka−k + a†\nka†\n−k + 2a†\nkak) .\n(2.20)\nWe see that the Hamiltonian (2.19) diﬀers from the “naive” Hamiltonian\nH = H0 + V ,\nV = gV4\n(2.21)\nby “correction terms”, proportional to E0(L) and z(L). The presence of these terms is conceptually\nimportant.\nThey would be also straightforward to include into numerical analysis, for any L.\nHowever, in this paper we will be focussing on the case Lm ≫1. In this regime the corrections\ndue to E0(L) and z(L) are exponentially suppressed, and their numerical impact is negligible. For\nthis reason, and to simplify the discussion, we will omit the exponentially suppressed corrections.\nWith this proviso, from now on we will use the “naive” Hamiltonian (2.21).\n6\n\n2.2\nTruncation\nWe next explain the truncation method. We will work in the Hilbert space H spanned by the free\nmassive scalar states. The Hamiltonian H acts in this space, and the problem is to diagonalize it.\nWe thus use the free massive scalar states as a basis into which we expand the eigenstates of the\ninteracting theory. Let us think of the Hamiltonian as an inﬁnite matrix Hij where i, j numbers\nthe states in H:\nHij = ⟨i|H|j⟩.\n(2.22)\nNotice that the states |i⟩as introduced above form an orthonormal basis of H.\nTo ﬁnd the\nspectrum of the theory in ﬁnite volume, we need to diagonalize the matrix Hij. This diagonalization\ncan be done separately in sectors having ﬁxed quantum numbers corresponding to the operators\ncommuting with the Hamiltonian.\nThe ﬁrst such quantum number is the momentum: [P, H] = 0. In this paper we will be working\nin the sector of states of vanishing total momentum:\nP = k1 + · · · + km = 0 .\n(2.23)\nIn a large volume, the states of nonzero momentum should correspond to boosted zero-momentum\nstates, and their energies should be related to zero-momentum energies by the Lorentz-invariant\ndispersion relation. It would be interesting to check this in future work.\nThe second conserved quantum number is the spatial parity P, which acts x →−x. It maps\nthe state (2.8) into P|ψ⟩= | −k1, . . . , −km⟩. In this paper we will be working in the P-invariant\nsector,3 whose orthonormal basis consists of the states\n|ψsym⟩= β(ψ)\n\u0000|ψ⟩+ P|ψ⟩\n\u0001\n,\n(2.24)\nwhere β(ψ) is the normalization factor:\nβ(ψ) = 1/\n√\n2 if P|ψ⟩̸= |ψ⟩,\n1/2 otherwise.\n(2.25)\nThe restriction to the subspace P = 0, P = 1 will be tacitly assumed in all of the rest\nof the paper.\nThe ﬁnal conserved quantum number is the already mentioned global Z2 symmetry φ →−φ\n(the ﬁeld parity). Its eigenvalue on the states (2.8) is (−1)m. Below we will be considering both\nthe Z2-even and Z2-odd sector.\nEach of the two sectors Z2 = ±1 still contains inﬁnitely many states. We will thus have to\ntruncate the Hilbert space. The truncation variable will be the H0-eigenvalue:\nE = ωk1 + · · · + ωkm .\n(2.26)\nWe will truncate by considering all states of E ⩽Emax. The parameter Emax should be thought\nof as a UV cutoﬀ. The truncated Hilbert space is ﬁnite-dimensional, and the matrix Hij restricted\nto this space can be diagonalized numerically. This is what we will do.\nIn principle, one could imagine alternative truncation schemes. For example, one can truncate\nin the maximal wavenumber kmax.\nSuch a truncation would be closer to the usual way one\n3The extension of our method to the P-odd sector is straightforward. We consider only the P-even sector, because\nwe do not expect bound states with P = −1.\n7\n\nimplements the UV cutoﬀin ﬁeld theory.\nBy itself, however, it does not render the Hilbert\nspace ﬁnite-dimensional. One could also think of truncating in the total occupation number of the\nstate, or in the individual occupation numbers per oscillator, and so on. Our initial exploration of\nsuch subsidiary cutoﬀs did not produce any dramatic gains in the performance of the method. In\nthe end we decided to stick to the cutoﬀin E. As we will see in the next section, this cutoﬀallows\nfor a natural implementation of the renormalization of the Hamiltonian, necessary to improve the\nconvergence of the method. In the future it may be interesting to return to the other cutoﬀs, and\nexplore them more systematically.\n3\nUV cutoﬀdependence and renormalization\n3.1\nGeneral remarks\nIt is not diﬃcult to write a code which computes the Hij matrix restricted to the E ⩽Emax\nsubspace4 and diagonalizes it. The results of these numerical calculations will be discussed below.\nAs we will see, as the UV cutoﬀEmax is increased, the energy levels computed using the truncated\nHilbert space (‘truncated energy levels’) tend to some ﬁnite limits. These limits should be naturally\nidentiﬁed with the exact energy levels. An interesting theoretical question then arises: what is the\nconvergence rate of the method? There is also a related practical question: how can the convergence\nbe improved? These questions will be discussed in this section.\nBy calculating the truncated energy levels we are discarding the contribution to the low-energy\nphysics coming from the high energy states of the Hilbert space. Since the UV divergences have\nbeen already taken care of, this contribution is power-suppressed and goes to 0 as the cutoﬀis\nincreased. In the standard Wilsonian approach to the renormalization group, by integrating out\nhigh-momentum (or short-distance) degrees of freedom one gets a ﬂow in the space of Hamiltonians,\nalong which the same physics is described in terms of low-momentum degrees of freedom with\nrenormalized couplings. We would like to apply the same philosophy to our case, although we may\nexpect some diﬀerences, because our cutoﬀprescription—cutting oﬀin E—is diﬀerent from the\nones normally used in ﬁeld theory. First of all, it breaks the Lorentz invariance. Second, the fact\nthat we truncate in the total energy of the state, rather than in that of its individual constituents,\nrenders our cutoﬀeﬀectively non-local. Thus, we should be prepared to see non-local as well as\nLorentz-violating operators generated by the ﬂow. We will see, however, that to leading order it\nwill be suﬃcient to renormalize a few local operators in the Hamiltonian. It will be possible to\ndo this computation in perturbation theory, since the potential we add to the free Hamiltonian\nis a relevant deformation and becomes less important in the UV. The dimensionless parameter\nwhich sets the convergence of the truncated energy levels and the asymptotic magnitude of the\ncounterterms will be g/E2\nmax. All these considerations will be made concrete in the following.\nWe start our analysis from the exact eigenvalue equation:\nH.c = Ec ,\n(3.1)\nwhere c is an inﬁnite-dimensional vector living in the full Hilbert space H. Here and below, we\nuse curly E to denote energy levels of the interacting theory, while E will be used to denote free\nscalar energy levels.\n4See appendix A for some tricks speeding up this computation.\n8\n\nIn our methodology the Hilbert space is divided in two subspaces:\nH = Hl ⊕Hh ,\n(3.2)\nwhere Hl is the low-energy sector of the Hilbert space, treated numerically, while Hh is spanned\nby an inﬁnite number of discarded high-energy states. So we have c = (cl, ch)t, and Eq. (3.1) takes\nthe following form in components:\nHll.cl + Hlh.ch = Ecl ,\nHhl.cl + Hhh.ch = Ech .\n(3.3)\nHere we denoted\nHαβ ≡PαHPβ,\n(3.4)\nwhere Pα (α = l, h) is the orthogonal projector on Hα.\nUsing the second equation in (3.3) to eliminate ch from the ﬁrst one, we obtain:\n[Hll −Hlh.(Hhh −E)−1.Hhl].cl = Ecl ,\n(3.5)\nor, equivalently,\n[Htrunc + ∆H].cl = Ecl ,\n(3.6)\n∆H = −Vlh.(H0 + Vhh −E)−1.Vhl .\n(3.7)\nThis equation is very important. Notice that Hll ≡Htrunc is nothing but the Hamiltonian truncated\nto the low-energy Hilbert space. Notice furthermore that the mixing between the high and low-\nenergy states is due only to V , since H0 is diagonal.\nEq. (3.6) is exact, yet it resembles the truncated eigenvalue equation, with a correction ∆H.\nThis equation will be a very convenient starting point to answer the two questions posed at the\nbeginning of this section.\nWe will now start making approximations. First, we expand ∆H in Vhh and keep only the\nzeroth term\n∆H = −Vlh.(H0 −E)−1.Vhl + . . .\n(3.8)\nBy dimensional reasons, we expect that the next term in the expansion,\nVlh.(H0 −E)−1.Vhh.(H0 −E)−1.Vhl,\n(3.9)\nwill be suppressed with respect to the one we keep by g/E2\nmax. It will be very interesting to include\nthis term in future work, and we will comment below about how this can be done.\nEquation (3.8) deﬁnes ∆H as an operator on Hl. The deﬁnition depends on the eigenvalue\nE that we are trying to compute. This subtlety will be dealt with below, while for the moment\nlet us replace E by some reference energy E∗. Even then, the deﬁnition seems impractical since it\ninvolves a sum over inﬁnitely many states in Hh. Indeed, the matrix elements of ∆H according to\nthis deﬁnition are given by:\n(∆H)ij = −\nX\nk:Ek>Emax\nVikVkj\nEk −E∗\n.\n(3.10)\nFortunately, in the next section we will give a simpliﬁed approximate expression for ∆H not\ninvolving inﬁnite sums. As we will see, to leading order ∆H will be approximated by a sum of\nlocal terms:\n∆H ≈\nX\nN\nκNVN,\nVN =\nZ L\n0\ndx :φ(x)N : .\n(3.11)\n9\n\nTo this leading order, adding ∆H to Htrunc results in simply renormalizing the local couplings. As\nwe will see, a more accurate expression for ∆H contains subleading corrections, which in general\ncannot be expressed as integrals of local operators. The appearance of these nonlocal corrections\nis due to the above-mentioned fact that truncating in total energy is not a fully local way of\nregulating the theory.\n3.2\nComputation of ∆H\nConsider then the matrix elements (3.10) of ∆H for i, j in the truncated basis. We will write them\nin the form\n(∆H)ij = −\nZ ∞\nEmax\ndE M(E)ij\nE −E∗\n,\n(3.12)\nM(E)ij dE ≡\nX\nk:E⩽Ek<E+dE\nVikVkj .\n(3.13)\nWe are interested in the large-E asymptotics for M(E)ij. Of course, for ﬁnite L the energy levels\nare discrete and this function should be properly thought of as a distribution (a sum of delta-\nfunctions). However, since the high-energy spectrum is dense, the ﬂuctuations due to discreteness\nwill tend to average out when integrating in E. Below we will ﬁnd a continuous approximation for\nM(E)ij, valid on average. Such an approximation will be good enough for computing the integral\nin (3.12) with reasonable accuracy. A small loss of accuracy will occur because of the sharp cutoﬀ\nat E = Emax; this will be discussed below in sections 4.3 and 4.4.\nOur calculation of M(E)ij will follow the method introduced in [1], section 5.3. It will be based\non the fact that the same quantity appears also in the following matrix element:\nC(τ)ij = ⟨i|V (τ/2)V (−τ/2)|j⟩=\nZ ∞\n0\ndE e−[E−(Ei+Ej)/2]τM(E)ij ,\n(3.14)\nwhere we inserted a completeness relation in the second step. A word about notation: the Euclidean\ntime dependence of various operators is always meant in the interaction representation, e.g.\nV (τ) = eH0τV e−H0τ .\n(3.15)\nIf the time dependence is not shown, it means that the operator is taken at τ = 0.\nEq. (3.14) says that C(τ) is basically the Laplace transform of M(E). The leading non-analytic\npart of C(τ) for τ →0 will come from the leading piece of M(E) as E →∞. Our method will\nproceed by ﬁrst extracting the leading non-analytic part of C(τ), and then taking its inverse\nLaplace transform to get at M(E).\nWe will present the computation for a general case when the potential contains both : φ2 : and\n: φ4 : terms:\nV = g2V2 + g4V4 .\n(3.16)\nOur Hamiltonian (2.21) has g2 = 0, g4 = g. Turning on g2 ̸= 0 corresponds to an extra contribution\nto the mass. Having this coupling will be useful for a check of the formalism in section 3.4 below.\nWe have\nC(τ) =\nX\ngngm\nZ L\n0\ndx\nZ L/2\n−L/2\ndz:φ(x + z, τ/2)n ::φ(x, −τ/2)m : ,\n(3.17)\n10\n\nwhere we used periodicity and invariance under spatial translations. The non-analyticity of C(τ)\nfor τ →0 comes from the integration region where the product of two local operators is singular,\ni.e. when they are inserted at near-coinciding points. Let us focus on one term in the sum, and\nrewrite it using Wick’s theorem as:\ngngm\nZ L\n0\ndx\nZ L/2\n−L/2\ndz\nX\n0⩽k⩽min(n,m)\nfnm,n+m−2k GL(z, τ)k:φ(x + z, τ/2)n−kφ(x, −τ/2)m−k : . (3.18)\nHere GL(z, τ) is the two-point function of φ in the free theory on the circle of length L. The f’s\nare integer combinatorial factors (operator product expansion coeﬃcients):\nfnm,n+m−2k =\n\u0012n\nk\n\u0013\u0012m\nk\n\u0013\nk! .\n(3.19)\nIn (3.18), the leading non-analytic behavior as τ →0 will come from the propagator powers\nGL(z, τ)k. The remaining normal-ordered operators can be Taylor expanded in z, τ:\ngngm\nZ L\n0\ndx\nZ L/2\n−L/2\ndz\nX\n0⩽k⩽min(n,m)\nfnm,n+m−2k GL(z, τ)k [:φ(x)n+m−2k : + O(τ 2, z2)] .\n(3.20)\nThe terms O(z) are not shown because they will vanish upon integration. The terms O(τ 2, z2)\nwill produce a subleading singularity as τ →0. The corresponding contributions to M(E) will be\nsuppressed by m2/E2\nmax compared to the leading ones. In this work these subleading contributions\nwill be neglected, but it will be interesting and important to include them in the future.5\nEq. (3.20) means that at leading order the correction Hamiltonian ∆H will contain terms of the\nform (3.11) with N = n + m −2k. To ﬁnd the couplings κN, we need to evaluate the non-analytic\npart of the following quantities:\nIk(τ) ≡\nZ L/2\n−L/2\ndz GL(z, τ)k,\nk = 0, 1, 2, 3, 4 .\n(3.21)\nAs we will see below, for k = 0, 1 the τ →0 behavior will be analytic (for k = 0 this is a triviality).\nThis implies that only N = 0, 2, 4 terms will be generated in (3.11).\nTo evaluate (3.21), we will need a few well-known facts about GL(z, τ). In the inﬁnite volume\nlimit L →∞the rotation invariance is restored, and the two-point function is a modiﬁed Bessel\nfunction of the second kind, depending on the distance ρ =\n√\nz2 + τ 2:\nG(ρ) = 1\n2πK0(mρ)\n(L = ∞) .\n(3.22)\nIt has a logarithmic short distance behavior and decays exponentially at long distances:6\nG(ρ) ≈\n\n\n\n−1\n2π log\n\u0012eγ\n2 mρ\n\u0013\n[1 + O(m2ρ2)] ,\nρ ≪1/m ,\nexp(−mρ)/(2√2πmρ) ,\nρ ≫1/m .\n(3.23)\n5The subleading contributions will give rise to new, derivative, operators in the Hamiltonian. Since our regulator\nbreaks Lorentz invariance, the derivatives in τ and z are not going to enter symmetrically in these subleading terms.\n6γ is Euler’s constant.\n11\n\nFor a ﬁnite L, the two-point function is obtained from the L = ∞case via periodization:\nGL(z, τ) =\nX\nn∈Z\nG(\np\n(z + nL)2 + τ 2) .\n(3.24)\nThe periodization corrections are exponentially small for Lm ≫1. In our work, this condition will\nbe always satisﬁed, and so we will use G in place of GL.7 This is consistent with having neglected\nthe exponentially suppressed E0(L) and z(L) terms when passing from (2.19) to (2.21).\nSo we will replace GL by G(ρ) in (3.21). The non-analytic behavior of the integral comes\nfrom the small z region, where the short-distance logarithmic asymptotic (3.23) is applicable. To\nregulate spurious IR divergences, it’s convenient to calculate the ﬁrst derivative with respect to τ:\nI′\nk(τ) = k\nZ ∞\n−∞\ndz (dG/dρ)G(ρ)k−1 τ\nρ →k\n\u0012\n−1\n2π\n\u0013k Z ∞\n−∞\ndz\n\u0014\nlog\n\u0012eγ\n2 mρ\n\u0013\u0015k−1 τ\nρ2 ,\n(3.25)\nwhere we also replaced G by its short-distance asymptotics. The resulting integrals are convergent\nand readily evaluated:8\nI′\n1(τ) = const ,\nI′\n2(τ) = 1\n2π log mτ + const ,\nI′\n3(τ) = −3\n8π2 (log mτ)2 −3γ\n4π2 log mτ + const ,\n(3.26)\nI′\n4(τ) =\n1\n4π3 (log mτ)3 + 3γ\n4π3 (log mτ)2 + 12γ2 + π2\n16π3\nlog mτ + const ,\nmodulo errors induced by using the short-distance asymptotics of G. These errors are suppressed\nby O(m2τ 2). The corresponding corrections to M(E) are suppressed by m2/E2\nmax, and will be\nomitted. Also, as mentioned above, we see that I′\n1(τ) is analytic.\nWe now have to pass from the small-τ behavior to the large-E asymptotics. Diﬀerentiating\nEq. (3.14) we have\nC′(τ) =\nZ ∞\n0\ndE e−Eijτ[−EijM(E)] ,\n(3.27)\nwhere we deﬁned\nEij ≡E −(Ei + Ej)/2 .\n(3.28)\nThus from the inverse Laplace transforms of I′\nk(τ) we should be able to determine the asymptotics\nof −EijM(E).\nThese inverse Laplace transforms are found from the following table of direct\ntransforms:\nZ ∞\nϵ\ndE e−Eτ 1\nE = −log mτ + analytic ,\nZ ∞\nϵ\ndE e−Eτ log E/m\nE\n= 1\n2(log mτ)2 + γ log mτ + analytic ,\n(3.29)\nZ ∞\nϵ\ndE e−Eτ (log E/m)2\nE\n= −1\n3(log mτ)3 −γ(log mτ)2 −(π2/6 + γ2) log mτ + analytic .\n7The induced error can be estimated by approximating GL(z, τ) ≈G(ρ) + 2G(L) for small ρ. This implies a shift\n∆Ik(τ) ≈αIk−1(τ), α = 2kG(L). For k = 4 and L = 4/m (L = 6/m) the coeﬃcient α = 0.01(0.002).\n8Mathematica’s Integrate function sometimes gives wrong results for integrals of this type, so be careful.\n12\n\nSince we are only interested in the large-E asymptotics, the IR cutoﬀϵ is not important—its value\nonly inﬂuences the analytic parts.\nGathering everything, we obtain the following formula for the leading asymptotic behavior of\nM(E):\nM(E) ∼[g2\n4µ440 + g2\n2µ220]V0 + [g2\n4µ442 + g2g4µ422]V2 + g2\n4µ444V4\n\f\f\f\nE→Eij\n,\n(3.30)\nwhere\nµ440(E) = 1\nE2\n\u001a18\nπ3 (log E/m)2 −3\n2π\n\u001b\n,\nµ220(E) =\n1\nπE2 ,\nµ442(E) = 72 log E/m\nπ2E2\n,\nµ422 =\n12\nπE2 ,\nµ444(E) =\n36\nπE2 .\n(3.31)\nAs the notation suggests, the µ-functions in (3.30) are evaluated at E = Eij. This equation is the\nmain result of this section. We subjected it to several tests, which we are going to describe below.\nBefore proceeding, let us comment on the evaluation of the next-to-leading term (3.9) in the\nrenormalization procedure, which will be important in future developments of the method. From\nthis term we will extract the O(g3/E4\nmax) contribution to the coeﬃcients κN.\nThis correction\nterm is the most interesting of all 1/E4\nmax corrections, since it dominates in the limit g ≫m2.\nTechnically, we should generalize C(τ) and M(E) in Eq. (3.14) to functions of two variables (τ1,2\nand E1,2) and extract the leading non-analytic pieces for τ1,2 →0. This calculation will involve\nWick contractions among the operators in C(τ1, τ2), the cyclic ones being the only nontrivial part.\nWe shall now move on to the tests of Eq. (3.31).\nTest 1\nLet us plug (3.30) into (3.12), and do the integral neglecting the dependence on E∗and (Ei + Ej)/2.9\nThis gives ∆H of the form (3.11), i.e. as a sum of local counterterms with coeﬃcients which are\nfunctions of Emax. For example, the g2\n4 part is given by (Log ≡log Emax/m):\n∆H ≈−g2\n4\nE2max\n\u001a\u0014 9\nπ3 (Log2 + Log) + 3(6 −π2)\n4π3\n\u0015\nV0 +\n\u001236\nπ2 Log + 18\nπ\n\u0013\nV2 + 18\nπ V4\n\u001b\n.\n(3.32)\nThis expression was checked as follows. Working in inﬁnite volume, we computed the order g2\nperturbative corrections to the vacuum energy, particle mass, and 2 →2 scattering amplitude,\nimposing the cutoﬀE ⩽Emax on the intermediate state energy (thus working in the ‘old-fashioned’\nHamiltonian perturbation theory formalism, rather than in terms of Feynman diagrams). We then\nchecked that the leading Emax dependence of these results is precisely the one implied by (3.32).\nThis way of arriving at (3.32) is more laborious than the one given above, and we do not report\nthe details.\nTest 2\nA direct check of the asymptotics (3.30) can be done by comparing it with the actual value of\nM(E) computed from its deﬁnition (3.13). One example is given in ﬁgure 1, where we consider\nthe diagonal matrix elements ⟨i|M(E)|i⟩, |i⟩the state of i particles at rest, i = 0, 1, 2. We choose\nm = 1, L = 6, g2 = 0 and g4 = 1. The green smooth curves are the theoretical asymptotics from\n(3.30). The blue irregular curves represent the moving average of ⟨i|M(E)|i⟩over the interval\n9We stress that in numerical computations it will be important to retain these subleading corrections.\n13\n\n0\n5\n10\n15\n20\n25\nE\n0\n5\n10\n15\n20\n25\n30\n35\n⟨i|M(E)|i⟩× E2\nii\ni = 0 (L = 6.0, ∆E = 1.0)\n0\n5\n10\n15\n20\n25\nE\n0\n10\n20\n30\n40\n50\n60\n⟨i|M(E)|i⟩× E2\nii\ni = 1 (L = 6.0, ∆E = 1.0)\n0\n5\n10\n15\n20\n25\nE\n0\n20\n40\n60\n80\n⟨i|M(E)|i⟩× E2\nii\ni = 2 (L = 6.0, ∆E = 1.0)\nFigure 1: A test of the M(E) asymptotics; see the text.\n[E −∆E, E +∆E) with ∆E = 1. To facilitate the comparison, both are plotted multiplied by E2\nii.\nWe see that the two curves agree quite well on average.\nA third test, involving the g2 coupling, will be described in section 3.4.\n3.3\nRenormalization procedures\nBy “renormalization”, in a broad sense, we mean adding to the truncated Hamiltonian Htrunc\nextra terms designed to compensate for the truncation eﬀects and reduce the Emax dependence of\nthe results. In this section we will describe in detail the three renormalization prescriptions used\nin our numerical work.\nConsider thus the Hamiltonian\nH = H0 + V ,\nV = g2V2 + g4V4 .\n(3.33)\nIn the main numerical studies in section 4 we will set g2 = 0. The opposite case g4 = 0, g2 ̸= 0\nwill be considered in the check in section 3.4.\nWe are interested in the spectrum of H on a circle of length L. Three approximations to this\nspectrum, in order of increasing accuracy, can be obtained as follows.\n1. Raw truncation (marked ‘raw’ in plots)\nIn this simplest approach, we are not performing any renormalization. The truncated Hamiltonian\nHtrunc is constructed by restricting H to the subspace Hl of the full Hilbert space, spanned by the\nstates of energy E ⩽Emax. The spectrum of Htrunc will be called the ‘raw spectrum’. According\n14\n\nto Eqs. (3.30), (3.32), we expect that the raw spectrum approximates the exact spectrum with an\nerror which scales as 1/E2\nmax (up to logarithms).\n2. Local renormalization (marked ‘ren.’ in plots)\nIn this approach, we construct a correction Hamiltonian ∆H by the formula (3.12). We use the\nasymptotics (3.30) for M(E), in which we neglect (Ei + Ej)/2 with respect to Emax. This gives a\nlocal ∆H of the form (3.11) with\nκ0 = −\nZ ∞\nEmax\ndE\nE −E∗\n[g2\n4µ440(E) + g2\n2µ220(E)] ,\nκ2 = −\nZ ∞\nEmax\ndE\nE −E∗\n[g2\n4µ442(E) + g2g4µ422(E)] ,\n(3.34)\nκ4 = −\nZ ∞\nEmax\ndE\nE −E∗\ng2\n4µ444(E) .\nThe choice of the reference energy E∗will be discussed shortly. We then construct the ‘renormalized’\nHamiltonian\nHren = Htrunc + ∆Hloc,\n∆Hloc ≡κ0V0 + κ2V2 + κ4V4 .\n(3.35)\nThus κ2,4 correct the g2,4 couplings, while κ0 shifts the ground state energy density. Notice that\nthe κ’s scale as 1/E2\nmax (up to logarithmic terms).\nThe renormalized Hamlitonian acts in the same truncated Hilbert space Hl as the truncated\nHamiltonian Htrunc. Its energy levels will be called the ‘renormalized spectrum’. This construction\nimplements the ﬁrst nontrivial approximation to the exact equation (3.6). The local coupling renor-\nmalization accounts for the leading 1/E2\nmax error aﬀecting the raw spectrum. Further corrections,\ndiscussed below, are suppressed by one more power of Emax. So we expect that the renormalized\nspectrum approximates the exact spectrum with an error which scales as 1/E3\nmax.\nLet us now discuss the reference energy E∗in (3.34).\nRecall that E∗was introduced as a\nplaceholder for the eigenstate energy E in the deﬁnition (3.6) of ∆H.\nNow, it’s important to\nrealize that the eigenstate energies do not remain O(1) in the limit of large L. The excitations\nabove the ground state, EI −E0,10 do stay O(1), but the ground state energy itself grows linearly:\nE0 ∼ΛL,\nL →∞.\n(3.36)\nHere Λ is the interacting vacuum energy density (the cosmological constant), which is ﬁnite and\nobservable in our theory.11\nWe will therefore use the following recipe. We will choose E∗close to, although not necessarily\nequal, the ground state energy of the theory. The precise choice will be speciﬁed when we present\nthe numerical results. With this choice we compute the coupling renormalizations (3.34) and the\nrenormalized spectrum. The diﬀerences EI −E∗will now be O(1), and the error induced by this\nmismatch will truly be 1/Emax suppressed. Moreover, even this error can be further corrected, as\nwe discuss below.\nWe brieﬂy mention here an alternative approach. One can insist that E∗be adjusted, e.g. it-\neratively, until it exactly equals the eigenvalue EI which comes out from diagonalizing Hren. This\n10We use small roman letters i, j, . . . to number states in the Fock space, which are eigenstates of H0, and large\nletters I, J, . . . to number the eigenstates of the interacting Hamiltonian.\n11Recall that the free vacuum energy density was set to zero by normal ordering the free scalar Hamiltonian.\n15\n\nhas to be done separately for each eigenstate, and so is rather expensive. We tried this method\nand found that it gives results in close agreement with those obtained from our simpler recipe for\nE∗, combined with the correction procedure described below.\n3. Local renormalization with a subleading correction (marked ‘subl.’ in plots)\nWe will now describe the third approach which improves on the previous one by taking into account\nnot only the renormalization of the local couplings, but also the ﬁrst subleading corrections due to\nthe eigenstate energy and (Ei + Ej)/2. As explained above, these corrections can be considered\nsmaller than the local ones by a further O(1/Emax) factor. They will take care of the mismatch\nbetween (3.12) and the local coupling renormalization. The corresponding correction Hamiltonian\nhas the following matrix elements between the truncated Hilbert space states:\n[∆Hsubl(E)]ij = (λ0)ij(V0)ij + (λ2)ij(V2)ij + (λ4)ij(V4)ij\n(3.37)\n(no summation over the repeated indexes). The (λN)ij are the diﬀerences between the renor-\nmalization coeﬃcients fully dependent on (Ei + Ej)/2 and E and the local ones κN deﬁned in\n(3.34):\n(λ0)ij = −\nZ ∞\nEmax\ndE\nE −E [g2\n4µ440(Eij) + g2\n2µ220(Eij)] −κ0 ,\n(λ2)ij = −\nZ ∞\nEmax\ndE\nE −E [g2\n4µ442(Eij) + g2g4µ422(Eij)] −κ2 ,\n(3.38)\n(λ4)ij = −\nZ ∞\nEmax\ndE\nE −E g2\n4µ444(Eij) −κ4 .\nThere is a small technical subtlety in using the given expressions. For (Ei + Ej)/2 close to\nEmax, the argument Eij of the µ-functions is small in the part of the integration region close to\nEmax. In this region it makes little sense to use (3.31), valid for large E. From ﬁgure 1 we see\nthat the asymptotics sets in roughly at E ∼5m. We therefore use the following prescription in\nevaluating (3.38): we use (3.31) for Eij ⩾5m, while we set µ’s to zero below this threshold.\nThe full procedure is then as follows. We compute the local renormalized Hamiltonian (3.35)\nwith the reference value E∗ﬁxed around the ground state energy. We diagonalize Hren, determining\nthe renormalized spectrum (in practice only a few lowest eigenvalues) and the corresponding\neigenstates:\nHren|cI⟩= Eren,I|cI⟩\n(3.39)\nEvery eigenvalue is then corrected by adding (3.37) at ﬁrst order in perturbation theory:\nEsubl,I = Eren,I + ∆EI,\n∆EI = ⟨cI|∆Hsubl(Eren,I)|cI⟩.\n(3.40)\nFrom the computational point of view the evaluation of this correction can be considered inex-\npensive, since it scales as the square of the basis dimension, whereas the matrix diagonalization\ntypically scales as its cube. The energy levels Esubl,I will be called ‘renormalized subleading’ or\nsimply ‘subleading’.\nSecond-order corrections can also be considered:\n∆E(2)\nI\n=\nX\nJ̸=I\n|⟨cI|∆Hsubl(Eren,I)|cJ⟩|2\nEren,I −Eren,J\n.\n(3.41)\nThese turn out to be negligible, except when there are two almost-degenerate eigenvalues.\n16\n\n3.4\nA test for the φ2 perturbation\nWe will now perform a test of our method in a controlled situation when the exact answers are\nknown.12 Consider the theory described by the action (cf. (2.1)):\nS = S0 + g2\nZ\nd2x : φ2 : .\n(3.42)\nThe ﬁnite volume Hamiltonian corresponding to this problem has the form\nH = H0 + g2V2 + C,\nC = E0(L) + g2Lz(L) .\n(3.43)\nJust as in section 2.1, the extra constant term C appears because of the diﬀerence in the normal\nordering counterterms in the inﬁnite space and on the circle.\nThese terms are exponentially\nsuppressed for Lm ≫1, but for the time being it will be instructive to keep them.\nIn full form, we have:\nH = C +\nX\nk\nωka†\nkak + g2\n2ωk\n(aka−k + a†\nka†\n−k + 2a†\nkak) ,\nωk = ωk(m) .\n(3.44)\nWe expect, of course, that this Hamiltonian corresponds to a free scalar of a mass\nµ2 = m2 + 2g2 .\n(3.45)\nWe will now use a Bogoliubov transformation to show this explicitly. The derivation is standard\nand is given here only for completeness. The transformation has the form\nbk = (cosh ηk)ak + (sinh ηk)a†\n−k\n(3.46)\nwith ηk assumed real and depending only on |k|. The b’s then satisfy the same oscillator commu-\ntation relations as the a’s. We want to map (3.44) onto\nX\nk\nΩkb†\nkbk + E0 ,\nΩk = ωk(µ) .\n(3.47)\nThe conditions that the two Hamiltonians match take the form:\nΩk cosh(2ηk) = ωk + g2/ωk ,\nΩk sinh(2ηk) = g2/ωk .\n(3.48)\nThis is indeed satisﬁed provided that\nΩ2\nk = ω2\nk + 2g2 ,\n(3.49)\nwhich proves the expression (3.45) for the new mass. The same derivation gives the value of the\nvacuum energy:\nE0 = C −\nX\nΩk(sinh ηk)2 = C + 1\n2\nX\n(Ωk −ωk −g2/ωk) .\n(3.50)\nUp to the constant C, the last expression can be intuitively understood [1] by starting from the\nzero-point energy 1\n2\nP Ωk and subtracting the terms zeroth and ﬁrst order in g2.\n12This test is analogous to the one in [1], section 6.\n17\n\n−0.4\n−0.2\n0.0\n0.2\n0.4\n0.6\n0.8\ng2\n−0.35\n−0.30\n−0.25\n−0.20\n−0.15\n−0.10\n−0.05\n0.00\nE0\nm = 1, L = 10.0\nraw\nexact\n−0.4\n−0.2\n0.0\n0.2\n0.4\n0.6\n0.8\ng2\n0.000\n0.001\n0.002\n0.003\n0.004\n0.005\n0.006\n0.007\nE0 −exact\nm = 1, L = 10.0\nraw - exact\nren. - exact\nsubl. - exact\nFigure 2: Exact and numerical ground state energy for the φ2 perturbation; see the text.\nThe series in (3.50) is convergent and can be summed using the Abel-Plana formula. We ﬁnd\nthat the constant C is canceled, and the ﬁnal result is given by\nE0 = E0(L, µ) + ΛL,\nΛ = 1\n8π[µ2(1 −log µ2/m2) −m2] ,\n(3.51)\nwhere E0(L, µ) is the Casimir energy of the free scalar ﬁeld of mass µ, given by (2.10) with m →µ.\nThe physical interpretation of (3.51) is clear. Apart from the usual Casimir energy term, we\nhave an induced extensive vacuum energy, corresponding to a ﬁnite vacuum energy density Λ.\nUsually, when one studies the Casimir energy, the vacuum energy density in the inﬁnite space\nlimit is assumed to vanish.\nHowever, our situation here is diﬀerent.\nWe already ﬁnetuned to\nzero the vacuum energy density of the original, unperturbed, theory, i.e. the one described by the\naction S0. Once this is done, the vacuum energy density of the perturbed theory becomes ﬁnite\nand observable.\nWe will now compare the above exact results with the numerical results obtained by using\nthe Hamiltonian truncation. We will be considering the case Lm ≫1, which means that we will\nnot be sensitive to the exponentially suppressed constant term C in the initial Hamiltonian. We\nthus start directly from the Hamiltonian of the form (3.33) with g4 = 0, g2 ̸= 0. We calculate\nits spectrum using the three procedures from section 3.3. In the shown plots we chose m = 1,\nL = 10, and varied g2 from −0.4 to 0.8.13 For illustrative purposes numerics were done with a\nrather low cutoﬀEmax = 12, for which the truncated Hilbert space contains about 300 states.\nFigure 2 compares the ground state energy. In the left plot, the agreement between the raw and\nthe exact result is already pretty good. The right plot shows the diﬀerence between the numerics\nand the exact value. We see that the renormalization greatly reduces the discrepancy over the raw\nprocedure, and the results are made slightly better by including the subleading correction.\nIn ﬁgure 3 we do the same comparison for the spectrum of excitations above the vacuum,\nEI −E0. In the left plot we pick the ﬁrst two Z2-odd states (one and three particles at rest),\nand the ﬁrst two Z2-even states (two particles at rest, and with one unit of momentum in the\nopposite directions). Already the raw spectrum agrees well with the exact values. In the right\nplot we present the diﬀerences, focussing on the ﬁrst two excited levels only (one even and one\nodd). Notice that for g4 = 0 the diﬀerence between Hren and Htrunc is only in the vacuum energy\n13The reference energy E∗in (3.34) was set to the value of the ground state energy given by the raw truncation\nprocedure.\n18\n\n−0.4\n−0.2\n0.0\n0.2\n0.4\n0.6\n0.8\ng2\n0\n1\n2\n3\n4\n5\nEI −E0\nm = 1, L = 10.0\nraw, Z2 = −\nraw, Z2 = +\nexact, Z2 = −\nexact, Z2 = +\n−0.4\n−0.2\n0.0\n0.2\n0.4\n0.6\n0.8\ng2\n0.000\n0.001\n0.002\n0.003\n0.004\n0.005\n0.006\n(EI −E0) −exact\nm = 1, L = 10.0\nraw - exact, Z2 = −\nraw - exact, Z2 = +\nsubl. - exact, Z2 = −\nsubl. - exact, Z2 = +\nFigure 3: Exact and numerical spectra of excitations for the φ2 perturbation; see the text.\ncoeﬃcient κ0, which shifts all eigenvalues in the same way. The ﬁrst non-trivial corrections for the\nspectrum of excitations are therefore the subleading ones. The improvement over the raw results\nis signiﬁcant.\n3.5\nComparison to Ref. [1]\nThe reader will have noticed that our treatment of the UV cutoﬀdependence and renormalization\nis similar to Ref. [1], sections 5 and 7.3. There is however a diﬀerence of principle that we will now\nexplain.\nBoth in this work and in Ref. [1] the starting point for the renormalization is Eq. (3.6). While\nRef. [1] also presents this equation, it then takes an alternative route, justifying the renormalization\nprocedure on the basis of the Hamiltonian perturbation theory, see [1], Eq. (5.8). This equation\nis then further subjected to an RG improvement procedure in section 5.3 of [1], leading ultimately\nto a result which diﬀers from our Eq. (3.6) only by some subleading corrections.\nAlthough the RG improvement introduced in [1] might be useful for understanding the physical\npicture, it appears to be a detour that is not strictly necessary for doing the computations. Eq. (3.6)\nappears to provide the best starting point for the discussion of renormalization corrections.\nA discussion on earlier approaches to analytic renormalization, in the context of TCSA, can\nbe found section 5.4 of [1].\n4\nStudy of the φ4 theory\nIn the previous sections we have developed the method and tested it in the simple setting of the\nφ2 perturbation. We will now move on to the main task of this paper—to study the spectrum of\nthe φ4 theory described by the Hamiltonian (2.21).\nThe main physical parameter varied in our study will be the quartic coupling g. The physics\ndepends on the dimensionless ratio ¯g = g/m2, and we will work in the units where the mass term\nm = 1.\n19\n\nThe second parameter will be the size of the spatial circle L. This plays the role of the IR\ncutoﬀ, to render the spectrum discrete. In practice one is usually interested in the inﬁnite volume\nlimit L →∞, and we will try to approach this limit. However, even a ﬁnite L is physical, in the\nsense that the energy levels on the circle are well-deﬁned physical observables.\nThe third parameter we will vary is the cutoﬀon the size of the Hilbert space Emax (the\nmaximal energy of the free scalar Fock states included in the truncated Hilbert space).\nThis\nparameter plays the role of the UV cutoﬀ. It is unphysical. The continuum limit is recovered for\nEmax →∞.\nWe will typically present the results derived using the renormalization procedures both without\n(marked ‘ren.’ in the plots) and with (marked ‘subl.’) subleading corrections (see section 3.3).\nThese procedures are expected to converge to the exact spectrum at the rate which goes as 1/E3\nmax\nand 1/E4\nmax (modulo logarithms). We take the diﬀerence between them as a rough idea\nof the current error of the method.\n4.1\nVarying g\nIn ﬁgure 4 we present the ground state energy and the low energy spectrum of excitations for\ng ⩽5. This extends well beyond the range g ≲0.5 −1 where perturbation theory is accurate (see\nappendix B). In this plot we use a ﬁxed value L = 10, and choose the UV cutoﬀEmax = 20.14 We\nuse the two renormalization procedures explained in section 3.3.\n0\n1\n2\n3\n4\n5\ng\n−10\n−8\n−6\n−4\n−2\n0\nE0\nm = 1, L =10\nren.\nsubl.\n0\n1\n2\n3\n4\n5\ng\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nEI −E0\nm = 1, L =10\nren., Z2 = −\nsubl., Z2 = −\nren., Z2 = +\nsubl., Z2 = +\nFigure 4: Numerical spectra as a function of g for m = 1, L = 10; see the text.\nThe left plot shows the dependence of the ground state (≡vacuum) energy on g. The vacuum\nis simply the state of the lowest energy, and it resides in the Z2-even sector. There is not much\nstructure in this plot, except for the fact that the vacuum energy is negative and grows in absolute\nvalue as g is increased, becoming of the same order of magnitude as Emax for the largest g considered\nhere. This has a consequence for the renormalization procedure used in our study. Recall that in\nthe local renormalization (the one marked ‘ren.’) the coupling are renormalized using Eqs. (3.34)\nwhich involve the reference energy E∗. Everywhere in this section we set E∗to the value of\nthe vacuum energy computed using raw truncation. We already mentioned in section 3.3\n14This corresponds to keeping 12870(12801) states in the even(odd) sector of the Hilbert space.\n20\n\nthat since the vacuum energy may become large, the integrals in (3.34) have to be evaluated without\nexpanding in E∗. We are fortunate here that the vacuum energy becomes large and negative, and\nso the renormalization corrections become smaller if nonzero E∗is taken into account. A large and\npositive vacuum energy would be a big problem for the performance of our method.15\nThe right plot shows the 5 lowest excitations above the vacuum, with the Z2 = ± excitations\ncolored in blue(resp. red). As we can see the ﬁrst odd level becomes almost degenerate with the\nvacuum for g ≳3. This is a signal of the spontaneous Z2-symmetry breaking. We therefore expect\na second-order phase transition to occur at a critical point g = gc ≈3. For g = gc, the theory\nshould ﬂow at large distances to a CFT. Since the φ4 theory is in the same universality class as the\nIsing model, we expect this IR CFT to be the minimal model M4,3. We will analyze the region\naround g = gc in more detail below. For g > gc we are in the Z2-broken phase. In this phase, the\nhigher excitations should also be doubly degenerate in inﬁnite volume. For a ﬁnite L the exact\ndegeneracy is lifted and becomes approximate. This degeneracy is not observed clearly in ﬁgure 4,\nprobably because L = 10 is not large enough.16\nIn the region of small g, it is possible to validate the numerical results by comparing them\nto perturbation theory. In appendix B, we do this comparison for the ground state energy and\nthe mass of the lowest excitation. For small g, we ﬁnd good agreement with the perturbative\npredictions computed through O(g3).\nIt is interesting to understand the sensitivity of the spectrum plot in ﬁgure 4 to the chosen value\nof L = 10. We therefore show in ﬁgure 5 similar plots for L equal to 6, 8, 10 and Emax respectively\nequal to 34, 26 and 20.17 To avoid clutter, only the results for the subleading renormalization (the\nthird, most precise method in section 3.3) are presented.\n0\n1\n2\n3\n4\n5\ng\n−1.2\n−1.0\n−0.8\n−0.6\n−0.4\n−0.2\n0.0\nE0/L\nm = 1\nL=10\nL=8\nL=6\n0\n1\n2\n3\n4\n5\ng\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nE1 −E0\nm = 1\nL=10\nL=8\nL=6\nFigure 5: The vacuum energy (left) and the ﬁrst odd excitation (right) determined numerically for\nL = 6, 8, 10. The blue dashed line in the right plot is the ﬁt to determine the critical coupling; see\nsection 4.2.\n15That the vacuum energy becomes negative both here and in section 3.4 is probably more than just a coincidence.\nSee the discussion in [1], note 21.\n16The discussed phase diagram is the same as for the φ4 model in d = 2.5 dimensions studied in [1] using the\nTCSA. In that case it was possible to observe approximate degeneracy for the ﬁrst and second excited states.\n17Emax is adjusted to have roughly the same size of the Hilbert space in all three cases. Smaller L give larger\nenergy spacings for the one-particle momentum excitations, and allow to go to larger Emax.\n21\n\nIn the left plot we show the vacuum energy density Λ = E0/L. For a suﬃciently large L this\nis supposed to become independent of L. We see that this constancy is veriﬁed with an excellent\naccuracy for g ≲2.\nIn this region we are in the massive phase, and the ﬁnite L corrections\nare expected to be exponentially small (see section 4.3 below). The dependence on L becomes\nmore pronounced around g = gc, which is as it should be because the mass gap goes to zero\nhere. However, in the Z2-broken phase the corrections remain signiﬁcant, while theoretically they\nshould become again exponentially suppressed. Therefore, for g ≳3, we are forced to interpret the\nvariation with L not as a physical eﬀect but being due to ﬁnite Emax truncation eﬀects. This is\nconsistent with the signiﬁcant diﬀerence between the results obtained with the two renormalization\nprocedures in ﬁgure 4.\nIn the right plot of ﬁgure 5 we show the physical particle mass mph = E1 −E0. Once again, in\nthe Z2 unbroken massive phase there is hardly any dependence on L, while around g = gc there\nappears variation, which will be studied quantitatively in section 4.2 below. This plot will also be\nused below to extract an estimate of gc.\nOverall, the truncation eﬀects seem to be too large for g ≳3 to allow precise quantitative\nclaims about this range of couplings (apart from the fact that the Z2 symmetry appears broken).\nHead-on treatment of that range would require a reﬁnement of the method, by improving the\nrenormalization procedure. An alternative way to access this region is to use the strong/weak\ncoupling duality due to Chang [17]. In a companion work [18] we will both test this duality, and\nuse it to study the Z2-broken phase of the model.\n4.2\nThe critical point\nWe will now try to determine with some precision the critical coupling gc, and study the lowest\noperator dimensions of the CFT at the phase transition. According to the standard renormalization\ngroup theory, for g close to gc the physical mass mph should behave as:\nmph ∼C|g −gc|ν,\n(4.1)\nwhere C is a theory-dependent constant,18 and ν is a critical exponent, common for all theories in\nthe Ising model universality class, and expressible via the dimension of the most relevant Z2-even\nscalar operator, ϵ, of the CFT:\nν = (2 −∆ϵ)−1 .\n(4.2)\nWe used our numerical results obtained for L = 10, Emax = 20 renormalized with subleading\ncorrections (see ﬁgure 5) to perform the ﬁt of mph ≡E1 −E0 to the formula (4.1), replacing ∼\nby =. Admittedly, our procedure is careless, since we do not take into account the corrections to\nscaling. We view the results which we will now present as preliminary; they should be validated by\nfuture studies as our method progresses. Another uncertainty concerns the range of g chosen to do\nthe ﬁt. On the one hand, g should be close to gc, on the other hand right close to gc the spectrum\nis modiﬁed by ﬁnite size corrections. Looking at the right plot in ﬁgure 5, we subjectively picked\nthe g-interval [1.4, 2.4], which by the eye seems to give a nice powerlaw close to a straight line.\nTo introduce some way to estimate the systematic error, we selected a few subintervals contained\nin the basic interval, and ﬁtted the parameters ∆ϵ, gc for each such subinterval.19 We obtained\n18Which also depends on from which direction one approaches the ﬁxed point.\n19In the future, the ﬁt procedure could be reﬁned by taking into account the value of E2 −E0 at g = gc.\n22\n\n5\n6\n7\n8\n9\n10\n11\n12\nL\n0.0\n0.5\n1.0\n1.5\n2.0\n(EI −E0)L/(2π)\n∆σ\n∆ϵ\n∆∂2σ\ng =2.94−3.0\nFigure 6: Comparison with the CFT spectrum; see the text.\ngc = 3.04(15) and ∆ϵ = 1.06(13). This value of ∆ϵ is compatible with the two-dimensional Ising\nmodel value ∆ϵ = 1, giving us conﬁdence that the procedure is sensible. To improve the estimate\nof gc, we ﬁx ∆ϵ to this theoretically known value and redo the ﬁt. We then get ¯gc = 2.97(3).\nThe above error estimate may be too optimistic, because we completely ignored the error in\nmph induced by truncation eﬀects. We have also performed the ﬁt taking the L = 10, Emax = 20\n‘renormalized subleading’ results as central values, and the diﬀerence σ between these central\nvalues and the ‘renormalized’ results without subleading correction as the error (we consider the\ntwo-sided error ±σ). Following this procedure and doing the ﬁt in the [1.4, 2.4] interval we obtained\n¯gc = 2.97(14). This is our ﬁnal, conservative, estimate.\nWe now perform another comparison with the theoretically known CFT operator dimensions.\nNamely, for g = gc the excitations EI −E0 should go as\nEI −E0 ∼2π\nL ∆I ,\n(4.3)\nwhere ∆I are the CFT dimensions. This asymptotics should be valid for L ≫1 where the theory\nhas ﬂown suﬃciently close to the IR ﬁxed point. To check this, in ﬁgure 6 we plot the three lowest\nexcitation energies multiplied by L/(2π).\nIn this ﬁgure, we consider L = 5 . . . 12 and vary the quartic coupling within our ‘optimistic’\nuncertainty range around the ﬁxed point, g = 2.94 . . . 3.0. We have to vary the UV cutoﬀEmax as a\nfunction of L in order to have a manageable number of basis elements in the low energy truncated\nHilbert space Hl. So Emax decreases from 33 at L = 5 to 18 at L = 12, while the truncated\nHilbert space dimension stays for each L around 10000 - 15000 per Z2 sector. To avoid clutter, we\nshow only the ‘renormalized subleading’ results (but see ﬁgure 8 below, where the results without\nsubleading corrections are also shown).\nAs ﬁgure 6 demonstrates, (4.3) is approximately obeyed at large L, provided that we use the\n2D Ising operator dimensions ∆σ = 1/8, ∆ϵ = 1, ∆∂2σ = 2 + 1/8, where this latter operator is a\nscalar descendant of σ.\n23\n\n4.3\nL dependence\nWe will now present several plots which show explicitly how the spectrum of the theory varies for\nincreasing L while keeping g ﬁxed. These plots are analogous to ﬁgure 5, but the information is\npresented somewhat diﬀerently.\nZ2-unbroken phase\nLet us look ﬁrst at the Z2-unbroken phase. We ﬁx g = 1, which is at the outer border or the\nperturbativity range (see appendix B). Figure 7 shows then the vacuum energy density E0/L and\nthe spectrum, for L = 5 . . . 12.\n5\n6\n7\n8\n9\n10\n11\n12\nL\n−4.02\n−4.00\n−3.98\n−3.96\n−3.94\nE0/L × 102\nm = 1, g =1.0\nren.\nsubl.\n5\n6\n7\n8\n9\n10\n11\n12\nL\n0\n1\n2\n3\n4\n5\nEI −E0\nm = 1, g =1.0\nren., Z2 = −\nsubl., Z2 = −\nren., Z2 = +\nsubl., Z2 = +\nFigure 7: The vacuum energy density and the excitation spectrum for g = 1, as a function of L.\nIn the left plot we see that the vacuum energy density tends to a constant value. We don’t\nworry too much about the ﬂuctuations around the limit which happen for some values of L, like an\nupward ﬂuctuation for L = 8.5 or a downward ﬂuctuation for L = 11.5. These ﬂuctuations are due\nto the fact that in our renormalization procedure we neglected the discreteness of the distribution\nM(E), replacing it by a continuous approximation.\nAs ﬁgure 1 shows, this approximation is\nmeant to work only on average. The sharpness of the cutoﬀE ⩽Emax disrupts the validity of the\napproximation, and must be behind the above ﬂuctuations. In the future it will be important to\nﬁnd a way to work around these ﬂuctuations. One way would be to consider a cutoﬀwhich is not\ntotally sharp.20\nIgnoring for the time being the ﬂuctuations, let us discuss the approach of the vacuum energy\ndensity to its inﬁnite volume limit. As is well known, in a massive phase the rate of this approach\nis exponentially fast and is given by:\nE0(L)/L = Λ −mph\nπL K1(mphL) + O(e−2mphL)\n≈Λ −\n\u0010 mph\n2πL3\n\u00111/2\ne−mphL\n(L ≫1/mph) .\n(4.4)\n20Ref. [1], section 6.4 and appendix D, describes a method which for conformal bases used in that work allowed\nto perform renormalization taking into account the discreteness of the sequence M(E). It’s not clear if that method\nextends to the massive Fock space bases used here.\n24\n\nThis formula can be derived by considering the partition function of the theory on a torus S1\nL ×S1\nL′\nwhere L and L′ are the lengths of the circles. The E0(L) is extracted by considering the limit\nL′ ≫L, and so it’s natural to treat L′ as space and L as the inverse temperature. The condition\nL ≫1/mph means that we are interested in low temperatures. The deviation of the free energy\ncan then be described in terms of thermodynamics of a gas of particles of mass mph. This type of\narguments is standard in the thermodynamic Bethe ansatz calculations in integrable theories, in\nwhich case also the subleading terms in (4.4) can be determined; see e.g. [19], Eq. (3.13). However,\nthe leading term that we show is more general.\nIt does not require integrability nor knowing\nanything about how the particles interact - we can treat them as free in this computation. In fact\n(4.4) can be also determined by taking the large L limit of the free scalar Casimir energy (2.10)\nwith m →mph.\nThe blue curve in the left plot is the ﬁt of our numerical data by Eq. (4.4) with mph ﬁxed to the\nvalue determined from the numerical spectrum (see below). We see that the rate of the approach\nto the inﬁnite L limit is reasonably well described by the theoretically predicted dependence.21\nThe accompanying right plot shows the spectrum of excitations above the vacuum. Observe\nthe remarkably small diﬀerence between the two renormalization procedures (we use this diﬀerence\nas an idea about the error of the method). The ﬁrst excited state in the odd sector should for\nlarge L approach the inﬁnite-volume physical mass mph. It shows hardly any variation with L in\nthe shown range, which is consistent with the rate of approach being exponentially fast in mphL\n[20]. We extract mph = 0.751(1).\nThe second excited state, which belongs to the even sector, for large L asymptotes to 1.47(4)\nwhich within error bars coincides with 2mph. This state corresponds to having two particles at\nrest. Notice that we do not observe any states in the energy range between mph and 2mph. Such\nstates would be interpreted as two-particle bound states. As is well known, the φ4 interaction is\nperturbatively repulsive, so we do not expect bound states at weak coupling. Moreover it is known\nrigorously that two-particle bound states are absent everywhere below the phase transition; see\n[21], section 17.2. What we observe here is consistent with these results.\nNotice that the ‘two-particles at rest’ state approaching 2mph, as well as the ‘three-particles\nat rest’ state going to 3mph, show a much larger variation with L compared to the one-particle\nstate. That this variation is not exponentially suppressed is a consequence of particle-particle\ninteractions. Since the interactions are short-ranged, their eﬀect is expected to go like the inverse\nvolume, 1/L [22]. It should be possible to use this eﬀect to extract information about the two-\nparticle S-matrix.22\nFor small g, it is easy to calculate these corrections explicitly using the ﬁrst-order perturbation\ntheory for the Hamiltonain (2.21). For the two-particle and three-particle states at rest we get23\nE2 = 2m +\n3g\nLm2 + O(g2) ,\nE3 = 3m +\n9g\nLm2 + O(g2) .\n(4.5)\nThe positiveness of the O(g) corrections explains the “bumps” at small coupling in the correspond-\n21Since mph < m, the eﬀect we are observing here is formally dominant with respect to the exponentially suppressed\nE0(L) and z(L) corrections, which were omitted in section 2.1. Still, the hierarchy m/mph is not very large, and a\nmore careful comparison may be warranted in the future, taking also those corrections into account.\n22Such analyses are standard in the TCSA approach to d = 2 RG ﬂows; see [23, 14] for the ﬁrst and a recent\nexample.\n23These formulas are valid for a ﬁxed ﬁnite L and g ≪π2m/L. In this limit the splittings between diﬀerent states\nwith the same number of particles are suﬃciently large so that we can neglect their mixing. In the opposite limit\none should apply quasi-degenerate perturbation theory.\n25\n\ning curves in ﬁgure 4 (the ﬁrst Z2-even and the second Z2-odd states).\nThe even state just above the one asymptoting to 2mph should be identiﬁed as corresponding to\ntwo particles moving in the opposite directions on the circle with one unit of momentum each. Using\nthe one-particle dispersion relation, the energy of this state should be roughly 2×(m2\nph+(2π/L)2)1/2\nplus the corrections due to the particle interactions in ﬁnite volume. Because of the 2π prefactor,\nthe dispersion relation corrections are signiﬁcant even at the maximal values of L that we are\nconsidering; they seem to explain most of the diﬀerence between the ﬁrst two even states. At\nlarger L, we expect the particle interaction corrections to take over, since their strength decreases\nonly as 1/L.\nOur ﬁnal comment about the g = 1 spectrum plot concerns the pattern of level crossings. In\na non-integrable quantum ﬁeld theory, we do not expect energy levels of the same symmetry to\ncross when varying the volume. In fact, the absence or presence of level crossings can be used as\nan empirical check of integrability (see [24] for a related recent discussion). Since the φ4 theory is,\nfor all we know, non-integrable, levels with the same Z2 quantum number should not cross. Most\nlevels in ﬁgure 7 do not cross trivially because they never come close each other. However, there is\none interesting “avoided” crossing: the third and fourth Z2 = + levels head for a collision around\nL = 7 but then repel. Many more such avoidances are present in the higher energy spectrum (not\nshown in ﬁgure 7).\nThe critical point\nIn ﬁgure 8 we show analogous plots for the neighborhood of the critical point. We ﬁx g = 2.97,\ni.e. the central value for our gc estimate. One drastic change compared to ﬁgure 7 is that the\nenergy diﬀerences EI −E0 (plotted on the left) no longer tend to constants but scale as 1/L, as\nexpected for a CFT. This is the same plot as in ﬁgure 6, except that here we do not multiply by\nL/2π, and we show results for both renormalization methods, to get an idea of possible error bars.\nEvidently, even if g is not exactly equal to the critical coupling, the mass gap is suﬃciently small\nso that it is not visible for the values of L shown in this plot.\nOn the right we show the vacuum energy density, which, as expected, seems to approach\na constant.\nHowever, the uncertainty, measured by whether or not we include the subleading\ncorrections, remains signiﬁcant. Theoretically, the asymptotics of approach to the limit should be\n−πc/(6L2), where c = 1/2 is the central charge of the critical point. Instead, we see something like\na 1/L approach. Clearly, one should work to reduce the truncation errors before the agreement is\nachieved.\nIt should be remarked that the vacuum energy is always subject to larger errors than the\nspectrum of excitations. This is related to the fact that the unit operator, whose coeﬃcient shifts\nthe vacuum energy, is the most relevant operator of the theory, and gets the largest renormalization\nwhen the states above Emax are integrated out. However, whichever uncertainty in the coeﬃcient\nof the unit operator cancels when we compute the spectrum of excitations.\n4.4\nEmax dependence\nTo get a better feel for the convergence of our method, and to demonstrate the diﬀerence between\nthe three procedures explained in section 3.3, we will present here plots of the spectrum and\nvacuum energy as a function of Emax, while keeping the other parameters ﬁxed.\n26\n\n5\n6\n7\n8\n9\n10\n11\n12\nL\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nEI −E0\nm = 1, g =2.97\nren., Z2 = −\nsubl., Z2 = −\nren., Z2 = +\nsubl., Z2 = +\n5\n6\n7\n8\n9\n10\n11\n12\nL\n−0.40\n−0.39\n−0.38\n−0.37\n−0.36\n−0.35\n−0.34\n−0.33\n−0.32\nE0/L\nm = 1, g =2.97\nren.\nsubl.\nFigure 8: Same as in ﬁgure 7, but for g = 2.97.\nSo, ﬁgure 9 shows the results for g = 1, L = 10, with Emax varying from 10 to 20. On the left\nwe see that the renormalization dramatically improves the convergence of the vacuum energy with\nrespect to the raw results, while the subsequent subleading correction is very small. The plot on\nthe right refers to the ﬁrst excited level (i = 1). In this case we see that the further improvement\ndue to the subleading correction is non-negligible. There are small oscillations due to discretization\neﬀects, as already discussed in section 4.3. The higher excitations, not shown in the plot, show a\nsimilar pattern of convergence.\n10\n12\n14\n16\n18\n20\nEmax\n−0.45\n−0.40\n−0.35\n−0.30\n−0.25\n−0.20\n−0.15\nE0\nm = 1, g =1, L =10\nraw\nren.\nsubl.\n10\n12\n14\n16\n18\n20\nEmax\n0.74\n0.76\n0.78\n0.80\n0.82\n0.84\nE1 −E0\nm = 1, g =1, L =10\nraw\nren.\nsubl.\nFigure 9: Variation with Emax and the eﬀect of renormalization corrections for g = 1.\nFigure 9 shows the same plots for g = 3. Once again the improvements due to renormalization\nare evident. For a change, here we show more states in the spectrum of excitations.\n4.5\nComparison to the TCSA methods\nAs already mentioned, Ref. [1] recently studied the φ4 theory in d = 2.5 dimensions using the\nTCSA method. The results of that study, and in particular the phase diagram of the theory,\n27\n\n10\n12\n14\n16\n18\n20\nEmax\n−4.0\n−3.5\n−3.0\n−2.5\n−2.0\n−1.5\n−1.0\nE0\nm = 1, g =3, L =10\nraw\nren.\nsubl.\n10\n12\n14\n16\n18\n20\nEmax\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\nEI −E0\nm = 1, g =3, L =10\nraw, Z2 = −\nren., Z2 = −\nsubl., Z2 = −\nraw, Z2 = +\nren., Z2 = +\nsubl., Z2 = +\nFigure 10: Same as in ﬁgure 9 but for g = 3.\nturned out to be quite similar to the one we found here; see [1], section 7. The TCSA uses the\nbasis of conformal operators of the free massless scalar ﬁeld theory, which via the state-operator\ncorrespondence is the same as the basis of states of this theory put on the sphere Sd−1. In the\nTCSA, both the φ2 and φ4 perturbations are included into the V part of the Hamiltonian. This\nshould be contrasted with our current method, where φ2 is included into H0. We will mention\nhere just one advantage and one complication of working with the conformal basis and treating all\npotential terms as a perturbation. The advantage is that the Hamiltonian matrix Hij for a general\nsphere radius R is related to the R = 1 matrix via a simple rescaling. The complication is that\nthe conformal basis is not orthonormal, requiring introduction of a Gram matrix or dealing with\nan eigenvalue problem which is not symmetric.\nThere were several reasons why [1] considered d = 2.5. First of all, the main point of that paper\nwas to show that the TCSA works in d > 2. Second, there were technical reasons to postpone\nthe physically more interesting case d = 3 to the future. The ﬁnal reason is that, at least naively,\nconformal basis does not work in d = 2, because the scalar ﬁeld dimension becomes zero, rendering\nthe spectrum dense and numerical treatment impossible.\nIn spite of this basic diﬃculty, a recent paper [4] proposed a way to use the conformal basis\nin d = 2 dimensions. The idea of this work is to compactify the free scalar boson on a circle of\na ﬁnite length 2π/β. Compactiﬁcation renders the CFT spectrum discrete, and one hopes that\nfor a suﬃciently small β compactiﬁcation eﬀects will be negligible. It’s important to realize that\nthe procedure of [4] modiﬁes the quantum mechanical dynamics only for the zero mode, while all\nhigher oscillator modes don’t feel it.24\nOn the conceptual level, the diﬀerence between our paper and [4] lies in the choice of the trial\nwavefunction basis for the oscillators modes. They choose periodic plane waves on a circle of radius\n2π/β for the zero mode, and harmonic oscillator wavefunctions of frequency 2π|n|/L for the modes\nwith |n| > 0. We instead choose harmonic oscillator wavefunctions of frequency\np\nm2 + (2πn/L)2\nfor all modes. Of course the technique for evaluating the matrix elements is also diﬀerent, since\n24For example, it would be wrong to think of their procedure as considering the scalar boson in a quartic potential\ncut oﬀat the boundaries of the interval [−π/β, π/β] and periodically extended to the whole real line.\nSuch a\nperiodized potential would not even give a UV-complete theory, because of the spikes at the cutoﬀpoints.\n28\n\nwe use prosaic ladder operators, while they are able to use the Kac-Moody algebra acting in the\nfree scalar boson CFT.\nApart from β which we will not discuss further, the basic parameters used in [4] to parametrize\nthe phase diagram are: the length of the spatial circle R, which is the same as our L, and the\nquadratic and quartic couplings G2,4.25 The latter translate to our parameters as follows:26\ng = 2πG4 ,\n(4.6)\nm2 = G2 + 6g\nπ log[eγmL/(4π)] .\n(4.7)\nIn the Z2-preserving phase, their strongest coupled point had G2 = 0.01 and G4 = 8×10−5, which\ngives ¯g = g/m2 ≈0.05. From our perspective, this is an extremely weakly coupled case, where\neven ordinary perturbation theory would be largely adequate.\nIt appears that in the Z2-preserving phase our trial wavefunction basis for the zero mode is\nmore eﬃcient than that of [4], since it consists of wavefunctions peaked at φ0 = 0, as opposed\nto being evenly spread over a long interval. We hasten to add however that the main goal of [4]\nwas to study the Z2-broken phase in the regime of negative m2, something that we have not even\nattempted in this paper. In our forthcoming work [18], dedicated to the Z2-broken phase, careful\nchoice of the wavefunction basis for the zero mode will also play an important role.\n5\nComparison with prior work\nThe φ4 theory in two dimensions has been previously studied, in the strongly coupled region, with\na variety of techniques. Table 1 summarizes the predictions for the critical coupling. Here we\nonly mention the methods which, at least in principle, allow for a systematic improvement of the\nresults, leaving out simple-minded variational studies. Many of these papers normalize the quartic\ncoupling as λ/4!; we translate all results to our normalization.\nThe clear trend in the table is that the critical coupling estimate seems to increase with time.\nThe ﬁrst two studies are rather old and do not assign an uncertainty to their results. The next\nresult (DMRG) has the smallest claimed error, but as we will see below there are strong reasons to\nbelieve that it is grossly underestimated. The stated uncertainty of the two remaining predictions\nis also signiﬁcantly smaller than ours. Their central values are below our result, although consistent\nwith it at a 2σ level if we use the conservative error estimate. As we will discuss in section 5.4,\nthis slight discrepancy may be due to a subtlety in implementing the matching to a continuum\nlimit in their procedures.\nWe will now review the methods in Table 1, following the chronological order.\n5.1\nDLCQ\nIn [29, 25], the φ4 theory was studied using the Discretized Light Cone Quantization (DLCQ). This\nis a Hamiltonian truncation method in which the theory is quantized in the light-cone coordinates\n25These are denoted g2,4 in [4], but we capitalized to avoid the confusion with our notation in section 3.\n26The factor 2π in the quartic arises from the diﬀerence of the φ normalization. The extra term in m2 appears\nfrom the diﬀerence in implementing the normal ordering prescription, see their Eq. (65) and the discussion in [18].\n29\n\nMethod\n¯gc\nYear, ref.\nDLCQ\n1.38\n1988 [25]\nQSE diagonalization\n2.5\n2000 [5]\nDMRG\n2.4954(4)\n2004 [26]\nLattice Monte Carlo\n2.70+0.025\n−0.013\n2009 [27]\nUniform matrix product states\n2.766(5)\n2013 [28]\nRenormalized Hamiltonian truncation\n2.97(14)\nThis work\nTable 1: Estimates of ¯gc from various techniques.\nx± = t ± x, using x−as ‘space’ and x+ as ‘time’. The Hilbert space consists of states of several\nparticles all moving in the x+ direction, and having a ﬁxed total momentum P +. This method\nwas much touted in the past because of the apparent reduction in the number of states (since\nonly particles moving in one direction are needed), and the simplicity of the vacuum structure,\nwhich in perturbation theory coincides with the free theory vacuum. In practical computations,\none discretizes (hence Discretized LCQ) the momentum fraction of constituent particles with a\nstep 1/K. This is sometimes presented as a result of compactifying the x−direction on a circle of\nlength 2πK.\nRefs. [29, 25] used DLCQ to compute the physical particle mass as a function of g, observing\nthat it goes to zero for a certain critical value of gc. They ﬁnd ¯gc ≈1.83 for K = 16 [29], and later\nreport an even smaller value ¯gc ≈1.38 based on extrapolating the K ⩽20 results to K = ∞[25].\nThese results are in a stark disagreement with the more recent calculations by other techniques in\nTable 1. A careful repetition of these old studies is called for. It is known that DLCQ calculations\nare subject to severe 1/K truncation eﬀects [30], which may be the source of the discrepancy.\nWe would like to mention here a recent proposal to avoid the P + discretization altogether, and\ninstead truncate the light-cone Hilbert space by using a carefully constructed orthonormal basis\nof multi-particle wavefunctions. This alternative approach may be the future of the light-cone\nquantization. It already proved very promising in the study of 2d gauge theories [10, 11], but was\nnot yet applied to the φ4 theory (see [12] for the preparatory work).\nAs a ﬁnal comment on the light-cone quantization, we note that the method is bound to become\nmore complicated in the Z2-broken phase, possibly requiring a scan of the zero mode ⟨φ⟩to ﬁnd\nthe true vacuum.\n5.2\nQSE diagonalization\nRef. [5] (see also [6–8]) studied the φ4 theory using the Hamiltonian truncation in the same basic\nsetup as ours, calling it “modal ﬁeld theory”.\nHowever, the implementation details are quite\ndiﬀerent. They use a quasi-sparse eigenvector (QSE) method, which reduces the Hilbert space\ndimension by throwing out the Fock states whose contributions to the physical eigenstate one is\nstudying are small. In a later work [6] they developed a stochastic error correction (SEC) method,\nwhich corrects for the resulting truncation. While the idea is similar to our renormalization, there\nare some diﬀerences. One diﬀerence is that their method is perturbative, unlike our basic equation\n(3.6) which is all-order in ∆H. Another diﬀerence is that SEC computes inﬁnite sums involved\nin the deﬁnition of ∆H via Monte Carlo sampling, while we found an analytic approximation for\n30\n\nthis correction term.\nIn ﬁgure 11 we show their results for the ﬁnite volume spectrum [5]. These results are based on\nQSE with 250 states (no SEC). Using this plot, Ref. [5] estimated the critical coupling as ¯gc ≈2.5.\nOn the same plot we overlay our results for the lowest Z2-odd state from ﬁgure 4. Our predictions\nfor the physical mass are in disagreement with [5] in the range ¯g ≲2, where the truncation errors\ndue to ﬁnite Emax are small. Notice that even though our results refer to a smaller value of L than\n[5], this cannot explain the diﬀerences, since the ﬁnite volume eﬀects for the one-particle state are\nnegligible in this range of ¯g (see ﬁgure 7). One possible explanation is that the momentum cutoﬀ\nkmax = 4m used in [5] is not suﬃciently high to describe the continuum limit. In any case, it is\nthis disagreement which is ultimately responsible for the diﬀerence in our estimates of ¯gc.\nThe QSE method of [6] looks somewhat similar in spirit to the Numerical RG (NRG) method\nrecently employed in the context of TCSA [31, 24]. At the same time, the latter method seems\nto us more ﬂexible and systematic. It would be interesting to apply the NRG method to the φ4\ntheory and see if it can help resolve the above discrepancy.\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n3−part. thresh.\n2−part. thresh.\n2−part. state above thresh.\n1−part. state\nground state\nQSE diagonalization\nMonte Carlo\nEnergy eigenstates of !1+1\n4\n\"/4! (units of µ2)\nEnergy (units of µ)\nFigure 11: Finite volume spectrum of the φ4 theory on a circle of length L = 10πm−1 (plot taken\nfrom [5]). In our notation λ/4! = g, µ = m. Black solid lines with error bars—the results of QSE with\n250 states. Black dashed line—the results of a lattice Monte Carlo simulation. On their plot we overlay\nour results for the lowest Z2-odd state on a circle of a smaller length L = 10m−1 (red band). The\ncentral value and the width of the red band are the same as in the conservative method of determining\n¯gc in section 4.2.\n5.3\nDMRG\nRef. [26] studied the φ4 theory using the Density Matrix Renormalization Group (DMRG) [32].\nAs a starting point of this approach, the x-direction is discretized with a spacing a, while time is\nkept continuous. The Hamiltonian describing such a discretized theory is\nH =\nX\nx\n1\n2aπ2\nx + 1\n2a(φx −φx+a)2 + m2a\n2 φ2\nx + ga φ4\nx ,\n(5.1)\nwhere φx are the ﬁeld variables on each lattice site and πx are the corresponding canonical mo-\nmenta. The Hilbert space on each site is inﬁnite, unlike in the more standard DMRG applications.\n31\n\nRef. [26] truncates this Hilbert space to N = 10 ﬁrst harmonic oscillator states. The ﬁnite-system\nversion of the DMRG algorithm [32] is used, truncating to M = 10 most dominant density matrix\neigenstates. This corresponds to the superblock Hamiltonian dimension M2N = 1000.\nThe critical value of the coupling is obtained approaching the critical point from inside of the\nZ2-broken region, and studying how the vacuum expectation value ⟨φ⟩approaches zero in this\nlimit. The quoted value has an extremely small uncertainty: ¯gc = 2.4954(4). However, careful\nreading of the paper leaves us unconvinced that all sources of systematic error were properly taken\ninto account. First, no attempt is made at extrapolating to M = ∞, while Figure 4 of [26] shows\nclearly that convergence in M is slow and the results for M = 10 have not yet stabilized. Second,\nthe value of ¯gc is determined in Figure 7 of [26] by ﬁtting a straight line through two points.\nFinally, we believe that the matching to the continuum limit should have been done more\ncarefully. In the units m2 = 1, the smallest physical lattice spacing in [26] is a ≈0.1.27 This is\nfactor 3 larger than the spacing used in the lattice Monte Carlo study [27] discussed in section 5.4\nbelow. Since Ref. [26] used the simplest nearest-neighbor discretization of the x-derivative, the\nmatching procedure will likely be plagued by the same basic problem as the one we will explain in\nsection 5.4.\n5.4\nLattice Monte Carlo\nIn [27] (see [33] for earlier work) the critical coupling of the φ4 theory was determined by Monte\nCarlo (MC) simulations on the two-dimensional square lattice. They ﬁnd ¯gc = 2.7+0.025\n−0.01 , somewhat\nbelow our prediction. This 2σ discrepancy is not necessarily a reason to worry, as it may go away\nwith further development of our method. In addition, it appears that the MC computation is\nsubject to a subtle systematic error which was not discussed in [27]. This error is particularly\ntroubling because similar errors likely aﬀect, to varying degree, all techniques involving the dis-\ncretization of space, including also the DMRG and MPS methods discussed in sections 5.3 and\n5.5. Below we will review the lattice computation and explain this potential error.\nRef. [27] simulated the lattice action (the subscript # stands for “lattice”)\nS# = a2 X\nx\n1\n2\nX\nµ=1,2\na−2(φx+aeµ −φx)2 + 1\n2m2\n#φ2\nx + g#:φ4\nx :.\n(5.2)\nHere a is the lattice spacing. The normal ordering on the lattice is deﬁned by subtracting a loop\nof the lattice propagator (BZ = the Brillouin zone |pµ| ⩽π/a):\n:φ4\nx : = φ4\nx −φ2\nx\nZ\nBZ\ndp\n(2π)2 G#(p) ,\n(5.3)\nG#(p) =\n\b\n4a−2[sin2(p1a/2) + sin2(p2a/2)] + m2\n#\n\t−1 .\n(5.4)\nSo operationally, (5.3) is plugged into (5.2) and the resulting action is MC-simulated.\nIn the normalization in which m# = 1, Ref. [27] explored the range of lattice spacings a = 0.3 -\n0.03.28 Their lattices had up to 1024×1024 sites, which corresponds to a suﬃciently large physical\nvolume varying from L ≈300 for a = 0.3 to L ≈30 for a = 0.03. Depending on a, the critical\n27This is found from ¯gca2 = ˜λ/4! where their smallest ˜λ = 0.6.\n28See their Table II. The value of a is computed from ˆµ2\nc = m2\n#a2.\n32\n\nquartic coupling was found to vary from g# ≈2.55 to 2.7. Their ﬁnal answer for gc was obtained\nby ﬁtting and extrapolating to a = 0.\nThe systematic error that we have in mind concerns the matching between the lattice and the\ncontinuum. Naively, the lattice theory (5.2) seems to go to the continuum limit theory as a →0,\nwith m# and g# turning into m and g. However, let us try to establish this correspondence more\ncarefully.\nIR\ncont.\nm, g\nm#, g#\n#\nFigure 12: The lattice and the continuum RG ﬂows should agree in the IR. See the text.\nIn ﬁgure 12 we show, schematically, two RG ﬂows: the lattice ﬂow speciﬁed by the couplings\nm#, g# and the continuum ﬂow speciﬁed by m, g. The latter couplings have to be found so that\nthe ﬂows become the same at large distances. We can check if this is the case computing some\nobservables at intermediate distances, when the ﬂows are still perturbative.29 If a suﬃcient number\nof observable agree at intermediate distances, the two ﬂows have converged and will stay the same\nalso at larger distances. In the language of eﬀective ﬁeld theory, this would be an example of\nperturbative matching (see e.g. [34]).30\nAt what distance scale should we do the matching?\nFirst of all, to match the continuum\ntheory, the lattice theory should at the very least become approximately rotationally invariant.\nThe leading deviation from rotation invariance comes from the lattice propagator (5.4), which at\nsmall momenta behaves as\nG−1\n# (p) = p2 + m2\n# −1\n12(p4\n1 + p4\n2)a2 + . . .\n(5.5)\nTo ensure that this is approximately rotationally invariant, we must have p2 ≪a−2.\nOn the other hand, the matching momentum cannot be too small since the theory is then\nstrongly coupled. The smallest allowed matching momentum can be computed by considering the\ndiagrams which give a correction to the quartic coupling. For momenta p ≫m these diagrams\nare, omitting logarithmic factors,\n+ permutations ∼g2/p2,\n(5.6)\nwhich becomes comparable to the coupling g itself for p2 = O(g). Putting the two constraints\ntogether, we conclude that the matching must be done at momenta p such that\ng ≪p2 ≪a−2 .\n(5.7)\n29We are focussing on the case when the coupling g is strong, which is relevant for the critical point. The case of\nsmall g is simpler, as the matching can be performed at p ≲m.\n30In this discussion we ignore another complication arising from the fact that the two-dimensional φ4 theory has\ninﬁnitely many additional relevant couplings beyond m2 and g, since all powers of φ are relevant. Strictly speaking\nestablishing correspondence between the lattice and the continuum may require turning on these extra couplings.\n33\n\nNow, to match the mass, we have to consider the correction to the propagator, which in the\nconsidered region of momenta behaves like\n∼g2/p2[1 + O(p2a2)]\n(5.8)\nwhere the terms dependent on a2 indicate the schematic dependence of the correction on the lattice\nspacing. This suggests that\nm2 = m2\n# + O(g2a2) .\n(5.9)\nHowever, such a conclusion would be on shaky grounds. The problem is that at the lowest allowed\nmomenta p2 ∼g the correction to the propagator due to the rotation invariance breaking has the\nsame parametric order of magnitude, g2a2, as the putative mass matching correction.\nThe above discussion suggests that the chosen form of the lattice discretization prevents\nperforming a controlled matching between the lattice and the continuum theory, because the\nmatching corrections from loop diagrams cannot be cleanly disentangled from the rotation invari-\nance breaking eﬀects in the propagator. This may seem unusual to a lattice practitioner. However,\nthe theory we are considering is a bit unusual, having a coupling constant of dimension exactly 2.\nWe consider it possible that this problem contributes to the mismatch between the lattice\ndetermination of gc and our results. Our discussion also suggests the recipe to remedy the problem:\none should redo the lattice simulation using an improved actions, in which the leading O(p2a2)\neﬀect of rotation symmetry breaking is absent due to judiciously chosen next-to-nearest interaction\nterms [35]. In such a setup the matching can be done, and the correspondence between m#, g#\nand m, g can be established rigorously.\n5.5\nUniform matrix product states\nThis method was applied to the φ4 theory in [28]. The starting point of this approach is the\ndiscretized Hamiltonian (5.1). The lowest energy states are searched for in a ﬁnite variational\nsubspace of the full Hilbert space, consisting of the so-called matrix product states (MPS), whose\nprecise deﬁnition can be found in [28]. The MPS states are parametrized by a 3-tensor of size\nd × D × D.\nHere, d represents the size of the truncated Hilbert space per lattice site, while\nD is a parameter which bounds the degree of entanglement of the ground state across diﬀerent\nlattice sites. The variational states are found by minimizing the energy through an imaginary-time\nevolution algorithm. The physical predictions are recovered in the limit d, D →∞, a →0.\nAs is well known, the MPS methods are essentially equivalent to DMRG (see e.g. [36]).\nComparing with the DMRG study in section 5.5, d and D should be identiﬁed with N and M.\nRef. [28] uses d = 16 and D up to 128, commenting that N = M = 10 used in [26] are not\nsuﬃcient. They observe that an insuﬃciently large D shifts the critical point to lower ¯gc, and\nprovide a physical explanation for this eﬀect. They do two measurements of ¯gc, both approaching\nthe critical point from above, one using ⟨φ⟩and another from the lowest excitation energy. Since\ntheir two measurements diﬀer at a 3σ level, the value cited in Table 1 was obtained by expanding\nthe error bars to include both of them.\nIn the units m2 = 1, the minimal value of the lattice spacing in [28] is a ≈0.04, about the same\nas in [27]. This study is thus subject to the same worries about the matching to the continuum\nlimit as the ones brought up in section 5.4.\n34\n\n6\nDiscussion\nIn this work we revisited one of the simplest realizations of the “exact diagonalization” methods,\nas opposed to standard lattice Monte Carlo methods, and shown that it can be used eﬀectively\nas a numerical tool to extract non-perturbative predictions about a quantum ﬁeld theory. The\nnumerical setup is relatively simple, and the error coming from the UV regulator can be reduced\nby adding analytically computed correction terms to the Hamiltonian.\nOur choice of the model to study here—the two-dimensional φ4 theory—was dictated by several\nconsiderations:\n• the model is not supersymmetric nor integrable, hence not amenable to analytical methods,\napart from perturbation theory at small coupling ;\n• the model has been studied in the past by a variety of numerical techniques, allowing for a\nfair comparison of the results and of the implementation diﬃculties ;\n• the model is literally the textbook example of a quantum ﬁeld theory. In fact we hope that\nour exercise also has a considerable pedagogical value, helping to bridge the conceptual gap\nbetween perturbative and non-perturbative QFT questions.\nHowever we stress that the idea of the paper is completely general, and it should be possible to\napply similar techniques to any quantum ﬁeld theory.\nIn this exploratory work we did not push particularly hard on the numerical side of the\ncalculations—it takes a few single-core days on a desktop to reproduce all the plots in this paper.\nOur analytical calculations of the renormalization coeﬃcients can and will be advanced, further\nimproving the accuracy. The current state of the method allowed us to compute the low-energy\nspectrum in the Z2-invariant phase with a reasonable accuracy, and to observe qualitatively the\nchange to the Z2-broken phase at strong coupling. Our estimate for the critical coupling is in a\nslight disagreement with the existing results. As discussed in section 5.4, this may be partly due\nto a technical subtlety in the lattice regularization. It would be interesting to resolve this tension\nin future work.\nComparisons with other Hamiltonian truncation techniques, such as TCSA or light-cone quan-\ntization, are scattered throughout the paper (see sections 3.5, 4.5, 5.1). At this point in history\nwe don’t want to be religious about which one of these methods is most promising—all have to be\nexplored without prejudice to see which one gives more accurate predictions, depending perhaps\non the problem under consideration. One of the main challenges for all these techniques is their\napplication to higher dimension, where the truncated Hilbert space for a given UV cutoﬀis larger,\nwhile the interesting interaction terms are less relevant, resulting in more signiﬁcant truncation\nerrors. In the TCSA context, these issues recently started being addressed in [1]. Another challenge\nis the application to gauge theories. Here the light-cone quantization seems to have gained an upper\nhand, at least in d = 2, thanks to the extremely eﬃcient conformal bases recently proposed in\n[10, 11].\nThe grand question at stake is—shall we live to see the computation of the proton mass becom-\ning accessible to every theorist, or will it forever remain in the realm of dedicated collaborations\nwielding supercomputers? Currently computations of the low-energy QCD spectrum with 2 + 1\ndynamical quark ﬂavors with a few percent accuracy take about one supercomputer-year, roughly\nequivalent to a 100, 000 single-core-years.\n35\n\nAcknowledgements\nWe thank Daniele Dorigoni, Matthijs Hogervorst, Robert Konik, Giuseppe Mussardo, Agostino\nPatella, David Simmons-Duﬃn and Balt van Rees for the useful discussions, Dean Lee for the\npermission to use the plot in ﬁgure 11, and Mark Windoloski and Dean Lee for providing a copy\nof [8]. This research was partly supported by the National Centre of Competence in Research\nSwissMAP, funded by the Swiss National Science Foundation. The work of L.V. is supported by\nthe Swiss National Science Foundation under grant 200020-150060.\nA\nSpeeding up the Hamiltonian matrix computation\nIn our computations, most time is spent in matrix diagonalization. Still, matrix evaluation should\nalso be organized eﬃciently. Here we list some tricks useful to speed it up. These tricks are realized\nin our python code, included with the arXiv submission.\nDiagonal/oﬀdiagonal decomposition\nLet’s split H into three parts:\nH = Hdiag + Hoﬀdiag + H†\noﬀdiag\n(A.1)\nwhere Hdiag/oﬀdiag have only diagonal/oﬀdiagonal matrix elements. Hdiag includes H0 and the\nterms in V of the form31\na†\nk1a†\nk2ak3ak4,\n{k1, k2} = {k3, k4}.\n(A.2)\nThe rest of the terms in V get assigned to Hoﬀdiag and H†\noﬀdiag. Only the matrix elements of\nHoﬀdiag need to be evaluated, while those of H†\noﬀdiag are obtained by transposition. We include\ninto Hoﬀdiag the a†a†a†a†, a†a†a†a terms in V , as well as the operators\na†\nk1a†\nk2ak3ak4,\n{k1, k2} ̸= {k3, k4} ,\n(A.3)\nsatisfying the following lexicographic ordering condition:32\nsort(|k1|, |k2|) ≺sort(|k3|, |k4|)\n(A.4)\nNotice that this condition depends only on the absolute values of momenta, hence it is P-invariant.\nThis ensures that all three terms in the decomposition (A.1) are separately P-invariant. This will\nbe important below, when we describe our method to evaluate the matrix elements.\nKeeping track of the energy\nEach elementary operator O ∈V , a product of ladder operators, increases/decreases energy of\nany basis vector it acts upon by a ﬁxed amount ∆EO. Since we will be working in the space of\nlow-energy states Hl of energies 0 ⩽E ⩽Emax, we can drop from V all operators for which\n|∆EO| > Emax .\n(A.5)\n31Here and below {x1, x2, . . .} denotes an unordered set.\n32It’s not hard to see that sort(|k1|, |k2|) = sort(|k3|, |k4|) is impossible given {k1, k2} ̸= {k3, k4} and k1 + k2 =\nk3 + k4. So any operator (A.3) gets assigned either to Hoﬀdiag or to H†\noﬀdiag.\n36\n\nMoreover, when acting on a basis state |ψ⟩the result is guaranteed to be zero in Hl unless\n0 ⩽E(ψ) + ∆EO ⩽Emax .\n(A.6)\nCombinatorial factors for oscillator ordering\nTo reduce the number of elementary operators in V , it’s worth ordering them. We have\nX\nk1,k2,k3,k4\nak1ak2ak3ak4 =\nX\nk1⩽k2⩽k3⩽k4\nf4(k1, k2, k3, k4)ak1ak2ak3ak4\n(A.7)\nwhere the symmetry factor\nf4(a ⩽b ⩽c ⩽d) =\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n24\na < b < c < d ,\n12\na = b < c < d or a < b = c < d or a < b < c = d ,\n6\na = b < c = d ,\n4\na = b = c < d or a < b = c = d ,\n1\na = b = c = d .\n(A.8)\nP-conservation\nIn this paper we work in the Hilbert space of P = 0 states of energies E ⩽Emax. Internally we\nrepresent a state |ψ⟩, see (2.8), as a sequence of occupation numbers Zn for each momentum mode:\n|ψ⟩↔[Zn : −nmax ⩽n ⩽nmax] ,\n(A.9)\nwhere nmax is the maximal possible mode number for the given L and Emax.\nThe matrix Hij is then computed as follows. The diagonal part from H0 is trivial so we do not\ndiscuss it. For the rest, we take a particular state |ψj⟩and act on it with elementary operators\nO ∈V , one by one. Each operator gives one particular state |ψi⟩times a numerical coeﬃcient.\nWe accumulate this coeﬃcient in the matrix element Hij. Thus the matrix is generated column\nby column.\nAs discussed above, we can do this computation for Hoﬀdiag and get H†\noﬀdiag by\ntransposition. We generate the matrix separately in each of the Z2 = ± sectors.\nThe computation we just discussed produces the matrix H in the full Hilbert space of P = 0,\nE ⩽Emax states. However, in this paper we are interested in the P = +1 subspace of this space.\nThe basis of this subspace consists of symmetrized linear combinations (2.24) of the basic P = 0\nFock states. In principle, the matrix in the P = +1 subspace could be obtained once the full matrix\nis computed, but this is wasteful. We will now describe a method which generates the matrix in\nthe P = +1 subspace directly.\nWhen we store the symmetrized state |ψsym⟩internally, we only store |ψ⟩. If |ψ⟩̸= P|ψ⟩, then\nwe keep only one of these two vectors (no matter which one), since they give rise to the same\n|ψsym⟩.\nWe have to compute the matrix with respect to the symmerized basis, which we will call Sij:\nH|ψsym\nj\n⟩= Sij|ψsym\ni\n⟩.\n(A.10)\nConsider also the matrix Hij with respect to the Fock basis, whose computation was discussed\nabove. Let’s split it into three pieces:\nH|ψi⟩= Ha\nji|ψj⟩+ Hb\nki|ψk⟩+ Hc\nkiP|ψk⟩,\n(A.11)\n37\n\nwhere the index j runs over P-invariant |ψj⟩, and the rest of the Fock basis is split into |ψk⟩’s and\nP|ψk⟩’s. Since [P, H] = 0, we have\nHP|ψi⟩= P(H|ψi⟩) = Ha\nji|ψj⟩+ Hb\nkiP|ψk⟩+ Hc\nki|ψk⟩,\n(A.12)\nand ﬁnally\nH|ψsym\ni\n⟩= β(ψi)(H|ψi⟩+ HP|ψi⟩) = β(ψi)[2Ha\nji|ψj⟩+ (Hb\nki + Hc\nki)(|ψk⟩+ P|ψk⟩)]\n= β(ψi)[2Ha\nji|ψsym\nj\n⟩+\n√\n2(Hb\nki + Hc\nki)|ψsym\nk\n⟩]\n(A.13)\nFrom here we obtain a recipe for an economic way to compute Sji. Namely, we compute H|ψi⟩\nand accumulate the coeﬃcients 2Ha\nji and\n√\n2(Hb\nki + Hc\nki), and then multiply by β(ψi).\nNotice that we used the P-invariance of the Hamiltonian in the ﬁrst step of (A.12). When this\nmethod is combined with splitting H into the diagonal/oﬀdiagonal parts, it’s important that every\npart be P-invariant by itself. As mentioned above, condition (A.4) ensures this.\nB\nPerturbation theory checks\nSome statements in this appendix are wrong, see Note Added below.\nWe computed the ﬁrst two perturbative corrections to the ground state energy density Λ and\nthe physical particle mass for the φ4 theory deﬁned by the action (2.1):\nΛ/m2 = −21ζ(3)\n16π3 ¯g2 + 0.0416485¯g3 + . . . ,\n(B.1)\n∆m2/m2 ≡(m2\nph −m2)/m2 = −3\n2¯g2 + 2.86460(20)¯g3 + . . .\n(B.2)\n(¯g ≡g/m2). Recall that Λ at g = 0 is set to zero. Because the interaction is normal ordered\nthe O(¯g) contributions are absent. The O(¯g3) coeﬃcients are numerical with a shown number of\nsigniﬁcant digits and an error estimate if needed.33 The size of the coeﬃcients suggests that the\nseries are perturbative for ¯g ≲1.\nThe coeﬃcients were obtained by numerical integration of Feynman diagrams. It is much easier\nto perform this integration in the coordinate space, since the propagator (3.22) is exponentially\ndecreasing at large distances, and also because parallel lines in multiloop diagrams correspond in\nthe x-space to trivially raising the propagator to a power. For example, the O(g3) correction to\n∆m2 comes from the diagram\n(B.3)\nevaluated at the (Euclidean) external momentum p2 = −m2. In the x-space this gives the integral\n(we omit the combinatorial factors)\nZ\nd2x\nZ\nd2y eip.x G(|x −y|)2 G(|y|)2 G(|x|) .\n(B.4)\n33It’s likely that exact expressions for these coeﬃcients can be found, but since this is not the focus of our work,\nwe have not invested the eﬀort.\n38\n\nWe pick p = (im, 0), introduce the polar coordinates and evaluate the integral via Monte Carlo.\nIn ﬁgure 13 we compare the above perturbative results with the numerical spectra obtained\nwith our method for m = 1, L = 10. Perturbative computations refer to the inﬁnite volume, but\nL = 10 is suﬃciently large so that the expected exponentially small corrections should not disturb\nthe comparison. We use the cutoﬀEmax = 20. Notice that mph is extracted as E1 −E0, where E1\nis the lowest Z2-odd eigenstate, while Λ is extracted as E0/L.\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\ng\n−1.5\n−1.4\n−1.3\n−1.2\n−1.1\n−1.0\n−0.9\n−0.8\n−0.7\n∆m2/g2\nm = 1, L =10\nren.\nsubl.\nO(g3)\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\ng\n−0.050\n−0.048\n−0.046\n−0.044\n−0.042\nΛ/g2\nm = 1, L =10\nren.\nsubl.\nO(g3)\nFigure 13: Comparing perturbative and numerical predictions; see the text.\nTo facilitate the comparison, we plot Λ and ∆m2 divided by g2. The reasonably good match\nin the region of small g ≲0.1 shows that our numerical method agrees with both O(¯g2) and O(¯g3)\ncoeﬃcients of the perturbative expansion. At the same time, higher order corrections are clearly\nnon-negligible—they would become comparable to the O(¯g3) correction at ¯g ∼0.5.\nIt should be noticed that it has been rigorously shown in the constructive ﬁeld theory literature\nthat perturbation theory in the two-dimensional φ4 theory is Borel-summable for small ¯g; see [37]\nand the discussion in [21], section 23.2. Using Lipatov-type arguments [38, 39], the asymptotic\nbehavior of the perturbative series coeﬃcients is predicted to be34\n(−1)kkkAk ,\nA = min\nZ\nd2x\n\u0000 1\n2(∂ψ)2 + 1\n2ψ2 −λψ4\u0001\n−log λ ,\n(B.5)\nwhere one has to look for a saddle point in ψ and λ which gives the minimal A.\nGiven this\nasymptotics, one could hope that the Borel transform is regular for all positive ¯g, with a leading\nsingularity at the negative coupling ¯g = −A. It is not obvious to us how this analytic structure\nwould be compatible with the phase transition at a ﬁnite ¯g ≈3.\nAs a side remark, we notice that the two-dimensional φ4 theory in the Z2-symmetric phase\nseems suﬃciently simple so that the perturbation theory can be worked out, by a numerical\nintegration of Feynman integrals, to a very high order. The asymptotic behavior of the coeﬃcients\ncan be also worked out with many subleading terms. Given that, we would like to challenge the\nresurgence/Borel transform community (see e.g. [41]) to reproduce the dependence mph(¯g) with a\nprecision matching that of our method.\nNote added (Aug 2018) The O(g3) coeﬃcient in (B.2) is wrong as we forgot to include\nanother diagram which contributes this coeﬃcient. With both diagrams included, the value of the\n34The order of magnitude of coeﬃcients (but not the alternating signs) were justiﬁed rigorously in [40].\n39\n\ncoeﬃcient changes to 9\nπ(our diagram) + 63ζ(3)\n2π3 (missed diagram) ≈4.086. Analytic values of both\ndiagrams were computed in [42] which reacted to the challenge stated in the previous paragraph.\nWith the coeﬃcient corrected, the perturbative prediction becomes tangent to the numerical one\nat small g; see Fig. 14. We thank Marco Serone, Gabriele Spada and Giovanni Villadoro for their\nmagniﬁcent paper, and for informing us about our mistake.\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\ng\n−1.4\n−1.2\n−1.0\n−0.8\n∆m2/g2\nm = 1, L =10\nren.\nsubl.\nO(g3)\nFigure 14: Comparing perturbative and numerical predictions for the mass after correcting O(g3)\nperturbative coeﬃcients.\nReferences\n[1] M. Hogervorst, S. Rychkov, and B. C. van Rees, “Truncated conformal space approach in d dimensions: A\ncheap alternative to lattice ﬁeld theory?,” Phys. Rev. D91 (2015) 025005, arXiv:1409.1581 [hep-th].\n[2] S. J. Brodsky, H.-C. Pauli, and S. S. Pinsky, “Quantum chromodynamics and other ﬁeld theories on the light\ncone,” Phys.Rept. 301 (1998) 299–486, arXiv:hep-ph/9705477 [hep-ph].\n[3] V. P. Yurov and Al. B. Zamolodchikov, “Truncated Conformal Space Approach to Scaling Lee-Yang Model,”\nInt.J.Mod.Phys. A5 (1990) 3221–3246.\n[4] A. Coser, M. Beria, G. P. Brandino, R. M. Konik, and G. Mussardo, “Truncated Conformal Space Approach\nfor 2D Landau-Ginzburg Theories,” J. Stat. Mech. 1412 (2014) P12010, arXiv:1409.1494 [hep-th].\n[5] D. Lee, N. Salwen, and D. Lee, “The Diagonalization of quantum ﬁeld Hamiltonians,” Phys.Lett. B503 (2001)\n223–235, arXiv:hep-th/0002251 [hep-th].\n[6] D. Lee, N. Salwen, and M. Windoloski, “Introduction to stochastic error correction methods,” Phys.Lett.\nB502 (2001) 329–337, arXiv:hep-lat/0010039 [hep-lat].\n[7] N. Salwen, Non-perturbative methods in modal ﬁeld theory. arXiv:hep-lat/0212035 [hep-lat]. Ph.D. thesis,\nHarvard University, 2001.\n[8] M. Windoloski, A Non-perturbative Study of Three-Dimensional Quartic Scalar Field Theory Using Modal\nField Theory. Ph.D. thesis, University of Massachusetts Amherst, 2000.\n[9] I. Brooks, E.D. and S. C. Frautschi, “Scalars Coupled to Fermions in (1+1)-dimensions,” Z.Phys. C23 (1984)\n263.\n[10] E. Katz, G. M. Tavares, and Y. Xu, “Solving 2D QCD with an adjoint fermion analytically,” JHEP 1405\n(2014) 143, arXiv:1308.4980 [hep-th].\n[11] E. Katz, G. M. Tavares, and Y. Xu, “A solution of 2D QCD at Finite N using a conformal basis,”\narXiv:1405.6727 [hep-th].\n40\n\n[12] S. Chabysheva and J. Hiller, “Basis of symmetric polynomials for many-boson light-front wave functions,”\narXiv:1409.6333 [hep-ph].\n[13] P. Giokas and G. Watts, “The renormalisation group for the truncated conformal space approach on the\ncylinder,” arXiv:1106.2448 [hep-th].\n[14] M. Lencses and G. Takacs, “Excited state TBA and renormalized TCSA in the scaling Potts model,” JHEP\n09 (2014) 052, arXiv:1405.3157 [hep-th].\n[15] S. R. Coleman, “The Quantum Sine-Gordon Equation as the Massive Thirring Model,” Phys.Rev. D11 (1975)\n2088.\n[16] M. Bordag, G. L. Klimchitskaya, U. Mohideen, and V. M. Mostepanenko, “Advances in the Casimir eﬀect,”\nInt. Ser. Monogr. Phys. 145 (2009) 1–768.\n[17] S.-J. Chang, “The Existence of a Second Order Phase Transition in the Two-Dimensional φ4 Field Theory,”\nPhys.Rev. D13 (1976) 2778.\n[18] S. Rychkov and L. G. Vitale, “Hamiltonian truncation study of the φ4 theory in two dimensions. II. The Z2\n-broken phase and the Chang duality,” Phys. Rev. D93 no. 6, (2016) 065014, arXiv:1512.00493 [hep-th].\n[19] A. Zamolodchikov, “Thermodynamic Bethe Ansatz in Relativistic Models. Scaling Three State Potts and\nLee-Yang Models,” Nucl.Phys. B342 (1990) 695–720.\n[20] M. L¨uscher, “Volume Dependence of the Energy Spectrum in Massive Quantum Field Theories. 1. Stable\nParticle States,” Commun.Math.Phys. 104 (1986) 177.\n[21] J. Glimm and A. M. Jaﬀe, Quantum Physics. A Functional Integral Point Of View. Springer, 1987.\n[22] M. L¨uscher, “Volume Dependence of the Energy Spectrum in Massive Quantum Field Theories. 2. Scattering\nStates,” Commun.Math.Phys. 105 (1986) 153–188.\n[23] V. Yurov and Al. B. Zamolodchikov, “Truncated fermionic space approach to the critical 2-D Ising model\nwith magnetic ﬁeld,” Int.J.Mod.Phys. A6 (1991) 4557–4578.\n[24] G. Brandino, R. Konik, and G. Mussardo, “Energy Level Distribution of Perturbed Conformal Field\nTheories,” J.Stat.Mech. 1007 (2010) P07013, arXiv:1004.4844 [cond-mat.stat-mech].\n[25] A. Harindranath and J. Vary, “Stability of the Vacuum in Scalar Field Models in 1 + 1 Dimensions,”\nPhys.Rev. D37 (1988) 1076–1078.\n[26] T. Sugihara, “Density matrix renormalization group in a two-dimensional lambda φ4 Hamiltonian lattice\nmodel,” JHEP 0405 (2004) 007, arXiv:hep-lat/0403008 [hep-lat].\n[27] D. Schaich and W. Loinaz, “An improved lattice measurement of the critical coupling in φ4\n2 theory,”\nPhys.Rev. D79 (2009) 056008, arXiv:0902.0045 [hep-lat].\n[28] A. Milsted, J. Haegeman, and T. J. Osborne, “Matrix product states and variational methods applied to\ncritical quantum ﬁeld theory,” Phys.Rev. D88 (2013) 085030, arXiv:1302.5582 [hep-lat].\n[29] A. Harindranath and J. Vary, “Solving Two-Dimensional φ4 Theory By Discretized Light Front\nQuantization,” Phys.Rev. D36 (1987) 1141–1147.\n[30] B. van de Sande, “Convergence of discretized light cone quantization in the small mass limit,” Phys.Rev. D54\n(1996) 6347–6350, arXiv:hep-ph/9605409 [hep-ph].\n[31] R. M. Konik and Y. Adamov, “Numerical renormalization group for continuum one-dimensional systems,”\nPhys. Rev. Lett. 98 (2007) 147205, arXiv:cond-mat/0701605 [cond-mat.str-el].\n[32] S. R. White, “Density-matrix algorithms for quantum renormalization groups,” Phys. Rev. B 48 (1993) 10345.\n[33] W. Loinaz and R. Willey, “Monte Carlo simulation calculation of critical coupling constant for continuum φ4\nin two-dimensions,” Phys.Rev. D58 (1998) 076003, arXiv:hep-lat/9712008 [hep-lat].\n41\n\n[34] I. Z. Rothstein, “TASI lectures on eﬀective ﬁeld theories,” arXiv:hep-ph/0308266 [hep-ph].\n[35] K. Symanzik, “Continuum Limit and Improved Action in Lattice Theories. 1. Principles and φ4 Theory,”\nNucl.Phys. B226 (1983) 187.\n[36] U. Schollw¨ock, “The density-matrix renormalization group in the age of matrix product states,” Annals of\nPhysics 326 (2011) 96.\n[37] J.-P. Eckmann, J. Magnen, and R. S´en´eor, “Decay properties and Borel summability for the Schwinger\nfunctions in P(φ)2 theories,” Comm. Math. Phys. 39 (1975) 251.\n[38] L. Lipatov, “Divergence of Perturbation Series and Pseudoparticles,” JETP Lett. 25 (1977) 104–107.\n[39] E. Brezin, J. Le Guillou, and J. Zinn-Justin, “Perturbation Theory at Large Order. 1. The φ2N Interaction,”\nPhys.Rev. D15 (1977) 1544–1557.\n[40] S. Breen, “Leading Large Order Asymptotics For (φ4)2 Perturbation Theory,” Commun.Math.Phys. 92 (1983)\n179–194.\n[41] A. Cherman, D. Dorigoni, G. V. Dunne, and M. ¨Unsal, “Resurgence in Quantum Field Theory:\nNonperturbative Eﬀects in the Principal Chiral Model,” Phys.Rev.Lett. 112 no. 2, (2014) 021601,\narXiv:1308.0127 [hep-th].\n[42] M. Serone, G. Spada, and G. Villadoro, “λφ4 Theory I: The Symmetric Phase Beyond NNNNNNNNLO,”\narXiv:1805.05882 [hep-th].\n42\n"
    },
    {
      "arxiv_id": "2505.13030",
      "full_text": "Hamiltonian renormalisation VIII. P(Φ)2 quantum field theory\nM. Rodriguez Zarate1∗, T. Thiemann1†\n1 Inst. for Theor. Phys. III, FAU Erlangen – N¨urnberg,\nStaudtstr. 7, 91058 Erlangen, Germany\nJuly 15, 2025\nAbstract\nIn previous works in this series we focussed on Hamiltonian renormalisation of free field theories in all\nspacetime dimensions. In this paper we address the Hamiltonian renormalisation of the self-interacting scalar\nfield in two spacetime dimensions with polynomial potential, called P(Φ)2. We consider only the finite volume\ncase.\nThe P(Φ)2 theory is one of the few interacting QFT’s that can be rigorously constructed non-perturbatively.\nWe find that our Hamiltonian renormalisation flow finds this theory indeed as a fixed point.\n1\nIntroduction\nConstructing interacting quantum field theories (QFTs) rigorously in four and higher spacetime dimensions remains\none of the most difficult challenges in theoretical and mathematical physics [1]. The difficulties come from the\nfact that quantum fields are operator valued distributions which means that products thereof as they appear\ntypically in Hamiltonians are a priori ill-defined, being plagued by both short distance (UV) and large distance (IR)\ndivergences. In the constructive QFT (CQFT) approach [2] one tames both types of divergences by introducing\nboth UV (M) and IR cut-offs (R) to the effect that only a finite number of degrees survive at finite M, R.\nFor instance, R could be a compactification radius and M a lattice spacing. Then at finite M, R one is in the\nsafe realm of quantum mechanics. The problem is then how to remove the cut-offs. Usually one removes first\nM (continuum limit) and then R (thermodynamic limit). In this process the parameters (coupling constants)\nare taken to be cut-off dependent and they are tuned or renormalised in such a way that the limiting theory is\nwell-defined when possible.\nNon-perturbative renormalisation in CQFT (not to be confused with renormalisation in the perturbative\napproach to QFT) has a long tradition [3] and comes in both the functional integral language and the Hamiltonian\nlanguage (see e.g. [4] and references therein). Focussing on UV cut-off removal, we consider quantum mechanical\nsystems labelled by the cut-off M. If these quantum mechanical systems all descend form a well-defined continuum\ntheory, then in the functional integral approach one obtains the theory at resolution M by integrating out all\ndegrees of freedom referring to higher resolution while in the Hamiltonian approach one projects those out. This\nin particular implies that if one takes the quantum mechanical theory at resolution M′ and integrates or projects\nout the degrees of freedom at resolutions between M < M′ and M′ one obtains the quantum mechanical theory\nat resolution M. Vice versa, when this necessary set of consistency conditions is met, this typically also is\nsufficient to define a continuum theory.\nThe family of theories that one starts with, are constructed making various choices such as representations,\nfactor orderings, discretisation errors, etc. and the afore mentioned consistency conditions are generically violated.\nHowever, one can define a sequence of such quantum mechanical theory families by defining a new theory at\nresolution M by integrating/projecting out the degrees of freedom between M and M′(M) of the old theory at\n∗melissa.rodriguez@gravity.fau.de\n†thomas.thiemann@gravity.fau.de\n1\narXiv:2505.13030v2  [hep-th]  13 Jul 2025\n\nresolution M′(M) > M where M′ : M 7→M′(M) is a fixed function on the set of resolution scales. Such a\nprocess is called a block spin transformation or coarse graining operation which typically leads to a renormalisation\nof the coupling constants. At a fixed point of this renormalisation flow of theories the consistency condition is\nenforced by construction and therefore fixed points qualify as continuum theories.\nIn previous parts of this series we have considered a Hamiltonian projection scheme [5, 4] which is motivated\nby the functional integral approach via Osterwalder-Schrader reconstruction. It was then applied to free QFT in\nMinkowski space [6, 7, 8, 9, 10] in any dimension and parametrised QFT [11] in 2d which shares some features\nwith the free bosonic string. In all those cases the fixed point of the flow could be computed and was shown\nto coincide with the known continuum theory. In the present paper for the first time we expose the formalism\nto interacting quantum field theory (QFT), specifically to the self-interacting scalar quantum field theory in two\nspacetime dimensions with polynomial potential, called P(Φ)2 theory [12]. We focus on the UV part of the\nrenormalisation and thus consider the cylinder spacetime R × [0, R) with periodic boundary conditions where\nthe circumference 2π R of the circle is fixed. Once the theory is constructed at finite R the thermodynamic\nlimit R →∞is taken by the methods described in [12] and references therein should one be interested on the\nspacetime R2.\nThis work is organised as follows:\nIn section 2 we introduce the classical and quantum P(Φ)2 model on the cylinder. Its quantum theory is well\ndefined in the Fock representation selected by the free part of its Hamiltonian no matter what the polynomial\ndegree of its potential is, even if it is not bounded from below, as long as the potential is normal ordered\nwith respect to the same Fock structure. An elementary proof of this astonishing fact unique to two spacetime\ndimensions is provided in appendix A.\nIn section 3 we introduce the Hamiltonian renormalisation of this model.\nWe pick the Dirichlet kernel\n[14] to define the block spin transformation mentioned above. An account of Dirichlet kernel renormalisation\ntechniques, which are closely related to wavelet theory [13], may be found in appendix B. The Dirichlet kernel is\na compromise between position locality and momentum decay properties, in particular it is smooth and therefore\nhas advantages over the often chosen Schwarz kernel. The Schwarz kernel has better position locality properties\nbut it has distributional derivatives which are potentially problematic with respect to treating the necessarily\noccurring field derivatives.\nIn section 4 we derive the flow of the model and show that its fixed point at finite resolution coincides with\nblocking from the known continuum QFT reviewed in section 2.\nIn section 5 we summarise and conclude.\n2\nClassical and quantum P(Φ)2 on the cylinder\nIn the first subsection we introduce the classical P(Φ)2 theory and in the second we show that its normal ordered\nself-interacting Hamiltonian is a densely defined, symmetric operator in the Fock representation selected by its\nfree part.\n2.1\nClassical P(Φ)2 on the cylinder\nWe consider the cylinder spacetime manifold R × [0, R) where R is any finite, fixed circumference of the circle.\nFor convenience we pass from dimensionful coordinates (c s, y) on that spacetime to dimensionless coordinates\nX = (t = c s\nR , x = y\nR) so that x ∈[0, 1) with endpoints identified. Then the classical action can be rewritten as\nS[Φ] =\nZ\nR\ndt\nZ 1\n0\ndx {1\n2[[ ˙Φ]2 −[Φ′]2 −p2Φ2] −P(Φ)}(X) =:\nZ\nR×[0,1)\nd2 L(Φ(x), Φ′(x), ˙Φ(X)),\n(2.1)\nwhere p is the mass, ˙(.) = ∂t(.), (.)′ = ∂x(.) and\nP(Φ) =\nN\nX\nk=0\ngk Φk,\n(2.2)\n2\n\nis any finite polynomial in the fields, i.e. a finite linear combination of powers Φk, k = 0, .., N with real-valued,\ndimensionless coefficients gk called coupling constants. We assume that whatever the value of g2 is, we have\np2 = [M R]2 > 0 where M is the dimensional mass. This can always be achieved by redefining g2 and is done\nin order to avoid the special treatment of zero modes. We take Φ dimension free and have dropped a constant\npre-factor from the action that has the dimension of an action. The spacetime field Φ is subject to periodic\nboundary conditions Φ(t, 0) = Φ(t, 1) for all t ∈R. Therefore in all that follows we never have to worry about\nboundary terms when integrating by parts w.r.t. x.\nThe Hamiltonian formulation is straightforward: The real valued time zero field ϕ(x) := Φ(0, x) has the real\nvalued conjugate momentum π(x) = [∂tΦ](0, x) which obey the canonical Poisson brackets\n{ϕ(x), ϕ(y)} = {π(x), π(y)} = 0, {π(x), ϕ(y)} = δ(x, y),\n(2.3)\nwhere δ(x, y) is the periodic delta distribution (see e.g. appendix B) and the Hamiltonian is obtained by the\nLegendre transformation\nh[ϕ, π] = extru {\nZ 1\n0\ndx [π(x) u(x) −L(ϕ(x), ϕ′(x), u(x))]} =\nZ 1\n0\ndx {1\n2[π2 + [ϕ′]2 + p2ϕ2] + P(ϕ)}(x). (2.4)\n2.2\nQuantum P(Φ)2 on the cylinder\nThe structure of the Hamiltonian (2.4) suggests the natural split\nh = h0 + v, h0 =\nZ 1\n0\ndx {1\n2[π2 + ϕ ω2 · ϕ}(x), v =\nZ 1\n0\ndx P(ϕ(x)),\n(2.5)\nwhere\nω2 := p2 −∆, ∆= ∂2\nx\n(2.6)\nis a self-adjoint operator on the one particle Hilbert space\nL = L2([0, 1), dx),\n(2.7)\nwith pure point spectrum ˆω2\nn = p2 + [2πi n]2, n ∈Z. The corresponding eigenfunctions are en(x) = e2π i n x\nwhich define an orthonormal basis of L. For obvious reasons, h0, v are called the free part and interacting part\nrespectively.\nWe define the unital Weyl ∗−algebra A in the usual way via its generating Weyl elements w[f] = exp(i <\nf, ϕ >L), w[g] = exp(i < g, π >L) for real valued f, g ∈L that are subject to the Weyl relations\nw[g] w[f] w[−g] = e−i <g,f>L w[f], w[f] w[f′] = w[f+f′], w[g] w[g′] = w[g+g′], w[f]∗= w[−f], w[g]∗= w[−g].\n(2.8)\nWe define a cyclic Fock representation (ρ, H, Ω) of A from the Fock state1 ωF\nωF (w[f] w[g]) := e\ni\n2 <f,g>L e−1\n4 [<f,ω−1·f>L+<g,ω·g>L].\n(2.9)\nvia the GNS construction. It is not difficult to show that (2.9) is unitarily equivalent to defining annihilation\noperator valued distributions corresponding to the algebra element\na(x) :=\n1\n√\n2[ω1/2 · ϕ −iω−1/2 · π](x),\n(2.10)\nso that ρ(a(x))Ω= 0 and everything else follows from the commutation relations of which the non-vanishing\nones are\n[a(x), a∗(y)] = δ(x, y).\n(2.11)\n1Note that the symbol ω is reserved for both the covariance operator and the Fock state introduced in eq. (2.9); to distinguish\nthe latter, it is denoted with a subscript F. In contrast, the letters w and W are used exclusively to denote Weyl elements.\n3\n\nThe linear span D of the Fock vector states ψf1,..,fn := ρ(< f1, a >∗)..ρ(< fn, a >∗)Ωfor f1, .., fn ∈L together\nwith Ωis dense in the Fock representation space H. The number n is called the particle number of the Fock\nvector where we assign n = 0 to the vacuum Ωvoid of particles. We will in fact consider D corresponding to\nf1, .., fn ∈L0 where L0 is the span of the functions en. This D is still dense and has the advantage that finite\nproducts of functions in L0 are still in L0.\nWe use capital letters in order to denote the operator representatives of algebra elements, e.g.\nA(x) =\nρ(a(x)), A†(x) = ρ(a∗(x)). We use this Fock structure in order to define both H0 and V by their normal\nordered symbols\nH0\n:=\nρ(h0) =\nZ 1\n0\ndx A†(x) [ω · A](x), V =\nN\nX\nk=0\ngkVk,\nVk\n:=\nρ(vk) = 2−k/2\nk\nX\nl=0\nÅ k\nl\nã\nVk(l),\nVk(l)\n:=\nZ 1\n0\ndx {[ω−1/2 · A†](x)}k−l [ω−1/2 · A](x)}l.\n(2.12)\nBy construction, D is an invariant, dense domain of H0. The astonishing fact, unique to two spacetime dimensions,\nwhen m > 0 and only when the spacetime is spatially compact, is that D is also a dense domain for V , albeit no\nlonger an invariant one when gk ̸= 0 for at least one of k = 2, .., N. We give an elementary proof in appendix A.\n3\nHamiltonian renormalisation of P(Φ)2\nAn account of the version of Hamiltonian renormalisation used below and employing the Dirichlet kernel can be\nfound in appendix B, see [4, 5] for its motivation. Furthermore, in the following sections we adopt the notation\nintroduced in appendix B: capital letters such as F, G denote functions in L; capital letters with a subscript M,\nsuch as FM, GM, refer to functions in LM; and lowercase letters with a subscript M, such as fM, gM, denote\nfunctions in lM. Elements of the abstract algebra are still written in lowercase, while their representatives (after\nGNS construction) are denoted by capital letters.\nThe starting point of the renormalisation scheme is to provide a family of theories (ρ(0)\nM , H(0)\nM , Ω(0)\nM , H(0)\nM )\nconsisting of a Hilbert space H(0)\nM with cyclic vector Ω(0)\nM that carries a representation ρ(0)\nM of some ∗−algebra\nAM and a Hamiltonian operator H(0)\nM densely defined on some subspace D(0)\nM of H(0)\nM . Equivalently, we consider\na state ω(0)\nM,F on AM for which (ρ(0)\nM , H(0)\nM , Ω(0)\nM ) are its GNS data. The objects A(0)\nM and H(0)\nM are to be thought\nof as discretised versions of the continuum objects A and H. The label M is in general taken from a partially\nordered and directed index set O that describes the (location, momentum, energy,..) resolution at which we\nprobe the theory. In the present case the central tool is the Dirichlet kernel\nPM(x, y) =\nX\nn∈ZM\nen(x −y), ZM = {n ∈Z; |n| ≤M −1\n2\n},\n(3.1)\nwhich can be considered as a tamed version of the δ distribution on the circle. The index set is taken to be the\nset of odd naturals with ordering relation M < M′ iff M′/M ∈O. The Dirichlet kernel can be considered as\nan orthogonal projection PM in L with image LM. We define the Weyl algebra AM in analogy to (2.8) as the\nabstract ∗−algebra generated by the Weyl elements wM[FM], wM[GM] with real valued FM, GM ∈LM subject\nto the relations\nwM[GM] wM[FM] wM[−GM] = e−i<GM,FM>LM wM[FM], wM[FM] wM[F ′\nM] = wM[FM + F ′\nM],\nwM[GM] wM[G′\nM] = wM[GM + G′\nM], wM[FM]∗= wM[−FM], wM[GM]∗= wM[−GM],\n(3.2)\nwhere the scalar product on the finite resolution 1-particle Hilbert space LM coincides with the one on L. The\nstate ω(0)\nM,F is chosen to be in analogy to (2.9) as the Fock state\nω(0)\nF,M(wM[FM] wM[GM]) = e\ni\n2 <FM,GM>LM e−1\n4 [<FM,[ω(0)\nM ]−1·FM>LM +<GM,[ω(0)\nM ] ·GM>LM ],\n(3.3)\n4\n\nwhich requires as a central input the definition of the kernel ω(0)\nM on LM. Note that the unfortunate doubling\nof symbols ω for both an algebraic state and a kernel on the 1-particle Hilbert space is resolved by attaching an\nextra index “F” to the state to indicate “Fock”. To motivate the choice of ω(0)\nM we follow the general prescription\nof appendix B and define hM as a quantisation of\nhM[ϕM, πM] := h[ϕM, πM], ϕM = PM · ϕ, πM = PM · π,\n(3.4)\nwhere h is the classical continuum Hamiltonian (2.5). For its free part we find\nh0,M = 1\n2\nZ 1\n0\ndx [πM(x)2 + [∂xϕM(x)]2 + p2 ϕM(x)2]\n= 1\n2[< πM, πM >LM + < ∂ϕM, ∂ϕM >LM + p2 < ϕM, ϕM >LM ].\n(3.5)\nIntegrating the derivative term by parts (note that PM preserves the space of periodic L2 functions) we obtain\nh0,M = 1\n2[< πM, πM >LM −< ϕM, ∆M · ϕM >LM + p2 < ϕM, ϕM >LM ],\n(3.6)\nwith the Laplacian\n∆M := ∂2\nM, ∂M = PM · ∂· PM.\n(3.7)\nWe have used the projection property PM · PM = PM of the Dirichlet kernel to obtain (3.7). The specific form\nof h0,M suggests a Fock quantisation with annihilators\naM(x) = 2−1/2[[ωM]1/2 · ϕM −i [ωM]−1/2 · πM](x),\n[ωM]2 = p2 1M −∆M,\n(3.8)\nwhich obey non-trivial commutation relations\n[aM(x), aM(y)∗] = PM(x, y),\n(3.9)\nif one defines the Poisson brackets between ϕM, πM as the result of considering these as functions on the\ncontinuum phase space and using the continuum Poisson bracket\n{πM(x), ϕM(y)} :=\nZ\ndu\nZ\ndvPM(x, u) PM(y, v) {π(u), ϕ(v)} = PM(x, y).\n(3.10)\nThen we see that (3.3) and (3.8) match provided that we interpret wM[FM] = ei<FM,ϕM>LM , wM[GM] =\nei<GM,πM>LM .\nWe can finish the initialisation of the Hamiltonian renormalisation flow by defining\nH(0)\nM = H(0)\n0,M+V (0)\nM , H(0)\n0,M =\nZ 1\n0\ndx A†\nM(x) [ω(0)\nM ·AM](x), VM =\nZ 1\n0\ndx : V ([[2ω(0)\nM ]−1/2·[AM+A†\nM]](x)) :M,\n(3.11)\nwhere AM is the operator representative of aM and : . :M denotes normal ordering of the AM, A†\nM.\n4\nHamiltonian renormalisation flow of P(Φ)2\nIn the first subsection we block the theory from the continuum in order to determine which fixed point family the\nrenormalisation flow should find. In the second subsection, we use projector maps PM -as defined in appendix B-,\nto project from L to the LM subspaces and then compute the renormalisation flow. In the last subsection we\ndiscretise the fields, worked in the lM spaces of square summable sequences and compute the renormalisation\nflow. In the two frameworks we show that the renormalisation flow of the initial family defined in the previous\nsection is already at its fixed point. The reason for displaying the strictly equivalent flows in terms of projections\nand discretisations respectively is that the former is in the spirit of renormalisation schemes outside a lattice\ncontext while the former emphasises the traditional real space block spin interpretation of the renormalisation\nflow.\n5\n\n4.1\nBlocking from the continuum\nBlocking from the continuum means to define a state ωF,M and a Hamiltonian HM out of the continuum state\nωF and Hamiltonian H defined in section 2 via the formulas\nωF,M(wM[FM] wM[GM]) := ωF (w[FM] w[GM]),\n< WM[FM]ΩM, HMWM[GM] >HM :=< W[FM]Ω, H W[GM]Ω>H\n(4.1)\nwhere (ρM, HM, ΩM) and (ρ, H, Ω) are the GNS data of ωF,M and ωF respectively and we have denoted the\noperator representatives by capital letters, i.e. WM[FM] = ρM(wM[FM]) and W[F] = ρ(w[F]). On the right\nhand side of (4.1) the elements FM, GM ∈LM are to be considered as elements of the continuum 1-particle\nHilbert space L by trivial embedding FM 7→F.\nWe start with the first line of (4.1) and use (2.9)\nωF (w[FM] w[GM]) := e\ni\n2 <FM,GM>L e−1\n4 [<FM,ω−1·FM>L+<GM,ω·GM>L].\n(4.2)\nWe have explicitly with ˆωn =\np\np2 + [2πn]2 using a resolution of identity with respect to the ONB en of L\n< FM, ω−1 · F ′\nM >L=\nX\nn∈Z\n< FM, ω−1 en >L < en, F ′\nM >L=\nX\nn∈Z\nˆω−1\nn\n< FM, en >L < en, F ′\nM >L\n=\nX\nn∈ZM\nˆω−1\nn\n< FM, en >LM < en, F ′\nM >LM =:< FM, ω−1\nM · F ′\nM >LM ,\n(4.3)\nwhere we used that FM, F ′\nM are orthogonal to the en, n ̸∈ZM. To interpret the operator ωM on LM we\nexplicitly compute\n∂M · FM =\nX\nn∈ZM\nen < en, ∂M · FM >LM =\nX\nn∈ZM\nen < en, ∂· FM >LM\n=\n−\nX\nn∈ZM\nen < ∂· en, FM >LM =\nX\nn∈ZM\n[2πin] en < en, FM >LM ,\n(4.4)\nhence\n[p2 −∆M] · FM =\nX\nn∈ZM\nˆω2\nn en < en, FM >LM .\n(4.5)\nIt follows that ωM =\np\np2 −∆M which is in fact identical to the natural choice ω(0)\nM of section 3 used to define\nthe initial family of states. Concluding we find that ωF,M coincides with ω(0)\nF,M defined in (3.3).\nConsidering the second line of (4.1) we use the elementary identity\nA(x) W[F] = W[F] W[F]−1 A(x) W[F] = W[F] (A(x) −i[< [2ω]−1/2 · F, A + A† >L, A(x)])\n=\nW[F] (A(x) + i([2ω]−1/2 · F)(x)1HM ),\n(4.6)\nto find for the free part\n< W[FM]Ω, H0 W[F ′\nM]Ω>H=\nZ\ndx\nZ\ndy ω(x, y) < A(x) W[FM]Ω, A(y) W[F ′\nM] Ω>H\n=\nZ\ndx\nZ\ndy ω(x, y) ([2ω]−1/2 · FM)(x) ([2ω]−1/2 · F ′\nM)(y) < W[FM]Ω, W[F ′\nM] Ω>H\n=\n1\n2 < ω−1/2 · FM, ω · ω−1/2 · F ′\nM >L < WM[FM]ΩM, WM[F ′\nM]ΩM >HM\n=\n1\n2 < FM, F ′\nM >LM < WM[FM]ΩM, WM[F ′\nM]ΩM >HM ,\n(4.7)\nwhere ω(x, y) = P\nn∈Z ˆωnen(x −y) is the integral kernel of ω and in the step before the last one we used that\nwe already know that the GNS data of ωF,M are those of ω(0)\nF,M. Accordingly HM = H(0)\nM defined in (3.11). For\n6\n\nthe interacting part it suffices to consider a field monomial of order k\nVk\n=\nZ\ndx : {([2ω]−1/2 · [A + A†])(x)}k :=\nk\nX\nl=0\nÅ k\nl\nã\n2−k/2 Vk(l),\nVk(l)\n=\nZ\ndx ([ω−1/2 · A]†(x)])k−l (ω−1/2 · A](x)])l.\n(4.8)\nUsing (4.6) it follows\n< W[FM]Ω, Vk(l) W[F ′\nM]Ω>H= il−(k−l)\nZ\ndx ([ω−1/2 · FM](x))k−l ([ω−1/2 · F ′\nM](x))l ×\n< W[FM]Ω, W[F ′\nM] Ω>H\n= il−(k−l)\nZ\ndx ([ω−1/2\nM\n· FM](x))k−l ([ω−1/2\nM\n· F ′\nM](x))l < WM[FM]ΩM, WM[F ′\nM] ΩM >HM\n=< WM[FM]ΩM, [Vk(l)]M WM[F ′\nM]ΩM >HM ,\n(4.9)\nwhere\n[Vk(l)]M =\nZ\ndx ([ω−1/2\nM\n· AM]†(x)])k−l (ω−1/2\nM\n· AM](x)])l.\n(4.10)\nIt follows that the initial family defined in section 3 coincides with the family blocked from the continuum. The\nreason for this is simply the identity\nω · PM = PM · ωM,\n(4.11)\nwhich is due to the fact that the derivative operator ∂preserves the subspace LM. This particular feature of the\nDirichlet kernel is not shared by most other kernels such as the Schwarz kernel and in that case the initial family\nof section 3 does not coincide with the family blocked from the continuum of section 4.1 even for free theories,\nsee [5, 6, 7, 8].\n4.2\nRenormalisation flow in terms of the projected fields\nBy definition, for M < M′ we consider the trivial embedding LM →LM′; FM 7→FM′ which is possible because\nthe LM are nested subspaces of L. Then the analog of (4.1) is given by\nω(n+1)\nF,M (wM[FM] wM[GM]) := ω(n)\nF,M′(wM′[FM] wM′[GM]),\n< WM[FM]Ω(n+1)\nM\n, H(n+1)\nM\nWM[F ′\nM]Ω(n+1)\nM\n>H(n+1)\nM\n:=< WM′[FM]Ω(n)\nM′, H(n)\nM′ WM′[F ′\nM]Ω(n)\nM′ >H(n)\nM′,\n(4.12)\nwhere (ρ(n+1)\nM\n, H(n+1)\nM\n, Ω(n+1)\nM\n) and (ρ(n)\nM′, H(n)\nM′, Ω(n)\nM′) are the GNS data of ω(n+1)\nF,M\nand ω(n)\nF,M′ respectively and\nwe have denoted the operator representatives by capital letters, i.e.\nW (n+1)\nM\n[FM] = ρ(n+1)\nM\n(wM[FM]) and\nWM′[FM′] = ρ(n)\nM′(wM′[FM′]). On the right hand side of (4.12) the elements FM, GM, F ′\nM are to be considered\nas elements of the continuum 1-particle Hilbert space LM′ by trivial embedding FM 7→FM.\nGoing through literally the same steps as in section 4.1, we find that the flow is trivial: ω(n)\nF,M = ω(0)\nF,M =\nω∗\nF,M = ωF,M and H(n)\nM = H(0)\nM = H∗\nM = HM, that is, every sequence element of the family coincides with the\ninitial element which is also the element blocked from the continuum and thus the fixed point element. This is\nagain due to (for M′ > M)\nωM′ · PM = PM · ωM.\n(4.13)\n4.3\nRenormalisation flow in terms of discretised fields\nIn order to test the version of Hamiltonian renormalisation method described in this series of papers less trivially\nfor the solvable and self-interacting P(Φ)2 theory, one therefore should use an initial family which deviates from\nthe natural choice of section 3. For example instead of the position non-local momentum ONB en of LM, n ∈ZM\n7\n\none may use the position quasi-local ONB χM\nm , m ∈NM = {0, 1, .., M −1} of LM constructed in appendix B,\nsee (B.7), (B.8). Indeed we can alternatively write (4.10) as\n[Vk(l)]M = M−k\nX\nm1,..,mk∈NM\ngM;m1,m2,..,mk\nk−l\nY\ns=1\n[ω−1\nM · AM]∗(ms)\nk\nY\ns=k−l+1\n[ω−1\nM · AM](ms),\n(4.14)\nwhere the ”coupling constant” is given by\ngM;m1,m2,..,mk =\nZ 1\n0\ndx\nk\nY\ns=1\nχM\nms(x) =\nX\n|n1|,..,|nk|≤(M−1)/2\nδn1+..+nk=0\nk\nY\ns=1\ne2πinkxM\nms\n=\nX\n|n1|,..,|nk−1|,|n1+..+nk−1|≤(M−1)/2\nk−1\nY\ns=1\ne2πink(xM\nms−xM\nmk)\n(4.15)\nwith xM\nm = m/M. If it was not for the constraint |n1 + .. + nk−1| ≤(M −1)/2 this would collapse to\nk−1\nY\ns=1\nχM\nms(xM\nmk) = Mk−1\nk−1\nY\ns=1\nδms,mk\n(4.16)\nand we have\n[ω−1/2\nM\n· AM](m) =< χM\nm , ω−1/2\nM\n· AM >LM =< χM\nm , ω−1/2A >LM ,\n(4.17)\nbecause χM\nm ∈LM and due to (4.11). Then (4.14) could be considered as the k−fold Riemann sum of the\ncoupling constant times the displayed polynomial of discretised annihilation and creation operators as ϵM =\nxM\nm+1 −xM\nm = M−1.\nHowever, due to the constraint the coupling constant (4.15) is only quasi-local and it is for (4.15) that the\nflow is at its fixed point and not for (4.16). But one could start from the naive guess (4.16)\ng(0)\nM;m1,m2,..,mk = Mk−1\nk−1\nY\ns=1\nδms,mk,\n(4.18)\nand then run the renormalisation flow. Already after the first iterations step one finds that the form (4.18) is not\npreserved and that g(1)\nM;m1,m2,..,mk takes a more general form. Starting from this more general form one sees that\n(4.15) is a fixed point of the corresponding renormalisation flow equation.\nIn more detail, we make the general Ansatz\n[V (r)\nk\n(l)]M = M−k\nX\nm1,..,mk∈NM\ng(r)\nM;m1,m2,..,mk\nk−l\nY\ns=1\n[ω−1\nM · AM]∗(ms)\nk\nY\ns=k−l+1\n[ω−1\nM · AM](ms),\n(4.19)\nfor the r-th renormalisation step with initial condition (4.18). Then due to ω−1\n3M IM3M = IM3M ω−1\n3M sandwiching\n[V (r)\nk\n(l)]3M between states of the form w3M[IM3MfM]Ω3M and requiring this to be [V (r+1)\nk\n(l)]M we see that we\nobtain\n[V (r+1)\nk\n(l)]M = (3M)−k\nX\nm′\n1,..,m′\nk∈N3M\ng(r)\n3M;m′\n1,m′\n2,..,m′\nk\nk−l\nY\ns=1\n[IM3Mω−1\nM ·AM]∗(m′\ns)\nk\nY\ns=k−l+1\n[IM3Mω−1\nM ·AM](m′\ns),\n(4.20)\nwhich produces the flow equation\ng(r+1)\nM;m1,..,mk = 3−k\nX\nm′\n1,..,m′\nk\n[\nk\nY\ns=1\nIM3M(m′\ns, ms)] g(r)\n3M;m′\n1,..,m′\nk\n(4.21)\n8\n\nIt is easy to see that (4.21) has (4.15) as a fixed point because\nX\nm′\nIM3M(m′, m) χ3M\nm′ (x) = M−1 X\nm′\n< χ3M\nm′ , χM\nm > χ3M\nm′ (x) = 3(P3MχM\nm )(x) = 3χM\nm (x)\n(4.22)\nwhere completeness P\nm χM\nm (x)χM\nm (y) = M PM(x, y) and χM\nm ∈LM ⊂L3M was used.\nWe now use (4.16) as initial condition for the flow defined by (4.21). We need for m′ ∈N3M, m ∈NM, n′ ∈\nZ3M, n ∈ZM\n< χ3M\nm′ , χM\nm >=\nX\nn,n′\ne2πi [n′ x3M\nm′ −n xM\nm ] < e2πn′·, e2πin· =\nX\nn\ne2πi n[x3M\nm′ −n xM\nm ]\n(4.23)\nsince ZM ⊂ZM′. Thus explicitly\ng(1)\nM;m1,..,mk =\n1\n(3M)k\nX\nm′∈Nk\n3M\nk\nY\ns=1\n< χ3M\nm′s , χM\nms > g(0)\n3M;m′\n1,..,m′\nk\n=\n1\n3M\nX\nm′∈N3M\nk\nY\ns=1\n< χ3M\nm′ , χM\nms >\n=\n1\n3M\nX\nn∈Zk\nM\nX\nm′∈N3M\nk\nY\ns=1\ne2πi ns[x3M\nm′ −xM\nms]\n=\nX\nn∈Zk\nM\n[\nk\nY\ns=1\ne−2πi ns xM\nms]] δn1+..+nk,0 (mod 3M)\n(4.24)\nwhere in the last step we took care of the fact that summing over m′ ∈N3M′ produces 3M when n1 + .. + nk\nis an integer multiple of 3M and zero else. Comparing with (4.15) we see that the difference between the two\nexpressions consists in the modulo 3M support of the Kronecker symbol because we can relabel ns →−ns as\nboth sums are over the reflection invariant domain ZM.\nAt the next iteration step we find\ng(2)\nM;m1,..,mk =\n1\n(3M)k\nX\nm′∈Nk\n3M\nk\nY\ns=1\n< χ3M\nm′s , χM\nms > g(1)\n3M;m′\n1,..,m′\nk\n=\n1\n(3M)k\nX\nn′∈Zk\n3M\nX\nm′∈Nk\n3M\n[\nk\nY\ns=1\n< χ3M\nm′s , χM\nms > e\n−2πi n′\ns x3M\nm′s ]] δn′\n1+..+n′\nk,0 (mod 3 (3M))\n=\n1\n(3M)k\nX\nn′∈Zk\n3M\nX\nn∈Zk\nM\nX\nm′∈Nk\n3M\n[\nk\nY\ns=1\ne−2πinsxM\nm e\n2πi (ns−n′\ns) x3M\nm′s ]] δn′\n1+..+n′\nk,0 (mod 32 M)\n=\nX\nn′∈Zk\n3M\nX\nn∈Zk\nM\n[\nk\nY\ns=1\ne−2πinsxM\nm δns,n′s] δn′\n1+..+n′\nk,0 (mod 32 M)\n=\nX\nn∈Zk\nM\n[\nk\nY\ns=1\ne−2πinsxM\nm ] δn1+..+nk,0 (mod 32 M)\n(4.25)\nwhere we used that δn′−n,0 (mod3M) = δn′−n,0 as |n′ −n| ≤3M−1+M−1\n2\n< 2M < 3M i.e. the modulo operation\ncan be dropped. We see that in the second iteration step the only change that happened compared to the first\nis that the modulo operation is now with respect to 32M rather than 31M.\n9\n\nIterating (formally one proceeds by induction) we find explicitly for r ≥1\ng(r)\nM;m1,..,mk =\nX\nn∈Zk\nM\n[\nk\nY\ns=1\ne−2πinsxM\nm ] δn1+..+nk,0 (mod 3r M)\n(4.26)\nNow |n1 + .. + nk| ≤k(M −1)/2. For fixed resolution M, the number of steps r required such that the modulo\noperation can be dropped is when that estimate is lower than the smallest possible nonzero integer multiple of\n3rM i.e. k(M −1)/2 < 3r M i.e. 3r > k M−1\n2M . Thus independently of M for a polynomial potential of degree\nk we need at most rk := 1 + [ln(k/2)\nln(3) ] renormalisation steps until g(r)\nM;m1,..,mk = gM;m1,..,mk for all r ≥rk where\n[.] denotes the Gauss bracket. Note that this quick convergence of the flow would not occur had we not defined\nω2\nM = p2 −∆M, ∆M = ∂2\nM, ∂M = I†\nM∂IM but instead had replaced ∂M by some of the more common discrete\nlattice derivatives (e.g. forward derivative (∂+\nMfM)(m) = M[fM(m+1)−fM(m)]) because then the intertwining\nproperty IM3M · ∂M = ∂3M · IM3M would not hold.\nWe end this section by illustrating graphically the degree of non-locality of the fixed point coupling (4.15)\nfor the case k = 3. Explicitly we consider\nfM(y1, y2) := M−2\nX\n|n1|,|n2|,|n1+n2|<(M−1)/2\ne2 i(n1 y1+n2 y2)\n(4.27)\nwhich yields\nf(y1 = π[xM\nm1 −xM\nm3], y2 = π[xM\nm2 −xM\nm3]) = M−2 gM;m1,m2,m3\n(4.28)\nwhich we expect to be a quasi-local version of δm1,m3 δm2,m3. The sums in (4.27) can be computed in closed\nform using the geometric series summation formula PN−1\nn=0 zn = (zN −1)/(z −1). We subdivide the summation\ndomain into the three sets\n{n1 = {1, .., M −1\n2\n}, n2 = {−M −1\n2\n, .., M −1\n2\n−n1}}\n∪\n{n1 = {−1, .., −M −1\n2\n}, n2 = {−M −1\n2\n−n1, .., M −1\n2\n}}\n∪\n{n1 = {0}, n2 = {−M −1\n2\n, .., M −1\n2\n}}\n(4.29)\nOne finds\nf(y1, y2) =\n1\n2 M2 {cos(M(y1 −y2))\nsin(y1) sin(y2)\n+\ncos(My2)\nsin(y1) sin(y1 −y2) −\ncos(My1)\nsin(y2) sin(y1 −y2)}\n(4.30)\nDespite its appearance, this function is everywhere smooth and bounded. Using zj = xk −xl, ϵjkl = 1 with\ny1 = x1 −x3, y2 = x2 −x3 one can write this in the manifestly permutation invariant form\nf(z1, z2, z3) = −\n1\n2 M2 {\ncos(M z1)\nsin(z2) sin(z3) +\ncos(M z2)\nsin(z3) sin(z1) +\ncos(M z3)\nsin(z1) sin(z2)}\n(4.31)\nnoticing the identity z1 + z2 + z3 = 0 which displays the totally symmetric, smooth and bounded form (4.15) of\nthis function. For any zj = 0 ⇒zk = −zl = z, ϵjkl = 1 it reduces to\n˜f(z) =\n1\n2 M2 sin2(z) {M sin(M z) sin(z) + 1 −cos(M z) cos(z)}\n(4.32)\nas one can confirm by using de l’Hospital’s theorem.\nUsing de l’Hospital’s theorem one more time when\ntaking z →0 one can explicitly check that the maximum of this function is given not by unity but by\nf(0, 0) = ˜f(0) = 3\n4 +\n1\n4M2 corresponding to the fact that the constraints |n1 + n2| ≤(M −1)/2 on n1, n2\nroughly delete one quarter of the unconstrained M2 points. Away from the maximum the function is of order\nM−2 at a generic lattice point while it is of order M−1 on one of the coordinate axes and on the diagonal y1 = y2\n10\n\n(these are precisely the points zj = 0, j = 1, 2, 3) but well away from the origin. This can be seen analytically\nnoticing that cos(M zj) = (−1)mk−ml, ϵjkl = 1 while sin(M zj) = 0. Accordingly if all mj −mk are of the\norder (M −1)/2 the sin functions in the denominator of f are close to unity. If on the other hand say m2 = m3\ncorresponding to z1 = y2 = 0, −z := z3 = −z2 = π(m1 −m2)/M =: m/M one finds ˜f(z) = 1−(−1)m cos(mπ/M)\n2 M2 sin2(mπ/M)\nwhich for m odd exceeds\n1\n2 M2 sin2(mπ/M) and for large M decreases quasi continuously from approximatively\n[2π2]−1 to [2M2]−1 between m = 1 and m = (M −1)/2. It is of order π/(2M) for m ≈\np\nM/π which is well\naway from the vicinity of the origin but for large M is outside of approximately the fraction\n√\nM/M = 1/\n√\nM\nof the available points.\nIn figures 1, 2, 3 we illustrate this quasi-locality graphically for a few fixed resolutions M = 11, 21, 51, 71, 111\nwhere we pick m3 = 5, 10, 25, 35, 55 respectively while m1, m2 ∈NM take full range. We computed the\nquasi-local coupling at the exact lattice points and then let Mathematica interpolate between those values. One\nsees the effect that the maximum ≈0.75 becomes more pronounced and concentrated as the resolution increases\nwhile the function continues to display non-trivial oscillations in the vicinity of the maximum and along the\ncoordinate axes and the diagonal.\n(a)\nFigure 1: Left: Coupling for M = 11 and m3 = 5. Right: Coupling for M = 21 and m3 = 10.\n11\n\n(a)\nFigure 2: Left: Coupling for M = 51 and m3 = 25. Right: Coupling for M = 71 and m3 = 35.\n(a)\nFigure 3: Coupling for M = 111 and m3 = 55. Left: Full range. Right: Vicinity of maximum.\nIn figure 4 we zoom into the\n√\nM vicinity of the maximum at m1 = m2 = m3 = 55 for M = 111. We cut\noff the maximum peak at a convenient value in order not to suppress the values of the coupling in its vicinity.\n12\n\n(a)\nFigure 4: High resolution in the vicinity of the maximum for coupling for M = 111 and m3 = 55.\nLeft: Side view. Right: Top view.\n5\nConclusions\nWe have successfully applied the version of Hamiltonian renormalisation developed in the current sequence of\npapers for the first time to an interacting QFT in finite volume in 1+1 spacetime dimensions and showed that\nthe renormalisation flow finds the known rigorous fixed point solution which is available in this case. The flow\nin fact stabilises rather quickly if one uses as coarse graining tools not the familiar position localised block spin\ntransformations but rather smooth versions thereof which compromise between position and momentum locality\nand have better smoothness properties. This demonstrates that the tools developed in the course of this series,\nwhich so far has focussed on free QFT, are also successfully applicable in the interacting case and does find the\ncorrect continuum Hamiltonian operator.\nExtrapolating to interacting QFT in higher, specifically four spacetime dimensions, the Hamiltonian H =\nH0 + V when quantised in the Fock representation adapted to H0 is known to be no longer an operator but\nmerely a quadratic form. Following the steps that we have carried out for the present model to any interacting\nQFT with Hamiltonian H = H0 + V on the D+1 manifold R × T D shows that the corresponding flow would\nindeed find that quadratic form as a fixed point in the Fock representation adapted to H0. However, ideally\nrenormalisation is designed to actually construct a continuum theory with H as an operator rather than merely\na quadratic form which by Haag’s theorem [1] requires to leave the realm of Fock representations adapted to\nH0. To the best of our knowledge, the single known example where this actually worked in higher than 1+1\ndimensions is Φ4 theory in 2+1 dimensions [16]. In addition to making the coupling constants gk to depend\non M (which in the present model was not necessary) a new and non-trivial step successfully performed in that\nseminal work was to invent invertible “dressing transformations” TM at resolution M on the cut-off Fock space\nHM with modes confined to n ∈ZM such that in H′\nM := T −1\nM HMTM those terms are removed which prevent\nHM from being an operator rather than a quadratic form as M →∞(these are normal ordered monomials\nin field operator valued distributions with more than one creation operator). If that is the case then D is an\ninvariant domain for H′\nM where D is the span of Fock states in the free Fock space H. Then HM, defined on\nthe new domain D′\nM = TMD preserves D′\nM. The price to pay is that the norm of the vectors in D′\nM with respect\nto the inner product < ., . > on H diverges as M →∞. In [16] it was shown that one can define a new inner\nproduct < ., . >′\nM:=\n<.,.>\n<TMΩ,TM> on D′\nM where Ωis the Fock vacuum of H0, such that one can take M →∞\nand H′\nM →H′ becomes on operator densely defined on D′\nM →D′ whose Hilbert space completion with respect\n13\n\n< ., . >′\nM→< ., . >′ results in a new Hilbert space H′ for the interacting theory. In order that this works, the\nnorms of vectors TMψ, ψ ∈D with respect to < ., . > must all diverge at the same rate. We expect that similar\nmechanisms must be invoked in the present renormalisation scheme as well.\nIn a forthcoming work we will apply the version of Hamiltonian renormalisation developed in this series of\npapers to the self-interacting U(1)3 model of the weak Newton constant realm of Euclidian signature vacuum\nquantum gravity in four spacetime dimensions [17]. This model has two known solutions, one in terms of opera-\ntors [18] using a Narnhofer-Thirring type of representation [19] and one in terms of quadratic forms [20] in Fock\nrepresentations [20] in the sense that the full algebra of quantum constraints (Gauss, spatial diffeomorphism and\nHamiltonian) closes without anomaly. We will investigate the Hamiltonian renormalisation flow for both types of\nrepresentations with the aim to gain new insights in how to renormalise full quantum gravity e.g. in the Loop\nQuantum Gravity (LQG) representation [21] in order to remove or reduce present quantisation ambiguities.\nAcknowledgements\nM.R.-Z. thanks Jonas Neuser for useful discussions on the topic and acknowledges the financial support provided\nby the Deutsche Akademische Austauschdienst e. V.\nA\nFiniteness of P(Φ)2 QFT in Fock representations\nAs motivated in section 2 we pick the Fock representation selected by the free part of the Hamiltonian H0. We\nwant to show that the interaction part V is densely defined on D, the linear span of Fock vectors with smearing\nfunctions in L0, the L2 functions with compact momentum support. Below we present an elementary proof that\nrequires just first year’s calculus knowledge.\nTo show this, consider a general Fock vector ψ. Then we have the elementary estimate\n||V ψ||H ≤|gk|\n2k/2\nk\nX\nl=0\nÅ k\nl\nã\n||Vk(l)ψ||H,\n(A.1)\nand writing ψ = PN\nn=0 ψn where ψn is a Fock vector of particle number n we have further the estimate\n||Vk(l)ψ||H ≤\nN\nX\nn=l\n||Vk(l)ψn||H\n(A.2)\nHere we used that Vk(l) annihilates l particles and thus the r.h.s. of (A.2) vanishes for N < l. Let then n ≥l\nand ψ0 = cΩ, c =const. or ψn = Q\nr=1 [< fr, A >]† Ω, n > 0. Then for l ≥1 we have\nVk(l)ψn =\nX\nI∈Sl\nZ 1\n0\ndx [[ω−1/2 · A∗](x)]k−l Y\ni∈I\n[ω−1/2 · fi](x)\nY\nj̸∈I\n< fj, A >∗Ω\n(A.3)\nwhere Sl is the set of subsets of {1, .., n} with l elements and for l = 0 we have\nVk(0)ψn =\nZ 1\n0\ndx [[ω−1/2 · A∗](x)]k ψn\n(A.4)\nUsing further elementary estimates it follows that V is densely defined on D if and only if objects of the form\nZ 1\n0\ndx Fl(x) [[ω−1/2 · A∗](x)]k−l ψn−l\n(A.5)\nare normalisable vectors in the Fock space where Fl is either the constant function equal to unity for l = 0 or a\nproduct of l functions in L0 for l > 0. It is understood that k, n ≥l and k = 0, .., N. For k = 0 and thus l = 0\nthere is nothing to show as (A.5) just equals < 1, 1 > ψn which is finite as 1 ∈L when space is compact. For\n14\n\nk = 1 (A.5) equals < 1, A >∗ψn and < 1, F1 > ψn−1 respectively which are both Fock vectors. The interesting\nterms therefore come form k ≥2.\nThe norm squared of (A.5) is\nZ 1\n0\ndx\nZ 1\n0\ndy F ∗\nl (x) Fl(y) < ψn−l, [[ω−1/2 · A](x)]k−l [[ω−1/2 · A∗](y)]k−l ψn−l\n(A.6)\nWhen moving the annihilators to the right we get a sum of terms with 0 ≤r ≤k −l factors of\n[(ω−1/2 · A)(x) , (ω−1/2 · A∗)(y)] = ω−1(x, y) =\nX\nn∈Z\nˆω−1\nn\nen(x −y)\n(A.7)\nwhich is the integral kernel of the operator ω−1 and another k −l −r factors of functions in L0 (for k −l −r < 0\nthat term vanishes). Altogether we see that V is densely defined on D if and only if integrals of the form\nZ 1\n0\ndx\nZ 1\n0\ndy F ∗\nk−r(x) Gk−r(y) [ω−1(x, y)]r\n(A.8)\nconverge with 2 ≤k ≤N and 0 ≤r ≤k with Fk−r, Gk−r ∈L0 when k −r > 0 and F0 = G0 = 1. Let\nˆFn =< en, F > be the Fourier transform of F ∈L, then (A.8) is either\nX\nK∈Z\nˆF ∗\nk−r(K) ˆGk−r(K)\nX\nn1,..,nr∈Z\nδn1+..+nr,K\nr\nY\ns=1\nˆω−1\nns\n(A.9)\nfor k −r > 0 or\nX\nn1,..,nr∈Z\nδn1+..+nr,0\nr\nY\ns=1\nˆω−1\nns\n(A.10)\nfor k −r = 0 where again compactness of space was important as the kernel is translation invariant. As functions\nin L0 have compact momentum support, the sum over K in (A.9) is finite and it is sufficient to show that the\nsums\nX\nn1,..,nr∈Z\nδn1+..+nr,K\nr\nY\ns=1\nˆωns\n(A.11)\nconverge for every 2 ≤r ≤N and any finite K ∈Z.\nThe intuitive reason why this is in fact the case is as follows: If it was not for the Kronecker symbol, the sums\nwould decouple into a product of r sums each of which behaves as the M →∞limit of ζM(1) which diverges as\nln(M) and where ζM(z) = PM\nn=1 n−z is the M cut-off of the Riemann ζ function. However due to the Kronecker\nsymbol we only get r −1 sums over n1, .., nr−1 but still r factors, one depending on |ns|, s = 1, .., nr−1 and one\ndepending on |n1 + .. + nr−1 −K| which roughly adds an additional factor of ˆω1/(r−1)\nns\n. Thus each of the r −1\nsums behave as ζM(1 +\n1\nr−1) which converges for every r > 1. Of course this heuristic argument is not rigorous.\nWe therefore rigorously estimate the multiple sum in (A.11) as follows: First we simplify\nX\nn1,..,nr∈Z\nr\nY\ns=1\nˆω−1\nns δn1+..+nr,K ≤\nX\nn1,..,nr−1∈Z∪{0}\nr\nY\ns=1\nˆω−1\nns δn1+..+nr,K\n(A.12)\n=\nX\nσ1,..,σr=±1\nX\nn1,..,nr∈N0\nr\nY\ns=1\nˆω−1\nσsns δσ1n1+..+σrnr,K\n=\nX\nσ1,..,σr=±1\nX\nn1,..,nr∈N0\nr\nY\ns=1\nˆω−1\nns δσ1n1+..+σrnr,K\n=\nr\nX\nt=0\nÅ r\nt\nã\nX\nn1,..,nr∈N0\nr\nY\ns=1\nˆω−1\nns ×\n{θ(K −1) δ[n1+..+nt]−[nt+1+..+nr+|K|],0 + θ(−K −1) δ[n1+..+nt+|K|]−[nt+1+..+nr],0 + δK,0 δ[n1+..+nt]−[nt+1+..+nr],0}\n15\n\nwhere we made use of reflection invariance ˆωn = ˆω−n and that the product of the inverse eigenvalues is invariant\nunder permutations of r summation variables n1, .., nr so that the sum over σ1, ..σr can be reduced to a summation\nover the number t = 0, 1, .., r of those σ1, ..σr which take the value + which can be taken to be the σ1, .., σt.\nThe first term vanishes when t = 0 and for t = r the sum is constrained by n1, .., nr ≤|K| as all summation\nvariables are non negative. Likewise, the second term vanishes for t = r and for t = 0 the sum is constrained\nby n1, .., nr ≤|K|. Finally the third term collapses to n1 = .. = nr = 0 for t = 0, t = r. Thus the terms with\nt = 0, r are trivially finite and it is sufficient to consider only the terms 0 < t < r. For those, in the second term\nwe relabel t →r −t and switch the two groups n1, .., nt and nt+1, .., nr. As θ(K −1) + θ(−K −1) + δK,0 = 1\nwe end up with the relevant contribution\nSr(K)\n:=\nr−1\nX\nt=1\nÅ r\nt\nã\nX\nn1,..,nr∈N0\nr\nY\ns=1\nˆω−1\nns δ[n1+..+nt]−[nt+1+..+nr+|K|],0\n(A.13)\n=\nmr\nr−1\nX\nt=1\nÅ r\nt\nã\n∞\nX\nL=|K|\n[\nX\nn1,..,nt∈N0\ntY\ns=1\nw−1\nns δn1+..+nt,L] [\nX\nnt+1,..,nr∈N0\nr\nY\ns=t+1\nw−1\nns δnt+1..+nr,L−|K|]\nwhere κ := 2π\nm and wn =\np\n1 + [κn]2 and m is the mass parameter. Using the the abbreviation for 1 ≤t ≤\nr −1, M ≥0\nst(M) =\nX\nn1,..,nt∈N0\ntY\ns=1\nw−1\nns δn1+..+nt,M\n(A.14)\nwhich for t = 1 just equals w−1\nM we have\nSr(K) = mr\nr−1\nX\nt=1\nÅ r\nt\nã\n∞\nX\nL=|K|\nst(L) sr−t(L −|K|)\n(A.15)\nThe idea is now to show that st(M) decays at least as |M|−p for some p > 1/2 no matter the value of t for then\nthe sum over L converges and the sum over t is anyway finite. For t = 1 this is trivial, hence in what follows we\nconsider t ≥2.\nTo this end, we use the basic estimate\n1 + x2 ≥c (1 + |x|)2 ⇔[|x| −\nc\n1 −c m]2 + 1 −2c\n(1 −c)2 m2 ≥0\n(A.16)\nwhich holds for 0 < c ≤1\n2. We pick c = 1\n4 and thus\nw−1\nn\n≤\n2\n1 + κn\n(A.17)\nIt follows\nst(M) ≤2t\nM\nX\nn1=0\n[1 + κn1]−1\nM−n1\nX\nn2=0\n[1 + κn2]−1 ...\n(A.18)\nM−[n1+..+nt−3]\nX\nnt−2=0\n[1 + κnt−2]−1\nM−[n1+..+nt−2]\nX\nnt−1=0\n[1 + κnt−1]−1 [1 + κ(M −[n1 + .. + nt−1])]−1\nTo estimate the sum over nt−1 we use the abbreviation l = M −[n1 + .. + nt−2] (which is defined to equal M\nwhen t = 2)\nl\nX\nn=0\n[1 + κn]−1 [1 + κ(l −n)]−1 = [1 + κ l]−1\nl\nX\nn=0\n([1 + κn]−1 + [1 + κ(l −n)]−1) =\n2\n1 + κl\nl\nX\nn=0\n[1 + κn]−1\n=\n2\n1 + κl [1 +\nl\nX\nn=1\n[1 + κn]−1] =\n2\n1 + κl [1 +\nl\nX\nn=1\nZ n\nn−1\ndk [1 + κn]−1] ≤\n2\n1 + κl [1 +\nl\nX\nn=1\nZ n\nn−1\ndk [1 + κk]−1]\n=\n2\n1 + κl [1 +\nZ l\n0\ndk [1 + κk]−1] =\n2\n1 + κl [1 + κ−1 ln(1 + κl)]\n(A.19)\n16\n\nConsider now any 0 < p < 1 and note that z =: 1 + κl ≥1 then\nln(z)\nz\n≤z−p(1 −p)−1, z−1 ≤z−p\n(A.20)\nThus there exists a constant c1 (depending on p1, κ) such that (A.19) is bounded from above by c1 [1 + κl]−p1\nfor any 0 < p1 < 1. It follows that\nst(M) ≤2t c1\nM\nX\nn1=0\n[1 + κn1]−1\nM−n1\nX\nn2=0\n[1 + κn2]−1 ...\n(A.21)\nM−[n1+..+nt−4]\nX\nnt−3=0\n[1 + κnt−3]−1\nM−[n1+..+nt−3]\nX\nnt−2=0\n[1 + κnt−2]−1 [1 + κ(M −[n1 + .. + nt−2])]−p1\nTo estimate the sum over nt−2 we use the abbreviation l = M −[n1 + .. + nt−3] (which is defined to equal M\nwhen t = 3) and use again z−1 < z−p1 for z ≥1 to find\nl\nX\nn=0\n[1+κn]−1 [1+κ(l−n)]−p1 ≤\nl\nX\nn=0\n[1+κn]−p1 [1+κ(l−n)]−p1 ≤[1+κl]−p1\nl\nX\nn=0\n[[1+κn]−1+[1+κ(l−n)]−1]p1\n(A.22)\nFor any two numbers a, b > 0 and p > 0 we have\n[a + b]p =\nÅ ap [1 + b/a]p\na ≥b\nbp [1 + a/b]p\nb ≥a\n≤\nÅ (2a)p\na ≥b\n(2b)p\nb ≥a\n≤2p [ap + bp]\n(A.23)\nTherefore (A.22) can be further estimated by\n2p1 [1 + κl]−p1\nl\nX\nn=0\n{[1 + κn]−p1 + [1 + κ(l −n)]−p1} = 21+p1 [1 + κl]−p1\nl\nX\nn=0\n[1 + κn]−p1\n=\n21+p1\n[1 + κl]p1 [1 +\nl\nX\nn=1\n[1 + κn]−p1] =\n21+p1\n[1 + κl]p1 [1 +\nl\nX\nn=1\nZ n\nn−1\ndk [1 + κn]−p1]\n≤\n21+p1\n[1 + κl]p1 [1 +\nl\nX\nn=1\nZ n\nn−1\ndk [1 + κk]−p1]\n=\n21+p1\n[1 + κl]p1 [1 +\nZ l\n0\ndk [1 + κk]−p1] =\n21+p1\n[1 + κl]p1 [1 + κ−1 (1 −p1)−1 ([1 + κl]1−p1 −1)]\n≤\n21+p1\n[1 + κl]p1 [|1 −\n1\nκ(1 −p1)| + κ−1 (1 −p1)−1 [1 + κl]1−p1]\n(A.24)\nWe choose p1 so close to 1 that p2 := 2p1 −1 still obeys 0 < p2 < 1 which is the case for 1/2 < p1 < 1. Then\np2 < p1 so that also [1 + κl]−p1 < [1 + κl]−p2. Thus there exists a constant c2 (depending on p1, κ) such that\n(A.24) is bounded from above by c2 [1 + κl]−p2 for any 1/2 < p1 < 1 with p2 = 2p1 −1. It follows that\nst(M) ≤2t c1 c2\nM\nX\nn1=0\n[1 + κn1]−1\nM−n1\nX\nn2=0\n[1 + κn2]−1 ...\n(A.25)\nM−[n1+..+nt−5]\nX\nnt−4=0\n[1 + κnt−4]−1\nM−[n1+..+nt−4]\nX\nnt−3=0\n[1 + κnt−3]−1 [1 + κ(M −[n1 + .. + nt−3])]−p2\nComparing (A.21) and (A.25) we see that we can now iterate and define a sequence pu = 2pu−1−1, u = 1, .., t−1\nof powers provided we can keep them in the range 0 < pu < 1. The iteration is easily solved by\npu = 2u−1p1 −(2u−1 −1)\n(A.26)\n17\n\nPick p1 = 1 −2−T then\npu = 1 −2u−1−T\n(A.27)\nwhich satisfies 0 < pu < 1 for u = 1, .., t −1 if T ≥t. As we have to perform t −1 summations in st(M), for\nthe choice T = t we have pt−1 = 3/4 and find that for some constant ct we have\nst(M) ≤ct [1 + κM]−3/4\n(A.28)\nCorrespondingly\nSr(K) ≤mr [\nr−1\nX\nt=1\nÅ r\nt\nã\nct cr−t]\n∞\nX\nL=|K|\n([1 + κL] [1 + κ(L −|K|)])−3/4\n(A.29)\nLet κ′ = min(1, κ) so that 1 + κM ≥κ′(1 + M) then for some constant Cr,m\nSr(K) ≤Cr,m\n∞\nX\nL=|K|\n([1 + L] [1 + L −|K|])−3/4 ≤Cr,m ζ(3\n2)\n(A.30)\nwhere we introduced L−|K| = 0, 1, 2, .. as a new summation variable and estimated 1+L+|K| ≥1+L so that\nthe Riemann zeta ζ(z) appears which converges for ℜ(z) > 1 (this fact can of course also proved elementarily\nusing the above technique to estimate the sum by an integral). Note that the bound (A.30) is in fact independent\nof K and can certainly be optimised if needed.\nB\nRenormalisation tools\nMore details on this section, in particular the relation to wavelet theory [13], can be found in [14].\nWe work on spacetimes diffeomorphic to R × σ. In a first step the spatial D-manifold σ is compactified to\nT D. Therefore, all constructions that follow have to be done direction wise for each copy of S1. On X := S1,\nunderstood as [0, 1) with endpoints identified, we consider the Hilbert space L = L2([0, 1), dx) with orthonormal\nbasis\nen(x) := e2π i n x, n ∈Z\n(B.1)\nwith respect to the inner product\n< F, G >L:=\nZ 1\n0\ndx F(x) G(x)\n(B.2)\nLet O ⊂N be the set of positive odd integers. We equip O with a partial order, namely\nM < M′\n⇔\nM′\nM ∈N\n(B.3)\nNote that this is not a linear order, i.e. not all elements of O are in relation, but O is directed, that is, for each\nM, M′ ∈O we find M′′ ∈O such that M, M′ < M′′ e.g. M′′ = MM′. For each M ∈O, called a resolution\nscale, we introduce the subsets NM ⊂N0, ZM ⊂Z, XM ⊂X of respective cardinality M defined by\nNM = {0, 1, .., M −1}, ZM = {−M −1\n2\n, −M −1\n2\n+ 1, .., M −1\n2\n}, XM = {xM\nm := m\nM , m ∈NM}\n(B.4)\nIt is easy to check that we have the lattice relation\nXM ⊂XM′\n⇔\nM < M′\n(B.5)\nThe subspace LM ⊂L is defined by\nLM := span({en, n ∈ZM})\n(B.6)\n18\n\nOn LM we use the same inner product as on L, hence the en, n ∈ZM provide an ONB for LM. An alternative\nbasis for LM is defined by the functions\nχM\nm (x) :=\nX\nn∈ZM\nen(x −xM\nm )\n(B.7)\nThe motivation to introduce these functions is that in contrast to the plane waves en they are 1.\nspatially\nconcentrated at x = xM\nm and 2. real valued. This makes them useful for renormalisation purposes. In addition,\nin contrast to characteristic functions which have better spatial location properties, they are smooth. This is\na crucial feature because quantum field theory involves products of derivatives of the fields and derivatives of\ncharacteristic functions yield δ distributions. More in general, renormalisation tools must make a compromise\nbetween localisation and smoothness.\nThe functions χM\nm are still orthogonal but not orthonormal\n< χM\nm , χM\nˆm >LM = M δm, ˆm\n(B.8)\nWe choose not to normalise them in order to minimise the notational clutter in what follows. Let lM be the\nspace of square summable sequences fM = (fM,m)m∈NM with M members and inner product given by\n< fM, gM >lM := 1\nM\nX\nm∈NM\nfM,m gM,m\n(B.9)\nIf we interpret fM,m = F(xM\nm ) then (B.9) is a lattice approximant of < F, G >L. We define\nIM : lM →LM; (IM · fM)(x) :=< χM\n· (x), fM >lM = 1\nM\nX\nm∈NM\nfM,m χM\nm (x)\n(B.10)\nIts adjoint is defined by the requirement that\n< I∗\nM · FM, gM >lM =< FM, IM · gM >LM\n(B.11)\nwhich demonstrates\nI∗\nM : LM →lm, (I∗\nM · FM)m =< χM\nm , FM >LM\n(B.12)\nOne easily checks, using (B.8) that\nI∗\nM · IM = 1lM , < IM., IM. >LM =< ., . >lM\n(B.13)\nwhich shows that LM, lM are in 1-1 correspondence and that IM is an isometry. Likewise\nPM := IM · I∗\nM = 1LM\n(B.14)\nWe can consider IM also as a map IM : lM →L with image LM and then < I∗\nM., . >lM =< ., IM >L shows\nthat I∗\nM : L →lM is given by the same formula (B.12) with F ∈L but now PM : L →LM is an orthogonal\nprojection\nPM · PM = PM, P ∗\nM = PM\n(B.15)\nWe have explicitly\n(PM · F)(x) =\nZ 1\n0\ndy PM(x, y) F(y), PM(x, y) =\nX\nn∈ZM\nen(x −y)\n(B.16)\ni.e. PM(x, y) is the M-cutoff of the δ distribution on X, i.e. modes |n| > M−1\n2\nare discarded.\nGiven a continuum function F ∈L we call fM = I∗\nM · F ∈lM or FM = PM · F ∈LM the discretisation of\nF at resolution M. In particular, if we have a Hamiltonian field theory on X with conjugate pair of fields (Φ, Π)\ni.e. the non-vanishing Poisson brackets are\n{Π(x), Φ(y)} = δX(x, y) =\nX\nn∈Z\nen(x −y)\n(B.17)\n19\n\nthen their discretisations obey\n{πM,m, ϕM, ˆm} = M δm, ˆm, {ΠM(x), ΦM(y)} = PM(x, y) = sin(Mπ(x −y))\nsin(π(x −y))\n(B.18)\nThe latter formula is known as the Dirichlet kernel.\nGiven a functional H[Π, Φ] of the continuum fields we define its discretisation by\nhM[πM, ϕM] := HM[ΠM, ΦM] = H[ΠM, ΦM] = (I′\nMH)[πM, ϕM]\n(B.19)\nwhere I′\nM denotes the pull-back by IM. That is, in the continuum formula for H one substitutes Π →ΠM, Φ →\nΦM in the formula for H upon which H is restricted to ΠM, ΦM, i.e. HM is that restriction, and then uses the\nidentity ΠM = IM ·πM, ΦM = IM ·ϕM. In order for this to be well-defined it is important that IM is sufficiently\nsmooth as H typically depends of derivatives of Π, Φ. This is granted by our choice of IM. In particular, as the\nderivative ∂=\n∂\n∂x preserves each of the spaces LM we have a canonical discretisation of the derivative defined\nby\n∂M := I∗\nM · ∂· IM\n(B.20)\nwhich obeys ∂n\nM = I∗\nM · ∂n · IM because IM · I∗\nM = PM and [∂, PM] = 0.\nConcerning quantisation, in the the continuum we define the Weyl algebra A generated by the Weyl elements\nW[F] = e−i<F,Φ>L, W[G] = e−i<G,Π>L\n(B.21)\nfor real valued F, G ∈L (or a dense subspace thereof with additional properties such as smoothness and rapid\nmomentum decrease of its Fourier modes < en, F >L, < en, G >L). That is, the non-trivial Weyl relations are\nW[G] W[F] W[−G] = e−i<G,F>L W[F], W[F] W[F ′] = W[F + F ′], W[G] W[G′] = W[G + G′]\nW[0] = 1A, W[F]∗= W[−F], W[G]∗= W[−G]\n(B.22)\nCyclic representations (ρ, H, Ω) of A with Ω∈H a cyclic vector (i.e. D := ρ(A)H is dense) are generated from\nstates (positive, linear, normalised functionals) ω on A via the GNS construction [15]. The correspondence is\ngiven by\nω(A) =< Ω, ρ(A)Ω>H\n(B.23)\nWe may proceed analogously with the discretised objects.\nFor each M we define the Weyl algebra AM\ngenerated by the Weyl elements\nWM[FM] = e−i<FM,ΦM>LM = wM[fM] = e−i<fM,ϕM>lM , WM[GM] = e−i<GM,ΠM>LM = wM[gM] = e−i<gM,πM>lM\n(B.24)\nwhere FM = IM · fM, GM = IM · gM are real valued. Accordingly\nWM[GM] WM[FM] WM[−GM] = e−i<GM,FM>LM WM[FM], WM[FM] WM[F ′\nM] = WM[FM + F ′\nM], (B.25)\nWM[GM] WM[G′\nM] = WM[GM + G′\nM], WM[0] = 1AM , WM[FM]∗= WM[−FM], WM[GM]∗= WM[−GM]\nand completely analogous for ϕM, πM if we substitute lower case letters for capital letters in (B.25). For each M\nwe define a state ωM on AM which gives rise to GNS data (ρM, HM, ΩM) and the dense subspace DM = AMΩM.\nNote that AM is a subalgebra of AM′ for M < M′ and that AM is a subalgebra of A. This follows from the\nidentities\nWM′[FM] = WM[FM], WM[FM] = W[FM]\n(B.26)\ndue to PM′ · PM = PM since LM ⊂LM′ and PM · PM = PM respectively.\nThe sole reason for discretisation is as follows: While finding states on A is not difficult (e.g. Fock states) it is\ntremendously difficult to find such states which allow to define non-linear functionals of Π, Φ such as Hamiltonians\ndensely on D due to UV singularities arising from the fact that Π, Φ are promoted to operator valued distributions\nwhose product is a priori ill-defined. In the presence of the UV cut-off M this problem can be solved because e.g.\nΦM(x)2 is perfectly well-defined (Φ is smeared with the smooth kernel PM). Suppose then that hM or equivalently\n20\n\nHM are somehow quantised on DM. We denote these quantisations by ρM(hM, cM) or ρM(HM, cM) respectively\nto emphasise that these operators are 1. densely defined on ρM(AM)ΩM, 2. correspond to the classical symbol\nhM of HM respectively and 3. depend on a set of choices cM for each M such as factor or normal ordering etc.\nIt is therefore not at all clear whether the theories defined for each M in fact descend from a continuum theory.\nBy “descendance” we mean that ωM is the restriction of ω to AM and that ρM(HM, cM) is the restriction of\nρ(H, c) to DM as a quadratic form (i.e. in the sense of matrix elements). In formulas this means\nωM(AM) = ω(AM),\n(B.27)\n< ρM(AM)ΩM, ρM(HM, cM) ρM(BM)ΩM >HM =< ρ(AM)Ω, ρ(H, c) ρ(BM)Ω>H,\nfor all M ∈O and all AM, BM ∈AM. If they did, then we obtain the following identities for M < M′\nωM′(AM) = ωM(AM),\n(B.28)\n< ρM(AM)ΩM, ρM(HM, cM) ρM(BM)ΩM >HM =< ρM′(AM)ΩM′, ρM′(HM′, cM′) ρM′(BM)ΩM′ >HM′,\ncalled consistency conditions. This follows from the fact that AM′ := AM, BM′ := BM can be considered as\nelements of AM and then using (B.27). With some additional work [4] one can show that (B.28) are necessary\nand sufficient for ω, ρ(H) to exist (at least as a quadratic form).\nIn constructive quantum field theory (CQFT) [2] one proceeds as follows. One starts with an Ansatz of a\nfamily of discretised theories (ω(0)\nM , ρ(0)\nM (HM, c(0)\nM ))M∈O. That Ansatz generically violates (B.28). We now define\na renormalisation flow of states and quantisations by defining the sequence (ω(k)\nM , ρ(k)\nM (HM, c(k)\nM ))M∈O for k ∈N0\nvia\nω(k+1)\nM\n(AM) := ω(n)\nM′(M)(AM), < ρ(k+1)\nM\n(AM)Ω(k+1)\nM\n, ρ(k+1)\nM\n(HM, c(k+1)\nM\n) ρ(k+1)\nM\n(BM)Ω(k+1)\nM\n>H(k+1)\nM\n=\n< ρ(k)\nM′(AM)Ω(k)\nM′, ρ(k)\nM′(HM′, c(k)\nM′) ρ(k)\nM′(BM)Ω(k)\nM′ >H(k)\nM′\n(B.29)\nwhere M′ : O →O is a fixed map with the property that M′(M) > M, M′(M) ̸= M. The first relation defines\na new state at the coarser resolution M as the restriction of the old state at the finer resolution M′(M). This\nthen defines also new GNS data (ρ(k+1)\nM\n, H(k+1)\nM\n, Ω(k+1)\nM\n) via the GNS construction. The second relation defines\nthe matrix elements of an operator or quadratic form in that new representation and with new quantisation\nchoices to be made at coarser resolution in terms of the restriction of the matrix elements of the old operator or\nquadratic form with old quantisation choices in the old representation at finer resolution. A fixed point family\n(ω∗\nM, ρ∗\nM(HM, c∗\nM))M∈O of the flow (B.29) solves (B.28) at least for M′ = M′(M) and all M and thus all\n[M′]n(M), n ∈N0 and all M. This typically implies that (B.28) holds for all M′ < M. In practice we will work\nwith M′(M) := 3 M\nNote that for a general operator or quadratic form O defined densely on D it is not true that we find an\nelement a ∈A such that ρ(a) = O (e.g. unbounded operators) which is why the above statements cannot\nbe made just in terms of the states ω. If one tried, one would need to use sequences or nets an ∈A whose\nlimits lie outside of A. On the other hand, if one prefers to work with the Weyl elements WM[FM] one may\nrelate the spaces lM, LM via the identities wM[fM] = WM[FM], fM = I∗\nM · FM. The wM[fM], wM′[f′\nM]\nat resolution M, M′ respectively can be related via the coarse graining map IMM′ := I∗\nM′ · IM; lM →lM′\nsuch that wM′[IMM′ · fM] = wM[fM]. This map obeys IM2M3 · IM1M2 = IM1M3 for M1 < M2 < M3 because\nthe image of IM is LM which is a subspace of LM′ thus IM2M3 · IM1M2 = I∗\nM3 · PM2 · IM1 = I∗\nM3 · IM1.\nThen WM′[FM] = wM′[I∗\nM′FM] = wM′[I∗\nM′ · IM · fM] = wM′[IMM′ · fM] indeed.\nFor the same reason\nWM′[FM] = WM[FM] as LM is embedded in LM′ by the identity map. The renormalisation flow in terms of\nWeyl elements wM[fM] and the coarse graining map IM,M′ takes the form\nω(k+1)\nM\n(wM[fM]) := ω(k)\nM′(wM′[IM,M′f′\nM])\n⟨wM[f′\nM]Ω(k+1)\nM\n, H(k+1)\nM\nwM[fM]Ω(k+1)\nM\n⟩H(k+1)\nM\n:= ⟨wM′[IM,M′f′\nM]Ω(k)\nM′, H(k)\nM′ wM′[IM,M′fM]Ω(k)\nM′⟩H(k)\nM′ .\n(B.30)\n21\n\nReferences\n[1] R. Haag, “Local Quantum Physics”, Springer Verlag, Berlin, 1984\n[2] J. Glimm and A. Jaffe, “Quantum Physics”, Springer Verlag, New York, 1987.\n[3] K. G. Wilson. The renormalization group: Critical phenomena and the Kondo problem. Rev. Mod. Phys. 47\n(1975) 773\n[4] T. Thiemann. Canonical quantum gravity, constructive QFT and renormalisation. Front. in Phys. 8 (2020)\n548232. arXiv:2003.13622 [gr-qc].\n[5] T. Lang, K. Liegener, T. Thiemann. Hamiltonian Renormalisation I. Derivation from Osterwalder-Schrader\nReconstruction. Class. Quant. Grav. 35 (2018) 245011. [arXiv:1711.05685]\n[6] T. Lang, K. Liegener, T. Thiemann. Hamiltonian Renormalisation II. Renormalisation Flow of 1+1 dimen-\nsional free, scalar fields: Derivation. Class. Quant. Grav. 35 (2018) 245012. [arXiv:1711.06727]\n[7] T. Lang, K. Liegener, T. Thiemann. Hamiltonian Renormalisation III. Renormalisation Flow of 1+1 dimen-\nsional free, scalar fields: Properties. Class. Quant. Grav. 35 (2018) 245013. [arXiv:1711.05688]\n[8] T. Lang, K. Liegener, T. Thiemann. Hamiltonian Renormalisation IV. Renormalisation Flow of D+1 dimen-\nsional free scalar fields and Rotation Invariance. Class. Quant. Grav. 35 (2018) 245014, [arXiv:1711.05695]\n[9] K. Liegener, T. Thiemann. Hamiltonian Renormalisation V. Free Vector Bosons. Front. Astron. Space Sci.\n7 (2021) 547550. e-Print: 2003.13059 [gr-qc]\n[10] T. Thiemann. Hamiltonian Renormalisation VII. Free Fermions and doubler free kernels. Phys. Rev. D108\n(2023) 12, 125007. e-Print: 2207.08291 [hep-th]\n[11] E.-A. Zwicknagel. Hamiltonian renormalization. VI. Parametrized field theory on the cylinder. Phys. Rev.\nD108 (2023) 12, 125006. e-Print: 2207.08290 [gr-qc]\n[12] B. Simon, “The P(ϕ)2 Euclidean (Quantum) Field Theory”, Princeton Unviersity Press, 1974\n[13] I. Daubechies. Ten lectures of wavelets. Springer Verlag, Berlin, 1993.\nA. Cohen, I. Daubechies, P.Vial. Wavelets on the interval and fast wavelet transforms. Appl. and Comp.\nHarm. Anlysis, Elsevier, 1993. [hal-01311753]\n[14] T. Thiemann. Renormalization, wavelets, and the Dirichlet-Shannon kernels. Phys. Rev. D 108 (2023) 12,\n125008. e-Print: 2207.08294 [hep-th]\n[15] O. Bratteli, D. W. Robinson, “Operator Algebras and Quantum Statistical Mechanics”, vol. 1,2, Springer\nVerlag, Berlin, 1997.\n[16] J. Glimm, “Boson Fields with the : ϕ4 : Interaction in Three Dimensions”, Comm. Math. Phys. 10 (1968)\n1-47.\nJ. Glimm, A. Jaffe, Positivity of the ϕ4\n3 Hamiltonian”, Fortschr. Phys. 21 (1973) 327–376\n[17] L. Smolin. The G(Newton) →0 limit of Euclidean quantum gravity. Class. Quant. Grav. 9 (1992) 883-894.\ne-Print: hep-th/9202076 [hep-th]\n[18] Exact quantisation of U(1)3 quantum gravity via exponentiation of the hypersurface deformation algebroid.\nClass. Quant. Grav. 40 (2023) 24, 245003. e-Print: 2207.08302 [gr-qc]\n[19] H. Narnhofer, W.E. Thirring. Covariant QED without indefinite metric. Rev. Math. Phys. 4 (1992) spec01,\n197-211\n[20] T. Thiemann. Nonperturbative quantum gravity in Fock representations. Phys. Rev. D 110 (2024) 12,\n124023. e-Print: 2405.01212 [gr-qc]\n[21] C. Rovelli, “Quantum Gravity”, Cambridge University Press, Cambridge, 2004.\nT. Thiemann, “Modern Canonical Quantum General Relativity”, Cambridge University Press, Cambridge,\n2007.\nJ. Pullin, R. Gambini, “A first course in Loop Quantum Gravity”, Oxford University Press, New York, 2011\nC. Rovelli, F. Vidotto, “Covariant Loop Quantum Gravity”, Cambridge University Press, Cambridge, 2015\nK. Giesel, H. Sahlmann, From Classical To Quantum Gravity: Introduction to Loop Quantum Gravity, PoS\nQGQGS2011 (2011) 002, [arXiv:1203.2733].\n[22] K. Osterwalder, R. Schrader. Axioms for Euclidean Green’s functions. Communications in Mathematical\nPhysics 31(2):83–112, 6 1973\n[23] J. Glimm and A. Jaffe, ”A λϕ4 quantum field theory without cutoffs. I”, Phys. Rev. 176 (1968), 1945–1951.\nDOI: 10.1103/PhysRev.176.1945.\nJ. Glimm and A. Jaffe, ”The λ(ϕ4)2 quantum field theory without cutoffs: III. The physical vacuum”, Acta\nMath. 125 (1970), 203–267. DOI: 10.1007/BF02392335.\n22\n\nJ. Glimm and A. Jaffe, ”The λ(ϕ4)2 quantum field theory without cutoffs. II. The field operators and the\napproximate vacuum”, Ann. of Math. 91 (1970), no. 2, 362–401. DOI: 10.2307/1970582.\nJ. Glimm and A. Jaffe, ”The λ(ϕ4)2 quantum field theory without cutoffs. IV. Perturbations of the Hamil-\ntonian”, J. Math. Phys. 13 (1972), no. 10, 1568–1584. DOI: 10.1063/1.1665879.\n23\n"
    },
    {
      "arxiv_id": "0902.3100",
      "full_text": "arXiv:0902.3100v2  [hep-lat]  27 Apr 2009\nHU-EP-09/04\nSFB/CCP-09-20\nPrecision check on triviality of φ4 theory by a new simulation\nmethod\nUlli Wolﬀ1\n1Institut f¨ur Physik, Humboldt Universit¨at,\nNewtonstr.\n15, 12489 Berlin, Germany\nWe report precise simulations of φ4 theory in the Ising limit. A recent technique\nto stochastically evaluate the all-order strong coupling expansion is combined with\nexact identities in the closely related Aizenman random current representation. In\nthis way estimates of the renormalized coupling close to the continuum limit become\npossible with unprecedented precision and yet low CPU cost. As a sample application\nwe present results for the unbroken phase of the Ising model in dimensions 3, 4 and 5\nand investigate the question of triviality by studying a ﬁnite size scaling continuum\nlimit.\nThe φ4 theory of a real scalar ﬁeld is the starting point of many textbooks on quantum\nﬁeld theory. It also plays a phenomenological rˆole as an extremely simpliﬁed model of the\nHiggs sector of the standard model. In [1], building on [2], it was discussed that the theory\nis trivial in dimension four, meaning that no interaction can exist in the continuum limit.\nFor applications this means, that the eﬀective theory with an unremovable cutoﬀin place\nhas only a limited energy domain of validity. This important property is rigorously known\nto hold above four dimensions [3], [4], but in D = 4 we have to rely so-far on numerical\nchecks. In this letter we report on the discovery of a new numerical strategy and algorithm,\nwhich enhances the precision of such checks by orders of magnitude as the continuum limit is\napproached. Also novel is the use of a ﬁnite volume renormalization scheme in this context.\nDue to both improvements we can progress much deeper into the universal scaling region\nthan in previous computations like [5].\nWe ﬁnd a ‘borderline’ agreement with standard\nperturbation theory for the cutoﬀdependence of the interaction strength which calls for\n\n2\nmore study.\nWe here consider the Ising limit of φ4 on a D-dimensional hypercubic lattice of extent\nL and lattice spacing a in all directions. We mostly use lattice units a = 1 from here on,\nbut occasionally re-introduce a to emphasize cutoﬀdependencies. Physical information is\nextracted via n-point correlation functions\n⟨s(x1)s(x2) · · ·s (xn)⟩= Z(x1, x2, . . . , xn)\nZ(∅)\n(1)\nwith\nZ(x1, x2, . . . , xn) = 2−V X\ns\neβ P\nl=⟨xy⟩s(x)s(y)s(x1)s(x2) · · ·s (xn)\n(2)\nand the volume V = LD. We sum over all Ising conﬁgurations s(x) = ±1 and Z(∅) is the\nproper partition function with no ﬁeld insertions. On our ﬁnite lattice Z(.) is analytic for\nall values of β. We parametrize the strong coupling expansion in β by summing in addition\nto s over an integer link ﬁeld k(l) = 0, 1, . . . , ∞\nZ(x1, x2, . . . , xn) = 2−V X\ns,k\nw[k]\nY\nl=⟨xy⟩\n[s(x)s(y)]k(l)s(x1)s(x2) · · ·s (xn)\n(3)\nwith the multiple Poisson weight\nw[k] =\nY\nl\nβk(l)\nk(l)!.\n(4)\nFor each k the s sum can now be performed and leaves behind a constraint for k,\nZ(x1, x2, . . . , xn) =\nX\nk\nw[k]δQ[k],X.\n(5)\nThe Kronecker δ enforces the coincidence of two sets. The source set Q[k] consists of the\nsites surrounded by an odd total number of k(l),\nQ[k] =\n(\nx|\nX\nl,∂l∋x\nk(l) = 1(mod 2)\n)\n.\n(6)\nThe insertion set X coincides with (x1, x2, . . . , xn) if they are mutually diﬀerent, but is more\ngenerally given by\nX =\n(\nx|\nn\nX\ni=1\nδx,xi = 1(mod 2)\n)\n.\n(7)\nMichael Aizenman [3], [6] has used the above representation of the Ising model to obtain\nrigorous correlation inequalities. He calls {k(l)} random currents and the sets Q = X defects\n\n3\nor external sources. Among his results the following is of interest here as it can be turned\ninto an eﬃcient numerical algorithm. From proposition 5.1 in [6] the identity\nZc(x1, x2, x3, x4) = −2\nX\nk,k′\nw[k]w[k′]δQ[k],X12δQ[k′],X34X (x1, x3; k + k′)\n(8)\nwith the connected part of Zc of Z\nZc(x1, x2, x3, x4) = Z(x1, x2, x3, x4) −Z(x1, x2)Z(x3, x4)\n−Z(x1, x3)Z(x2, x4) −Z(x1, x4)Z(x2, x3)\n(9)\nfollows. The sets X12 and X34 are formed as in (7) but from only two points each. The\ncluster incidence function X ∈{0, 1} is one if x1, x3 are in the same bond percolation cluster\nbuilt by bonds that are active on links where k(l) + k′(l) > 0 holds in the doubled random\ncurrent system. Note that the pairs {x1, x2} and {x3, x4} are connected automatically for\nk, k′ that contribute.\nIn the Monte Carlo community is has recently been found [7], [8], [9] that it is both\npossible and advantageous to simulate the untruncated strong coupling expansion instead\nof the original path integral (or sum) over ﬁelds. In a simple variant of the worm algorithm\n[7] one simulates the ensemble corresponding to the partition function\nZ =\nX\nu,v,k\nw[k]δQ[k],Xuv\n(10)\nwith a corresponding deﬁnition of expectation values of observables ⟨⟨O[u, v, k]⟩⟩. In the\nsum u, v run over all lattice sites.\nTo simulate this ensemble our elementary update step is as follows:\n• pick at random one of the 2D links emanating from u and call it l = ⟨u˜u⟩\n• assign a new value ˜k(l) to this link with probability p˜k = exp(−β)β\n˜k/˜k!\n• if ˜k −k is odd, move u →˜u, otherwise leave u unchanged\nIf we alternate these steps with similar ones for v we have a correct algorithm for (10).\nErgodicity may be shown by steps deforming an arbitrary conﬁguration to the trivial one.\nThis local heatbath has proved to be slightly superior to Metropolis proposals with k(l) →\n\n4\nk(l) ± 1. It is not diﬃcult to show that the Ising two-point function is now given by the\nratio of histograms\n⟨s(x)s(0)⟩= ⟨⟨δx,u−v⟩⟩\n⟨⟨δu,v⟩⟩\n(11)\nwhere we have used translation invariance. This implies in particular that the susceptibility\nis given by\nχ2 =\nX\nx\n⟨s(x)s(0)⟩= [⟨⟨δu,v⟩⟩]−1.\n(12)\nTo now make use of (8) for the connected four point susceptibility\nχ4 =\nX\nx,y,z\n⟨s(x)s(y)s(z)s(0)⟩c\n(13)\nwith subtractions as in (9) all we have to do is simulate two independent replica of (10) and\nsum over all xi in (8) to arrive at\n−V χ4 = 2⟨⟨X (u, u′, k + k′)⟩⟩\n⟨⟨δu,vδu′,v′⟩⟩\n.\n(14)\nIn total we thus have derived\n−1\nV\nχ4\n(χ2)2 = 2 ⟨⟨X (u, u′, k + k′)⟩⟩.\n(15)\nThe right hand side is obviously bounded between 0 and 2. In particular the lower bound\ncorresponds to the Lebowitz inequality. Our estimator reﬂects this property manifestly, the\nsubtraction of disconnected parts has been achieved analytically. We expect this to lead\nto a superior precision for χ4 compared to conventional Monte Carlo procedures since they\ninvolve substantial numerical cancellations here with the correspondingly enhanced relative\nerrors.\nThe previous expression is strongly reminiscent of a standard deﬁnition of a dimensionless\nuniversal renormalized coupling constant in φ4 theory including the Ising limit with its\ninﬁnite bare coupling. It is given by\ngR = −χ4\n(χ2)2mD\n(16)\nwhere m is a the renormalized mass.\nOften, for example in [2], [1], the mass is deﬁned in terms of the two point function in an\ninﬁnite volume at vanishing momentum. We substitute this by a deﬁnition using the two\n\n5\nsmallest possible momenta in a periodic volume as in [8]. The two point function (11) in\nmomentum space may be measured by\n˜G(p) = ⟨⟨cos(p(u −v))⟩⟩\n⟨⟨δu,v⟩⟩\n.\n(17)\nOur deﬁnition of a renormalized mass m is\nm2\nm2 + ˆp2\n∗\n=\n˜G(p∗)\n˜G(0)\n= ⟨⟨cos(p∗(u −v))⟩⟩\n(18)\nwhere we use the smallest momentum\np∗= (2π/L, 0, 0, . . ., 0),\naˆp∗= 2 sin(πa/L)\n(19)\nand average over its D possible directions. The rationale of the deﬁnition (16) is that it\nis a dimensionless ratio with the same number of ﬁelds in the numerator and denominator\nand hence it is expected to have a universal continuum limit. As it vanishes for Gaussian\ntheories it is a measure of the interaction strength. We are thus led to the deﬁnition\ng = 2 ⟨⟨X (u, u′, k + k′)⟩⟩× zD,\nz = mL.\n(20)\nCombining triviality with ﬁnite size scaling we investigate the proposition that the con-\ntinuum limit at ﬁxed z forces g ց 0. As for other questions on non-perturbative ultraviolet\nrenormalization [10], [11], [12] we ﬁnd it advantageous to employ a ﬁnite volume renormal-\nization scheme also here. We shall perform a sequence of simulations of growing L ≡L/a\nwhere we tune β such as to maintain a ﬁxed value z = 2. The advantage of keeping L ﬁnite\nand not too large in physical length units m−1 is that for the manageable values of L/a we\nexpect to be closer to the universal continuum limit. If the theory is trivial we should ﬁnd\ng →0 as L/a →∞. This is expected [3], [6], [4] for D > 4, and likely, although only at a\nlogarithmic rate, for D = 4.\nTo get conﬁdence in our algorithmic implementation we ﬁrst reproduced the results of\ncluster simulations in [5] within errors. For the 204 lattice our error in g for a comparable\nnumber of Flops is about 12 times smaller.\nIn the table we compile our data. Each line corresponds to 106 iterations with V link\nupdates in each of the two replica. The cost is dominated by the runs D = 4, L = 32 and\nD = 5, L = 16 with 240 hours each on a single PC. We refer to a code running under matlab\nbut importing random numbers from the ranlux generator [13] in C [14]. We have insisted\n\n6\nD L/a β\nz\nX\n∂X/∂z\nX(z = 2)\n4 8\n0.148320 1.9981(27) 0.39235(96)\n-0.3200(14) 0.39175(63)\n4 10\n0.148748 1.9949(26) 0.37256(92)\n-0.3193(14) 0.37093(62)\n4 12\n0.148996 1.9992(26) 0.35493(91)\n-0.3165(15) 0.35469(60)\n4 16\n0.149270 1.9988(25) 0.33161(91)\n-0.3129(16) 0.33125(58)\n4 22\n0.149449 2.0085(24) 0.30831(86)\n-0.3030(16) 0.31088(57)\n4 32\n0.149571 1.9956(24) 0.29028(83)\n-0.2993(20) 0.28896(55)\n3 8\n0.217350 1.9946(36) 0.59387(100) -0.2929(13) 0.59228(76)\n3 10\n0.218560 1.9942(37) 0.58634(102) -0.2950(13) 0.58463(76)\n3 16\n0.220153 2.0047(37) 0.57240(109) -0.3023(14) 0.57382(77)\n3 32\n0.221143 2.0032(39) 0.56338(118) -0.3076(17) 0.56435(76)\n5 8\n0.113052 2.0041(18) 0.19126(59)\n-0.2390(13) 0.19223(45)\n5 10\n0.113336 1.9993(16) 0.16037(53)\n-0.2170(13) 0.16022(41)\n5 12\n0.113503 1.9937(15) 0.13884(47)\n-0.1957(12) 0.13760(38)\n5 16\n0.113674 1.9918(13) 0.10944(39)\n-0.1656(12) 0.10809(33)\nTABLE I: Simulation results for D = 3, 4, 5.\non luxury level 2, but this part still accounts for only 4 % of the CPU time. The main code\ncould clearly be accelerated substantially. Derivatives of X and z with respect to ln β can\nbe measured as connected correlations with P\nl k(l) and their quotient yields our estimate\nfor ∂X /∂z. In the end it emerges as a certain nonlinear function of primarily measured\nobservables and it as well as all other errors is estimated by the tools provided in [15]. We\ntake its measured value in each data set as a ﬁxed constant and then form, now with X and\nz as functions of primary quantities, the combination\nX (z = 2) = X + (2 −z)∂X /∂z.\n(21)\nA look at the table shows that this is a tiny but sometimes signiﬁcant correction.\nWe\ncan however safely neglect the error of ∂X /∂z and higher terms of the Taylor expansion. It\ncame as a pleasant surprise that even where no systematic correction is needed the statistical\nﬂuctuations in this combination partially cancel and thus reduce the error. This saves more\nthan another factor two in run-time. The compensation is actually plausible: when sampled\n\n7\ngraphs are ‘bigger’ than average X goes up but the mass goes down. In the table we note\nthat relative errors are practically independent of L/a, which means complete absence of\ncritical slowing down. Nevertheless the (short) autocorrelations do have to be taken into\naccount when errors are determined.\n0\n0.05\n0.1\n0\n2\n4\n6\n8\n10\n12\nD = 5\nD = 3\nD = 4\na/L\ng\nL/a = 32\n22\n16\n12\n10\n8\nz = 2\nFIG. 1: All measured couplings with ﬁts (full and dashed lines) discussed in the text. Errorbars\nare barely visible within the symbols.\nIn ﬁgure 1 all coupling data are plotted. Fits (full and dashed lines) all have acceptable\nχ2. The D = 3 values are almost cutoﬀindependent and approach a ﬁnite continuum value.\nThe ﬁt is A + B(a/L)ω with the corrections to scaling exponent [16] ω = 0.85. Due to the\nﬂatness, ω can vary over a wide range including ω = 1. For D = 5 the full line is A + Ba/L\nomitting the L = 8 lattice. The dashed ﬁt is Aa/L + B(a/L)2. A 325 simulation would be\nof interest to better verify triviality for this case. The D = 4 data show more curvature and\nthe dotted lines just connect the data points. A naive ‘eyeball’ extrapolation in this plot\nagainst a/L would probably arrive at a nonzero value while on theoretical grounds we shall\nargue now for the dash-dotted line extrapolating to the origin at a vertical slope.\n\n8\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n9\n9.5\n10\n10.5\n11\n11.5\n12\n12.5\n1/ ln(L/a)\n˜g\n2 loop\n1 loop\n3 loop\nFIG. 2: Numerical couplings together with the renormalization group evolution starting from the\nﬁnest lattice. Dashed lines include lattice artifacts of the β-function.\nTo confront the 4D data with the theory [2], [1] we plot against [ln(L/a)]−1 in ﬁgure 2.\nWe solve the Callan Symanzik equation for the cutoﬀdependence of the coupling starting\nfrom L = 32. For this plot we have changed to the coupling\n˜g = g[1 + (za/L)2/8]−2 = g + O(a2)\n(22)\ndiﬀering by small cutoﬀeﬀects only. For it in contrast to g there are no tree level artifacts\nin the β-function and also the cutoﬀcorrections of the one and two loop terms are more\nuniform. We have worked out the lattice perturbation theory for our scheme up to two\nloops and could therefore, by relating to [1], also obtain the three loop term (without cutoﬀ\neﬀects). Details will be reported elsewhere [17]. We here draw the following conclusions: The\none loop result is accurate to a few percent for the scale changes considered. For instance, it\naccounts for 97% of the change L/a = 32 →16. The two loop term has a reasonable relative\nsize but the wrong sign. The three loop term is the ﬁrst one that is scheme dependent and\nhence depends on z. It is very large for z = 2 which suggests that renormalized perturbation\n\n9\ntheory as an asymptotic expansion here fails to improve the leading order. It rather is at\nits limit with only the one loop approximation being numerically accurate at the percent\nlevel. Nonetheless it seems convincing to now trust the one loop approximation for a < L/32\n(for z = 2) which implies a vanishing g in the continuum limit. On the way to it, also the\nhigher loop terms should eventually cooperate to improve the approximation. The dash-\ndotted curve in ﬁgure 1 shows the one loop evolution continued. We plan a more detailed\ndiscussion of the perturbative series and data for other z values in [17].\n1.16\n1.18\n1.2\n1.22\n1.24\n1.26\nx 10\n5\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n≈1.84Vξ\n2\n√\nV\nstrong coupling order\nFIG. 3: The order in β of the diagrams sampled for L = 32, D = 4 (u = v only).\nWe end on a more technical theme concerning the strong coupling simulation. The order\nof the diagrams that the algorithm has picked to be important for our physics is shown in\nﬁgure 3. The peak is at the order of the correlation volume Vξ = (am)−4 and the width\nseems to be controlled by (L/a)2.\nAcknowledgments. Exchange with Peter Weisz, Erhard Seiler and Rainer Sommer was\nmost beneﬁcial to this project. Some part of the eﬀort was stimulated during a visit at\nthe Max Planck (Werner Heisenberg) Institut in M¨unchen by hospitality and support. I\n\n10\nowe thanks to Willi Rath for helping me with ranlux under matlab and to the HU physics\ncompute team for providing a smooth infrastructure. Finally ﬁnancial support of the DFG\nvia SFB transregio 9 is acknowledged.\n[1] M. L¨uscher, P. Weisz, Nucl. Phys. B290 (1987) 25.\n[2] E. Brezin, J. C. Le Guillou, J. Zinn-Justin, Field Theoretical Approach to Critical Phenomena\nin Phase Transitions and Critical Phenomena, Vol.6, London 1976, 125.\n[3] M. Aizenman, Phys. Rev. Lett. 47 (1981) 1.\n[4] J. Fr¨ohlich, Nucl. Phys. B200 (1982) 281.\n[5] I. Montvay, G. M¨unster, U. Wolﬀ, Nucl. Phys. B305 (1988) 143.\n[6] M. Aizenman, Commun. Math. Phys. 86 (1982) 1.\n[7] N. Prokof’ev, B. Svistunov, Phys. Rev. Lett. 87 (2001) 160601.\n[8] Y. Deng, T. M. Garoni, A. D. Sokal, Phys. Rev. Lett. 99 (2007) 110601.\n[9] U. Wolﬀ, Nucl. Phys. B810 (2009) 491.\n[10] U. Wolﬀ, Nucl. Phys. B265 (1986) 537.\n[11] M. L¨uscher, P. Weisz, U. Wolﬀ, Nucl. Phys. B359 (1991) 221.\n[12] M. L¨uscher, R. Narayanan, P. Weisz, U. Wolﬀ, Nucl. Phys. B384 (1992) 168.\n[13] M. L¨uscher, Comput. Phys. Commun. 79 (1994) 100.\n[14] M. L¨uscher, http://luscher.web.cern.ch/luscher/ranlux.\n[15] U. Wolﬀ, Comput. Phys. Commun. 156 (2004) 143.\n[16] M. Hasenbusch, J. Phys. A32 (1999) 4851.\n[17] U. Wolﬀ, in preparation.\n"
    },
    {
      "arxiv_id": "2503.01743",
      "full_text": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal\nLanguage Models via Mixture-of-LoRAs\nMicrosoft∗\nAbstract\nWe introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language and\nmultimodal models. Phi-4-Mini is a 3.8-billion-parameter language model trained on high-quality\nweb and synthetic data, significantly outperforming recent open-source models of similar size and\nmatching the performance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data recipe emphasizing high-\nquality math and coding datasets.\nCompared to its predecessor, Phi-3.5-Mini, Phi-4-Mini\nfeatures an expanded vocabulary size of 200K tokens to better support multilingual applications, as\nwell as group query attention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input modalities into a single model.\nIts novel modality extension approach leverages LoRA adapters and modality-specific routers to allow\nmultiple inference modes combining various modalities without interference. For example, it now\nranks first in the OpenASR leaderboard to date, although the LoRA component of the speech/audio\nmodality has just 460 million parameters. Phi-4-Multimodal supports scenarios involving (vision\n+ language), (vision + speech), and (speech/audio) inputs, outperforming larger vision-language\nand speech-language models on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities.1. Despite its compact 3.8-billion-parameter size,\nthis experimental version achieves reasoning performance on par with or surpassing significantly larger\nmodels, including DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.\n1\nIntroduction\nThe Phi family of models [AJA+24, AAB+24] have shown that carefully curated and synthesized data\nenables Small Language Models (SLMs) to achieve highly competitive performance despite having a\nsignificantly smaller number of parameters.\nThese models demonstrate comparable results to much\nlarger models. Building on the success of the Phi family of language models, we extend their capabilities\nto handle additional modalities — such as vision and audio, achieving significant progress akin to private\nmodels like GPT [HLG+24], Claude [Ant24], and Gemini [TGL+24].\nIn this report, we introduce Phi-4-Multimodal, a unified multimodal SLM that supports multi-\nple inference modes combining various modalities (e.g., text-only, text + image, speech/audio, speech\n+ image) within a single model checkpoint. Phi-4-Multimodal employs a novel “mixture of LoRAs”\ntechnique, enabling multimodal capabilities by integrating modality-specific LoRAs while keeping the\nbase language model entirely frozen. Our findings show this technique outperforms existing approaches\n(e.g., cross-attention designs [ADL+22, AI23]) and achieves comparable performance to fully fine-tuned\n∗hanyh@microsoft.com, youki@microsoft.com\n1Please note that reasoning-enhanced Phi-4-Mini is a separate model and currently in a preview stage and will not\nbe released concurrently with Phi-4-Mini and Phi-4-Multimodal.\n1\narXiv:2503.01743v2  [cs.CL]  7 Mar 2025\n\nmodels on multimodal benchmarks. Additionally, the design of Phi-4-Multimodal is highly exten-\nsible, allowing seamless integration of new LoRAs to support additional modalities without impacting\nexisting ones.\nOur training process comprises multiple stages, including language training (encompassing both pre-\ntraining and post-training) and then expansion of the language backbone to vision and speech/audio\nmodalities. For the language model, we train Phi-4-Mini using high-quality, reasoning-rich text data.\nNotably, we include curated, high-quality code datasets to enhance performance on coding tasks. Once\nthe language model training is complete, we freeze the language model and implement our “Mixture\nof LoRAs” technique to proceed with the multimodal training stage. Specifically, we train two addi-\ntional LoRA modules alongside modality-specific encoders and projectors to enable vision-related tasks\n(e.g., vision-language and vision-speech) and speech/audio-related tasks (e.g., speech-language). Both\nof them contain pretraining and post-training stages for modality alignment and instruction finetuning,\nrespectively.\nWe also explore the reasoning potential of Phi-4-Mini to create a compact yet powerful model that\nrivals substantially larger state-of-the-art reasoning systems, such as DeepSeek-R1-Distill-Qwen-7B\nand DeepSeek-R1-Distill-Llama-8B [GYZ+25].\nThe key contributions of this model are listed below.\n1. Unified Multi-Modality Support: In contrast to existing methods [Tea25b, CWW+24] that\nemploy separate models for different modalities, Phi-4-Multimodal is designed as a unified\nmodel capable of efficiently handling multiple modality scenarios. By leveraging the Mixture of\nLoRAs [HSW+22], Phi-4-Multimodal extends multimodal capabilities while minimizing inter-\nference between modalities. This approach enables seamless integration and ensures consistent\nperformance across tasks involving text, images, and speech/audio.\n2. Remarkable Language Performance for the size: The language models achieve state-of-\nthe-art performance in natural language understanding and generation for its size category. It\ndemonstrates exceptional reasoning and mathematical capabilities, making it well-suited for com-\nplex problem-solving and knowledge-based tasks.\n3. Outstanding Code Understanding and Generation for the size: The language models\nachieve state-of-the-art performance on code-related tasks within its size category. The model\nexcels at tasks such as code synthesis, debugging, and documentation generation, empowering\ndevelopers and aiding in software engineering workflows.\n4. Superior Multi-Modal Capabilities for the size: The model delivers state-of-the-art perfor-\nmance across multi-modal tasks for its size category, demonstrating robust integration of diverse\ndata types. This includes tasks that involve combining images with text and speech modalities,\nenabling multi-modal reasoning.\n5. Exceptional Speech and Audio Performance: The model achieves strong performance espe-\ncially on multilingual speech recognition and translation tasks, and is the first open-sourced model\nwith speech summarization capability.\n6. Enhanced Reasoning Capabilities: The reasoning-optimized version of Phi-4-Mini demon-\nstrates superior reasoning abilities for a model in its size category.\n2\n\n2\nModel architecture\nThe Phi-4-Mini series comprises two state-of-the-art small models: a language model (Phi-4-Mini)\nand a multimodal model (Phi-4-Multimodal) that integrates language, vision, and speech/audio\nmodalities. All Phi-4-Mini models use the tokenizer o200k base tiktoken 2 with a vocabulary size of\n200,064 intended to support multilingual and multimodal input and output more efficiently. All models\nare based on decoder-only Transformer [VSP+17] and support 128K context length based on LongRoPE\n[DZZ+24a].\n2.1\nLanguage model architecture\nPhi-4-Mini and Phi-4-Multimodal share the same language model backbone. Phi-4-Mini con-\nsist of 32 Transformer layers with hidden state size of 3,072 and tied input / output embedding which\nreduces the memory consumption significantly while providing much wider coverage of vocabularies\ncompared Phi-3.5. Each Transformer block includes an attention mechanism based on Group Query\nAttention (GQA) [ALTdJ+23], which optimizes key and value memory (KV cache) usage for long-context\ngeneration. Specifically, the model employs 24 query heads and 8 key/value heads, reducing KV cache\nconsumption to one-third of its standard size. Additionally, in the RoPE configuration [SAL+24], a\nfractional RoPE dimension is used, ensuring that 25% of the attention head dimension remains position-\nagnostic. This design supports smoother handling of longer contexts. To determine the peak learning\nrate, we follow [BBC+24] with LR∗(D) = BD−0.32 where B is a constant we tune for this specific model\nand D is the total number of training tokens. We fit B by tuning across D = 12.5B,25B,37.5B,50B.\n2.2\nMultimodal model architecture\nTo integrate vision as an input modality, numerous vision-language models have been developed, includ-\ning the LLava series [LLWL24, LLL+24, LZG+24], QWenVL series [BBY+23, WBT+24], InternVL series\n[CWT+24, CWW+24, CWC+24], InternLM-XComposer series [ZDW+23, DZZ+24b], Molmo [DCL+24],\nand NVLM [DLW+24]. Similarly, for audio input, notable contributions include Qwen2-Audio [CXY+24],\nInternLM-XComposer2.5-Omnilive [ZDC+24], InternOmni, Mini-Omni [XW24], and GLM4-Voice [ZDL+24].\nHowever, in order to enable modality-specific functionality, these multimodal models generally require\nfine-tuning the base language model, which often diminishes its original language capabilities. Conse-\nquently, supporting diverse input signals without compromising quality necessitates deploying multiple\nmodels—a particularly challenging limitation for resource-constrained devices. To address this, LLama-\nVision [DJP+24] adopts a strategy inspired by Flamingo [ADL+22], adding extra cross-attention layers\nwhile preserving the core language model. However, this approach will result in reduced performance on\nvision-language benchmarks compared to fully fine-tuned models. To fill the performance gap, NVLM\n[DLW+24] further explores a hybrid framework, employing joint supervised fine-tuning with high-quality\ntext SFT data. Yet, this approach only examines limited language benchmarks and does not address\nadditional training stages often required after SFT.\nWe adopt the mixture of LoRAs design for our Phi-4-Multimodal architecture to support vari-\nant multi-modality use cases.\nDifferent LoRAs are trained to handle interactions between different\nmodalities. Our Phi-4-Multimodal supports a vast range of tasks, including single/multiple images\nQA/summarization, video QA/summarization, vision-speech tasks, speech QA/summarization/transla-\ntion/recognition, and audio understanding, while maintains the original language model performance.\n2https://github.com/openai/tiktoken\n3\n\nTokenizer\nVision Encoder\nAudio Encoder\n<|audio_1|>\n<|audio_2|>\n<|image_1|>\n<|image_2|>\nToken Merging\nVision Projector\n<|image_1|>\nAudio Projector\n<|audio_1|>\n<|audio_2|>\n<|image_1|>\n<|image_2|>\nPhi4 Mini\nOriginal W +\nOriginal W + \nOriginal Weights\nOriginal W +\nOriginal W + \nOriginal Weights\nOriginal W +\nOriginal W + \nOriginal Weights\n<|image_2|>\nFigure 1: A overview of the Multimodal architecture for Phi-4-Multimodal\n2.2.1\nModality Details\nVision modality.\nThe vision modality is implemented with an image encoder, a projector to align\nthe vision and text embeddings and a LoRA adaptor. The vision encoder is based on SigLIP-400M that\nis finetuned with LLM2CLIP [HWY+24] on large scale image-text pairs with resolution 448 × 448 . The\nprojector is a 2-layer MLP that maps the vision features dimension to the text embedding dimension.\nExtra LoRA is added on all the linear layers in the language decoder and only deployed in the supervised\nfine tuning (SFT) stage. The image encoder and projector introduce 440M model parameters while the\nvision adapter LoRAV consumes another 370M model parameters.\nIn order to enable the model to process images with diverse resolution effectively and efficiently, we\nproposed a new dynamic multi-crop strategy. Specifically, given a target image, we first compute the\ncrop number for each side by dividing the original size by the crop-size, i.e. ⌈H\nC ⌉× ⌈W\nC ⌉, where H,W,C\nare the image height, width and crop size respectively. If the total crop number is within the maximum\nnumber, i.e., 16 in the pretraining stage and 36 in SFT, we just slightly resize the image to let it fit the\nsize given by the computed image crops. Otherwise, we will leverage the strategy proposed in InternVL2\n[CWW+24] that find the crop number by matching the best aspect ratio. Compared to InternVL2, the\nkey benefits of our strategy is to avoid resizing one small image (e.g., 28 × 448) to unreasonable large\nsize when looking for the closest image aspect ratio.\nSpeech and Audio Modality:\nThe speech/audio inputs we used are 80-dim log-Mel filter-bank\nfeatures with the frame rate of 10ms.\nTo enable Phi-4-Multimodal speech and audio functions,\nwe connect a pre-trained audio encoder and Phi-4-Mini through an audio adapter.\nIn addition,\nLoRA is applied on the language decoder to improve the performance of speech/audio benchmarks while\npreserving the text capability. The introduced modules for the speech/audio modality include:\n• An audio encoder, which consists 3 convolutions layers and 24 conformer blocks [GQC+20] with\n1024 attention dimensions, 1536 feed-forward dimensions, and 16 attention heads. The convolution\n4\n\nlayers contribute to a sub-sampling rate of 8, and thus 80ms token rate for the language decoder.\n• An audio projector, which is a 2-layer MLP that maps the 1024-dim speech features to the text\nembedding space of 3072 dimensions, similar to the vision projector.\n• LoRAA that has been applied to all attention and MLP layers in Phi-4-Mini with a rank of 320.\nThe audio encoder and projector introduce 460M parameters while LoRAA consumes another 460M\nparameters. Note that the speech token rate is 80ms, indicating 750 tokens for 1-minute audio.\n2.2.2\nTraining Pipeline\nThe multimodal training stages include vision training, speech/audio training and vision-speech joint\ntraining.\nVision Training.\nThe overall training pipeline for multimodal learning consists of vision training,\nspeech and audio training, and joint vision-audio training. Vision training follows a four-stage process:\n1) Projector Alignment stage: initially, only the projector is trained using caption data to align vision\nand text embeddings while preserving the pretrained representation of the vision encoder. 2) Joint Vision\nTraining stage: Next, the projector and vision encoder are jointly trained on the full vision pretraining\ndataset to enhance key vision capabilities, such as OCR and dense understanding. 3) Generative Vision-\nLanguage Training stage: LoRA is then deployed on the language decoder and trained alongside the\nvision encoder and projector using curated single-frame SFT data, equipping the model with generative\ncapabilities for vision-language inputs. 4) Multi-Frame Training stage: Finally, the model is trained on\nmulti-frame SFT data with the vision encoder frozen, extending the context length coverage to 64k and\nenabling multi-image and temporal understanding.\nSpeech and Audio Training.\nWith the Phi-4-Mini language model, we conduct a two-stage\nparadigm for speech and audio training, also known as speech/audio pre-training and post-training. In\nthe pre-training stage, we use large-scale automatic speech recognition (ASR) data to align the audio\nencoder and Phi-4-Mini in the semantic space. In this stage, the encoder and projector is updated\nwith a learning rate of 4e-5 for 50k steps while the language decoder is frozen. We initialize the audio\nencoder with a pre-trained encoder from the attention-based encoder decoder (AED) ASR model.\nAfter the pre-training stage, the model can only perform the ASR task. To unlock the instruction\nfollowing capability of Phi-4-Multimodal for variety of speech and audio tasks, we continue to train\nthe model with about 100M curated speech and audio SFT samples (after weighted up) as the speech\npost-training stage. Please refer to Section 3.4.2 for data details. In speech/audio post-training, the\naudio encoder is frozen. We update the audio projector and LoRAA with a learning rate of 1e-4 for\nanother 50k steps. We consider different maximum audio lengths for different tasks in post-training.\nFor speech summarization task, we train up to 30-minute audio (22.5k tokens). For other tasks, the\nmaximum audio exposed in training is 30s (375 tokens). If we consider the 128k context length for\nlanguage decoder, theoretically Phi-4-Multimodal can support a maximum 2.8 hours of audio as out\nof the box inference. It is worth noting that we have not fine tuned the model on such long audio data\nand it may need further fine tuning to practically support such use cases.\nVision-speech Joint Training.\nThe vision-speech joint training is conducted after vision post-\ntraining and speech post-training. We freeze the language base model, audio encoder, and audio projec-\ntor, while finetuning the vision adapter LoRAV , vision encoder, and the vision projector. In this stage,\n5\n\nwe train the model mainly on vision-speech SFT data but we also include a mixture of language and\nvision post-training data to maintain the corresponding performance.\nReasoning Training\nRecent studies have suggested that training a robust reasoning model only\nrequires a small amount of high-quality data, such as LIMO [YHX+25] and S1K [MYS+25]. However, we\npropose a fundamentally different training paradigm for SLM: we need to conduct a pre-training phase\non extensive reasoning data to capture general reasoning chains, and then perform careful fine-tuning\non curated SFT or preference data. The continued training of Phi-4-Mini for reasoning proceeds in\nthree distinct stages. 1) First, building on Phi-4-Mini, the model is pre-trained on approximately 60\nbillion reasoning CoT tokens generated by frontier reasoning LLMs, after which rejection sampling is\nemployed to filter out incorrect outputs. This allows the reasoning extension of Phi-4-Mini to learn\nthe reasoning chains produced by these models. 2) In the second stage, the model is fine-tuned on a\nsmaller but carefully curated dataset of around 200K high-quality CoT samples, chosen to cover diverse\ndomains and varying difficulty levels. 3) Roll-Out DPO: finally, in the third stage, we label filtered\nincorrect outputs as “dis-preferred” and their corrected counterparts as ‘preferred’, compiling a new\ndataset of 300K preference samples for DPO training.\n3\nData and training details\n3.1\nLanguage training data\n3.1.1\nPre-training data\nCompared with Phi-3.5-Mini, we improved the quality of the pre-training data from several key aspects:\n1. Better data filtering: By using an enhanced quality classifier, which is trained on a larger curated\ndataset consisting of cleaner positive and negative samples, we end up with better filtering quality\nacross multiple languages with various aspects (e.g. toxic, obscure, scientific, etc.), leading to a\nmore comprehensive and controllable filtering strategy overall.\n2. Better math and coding data: For the math and coding data, we have augmented our original\ndata with a specific instruction-based math and coding data set. This enhancement has resulted\nin effective results in math, coding and reasoning.\n3. Better synthetic data: we incorporated Phi-4 synthetic data [AAB+24] into this model training\nwith the same processing and decontamination.\n4. Better data mixture: With the better classifiers, we re-tuned the data mixture with ablation\nexperiments. Especially we increased the ratio for the reasoning data. That gives us a boost for\nthe model quality.\nWith these techniques, we built the 5 trillion pre-training data corpus, which is larger and in higher\nquality compared to the Phi-3.5-Mini.\n3.1.2\nPost-training data\nCompared to Phi-3.5-Mini, Phi-4-Mini includes a significantly larger and more diverse set of func-\ntion calling and summarization data. Additionally, we synthesize a substantial amount of instruction-\nfollowing data to enhance the model’s instruction-following capabilities.\nFor coding, we incorporate\nextensive code completion data, including tasks that require the model to generate missing code in the\n6\n\nmiddle of an existing code snippet. This challenges the model to understand both the requirements and\nthe existing context, leading to significant performance improvements.\n3.1.3\nReasoning training data\nWe generate a large volume of synthetic chain-of-thought (CoT) data from larger reasoning models,\ncovering diverse domains and difficulty levels. During sampling, we employ both rule-based and model-\nbased rejection methods to discard incorrect generations and feed them back for resampling. Also, we\nlabel correct sampled answers as preferred generations and incorrect ones as dis-preferred, and create\nthe DPO data. This data has been utilized exclusively for the experimental reasoning model and has\nnot been applied to the officially released checkpoint Phi-4-Mini.\n3.2\nVision-language training data\nThe Phi-4-Multimodal model’s pre-training phase involves a rich and varied dataset, encompassing\ninterleaved image-text documents, image-text pairs, image grounding data, synthetic datasets from\nOCR of PDFs and realistic images, and synthesized datasets for chart comprehension.\nDuring this\nphase, the model’s primary focus is on predicting the next token, concentrating solely on text tokens\nand disregarding any loss associated with image tokens. The pre-training process involves a total of\n0.5T tokens, combining both visual and textual elements. Additionally, the maximum image resolution\nis capped at 1344x1344, as most training images are smaller than this size. For supervised fine-tuning\n(SFT), we utilized a combination of a text SFT dataset, publicly available multimodal instruction tuning\ndatasets, and large-scale in-house multimodal instruction tuning datasets that we developed. These\ndatasets span diverse domains and tasks, including general natural image understanding, chart, table,\nand diagram comprehension and reasoning, PowerPoint analysis, OCR, multi-image comparison, video\nsummarization, and model safety. Collectively, the multimodal SFT data comprises approximately 0.3T\ntokens.\n3.3\nVision-speech training data\nFor vision-speech data, Phi-4-Multimodal model is trained on a diverse set of synthetic vision-speech\ndata, covering single-frame and multi-frame scenarios. Specifically, we reuse a subset of vision-language\nSFT data and run in-house text-to-speech (TTS) engine to convert the user queries from texts to audios.\nThis subset is carefully selected to avoid certain datasets where the queries are not suitable to read out\nin speech. We also measure the quality of the synthetic speech by transcribing the audio with in-house\nASR model and calculating the word error rate (WER) between original text and transcription. Our\nfinal vision-speech data is generated with the WER-based filtering to ensure the quality.\n3.4\nSpeech and Audio Training Data\nThe training data for speech/audio functions can be categorized into two types: 1) pre-training data\nwith ASR transcriptions to provide a strong alignment between the speech and text modalities; 2) post-\ntraining data to unlock the instruction-following capability of Phi-4-Multimodal with the speech/au-\ndio modality involved. The post-training data covers a variety of tasks, including automatic speech\nrecognition (ASR), automatic speech translation (AST), speech question answering (SQA), spoken query\nquestion answering (SQQA), speech summarization (SSUM), and audio understanding (AU).\n7\n\n3.4.1\nPre-training Data\nDespite that the audio encoder is initialized from a well-trained ASR model as mentioned in Sec. 2.2,\nthe speech and text latent spaces differ. To pre-train the adapter and reduce the modality gap between\nthe speech and text sequences, we curate a dataset of approximately 2M hours of anonymized in-house\nspeech-text pairs with strong/weak ASR supervisions, covering the eight supported languages 3.\n3.4.2\nPost-training Data\nFollowing language post-training paradigm, we curate SFT data for speech/audio post-training, aiming\nfor unlocking the instruction-following capability with speech/audio as query or context. We use both\nthe real and synthetic speech/audio data during speech post-training, covering the majority of speech\nand audio understanding tasks. All the SFT data are formatted as:\n< ∣user∣>< audio > {task prompt} < ∣end∣>< ∣assistant∣> {label} < ∣end∣>\nwhere task prompt is to describe each task in the natural language description and it is null for the\nSQQA task.\nSpeech Recognition Data.\nASR training data contains about 20k hours anonymized in-house, and\n20k hours selected public transcribed speech recordings that span eight languages. The weighted ASR\ntraining data contributes to 28M SFT examples.\nSpeech Translation Data.\nAST training data contains about 30K hours of anonymized in-house and\npublic speech data with translations in two directions: from 7 languages to English and from English to\n7 languages. This data contains both supervised and synthetic translation from a machine translation\nmodel. The AST data is created with two formats: direct ST and ASR + translation in a Chain-of-\nthoughts (CoT) manner, contributing to 28M weighted training examples in post-training.\nSpeech and Spoken Query Question Answering Data.\nSQA and SQQA training data contain\nsynthetic QA pairs from real speech and synthetic audio from text SFT data.\n• Synthetic QA pairs for SQA: To enable SQA capability, we reuse the speech-transcript pairs in the\nASR training data and prompt the language model to generate multiple text QA pairs for each\ntranscript. The low-quality QA pairs are filtered during training.\n• Synthetic spoken query (audio) for SQQA: SQA is tasked to respond speech context plus text query.\nResponding to spoken query directly is also an important capability for Phi-4-Multimodal.\nConsequently, We sample from the language post-training data and convert the text query to\naudio query using our internal zero-shot TTS system.\n• Synthetic LM response for SQQA: Similar to [FWL+24], we synthetically generate responses for\nspeech prompts by prompting the language model with the ASR transcripts of those prompts. The\nLM response data can improve the SQQA robustness of Phi-4-Multimodal in real scenarios\nbecause of more diverse spoken queries sampled from the ASR training data.\nThe total SQA and SQAQA data contribute to 26M weighted SFT examples.\n3The speech interface supports the following 8 languages: Chinese, English, French, German, Italian, Japanese, Por-\ntuguese, and Spanish.\n8\n\nSpeech Summarization Data.\nThe summarization training data is assembled from anonymized\naudio recordings paired with their transcripts. The audio consists of multi-speaker conversational speech\nthat spans a range of topics. Rather than dividing the audio into shorter segments, we maintain its full\nlength up to a maximum of 30 minutes. To construct query-summary pairs for each audio clip, we use\nGPT-4 to generate a variety of queries and their respective summaries based on the transcripts. For\neach audio clip, the summarization queries address specific or general aspects of the conversation and\nvary in format, including length (number of words or sentences) and structure (summaries formatted\nas bullet points, JSON, or email). The weighted dataset contributes to 1M SFT examples with English\nspeech only.\nAudio Understanding Data.\nThe audio understanding data contributes to around 17M weighted\nSFT examples sourced from public. The dataset is created in the form of (audio, question, answer)\ntuples, where “audio” contains speech, audio, and music inputs. Similar to [GLL+23], the question and\nanswer pairs are generated from GPT4 based on audio transcripts and/or meta information.\nIn addition the task-specific data, we also include audio safety data in speech/audio post-training.\nPlease refer to Sec. 5.2 for the details of audio safety data. For all the public data, we utilize our Azure\nPII Detector4 to identify and handle Personally Identifiable Information (PII). The training examples\nwith PII detected are removed for privacy concerns.\n4\nEvaluation\n4.1\nMultimodal Benchmarks\n4.1.1\nVision Benchmarks\nWe report in Table 1 the evaluation results of Phi-4-Multimodal on 13 open-source academic single-\nimage vision-language benchmarks, 2 open-source multi-image/video vision-language benchmarks, and\n4 vision-speech benchmarks. Additionally, we compare Phi-4-Multimodal with multiple state-of-\nthe-art open-source models: our previous Phi-3.5-Vision [AJA+24], Qwen2.5-VL-3B & 7B [Tea25b],\nInternVL2.5-4B & 8B [CWC+24], and close-sourced multimodal models Gemini [TAB+23], Claude-\n3.5 [Ant24]5, and GPT-4o [HLG+24]6.\nFor most benchmarks, we used the same internal evaluation\npipeline as in Phi-3.5-Vision [AJA+24] to ensure fair comparisons across all baseline methods.\nFor\nbenchmarks (e.g., DocVQA and InfoVQA) requiring submission to an evaluation server, we directly\nutilized results reported in previous papers for baseline methods and submitted our own evaluations to\nthe server to obtain results for Phi-4-Multimodal.\nFor single-image vision-language benchmarks, the evaluations assess reasoning and perceptual capa-\nbilities across various domains, including but not limited to science, charts, OCR, and general knowledge.\nFor multi-image/video vision-language benchmarks, we used one multi-image benchmark (BLINK [FHL+24])\nand one video benchmark (VideoMME [FDL+24]). In the case of VideoMME, the evaluation setup is\nsame as the one used in Phi-3.5-Vision [AJA+24], where 16 frames are extracted from each video by\nsampling frames at a rate ensuring uniform time coverage. These benchmarks evaluate perceptual ca-\npabilities across multiple images/frames and text, covering scenarios such as art and style recognition,\nforensic detection, and video understanding. For vision-speech benchmarks, we adopted four existing\n4https://learn.microsoft.com/en-us/azure/ai-services/language-service/\npersonally-identifiable-information/overview\n5Claude-3.5-Sonnet-2024-10-22\n6GPT-4o-2024-11-20 and GPT-4o-mini-2024-07-18\n9\n\nPhi-4-Multimodal\n5.6B\nPhi-3.5-Vision\n4.2B\nQwen2.5-VL-3B\n3.8B\nInternVL2.5-4B\n3.7B\nQwen2.5-VL-7B\n8.3B\nInternVL2.5-8B\n8.1B\nGemini-2.0-Flash-\nLite-prv-02-05\nGemini-2.0-\nFlash\nClaude-3.5\n-Sonnet\nGPT-4o\n-mini\nGPT-4o\n-\nMMMU\n(val) [YNZ+23]\n55.1\n43.0\n47.0\n48.3\n51.8\n50.6\n54.1\n64.7\n55.8\n52.1\n61.7\nMMMUPro\n(standard/vision) [YZN+24]\n38.5\n(39.7/37.3)\n21.8\n(25.5/18.0)\n29.9\n(31.8/28.0)\n32.4\n(36.1/28.6)\n38.7\n(39.5/37.9)\n34.4\n(39.0/29.8)\n45.1\n(45.8/44.3)\n54.4\n(57.1/51.6)\n54.3\n(56.5/52.1)\n40.8\n(44.0/37.7)\n53.0\n(55.3/50.7)\nScienceQA\n(test) [LMX+22]\n97.5\n91.3\n79.4\n96.2\n87.7\n97.3\n85.0\n88.3\n81.2\n84.0\n88.2\nMathVista\n(testmini) [LBX+24]\n62.4\n43.9\n60.8\n51.2\n67.8\n56.7\n57.6\n47.2\n56.9\n38.8\n56.1\nInter-GPS\n(test) [LGJ+21]\n48.6\n36.3\n48.3\n53.7\n52.7\n54.1\n57.9\n65.4\n47.1\n39.9\n49.1\nMMBench\n(dev-en) [LDZ+24]\n86.7\n81.9\n84.3\n86.8\n87.8\n88.2\n85.0\n90.0\n86.7\n83.8\n89.0\nPOPE\n(test)\n[LDZ+23]\n85.6\n86.1\n87.9\n89.4\n87.5\n89.1\n87.5\n88.0\n82.6\n83.6\n86.5\nAI2D\n(test) [KSK+16]\n82.3\n78.1\n78.4\n80.0\n82.6\n83.0\n77.6\n82.1\n70.6\n75.2\n83.8\nChartQA\n(test) [MLT+22]\n81.4\n81.8\n80.0\n79.1\n85.0\n81.0\n73.0\n79.0\n78.4\n54.5\n75.1\nTextVQA\n(test) [SNS+19]\n75.6\n72.0\n76.8\n70.9\n77.7\n74.8\n72.9\n74.4\n58.6\n70.9\n73.1\nDocVQA\n(test) [MKJ21]\n93.2\n69.3\n93.9\n91.6\n95.7\n93.0\n91.2\n92.1\n95.2\n84.2\n90.9\nInfoVQA\n(test) [MBT+22]\n72.7\n36.6\n77.1\n72.1\n82.6\n77.6\n73.0\n77.8\n74.3\n59.5\n71.9\nOCRBench\n[LLH+24]\n84.4\n63.8\n82.2\n71.6\n87.7\n74.8\n75.7\n81.0\n77.0\n77.1\n77.7\nBLINK\n(test) [FHL+25]\n61.3\n57.0\n48.1\n51.2\n55.3\n52.5\n59.3\n64.0\n56.9\n51.9\n62.4\nVideoMME-16Frame\n(test) [FDL+24]\n55.0\n50.8\n56.5\n57.3\n58.2\n58.7\n58.8\n65.5\n60.2\n61.2\n68.2\nAverage\n72.0\n60.9\n68.7\n68.8\n73.3\n71.1\n70.2\n74.3\n69.1\n63.8\n72.4\nTable 1: Comparison results on public vision-language benchmarks. All the reported numbers are produced with\nthe exact same internal pipeline to ensure that the numbers are comparable. These numbers might differ from\nother published numbers due to slightly different prompts. ∗Note that for MathVista number of Gemini-2.0-\nFlash, we find the low performance is because its output sometimes cannot follow the format defined in the input\ninstruction and the evaluation script cannot parse the answer easily.\nPhi-4-Multimodal\n5.6B\nInternOmni\n8.7B\nGemini-2.0-Flash-\nLite-prv-02-05\nGemini-2.0-\nFlash\nShareGPT4o AI2D[CWT+24]\n68.9\n53.9\n62.0\n69.4\nShareGPT4o ChartQA[CWT+24]\n69.0\n56.1\n35.5\n51.3\nShareGPT4o DocVQA[CWT+24]\n87.3\n79.9\n76.0\n80.3\nShareGPT4o InfoVQA[CWT+24]\n63.7\n60.3\n59.4\n63.6\nAverage\n72.2\n62.6\n58.2\n66.2\nTable 2: Comparison results on public vision-speech benchmarks. All the reported numbers are produced with\nthe exact same internal pipeline to ensure that the numbers are comparable.\nbenchmarks from InternOmni [CWT+24], which convert text prompts into speech format for evaluation\non four vision-language benchmarks. Since Claude and GPT-4o endpoints do not support audio input\nalong with images, we do not report their numbers here. For Gemini models, promting with only image\nand speech input will generate free-form responses that are difficult to extract and evaluate. Therefore,\nwe add the corresponding text instructions to prompt the model to respond with one of ABCD options\nor single-word-or-phrase answers for the respective ShareGPT4o benchmark.\nFrom the results in Table 1 and Table 2, we summarize Phi-4-Multimodal’s performance as\nfollows:\n• On vision-language benchmarks, Phi-4-Multimodal demonstrates significant improvements\nover our previous model Phi-3.5-Vision [AJA+24] and outperforms baseline models of similar sizes\noverall. Notably, in chart understanding and science reasoning tasks, Phi-4-Multimodal even\nsurpasses some close-sourced models like Gemini and GPT-4o. We have shown one demo case in\nFigure 2.\n• On vision-speech benchmarks, Phi-4-Multimodal significantly outperforms InternOmni and\n10\n\nFigure\n2:\nOne\ndemo\ncase\nto\nshow\nthe\nvision-language\nunderstanding\nand\nreasoning\ncapability\nof\nPhi-4-Multimodal.\nGemini-2.0-Flash by a large margin, which have larger model sizes. For instance, on ShareGPT4o AI2D\nand ShareGPT4o ChartQA benchmarks, Phi-4-Multimodal achieves more than 10 points higher\nperformance than InternOmni.\n• Unlike other open-source vision-language models that fully fine-tune their base language models\n(often resulting in performance degradation on pure language benchmarks), Phi-4-Multimodal\nkeeps the language model entirely frozen by only incorporating additional fine-tunable LoRA mod-\nules. This approach ensures that language performance remains unchanged for pure text inputs.\nWhile some academic efforts aim to enable multimodal capabilities while preserving original lan-\nguage performance (e.g., through added cross-attention layers [AI23, DLW+24]), these techniques\noften lead to performance drops on vision-language benchmarks compared to fully fine-tuned large\nlanguage models. Our proposed LoRA solution provides a novel perspective for the community,\nmaintaining language capabilities while achieving minimal performance loss on multimodal bench-\nmarks compared to fully fine-tuned baselines.\n4.1.2\nSpeech and Audio Benchmarks\nWe evaluate the speech and audio capabilities of Phi-4-Multimodal on a variety of understand-\ning tasks. The performance of Phi-4-Multimodal is compared with several state-of-the-art open-\nsourced models for the speech and audio understanding, including WhisperV3 [RKX+23], SeamlessM4T-\nv2 [BCM+23], Qwen2-audio [CXY+24]. We also include the performance of close-sourced multi-modal\nmodels (GPT-4o [HLG+24] and Gemini [TAB+23]) for comparisons 7. The results are obtained through\n7Speech evaluations for closed models are done through Azure cloud API.\n11\n\nTable 3: Main Results on the speech benchmarks. All results are obtained with 0-shot evaluations except ad-\nditional CoT evaluations on the AST task, where CoT refers to chain-of-thoughts decoding with transcription\nplus translation in generation. MT-Bench results are averaged scores over two-turn SQA conversations. SSUM\nevaluation is with the overall numbers covering the adherence and hallucination scores. The scores in the table\nare judged by GPT-4-0613. N/A indicates the model does not have such a capability.\nPhi-4-Multimodal\nWhisperV3\nSeamlessM4T-V2\nQwen2-audio\nGemini-\nGPT-4o\nTask\nMetric\nDataset\n5.6B\n1.5B\n2.3B\n8B\n2.0-Flash\n-\nASR\nWER ↓\nCV15\n6.80\n8.13\n8.46\n8.55\n9.29\n18.14\nFLEURS\n4.00\n4.58\n7.34\n8.28\n4.73\n5.42\nOpenASR\n6.14\n7.44\n20.70\n7.43\n8.56\n15.76\nAST\nBLEU ↑\nInference Type\n(0-shot, CoT)\n0-shot\n0-shot\n0-shot\n0-shot\n0-shot\nCoVoST2 X-EN\n(39.33, 40.76)\n33.26\n37.54\n34.80\n36.62\n37.09\nCoVoST2 EN-X\n(37.82, 38.73)\nN/A\n32.84\n34.04\n35.93\n37.19\nFLEURS X-EN\n(29.86, 32.35)\n25.76\n28.87\n23.72\n30.69\n32.61\nFLEURS EN-X\n(32.15, 33.56)\nN/A\n30.44\n23.24\n37.33\n36.78\nSQQA\nScore 1-10 ↑\nMT-Bench\n7.05\nN/A\nN/A\n4.92\n8.07\n8.11\nACC ↑\nMMMLU\n38.50\nN/A\nN/A\n15.53\n72.31\n72.56\nSSUM\nScore 1-7 ↑\nGolden3\n6.28\nN/A\nN/A\n2.25\n6.29\n6.76\nAMI\n6.29\nN/A\nN/A\n1.34\n5.97\n6.53\nAU\nScore 1-10 ↑\nAirBench-chat\n6.98\nN/A\nN/A\n6.93\n6.68\n6.54\nACC ↑\nMMAU\n55.56\nN/A\nN/A\n52.50\n61.23\n53.29\nevaluation on the exact same test data version without further clarifications. We sample the top-1 token\nat each generation step during inference.\nThe main results on the speech benchmark are presented in Table 3. We summarize the performance\nof Phi-4-Multimodal as listed:\n• Phi-4-Multimodal achieves very strong ASR and AST performance, surpassing the expert ASR\nmodel, WhisperV3, and expert AST model, SeamlessM4T-large-v2, on CommonVoice [ABD+20],\nFLEURS [CMK+23], OpenASR [SMK+23], and CoVoST2 [WWGP21] test sets.\n• Phi-4-Multimodal is 5.5% relatively better in WER than the best model on the Huggingface\nOpenASR leaderboard8 and now ranks No.1 on the leaderboard as of 1/14/2025.\n• Phi-4-Multimodal is the first open-sourced model with speech summarization capability. The\nsummarization quality is close to that of GPT-4o in the sense of adherence and low hallucinations.\n• Phi-4-Multimodal is the smallest open-sourced multi-modal LLM that behaves better than the\nopen-sourced Qwen2-audio [CXY+24] with ∼2x in size.\nWe should notice in Table 3 that Phi-4-Multimodal is optimized for speech and audio under-\nstanding tasks while Gemini and GPT-4o might be optimized towards chat experience. That may be the\nreason why Phi-4-Multimodal outperforms Gemini-2.0-Flash and GPT-4o on ASR and AST tasks\nwhile lags behind on the SQQA tasks. We describe the benchmark and evaluation details for each task\nbelow.\nAutomatic Speech Recognition.\nWe evaluate the ASR performance on three public benchmarks:\nCommonVoice [ABD+20], FLEURS [CMK+23], and OpenASR [SMK+23].\n• CommonVoice is an open-source, multilingual speech dataset developed by Mozilla. The test set\nof CommonVoice version 15.0 (CV15) is adopted in our evaluation, in which the data is collected\nbefore 9/13/2023. We conduct the evaluations on the eight supported languages.\n8https://huggingface.co/spaces/hf-audio/open_asr_leaderboard\n12\n\nTable 4: Detailed results on ASR benchmarks. We compute CER (↓) for JA and ZH, and WER (↓) for other\nlanguages. nvidia/canary-1B model is the best performing model on the Huggingface OpenASR leaderboard to\ndate. The results of canary and WhisperV3 are from the official report while others are obtained through internal\nevaluation on the same test data version.\nPhi-4-Multimodal\nnvidia/canary\nWhisperV3\nSeamlessM4T-V2\nQwen2-audio\nGemini-\nGPT-4o\nDataset\nSub-Category\n5.6B\n1B\n1.5B\n2.3B\n8B\n2.0-Flash\n-\nCV15\nEN\n7.61\nN/A\n9.30\n7.65\n8.68\n11.21\n21.48\nDE\n5.13\nN/A\n5.70\n6.43\n7.61\n6.2\n10.91\nES\n4.47\nN/A\n4.70\n5.42\n5.71\n4.81\n11.24\nFR\n8.08\nN/A\n10.80\n9.75\n9.57\n10.45\n17.63\nIT\n3.78\nN/A\n5.50\n5.50\n6.78\n4.88\n13.84\nJA\n10.98\nN/A\n10.30\n12.37\n13.55\n13.46\n19.36\nPT\n6.97\nN/A\n5.90\n9.19\n10.03\n7.4\n23.07\nZH\n7.35\nN/A\n12.80\n11.36\n6.47\n15.87\n27.55\nAverage\n6.80\nN/A\n8.13\n8.46\n8.55\n9.29\n18.14\nFLEURS\nEN\n3.38\nN/A\n4.10\n6.54\n5.27\n3.96\n6.52\nDE\n3.96\nN/A\n4.90\n6.95\n8.77\n4.06\n4.17\nES\n3.02\nN/A\n2.80\n5.39\n6.90\n2.61\n3.69\nFR\n4.35\nN/A\n5.30\n7.40\n9.00\n5.06\n6.42\nIT\n1.98\nN/A\n3.00\n4.70\n5.78\n1.86\n3.28\nJA\n4.50\nN/A\n4.80\n11.47\n12.68\n4.94\n5.18\nPT\n3.98\nN/A\n4.00\n7.67\n10.59\n3.57\n6.33\nZH\n6.83\nN/A\n7.70\n8.6\n7.21\n11.74\n7.77\nAverage\n4.00\nN/A\n4.58\n7.34\n8.28\n4.73\n5.42\nOpenASR\nAMI\n11.69\n13.90\n15.95\n56.1\n15.24\n21.58\n57.76\nEarnings22\n10.16\n12.19\n11.29\n37.18\n14.09\n13.13\n20.94\nGigaspeech\n9.78\n10.12\n10.02\n26.22\n10.26\n10.71\n13.64\nSpgispeech\n3.13\n2.06\n2.01\n12.04\n3.00\n3.82\n5.66\nTedlium\n2.90\n3.56\n3.91\n19.26\n4.05\n3.01\n5.79\nLS-clean\n1.68\n1.48\n2.94\n2.60\n1.74\n2.49\n3.48\nLS-other\n3.83\n2.93\n3.86\n4.86\n4.03\n5.84\n7.97\nVoxpopuli\n5.91\n5.79\n9.54\n7.37\n7.05\n7.89\n10.83\nAverage\n6.14\n6.50\n7.44\n20.70\n7.43\n8.56\n15.76\n• FLEURS a multilingual speech dataset designed for evaluating speech recognition and speech-to-\ntext translation models across a wide range of languages. The models are evaluated on the test\nsets of the eight supported languages for ASR.\n• OpenASR Leaderboard on Hugging Face is designed for benchmarking and evaluating the robust-\nness of ASR models on English. The datasets in the leaderboard cover diverse speech domains\nincluding reading speech, conversations, meetings, and so on.\nThe ASR prompt for Phi-4-Multimodal is “Transcribe the audio clip into text.”, which is\nlanguage agnostic. We notice that the model can learn to recognize in the target language perfectly\nwithout providing language information, while Qwen2-audio and Gemini-2.0-Flash require the language\ninformation in the prompt to obtain the optimal ASR performance. For example, the ASR prompt\nfor Gemini-2.0-Flash is “Transcribe the audio clip into {tgt-lang}. Please ignore background\nnoise.” We compute the Character Error Rate (CER) for Japanese and Chinese language and Word\nError Rate (WER) for other six languages.\nThe detailed ASR results on the three benchmarks are summarized in Table 4. Overall, we achieve\nthe new SOTA multi-lingual ASR performance on the eight supported languages, surpassing the ex-\npert ASR models like WhisperV3. Noticeably, Phi-4-Multimodal beats the best performing model,\nnvidia/canary-1b, by 5.5% relative WER on the Huggingface OpenASR leaderboard and now ranks No.1\nin the leaderboard to date. Phi-4-Multimodal is also better than the open-sourced Qwen2-audio with\ndoubled model size. Note that GPT-4o is very sensitive to ASR prompt. We tried many ASR prompts\nand present the one with the best overall ASR results we can obtain on the test sets. The ASR prompt\nwe finally use is “Capture the speech in written format in the language spoken, please. Don’t\ninclude any information outside of the spoken content in your response. Remove any hes-\nitation words like um, uh. Support mixed language. Your response should be formatted\nas follows: Spoken Content: <transcribed text here>.”.\n13\n\nAutomatic Speech Translation.\nWe evaluate the AST performance on two public benchmarks:\nCoVoST2 [WWGP21] and FLEURS [CMK+23].\n• CoVoST2 is a multilingual speech-to-text translation dataset derived from Mozilla’s Common Voice\nproject. It is one of the largest open datasets available for speech translation, providing support for\nboth X-to-English (X-En) and English-to-X (En-X) translation tasks. We evaluate the directions\nwith supported languages on the test sets.\n• We use the same FLEURS test audios as those in ASR evaluation but replacing the ASR tran-\nscription with the translations. We evaluate EN-X and X-EN directions with supported languages\non the test sets.\nThe AST prompts for 0-shot and CoT evaluation are “Translate the audio to {tgt-lang}.” and\n“Transcribe the audio to text, and then translate the audio to {tgt-lang}. Use < sep > as\na separator between the original transcript and the translation.”, respectively. We compute\nBLEU score between the reference and text translations. For CoT evaluation, the text after < sep > is\nregarded as the translation.\nThe detailed AST results on each translation direction are shown in Table 5. As we can see from the\ntable, CoT inference can largely benefit the translation quality, improving 1-2 BLUE score on various\ntest sets. Phi-4-Multimodal achieves the best AST performance among the evaluated models on\nCoVoST2 benchmark, including Gemini-2.0-Flash and GPT-4o. On FLEURS, Phi-4-Multimodal is\nbetter than the expert model SeamlessM4T-large-V2 and the performance is on par with GPT-4o, the\nsize of which is much larger than Phi-4-Multimodal. We don’t apply CoT evaluation to other models\nsince either the model does not support CoT decoding, or it is hard to find a good CoT prompt for the\nmodel to respond to each test sample correctly. Similar to ASR, Phi-4-Multimodal does not require\nsource language information in the AST prompt.\nSpoken Query Question Answering.\nWe evaluate the SQQA performance on two language bench-\nmarks with synthetic audio query: MT-Bench [ZCS+23] and MMMLU [HBB+20]. The text query is\nsynthesized into the audio query with the internal zero-shot TTS system.\n• MT-Bench (Multi-turn Benchmark) is specifically designed to evaluate the conversational and\ninstruction-following abilities of AI models in multi-turn question-answering (QA) scenarios.\n• MMMLU (Multilingual Massive Multitask Language Understanding) is an extensive benchmark\ndesigned to evaluate the general knowledge and reasoning capabilities of AI models across a wide\narray of subjects. We evaluate the model on the eight supported languages for this test set.\nThe task prompt is null for the spoken query QA task. The metrics are different for the two benchmarks.\nThe answer for MT-bench is open-ended, so we use GPT-4 as a judge to score the model outputs from 1\nto 10. We evaluate the model outputs in the first two turns for MT-bench. Please refer to Appendix A\nfor the judege prompts for GPT-4. MMMLU is a QA task with multiple-choice questions. We use the\naccuracy to measure the model quality.\nWe summarize the SQQA results in Table 6. It can be seen from the table that Phi-4-Multimodal\noutperforms Qwen2-audio with doubled model size on MT-bench. However, the performance lags far\nbehind than the Gemini-2.0-Flash and GPT-4o, which show strong SQQA capability. The results on\nSQQA show that Phi-4-Multimodal is more good at conversational chat rather than general knowl-\nedge and reasoning chat (less gap to closed-source models on MT-bench than that on MMMLU). The\nreason might be that we weighed more conversational SQQA data in the speech/audio post-training\nstage.\n14\n\nTable 5: Detailed results on AST benchmarks with BLEU (↑) score reported. We use “zh”, “ja-mecab”, and\n“13a” tokenizer in Sacrebleu [Pos18] to compute BLUE scores for Chinese, Japanese, and other six languages,\nrespectively. All results are obtained through our internal evaluation.\nPhi-4-Multimodal\n(+CoT)\nWhisperV3\nSeamlessM4T-V2\nQwen2-audio\nGemini-\nGPT-4o\nDataset\nSub-Category\n5.6B\n1.5B\n2.3B\n8B\n2.0-Flash\n-\nCoVoST2 X-EN\nDE\n39.81\n40.83\n34.17\n39.90\n34.99\n38.34\n39.29\nES\n43.60\n44.84\n39.21\n42.90\n39.91\n41.74\n41.49\nFR\n42.24\n43.42\n35.43\n42.18\n38.31\n38.96\n38.56\nIT\n41.42\n42.45\n35.82\n39.85\n36.35\n37.76\n37.33\nJA\n30.54\n31.87\n23.59\n22.18\n22.98\n28.04\n30.46\nPT\n55.28\n56.25\n50.22\n53.82\n47.79\n50.81\n50.60\nZH\n22.39\n25.64\n14.36\n21.92\n23.27\n20.69\n21.93\nAverage\n39.33\n40.76\n33.26\n37.54\n34.8\n36.62\n37.09\nCoVoST2 EN-X\nDE\n34.22\n34.87\nN/A\n37.16\n29.72\n34.32\n34.38\nJA\n32.93\n34.04\nN/A\n24.94\n27.30\n32.56\n32.98\nZH\n46.30\n47.28\nN/A\n36.41\n45.09\n40.91\n44.22\nAverage\n37.82\n38.73\nN/A\n32.84\n34.04\n35.93\n37.19\nFLEURS X-EN\nDE\n37.71\n39.43\n33.49\n36.80\n32.88\n38.48\n41.03\nES\n25.33\n27.56\n22.68\n25.67\n22.40\n26.51\n29.10\nFR\n35.10\n37.42\n30.98\n33.78\n30.82\n35.18\n37.98\nIT\n26.06\n28.45\n23.00\n26.80\n22.12\n25.02\n28.51\nJA\n21.62\n25.22\n16.63\n18.63\n4.49\n23.89\n24.17\nPT\n40.80\n42.85\n37.50\n37.61\n35.38\n41.51\n43.33\nZH\n22.37\n25.49\n16.07\n22.78\n17.95\n24.27\n24.12\nAverage\n29.86\n32.35\n25.76\n28.87\n23.72\n30.69\n32.61\nFLEURS EN-X\nDE\n34.44\n35.94\nN/A\n32.35\n23.60\n37.15\n36.68\nES\n23.66\n25.09\nN/A\n23.37\n19.47\n26.40\n25.99\nFR\n37.92\n40.12\nN/A\n42.08\n27.71\n46.51\n44.26\nIT\n23.44\n24.85\nN/A\n24.55\n19.61\n29.04\n28.59\nJA\n30.67\n30.81\nN/A\n20.46\n12.38\n35.51\n33.99\nPT\n37.79\n38.94\nN/A\n42.36\n32.52\n45.34\n45.82\nZH\n37.10\n39.19\nN/A\n27.93\n27.38\n41.36\n42.16\nAverage\n32.15\n33.56\nN/A\n30.44\n23.24\n37.33\n36.78\nSpeech Summarization.\nWe evaluate the speech summarization performance on an in-house (Golden3)\nand a public (AMI [CAB+05]) benchmark.\n• Golden3 is a real-world meeting dataset, containing 108 meeting recordings with corresponding\ntranscripts, averaging 6 minutes each. The dataset is primarily in English, covering a wide range\nof topics. There are in total 1071 queries for the entire dataset, averaging 9.9 instructions for each\nconversation.\n• The AMI (Augmented Multi-Party Interaction) dataset is a comprehensive collection of meeting\nrecordings, encompassing approximately 100 hours of data. These recordings feature synchronized\naudio and video streams, including close-talking and far-field microphones, individual and room-\nview cameras, and outputs from devices like slide projectors and electronic whiteboards.\nThe\ndataset is primarily in English and includes contributions from both native and non-native speakers,\ncaptured in various rooms with distinct acoustic properties. The test split contains 20 meeting\nrecordings with average duration of 32 minutes. We test on close-talking version of audio. There\nare 10 instructions generated for each conversation, summing up to 200 for the dataset.\nTo generate the summarization instructions for the test data, GPT-4 is employed being asked to\nsummarize partial or the entire conversation or control the output style/length/structure. An example\nprompt could be “Summarize the ideas shared for making the remote control suitable for older gener-\nations.” or “Summarize in bullet points the key product specifications discussed.” The summarization\ninstructions are regarded as task prompt for multi-model LLM inference. During evaluation, we use\nGPT4 to score the response corresponding to each instruction in 3 criteria: overall quality, halluci-\nnation, and instruction adherence. The overall quality, scaled 1 to 7, measures accuracy in capturing\ndetails, coherence, and writing style. The hallucination score is a binary flag that measures whether any\n15\n\nTable 6: Result details on speech QA/summarization/audio understanding tasks for multi-modal models. The\nscores are obtained using GPT-4-0613 as a judge.\nPhi-4-Multimodal\nQwen2-audio\nGemini-\nGPT-4o\nTask\nMetric\nDataset\nSub-Category\n5.6B\n8B\n2.0-Flash\n-\nSQQA\nScore 1-10 ↑\nMT-Bench\nturn-1\n7.42\n5.07\n8.08\n8.27\nturn-2\n6.67\n4.76\n8.06\n7.94\nAVG\n7.05\n4.92\n8.07\n8.11\nACC ↑\nMMMLU\nEN\n54.25\n16.00\n74.00\n78.75\nDE\n39.50\n10.50\n78.75\n73.70\nES\n42.25\n25.00\n75.75\n78.32\nFR\n38.50\n19.25\n74.25\n76.21\nIT\n35.00\n18.50\n70.50\n71.84\nJA\n30.00\n14.25\n68.75\n67.40\nPT\n34.00\n11.25\n70.50\n70.48\nZH\n34.50\n9.50\n66.00\n63.77\nAVG\n38.50\n15.53\n72.31\n72.56\nSSUM\nScore 1-7 ↑\nGolden3\nHallucination ↓\n0.14\n0.51\n0.20\n0.09\nInstruction adherence ↑\n5.87\n2.64\n6.25\n6.73\nOverall ↑\n6.28\n2.25\n6.29\n6.76\nAMI\nHallucination ↓\n0.13\n0.96\n0.28\n0.10\nInstruction adherence ↑\n6.50\n1.40\n6.25\n6.83\nOverall ↑\n6.29\n1.34\n5.97\n6.53\nAU\nScore 1-10 ↑\nAirBench-chat\nmixed\n6.78\n6.77\n6.84\n6.00\nmusic\n6.67\n6.79\n6.33\n5.55\nsound\n7.00\n6.99\n5.62\n7.45\nspeech\n7.47\n7.18\n7.92\n7.17\nAVG\n6.98\n6.93\n6.68\n6.54\nACC ↑\nMMAU\nmusic\n52.87\n53.26\n58.33\n55.27\nsound\n60.97\n58.34\n62.60\n48.30\nspeech\n52.83\n45.90\n62.77\n56.30\nAVG\n55.56\n52.50\n61.23\n53.29\npart of the summary is fabricated or in consistent with the source content (0 represents no hallucination\nand vice versa). The adherence score, scaled 1 to 7, measures how well the response follows the instruc-\ntion in specific format, content or length requirements. During scoring, GPT4 has access to the ground\ntruth transcripts of each recording. Please refer to Appendix A for the GPT4 scoring prompt.\nWe average the scores of all responses belong to the same dataset for each criteria.\nThe de-\ntailed summarization scores are presented in Table 6. Qwen2-Audio has a 30-second cut-off for au-\ndio input, therefore it couldn’t deal with long-form audio input and appears incompetent in this task.\nPhi-4-Multimodal instead can naturally encode long-form audio in one-shot and perform speech\nunderstanding. It exhibits competitive performance on both Golden3 and AMI test sets, compared with\nGemini-2.0-Flash and GPT-4o. Considering that speech summarization data contributes only 1% of the\ndata in speech post-training, the gap can be reduced easily with finetuning on more summarization data.\nAudio Understanding.\nWe evaluate the audio understanding capability on two benchmarks: AIRBench-\nchat [YXL+24] and MMAU [STK+24].\n• AIR-Bench (Audio Instruction and Response Benchmark) is a comprehensive evaluation framework\ndesigned to test the capabilities of large audio language models. It includes both foundation and\nchat benchmarks. The chat benchmark is selected for the open-end QA style evaluation. The chat\nbenchmark includes the categories of music, sound, speech and mixed domain.\n• The MMAU (Massive Multi-Task Audio Understanding) benchmark is a comprehensive dataset\ndesigned to evaluate the capabilities of multi-modal models in audio-based understanding and\nreasoning tasks. The test sets are in the form of multiple-choices QA, covering the categories of\nmusic, sound, and speech.\nSimilar to open-ended QA as MT-bench, we use GPT-4-0613 as a judge to score the model outputs.\n16\n\nFigure 3: An example to showcase the understanding capabilities for Phi-4-Multimodal, including audio\nunderstanding, summarization, ASR, and AST.\nPlease refer to the Appendix A for the GPT4 scoring prompt. The accuracy is used to measure the\nmodel quality on MMAU.\nThe detailed results on each category for multi-model models are presented in Table 6. Although\nwe freeze the audio encoder in post-training, Phi-4-Multimodal achieves strong speech, audio, and\nmusic understanding capability on the two evaluated benchmarks, surpassing the open-sourced Qwen2-\naudio. The GPT-4o does not perform well on the audio and music understanding tasks because the\nmodels may not respond to the audio/music inputs for some test samples. In other words, GPT-4o is\neither sensitive to the prompts for audio and music understanding tasks .\nWe showcase an example for strong speech understanding capabilities of Phi-4-Multimodal in\nFigure 3.\n4.2\nLanguage benchmarks\n4.2.1\nLanguage\nWe have conducted benchmarks on various different academic datasets. We compare the scores with the\nlatest open-source models - Qwen 2.5 [YYZ+24], Llama-3.2 [DJP+24], Ministral [Mis24] and Gemma2\n[TRP+24] series.\nOverall, we observe Phi-4-Mini shows very strong performance across different\nbenchmarks as shown in Table 7.\n1. Overall performance: Across different language understanding benchmarks, Phi-4-Mini out-\nperforms similar size models size models and on-par with the models with 2 times larger. Especially,\nPhi-4-Mini outperforms most of the larger models except for Qwen2.5 7B with large margins\nas well as similar sized models.\n2. Strong Math and Reasoning capabilities: Phi-4-Mini excels on math and reasoning related\nbenchmarks thanks to the reasoning-rich synthetic data it’s trained on. For the Math benchmark,\n17\n\nPhi-4-Mini\n3.8b\nPhi-3.5-Mini\n3.8b\nLlama-3.2-Ins\n3B\nMinistral\n3B\nQwen2.5-Ins\n3B\nQwne2.5-Ins\n7B\nMinistral-2410\n8B\nLlama-3.1\n8B\nLlama-3.1\nTulu-3\n8B\nGemma2-It\n9B\nBigBench-Hard\n(0-Shot; CoT) [SRR+22, SSS+22]\n70.4\n63.1\n55.4\n51.2\n56.2\n72.4\n53.3\n63.4\n55.5\n65.7\nMMLU\n(5-Shot) [HBK+21a]\n67.3\n65.5\n61.8\n60.8\n65.0\n72.6\n63.0\n68.1\n65.0\n71.3\nMMLU-Pro\n(0-Shot; CoT) [WMZ+24]\n52.8\n47.4\n39.2\n35.3\n44.7\n56.2\n36.6\n44.0\n40.9\n50.1\nArc-C\n(10-Shot) [CCE+18]\n83.7\n84.6\n76.1\n80.3\n82.6\n90.1\n82.7\n83.1\n79.4\n89.8\nBoolQ\n(2-Shot) [CLC+19]\n81.2\n77.7\n71.4\n79.4\n65.4\n80.0\n80.5\n82.8\n79.0\n85.7\nGPQA\n(0-Shot; CoT) [RHS+23]\n30.4\n25.2\n26.6\n24.3\n24.3\n30.6\n26.3\n26.3\n29.9\n31.0\nHellaSwag\n(5-Shot) [ZHB+19]\n69.1\n72.2\n69.0\n77.2\n74.6\n80.1\n80.9\n73.5\n72.8\n80.9\nOpenBookQA\n(10-Shot) [MCKS18]\n79.2\n81.2\n72.6\n79.8\n77.6\n86.0\n80.2\n84.8\n79.8\n89.6\nPIQA\n(5-Shot) [BZGC19]\n77.6\n78.2\n68.2\n78.3\n77.2\n80.8\n76.2\n81.2\n83.2\n83.7\nSociQA\n(5-Shot) [SRC+19]\n72.5\n75.1\n68.3\n73.9\n75.3\n75.3\n77.6\n71.8\n73.4\n74.7\nTruthfulQA\n(10-Shot; MC2) [LHE22]\n66.4\n65.6\n59.2\n62.9\n64.3\n69.4\n63.0\n69.2\n64.1\n76.6\nWinoGrande\n(5-Shot) [SLBBC19]\n67.0\n72.2\n53.2\n59.8\n63.3\n71.1\n63.1\n64.7\n65.4\n74.0\nMultilingual-MMLU\n(5-Shot) [HBK+21a, DLVNN+23]\n49.3\n55.4\n48.1\n46.4\n55.9\n64.4\n53.7\n56.2\n54.5\n63.8\nMGSM\n(0-Shot; CoT) [CKB+21, SSF+22]\n63.9\n47.9\n49.6\n44.6\n53.5\n64.5\n58.3\n56.7\n58.6\n75.1\nGSM-8K\n(8-Shot; CoT) [CKB+21]\n88.6\n86.2\n75.6\n80.1\n80.6\n88.7\n81.9\n82.4\n84.3\n84.9\nMATH\n(0-Shot; CoT) [HBK+21b]\n64.0\n48.5\n46.7\n41.8\n61.7\n60.4\n41.6\n47.6\n46.1\n51.3\nQasper\n(0-shot) [DLB+21]\n40.4\n41.9\n33.4\n35.3\n32.1\n38.1\n37.4\n37.2\n35.4\n13.9\nSQuALITY\n(0-shot) [WPC+22]\n22.8\n25.3\n25.7\n25.5\n25.3\n10.0\n24.9\n26.2\n26.7\n23.6\nIFEval\n(0-shot) [ZLM+23]\n70.1\n50.6\n68.0\n47.5\n59.0\n69.5\n52.5\n74.1\n77.3\n73.2\nBFCL\n(0-shot) [YMJ+24]\n70.3\n66.1\n78.6\n61.4\n74.2\n81.3\n74.0\n77.0\n59.4\n59.9\nHumanEval\n(0-Shot) [CTJ+21]\n74.4\n70.1\n62.8\n72.0\n72.0\n75.0\n70.7\n66.5\n62.8\n63.4\nMBPP\n(3-Shot) [AON+21]\n65.3\n70.0\n67.2\n65.1\n65.3\n76.3\n68.9\n69.4\n63.9\n69.6\nAverage\n64.9\n62.3\n58.0\n58.3\n61.4\n67.9\n61.2\n63.9\n61.7\n66.0\nTable 7: Phi-4-Mini language benchmark scores in comparison with Llama 3.2, Llama 3.1-8B, Qwen 2.5,\nMinistral and Gemma series.\n18\n\nPhi-4-Mini\n3.8b\nPhi-3.5-Mini\n3.8b\nLlama-3.2-Ins\n3B\nMinistral\n3B\nQwen2.5-Ins\n3B\nQwne2.5-Ins\n7B\nMinistral-2410\n8B\nLlama-3.1\n8B\nLlama-3.1\nTulu-3\n8B\nGemma2-It\n9B\nBigCodeBench\nCompletion\n(0-Shot) [ZVC+24]\n43.0\n40.4\n25.7\n50.0\n33.8\n43.4\n47.4\n34.1\n30.4\n40.6\nBigCodeBench\ninstruct\n(0-Shot) [ZVC+24]\n33.8\n14.3\n18.6\n33.8\n25.0\n33.5\n35.6\n34.8\n28.0\n33.6\nHumanEval\n(0-Shot) [CTJ+21]\n74.4\n70.1\n62.8\n72.0\n72.0\n75.0\n70.7\n66.5\n62.8\n63.4\nHumanEval+\n(0-Shot) [LXWZ23]\n68.3\n62.8\n51.8\n67.5\n64.6\n68.9\n70.7\n57.3\n50.0\n54.3\nLCB\n(05-09-2024) [JHG+24]\n19.9\n15.7\n9.9\n7.3\n14.7\n19.9\n16.2\n16.8\n17.8\n14.7\nLiveBench\n(code task) [WDR+24]\n30.5\n18.3\n14.8\n14.8\n22.7\n38.3\n25.0\n18.8\n22.7\n23.4\nMBPP\n(3-Shot) [AON+21]\n65.3\n70.0\n67.2\n65.1\n65.3\n76.3\n68.9\n69.4\n63.9\n69.6\nMBPP+\n(3-Shot) [LXWZ23]\n63.8\n63.8\n52.9\n60.8\n60.6\n65.9\n61.6\n11.4\n55.3\n63.5\nSpider\n(4-Shot) [YZY+18]\n42.2\n47.0\n51.5\n42.1\n24.8\n48.2\n22.1\n61.6\n43.4\n44.7\nAverage\n49.0\n44.7\n39.5\n45.9\n42.6\n52.2\n46.5\n41.2\n41.6\n45.3\nTable 8: Phi-4-Mini coding performance comparison with Llama 3.2, Llama 3.1-8B, Qwen 2.5, Ministral and\nGemma models.\nthe model outperforms similar sized model with large margins sometimes more 20 points. It even\noutperforms two times larger models’ scores.\n3. Excellent instruction following and function calling performance:\nCompared to the\npredecessor Phi-3.5-Mini, Phi-4-Mini shows significantly improved performance on instruction\nfollowing and function calling thanks to the curated data and improved post-training.\n4. Strong coding performance: Phi-4-Mini’s strong reasoning capabilities are also shown on\nthe coding tasks thanks to the curated organic and synthetic data. In the HumanEval benchmark,\nPhi-4-Mini outperforms most of the similar sized and two times larger sized models.\n4.2.2\nCoding\nIn Phi-4-Mini training, we have put special emphasis on the coding capability. We have collected\nhigh quality code data and generated various code related data. As a result, Phi-4-Mini shows very\nstrong performance on coding tasks as shown in the Table 8. Across 9 different coding benchmarks,\nPhi-4-Mini outperforms all 3B sized model and 8B sized model except for Qwen2.5 on the average\nscore.\n4.2.3\nCoT Reasoning\nWe evaluate the reasoning performance of a reasoning-enhanced model that we have trained over\nPhi-4-Mini. We show results on AIME 2024 [MAA24], MATH-500 [LKB+23], and GPQA Diamond\n[RHS+], comparing it against OpenAI reasoning models and several recent, larger reasoning models from\nDeepseek and others. Despite having only 3.8B parameters, Phi-4-Mini reasoning-enhanced model\noutperforms DeepSeek-R1-Distill-Llama-8B [GYZ+25], Bespoke-Stratos-7B [Lab25], OpenThinker-7B\n[Tea25a], and achieves performance comparable to DeepSeek-R1-Distill-Qwen-7B as shown in the Ta-\nble 9. Moreover, we present an ablation study that shows the effectiveness of our training process for\nreasoning-enhanced Phi-4-Mini.\n19\n\nModel\nAIME\nMATH-500\nGPQA Diamond\no1-mini*\n63.6\n90.0\n60.0\nDeepSeek-R1-Distill-Qwen-7B\n53.3\n91.4\n49.5\nDeepSeek-R1-Distill-Llama-8B\n43.3\n86.9\n47.3\nBespoke-Stratos-7B*\n20.0\n82.0\n37.8\nOpenThinker-7B*\n31.3\n83.0\n42.4\nLlama-3.2-3B-Instruct\n6.7\n44.4\n25.3\nPhi-4-Mini\n10.0\n71.8\n36.9\n+ Distill Pre-training\n30.0\n82.9\n42.6\n+ Distill Fine-tuning\n43.3\n89.3\n48.3\n+ Roll-Out DPO (final reasoning-enhanced Phi-4-Mini)\n50.0\n90.4\n49.0\nTable 9: CoT Reasoning results of reasoning-enhanced Phi-4-Mini compared with larger 7B reasoning models\nand OpenAI models. An asterisk (*) indicates results taken directly from the published reports, while the remaining\nresults were reproduced in our work.\n5\nSafety\nPhi-4-Mini and Phi-4-Multimodal were developed in accordance with Microsoft’s responsible AI\nprinciples. The overall approach consisted of safety alignment in post-training, red-teaming, automated\ntesting and evaluations across dozens of RAI harm categories.\n5.1\nText safety\nOur approach was almost identical to the one described in the Phi-3 Technical Report [AJA+24]. Further\ndetails can be found in the Phi-3 Safety Paper [Mic24]. The main improvement was to extend our Safety\npost-training datasets to all Tier 1 languages by performing (and verifying) machine translation with a\nGPT-4o-mini model.\nHelpfulness and harmlessness preference datasets [BJN+22, JLD+23] with modifications inspired by\n[BSA+24] and multiple in-house generated datasets were leveraged to address the RAI harm categories\nin safety post-training.\nAn independent red team at Microsoft iteratively examined Phi-4-Mini to further identify areas of\nimprovement during the post-training process. Based on their feedback, we curated additional datasets\ntailored to address their insights, thereby refining the post-training dataset.\nSystematic Safety evaluations were carried out as described in the Phi-3 Safety Paper [Mic24]. The\nmain difference lied with our evaluations for Harmful Content, which now leverage Microsoft’s Azure AI\nEvaluation SDK. We used GPT-4o to simulate adversarial conversations with our model, and to evaluate\nthe model’s responses toxicity along four harm categories: Violence, Sexual Content, Self-Harm, and\nHateful Content. We then computed a Defect Rate for each category - the fraction of responses that did\ncontain harmful content. Table 10 shows that our models are on par with other models of similar size,\nand with our previously released Phi-3.5-mini (which is not surprising, due to the similar approach for\nsafety alignment).\nTo assess the vulnerability of the model to jailbreaks (JB’s), we repeated the previous evaluation\nwhile prepending the simulated user prompts with known JB’s. The results shown in table 11 allow us\nto draw 2 conclusions. First, our latest Phi models are more robust to jailbreaks than our previously\nreleased Phi-3.5-mini, and than other models of similar size. Second, our models seem to manage to\ndetect the presence of JB’s, and in such cases are even less likely to comply with prompts eliciting harmful\nresponses. This can be seen from the Defect Rates being smaller than the ones obtained without JB’s\nshown in table 10.\nTo assess the ability of the model to refuse answering harmful prompts without sacrificing the ability\n20\n\nDefect Rate\nPhi-4-Mini\nPhi-4-Multimodal\nPhi-3.5-mini\nGPT-4o-mini\nLlama-3.2-3B\nQwen-2.5-3B\nViolence\n6%\n7%\n7%\n6%\n8%\n7%\nSexual\n6%\n6%\n7%\n7%\n8%\n6%\nSelf-Harm\n0%\n0%\n0%\n1%\n1%\n1%\nHateful\n3%\n3%\n2%\n3%\n3%\n3%\nAverage\n3.75%\n4%\n4%\n4.25%\n5%\n4.25%\nTable 10: RAI benchmark results for Phi-4-Mini, Phi-4-Multimodal, Phi-3.5-mini, and other models of\nsimilar size. The Defect Rate denotes the fraction of model responses containing harmful content. The last row\nshows the average Defect Rates across all 4 harm categories.\nJB Defect Rate\nPhi-4-Mini\nPhi-4-Multimodal\nPhi-3.5-mini\nGPT-4o-mini\nLlama-3.2-3B\nQwen-2.5-3B\nViolence\n2%\n4%\n11%\n7%\n11%\n20%\nSexual\n1%\n3%\n8%\n7%\n8%\n14%\nSelf-Harm\n0%\n0%\n1%\n1%\n1%\n3%\nHateful\n2%\n2%\n10%\n6%\n12%\n19%\nAverage\n1.25%\n2.25%\n7.5%\n5.25%\n8%\n14%\nTable 11: RAI benchmark results for Phi-4-Mini, Phi-4-Multimodal, Phi-3.5-mini, and other models of\nsimilar size. The Defect Rate denotes the fraction of model responses containing harmful content, when known\njailbreaks are included in the user prompts.\nThe last row shows the average Defect Rates across all 4 harm\ncategories.\nto answer seemingly harmful but innocuous prompts, we leveraged the XSTest framework described in\n[RKV+23]. Two metrics were computed: the Refusal Rate to harmful prompts (IPRR a.k.a. Inap-\npropriate Prompt Refusal Rate - the higher, the better) and the Refusal Rate to innocuous prompts\n(VPRR a.k.a. Valid Prompt Refusal Rate - the lower, the better). Results for Phi models and some\ncompetitor models are shown in table 12. Two conclusions can be drawn. First, both Phi-4-Mini and\nPhi-4-Multimodal are very good at refusing to answer harmful prompts. Second, when it comes to\nanswering innocuous prompts, Phi-4-Multimodal errs a little more on the safety side compared to\nthe rest of the field.\nRefusal Rate\nPhi-4-Mini\nPhi-4-Multimodal\nPhi-3.5-mini\nLlama-3.2-3B\nQwen-2.5-3B\nIPRR ↑\n93.5%\n92%\n87%\n92.5%\n92%\nVPRR ↓\n20.8%\n26.4%\n21.2%\n15.6%\n25.6%\nTable 12: XSTest benchmark results for Phi-4-Mini, Phi-4-Multimodal, Phi-3.5-mini, and other models of\nsimilar size. IPRR is the Refusal Rate to inappropriate prompts (e.g. ”How can I kill my neighbor?”) - the higher,\nthe better. VPRR is the Refusal Rate to valid prompts (e.g. ”How can I kill a python process?”) - the lower, the\nbetter.\nWe also evaluated the models’ tendency to produce harmful content across all Tier 1 languages by\nfollowing the approach described above, that leverages the Azure AI Evaluation SDK. Defect Rates can\nbe seen in table 13, where the numbers were averaged over the 4 harm categories (Violence, Sexual\nContent, Self-Harm, and Hateful Content) to produce a single number per language. These results show\nan improvement for both Phi-4-Mini and Phi-4-Multimodal compared to Phi-3.5-mini, and show\ncomparable performance to other competitor models.\n5.2\nAudio safety\nFor the audio safety alignment of Phi-4-Multimodal, we followed an approach analogous to that\nof text safety alignment described above. Our audio safety datasets were obtained by performing TTS\n21\n\nLanguage\nPhi-4-Mini\nPhi-4-Multimodal\nPhi-3.5-mini\nGPT-4o-mini\nLlama-3.2-3B\nQwen-2.5-3B\nGerman\n3.25%\n4.5%\n6.75%\n3.75%\n4.5%\n7%\nFrench\n3.25%\n5%\n6%\n4.25%\n4.25%\n5.5%\nSpanish\n3%\n4.5%\n6.25%\n4.25%\n4.25%\n5.5%\nItalian\n2.25%\n4.75%\n6.25%\n3.75%\n4.25%\n5.5%\nPortuguese\n4.5%\n5.5%\n6%\n5.25%\n4.25%\n5.25%\nChinese\n6.25%\n6.5%\n8.5%\n4.5%\n4.75%\n6.5%\nJapanese\n5%\n5.75%\n6.75%\n3%\n5.75%\n5.75%\nAverage\n3.91%\n5.06%\n6.31%\n4.13%\n4.63%\n5.66%\nTable 13: Defect Rates for production of harmful content for Phi-4-Mini, Phi-4-Multimodal, Phi-3.5-mini,\nand other models. The lower the value, the better. The last row shows the average across all Tier 1 languages\n(including English numbers from table 10).\n(Text-To-Speech) synthesis on our text safety datasets. We want to acknowledge two limitations of this\napproach.\n1. Our audio safety datasets are voice-only. No other types of sounds (non-speech) were included.\n2. We did not train against audio-specific jailbreaks.\nFor audio safety evaluations, we carried out three families of automated evaluations. First, like we did\nwith text inputs, we leveraged Microsoft’s Azure AI Evaluation SDK to detect the presence of harmful\ncontent in the model’s responses to speech prompts. The Defect Rates are shown in table 14. Although\nsomewhat higher than those obtained with GPT-4o (a model of much bigger size), they are comparable\nto those shown in table 10 for text inputs.\nDefect Rate\nPhi-4-Multimodal\nGPT-4o\nViolence\n4%\n2%\nSexual\n4%\n1%\nSelf-Harm\n1%\n1%\nHateful\n4%\n0%\nAverage\n3.25%\n1%\nTable 14: RAI benchmark results for Phi-4-Multimodal and GPT-4o. The Defect Rate denotes the fraction\nof model responses containing harmful content, when the input prompt was an audio trace. The last row shows\nthe average Defect Rates across all 4 harm categories.\nSecond, we ran Microsoft’s Speech Fairness evaluation to verify that Speech-To-Text transcription\nworked well across a variety of demographics - as measured by the WER metric. The audio samples\nwere spread across 2 gender sub-groups, and 3 age sub-groups (17-30, 31-45, and 46-65). The following\nlocales (corresponding to Tier 1 languages) were considered: it-IT, fr-FR, ja-JP, es-MX, pt-BR, es-ES,\nzh-CN, en-US, en-GB, and de-DE.\nNo sub-group with egregiously worse performance than the overall population was found.\nSome\nsub-groups did have slightly better/worse performance than the overall population in their given locale.\nThe sub-groups with slightly better performance than the overall population were: it-IT 17-30, es-MX\n46-65, es-ES 17-30, en-US Female, en-US 46-65, and de-DE 46-65. The sub-groups with slightly worse\nperformance than the overall population were: en-US Male and es-MX 17-30.\nThird, we implemented a custom evaluation to assess whether the model would infer Sensitive At-\ntributes (SA’s) from the voice of a user - ideally, it should not.\nThe 12 SA’s were: Race, Sexual\n22\n\nOrientation, Political Orientation, Religious Beliefs, Trade Union Membership, Personality Character-\nistics, Age, Gender, Medical Conditions, Country or Region of Origin, Social Economic Status, and\nProfession). We used a variety of voices and prepared hundreds of audio prompts containing a “prompt\nseed”, and an explicit ask for the model to infer the SA. Prompt seeds were either a generic truth (e.g.\n“Fire is hot.”) or a first-person statement about the user that had no obvious relation to the SA (e.g.\n“I am 6 feet tall.”). We then used GPT-4 to determine whether the model responses did contain an\ninference of the SA’s.\nThe results were as follows. Without any additional mitigation measure, Phi-4-Multimodal per-\nformed the inference of SA (ISA) on 27% of our test prompts – less frequently than Qwen2-Audio (49%).\nFor both models, Personality Characteristics and Country or Region of Origin were the SA’s most likely\nto be inferred. ISA can be very well mitigated for Phi-4-Multimodal by using a system prompt,\nwhich brings down the Defect Rate to 0.4% - comparable to the 2% we measured for GTP-4o deployed\nto a real-time audio endpoint that uses Microsoft’s meta prompt to prevent ISA.\nIn addition to these automated evaluations, extensive red teaming was performed by an independent\ngroup within Microsoft. The red teaming effort focused on the following safety areas: harmful content,\nself-injury risks, and exploits. Phi-4-Multimodal was found to be more susceptible to providing\nundesirable outputs when attacked with context manipulation or persuasive techniques. These findings\napply to all languages, with the susceptibility to persuasive techniques mostly affecting French and\nItalian.\n5.3\nVision safety\nTo assess model safety in scenarios involving both text and images, we utilized Microsoft’s Azure AI\nEvaluation SDK. This tool enables the simulation of single-turn conversations with the target model by\nproviding prompt text and images specifically designed to elicit harmful responses. The target model’s\nresponses are then evaluated by a fine-tuned GPT-4o model across multiple harm categories, including\nviolence, sexual content, self-harm, hateful or unfair content. Each response is assigned a severity score\nbased on the level of harm identified. We compared the vision safety evaluation of Phi-4-Multimodal\nwith those of Phi-3.5-Vision, open-source models of comparable size, as well as OpenAI models.\nIn addition, we ran both an internal and the public RTVLM [LLY+24] and VLGuard [ZBY+24] multi-\nmodal (text & vision) RAI benchmarks. In table 15, we compare vision safety metrics of Phi-4-Multimodal\nwith Phi-3.5-Vision, the open-source models Llava-1.6 [LLL+24] and Qwen-VL-Chat [BBY+23], as well\nas GPT4-V [Ope23].\nText & Vision\nSafety Evaluation\nPhi-4-Multimodal\nPhi-3.5-Vision\nLlava-1.6 Vicuna\nQwen-VL-Chat\nGPT4-V\nInternal (private)\n7.96\n8.16\n5.44\n7.27\n8.55\nRTVLM (public)\n6.39\n5.44\n3.86\n4.78\n6.81\nVLGuard (public)\n8.91\n9.10\n5.62\n8.33\n8.90\nTable 15: Model safety evaluation for vision and text scenarios using public and private multi-modal RAI bench-\nmarks. Note that all metrics in the table are bound between [0,10], with higher values indicating safer models.\n6\nWeaknesses and limitations\nDue to the model size limitation, the model could not remember some specific facts such as information\nof Olympic games results. Also, multilingual capability is limited by the number of model parameters.\n23\n\nAs we emphasize more on the coding data, multilingual data ratio went down. This results in worse\nperformance on other languages than English.\nLike every other model, both Phi-4-Mini and Phi-4-Multimodal can sometimes output un-\ndesirable content. We stress the importance for developers to implement application-level measures to\nfurther mitigate the impact of harmful responses. Mitigation strategies include (but are not limited to)\nsystem prompts, content filters, etc.\nPhi-4-Multimodal is not designed or intended to be used as a biometric categorization system\nto categorize individuals based on their biometric data to deduce or infer their race, political opinions,\ntrade union membership, religious or philosophical beliefs, sex life, or sexual orientation.\nReferences\n[AAB+24]\nMarah Abdin, Jyoti Aneja, Harkirat Behl, S´ebastien Bubeck, Ronen Eldan, Suriya Gu-\nnasekar, Michael Harrison, Russell J Hewett, Mojan Javaheripi, Piero Kauffmann, et al.\nPhi-4 technical report. arXiv preprint arXiv:2412.08905, 2024.\n[ABD+20]\nRosana Ardila, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael Hen-\nretty, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber.\nCommon\nvoice: A massively-multilingual speech corpus. In Proceedings of the Twelfth Language\nResources and Evaluation Conference, pages 4218–4222, Marseille, France, May 2020. Eu-\nropean Language Resources Association.\n[ADL+22]\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson,\nKarel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. Flamingo: a\nvisual language model for few-shot learning. Advances in neural information processing\nsystems, 35:23716–23736, 2022.\n[AI23]\nMeta AI. Introducing meta llama 3: The most capable openly available llm to date, 2023.\n[AJA+24]\nMarah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah,\nHany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al. Phi-3\ntechnical report: A highly capable language model locally on your phone. arXiv preprint\narXiv:2404.14219, 2024.\n[ALTdJ+23]\nJoshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebr´on,\nand Sumit Sanghai. Gqa: Training generalized multi-query transformer models from multi-\nhead checkpoints. arXiv preprint arXiv:2305.13245, 2023.\n[Ant24]\nAI Anthropic. The claude 3 model family: Opus, sonnet, haiku. Claude-3 Model Card,\n2024.\n[AON+21]\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski,\nDavid Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton.\nProgram synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021.\n[BBC+24]\nJohan Bjorck, Alon Benhaim, Vishrav Chaudhary, Furu Wei, and Xia Song.\nScaling\noptimal lr across token horizons, 2024.\n[BBY+23]\nJinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin,\nChang Zhou, and Jingren Zhou. Qwen-vl: A frontier large vision-language model with\nversatile abilities. arXiv preprint arXiv:2308.12966, 2023.\n24\n\n[BCM+23]\nLo¨ıc Barrault, Yu-An Chung, Mariano Cora Meglioli, David Dale, Ning Dong, Paul-\nAmbroise Duquenne, Hady Elsahar, Hongyu Gong, Kevin Heffernan, John Hoffman, et al.\nSeamlessm4t-massively multilingual & multimodal machine translation. arXiv preprint\narXiv:2308.11596, 2023.\n[BJN+22]\nYuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,\nDawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Ka-\ndavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-\nDodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt,\nNeel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish,\nChris Olah, Ben Mann, and Jared Kaplan. Training a helpful and harmless assistant with\nreinforcement learning from human feedback, 2022.\n[BSA+24]\nFederico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul R¨ottger, Dan Jurafsky, Tat-\nsunori Hashimoto, and James Zou. Safety-tuned llamas: Lessons from improving the safety\nof large language models that follow instructions, 2024.\n[BZGC19]\nYonatan Bisk, Rowan Zellers, Jianfeng Gao, and Yejin Choi.\nPiqa: Reasoning about\nphysical commonsense in natural language. arXiv preprint arXiv:1911.11641, 2019.\n[CAB+05]\nJean Carletta, Simone Ashby, Sebastien Bourban, Matthew Flynn, Mael Guillemot,\nThomas Hain, Jaroslav Kadlec, Vasilis Karaiskos, Wessel Kraaij, Melissa Kronenthal, et al.\nThe ami meeting corpus: A pre-announcement. In International Workshop on Machine\nLearning for Multimodal Interaction, pages 28–39. Springer, 2005.\n[CCE+18]\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa\nSchoenick, and Oyvind Tafjord.\nThink you have solved question answering?\ntry arc,\nthe ai2 reasoning challenge, 2018.\n[CKB+21]\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz\nKaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher\nHesse, and John Schulman. Training verifiers to solve math word problems. arXiv preprint\narXiv:2110.14168, 2021.\n[CLC+19]\nChristopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and\nKristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions.\nIn Proceedings of the 2019 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short\nPapers), pages 2924–2936, 2019.\n[CMK+23]\nAlexis Conneau, Min Ma, Simran Khanuja, Yu Zhang, Vera Axelrod, Siddharth Dalmia,\nJason Riesa, Clara Rivera, and Ankur Bapna. Fleurs: Few-shot learning evaluation of\nuniversal representations of speech. In 2022 IEEE Spoken Language Technology Workshop\n(SLT), pages 798–805. IEEE, 2023.\n[CTJ+21]\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto,\nJared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray,\nRaul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela\nMishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\nKaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave\nCummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss,\n25\n\nWilliam Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin,\nSuchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan\nLeike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam\nMcCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models\ntrained on code, 2021.\n[CWC+24]\nZhe Chen, Weiyun Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Erfei Cui, Jinguo Zhu,\nShenglong Ye, Hao Tian, Zhaoyang Liu, et al.\nExpanding performance boundaries of\nopen-source multimodal models with model, data, and test-time scaling. arXiv preprint\narXiv:2412.05271, 2024.\n[CWT+24]\nZhe Chen, Weiyun Wang, Hao Tian, Shenglong Ye, Zhangwei Gao, Erfei Cui, Wenwen\nTong, Kongzhi Hu, Jiapeng Luo, Zheng Ma, et al.\nHow far are we to gpt-4v?\nclos-\ning the gap to commercial multimodal models with open-source suites. arXiv preprint\narXiv:2404.16821, 2024.\n[CWW+24]\nZhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong,\nQinglong Zhang, Xizhou Zhu, Lewei Lu, et al. Internvl: Scaling up vision foundation\nmodels and aligning for generic visual-linguistic tasks. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition, pages 24185–24198, 2024.\n[CXY+24]\nYunfei Chu, Jin Xu, Qian Yang, Haojie Wei, Xipin Wei, Zhifang Guo, Yichong Leng,\nYuanjun Lv, Jinzheng He, Junyang Lin, et al.\nQwen2-audio technical report.\narXiv\npreprint arXiv:2407.10759, 2024.\n[DCL+24]\nMatt Deitke, Christopher Clark, Sangho Lee, Rohun Tripathi, Yue Yang, Jae Sung Park,\nMohammadreza Salehi, Niklas Muennighoff, Kyle Lo, Luca Soldaini, et al. Molmo and\npixmo: Open weights and open data for state-of-the-art multimodal models. arXiv preprint\narXiv:2409.17146, 2024.\n[DJP+24]\nAbhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle,\nAiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3\nherd of models. arXiv preprint arXiv:2407.21783, 2024.\n[DLB+21]\nPradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan, Noah A. Smith, and Matt Gardner. A\ndataset of information-seeking questions and answers anchored in research papers. 2021.\n[DLVNN+23] Viet Dac Lai, Chien Van Nguyen, Nghia Trung Ngo, Thuat Nguyen, Franck Dernoncourt,\nRyan A Rossi, and Thien Huu Nguyen. Okapi: Instruction-tuned large language models\nin multiple languages with reinforcement learning from human feedback. arXiv e-prints,\npages arXiv–2307, 2023.\n[DLW+24]\nWenliang Dai, Nayeon Lee, Boxin Wang, Zhuolin Yang, Zihan Liu, Jon Barker, Tuomas\nRintamaki, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. Nvlm: Open frontier-\nclass multimodal llms. arXiv preprint arXiv:2409.11402, 2024.\n[DZZ+24a]\nYiran Ding, Li Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang\nXu, Fan Yang, and Mao Yang. Longrope: Extending llm context window beyond 2 million\ntokens, 2024.\n26\n\n[DZZ+24b]\nXiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, Linke Ouyang, Xilin Wei,\nSongyang Zhang, Haodong Duan, Maosong Cao, et al. Internlm-xcomposer2: Mastering\nfree-form text-image composition and comprehension in vision-language large model. arXiv\npreprint arXiv:2401.16420, 2024.\n[FDL+24]\nChaoyou Fu, Yuhan Dai, Yondong Luo, Lei Li, Shuhuai Ren, Renrui Zhang, Zihan Wang,\nChenyu Zhou, Yunhang Shen, Mengdan Zhang, et al. Video-mme: The first-ever com-\nprehensive evaluation benchmark of multi-modal llms in video analysis. arXiv preprint\narXiv:2405.21075, 2024.\n[FHL+24]\nXingyu Fu, Yushi Hu, Bangzheng Li, Yu Feng, Haoyu Wang, Xudong Lin, Dan Roth,\nNoah A Smith, Wei-Chiu Ma, and Ranjay Krishna. Blink: Multimodal large language\nmodels can see but not perceive. arXiv preprint arXiv:2404.12390, 2024.\n[FHL+25]\nXingyu Fu, Yushi Hu, Bangzheng Li, Yu Feng, Haoyu Wang, Xudong Lin, Dan Roth,\nNoah A Smith, Wei-Chiu Ma, and Ranjay Krishna. Blink: Multimodal large language\nmodels can see but not perceive. In European Conference on Computer Vision, pages\n148–166. Springer, 2025.\n[FWL+24]\nYassir Fathullah, Chunyang Wu, Egor Lakomkin, Ke Li, Junteng Jia, Yuan Shangguan,\nJay Mahadeokar, Ozlem Kalinli, Christian Fuegen, and Mike Seltzer. Audiochatllama:\nTowards general-purpose speech abilities for llms. In Proceedings of the 2024 Conference\nof the North American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies (Volume 1: Long Papers), pages 5522–5532, 2024.\n[GLL+23]\nYuan Gong, Alexander H Liu, Hongyin Luo, Leonid Karlinsky, and James Glass. Joint\naudio and speech understanding. In 2023 IEEE Automatic Speech Recognition and Un-\nderstanding Workshop (ASRU), 2023.\n[GQC+20]\nAnmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei\nHan, Shibo Wang, Zhengdong Zhang, Yonghui Wu, and Ruoming Pang.\nConformer:\nConvolution-augmented transformer for speech recognition. In 21st Annual Conference\nof the International Speech Communication Association, Interspeech 2020, Virtual Event,\nShanghai, China, October 25-29, 2020, pages 5036–5040. ISCA, 2020.\n[GYZ+25]\nDaya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qi-\nhao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning\ncapability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025.\n[HBB+20]\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and\nJacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint\narXiv:2009.03300, 2020.\n[HBK+21a]\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,\nDawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the\nMATH dataset, 2021.\n[HBK+21b]\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,\nDawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the\nmath dataset. NeurIPS, 2021.\n27\n\n[HLG+24]\nAaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan\nClark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card.\narXiv preprint arXiv:2410.21276, 2024.\n[HSW+22]\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,\nLu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In\nInternational Conference on Learning Representations, 2022.\n[HWY+24]\nWeiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai,\nXiyang Dai, Dongdong Chen, Chong Luo, et al.\nLlm2clip: Powerful language model\nunlock richer visual representation. arXiv preprint arXiv:2411.04997, 2024.\n[JHG+24]\nNaman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida\nWang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica. Livecodebench: Holistic\nand contamination free evaluation of large language models for code.\narXiv preprint\narXiv:2403.07974, 2024.\n[JLD+23]\nJiaming Ji, Mickel Liu, Juntao Dai, Xuehai Pan, Chi Zhang, Ce Bian, Chi Zhang, Ruiyang\nSun, Yizhou Wang, and Yaodong Yang. Beavertails: Towards improved safety alignment\nof llm via a human-preference dataset, 2023.\n[KSK+16]\nAniruddha Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi, and\nAli Farhadi. A diagram is worth a dozen images, 2016.\n[Lab25]\nBespoke Labs.\nBespoke-stratos:\nThe unreasonable effectiveness of reasoning distilla-\ntion. https://www.bespokelabs.ai/blog/bespoke-stratos-the-unreasonable-effectiveness-of-\nreasoning-distillation, 2025. Accessed: 2025-01-22.\n[LBX+24]\nPan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao\nCheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao. Mathvista: Evaluating mathe-\nmatical reasoning of foundation models in visual contexts, 2024.\n[LDZ+23]\nYifan Li, Yifan Du, Kun Zhou, Jinpeng Wang, Wayne Xin Zhao, and Ji-Rong Wen.\nEvaluating object hallucination in large vision-language models, 2023.\n[LDZ+24]\nYuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhang, Wangbo Zhao, Yike\nYuan, Jiaqi Wang, Conghui He, Ziwei Liu, Kai Chen, and Dahua Lin. Mmbench: Is your\nmulti-modal model an all-around player?, 2024.\n[LGJ+21]\nPan Lu, Ran Gong, Shibiao Jiang, Liang Qiu, Siyuan Huang, Xiaodan Liang, and Song-\nChun Zhu. Inter-gps: Interpretable geometry problem solving with formal language and\nsymbolic reasoning, 2021.\n[LHE22]\nStephanie Lin, Jacob Hilton, and Owain Evans. Truthfulqa: Measuring how models mimic\nhuman falsehoods, 2022.\n[LKB+23]\nHunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy\nLee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step.\narXiv preprint arXiv:2305.20050, 2023.\n[LLH+24]\nYuliang Liu, Zhang Li, Mingxin Huang, Biao Yang, Wenwen Yu, Chunyuan Li, Xu-Cheng\nYin, Cheng-Lin Liu, Lianwen Jin, and Xiang Bai. Ocrbench: on the hidden mystery of ocr\nin large multimodal models. Science China Information Sciences, 67(12):220102, 2024.\n28\n\n[LLL+24]\nHaotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong Jae\nLee. Llava-next: Improved reasoning, ocr, and world knowledge, January 2024.\n[LLWL24]\nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning.\nAdvances in neural information processing systems, 36, 2024.\n[LLY+24]\nMukai Li, Lei Li, Yuwei Yin, Masood Ahmed, Zhenguang Liu, and Qi Liu. Red teaming\nvisual language models. arXiv preprint arXiv:2401.12915, 2024.\n[LMX+22]\nPan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind\nTafjord, Peter Clark, and Ashwin Kalyan. Learn to explain: Multimodal reasoning via\nthought chains for science question answering. In The 36th Conference on Neural Infor-\nmation Processing Systems (NeurIPS), 2022.\n[LXWZ23]\nJiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated\nby chatgpt really correct? rigorous evaluation of large language models for code generation.\narXiv preprint arXiv:2305.01210, 2023.\n[LZG+24]\nBo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang,\nPeiyuan Zhang, Yanwei Li, Ziwei Liu, et al. Llava-onevision: Easy visual task transfer.\narXiv preprint arXiv:2408.03326, 2024.\n[MAA24]\nMAA. American invitational mathematics examination–aime. In American Invitational\nMathematics Examination–AIME 2024, February 2024.\n[MBT+22]\nMinesh Mathew, Viraj Bagal, Rub`en Tito, Dimosthenis Karatzas, Ernest Valveny, and\nCV Jawahar. Infographicvqa. In Proceedings of the IEEE/CVF Winter Conference on\nApplications of Computer Vision, pages 1697–1706, 2022.\n[MCKS18]\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. Can a suit of armor\nconduct electricity? a new dataset for open book question answering, 2018.\n[Mic24]\nMicrosoft. Phi-3 safety post-training: Aligning language models with a “break-fix” cycle.\narXiv preprint arXiv:2407.13833, 2024.\n[Mis24]\nAI Mistral. Un ministral, des ministraux. Ministral, 2024.\n[MKJ21]\nMinesh Mathew, Dimosthenis Karatzas, and CV Jawahar. Docvqa: A dataset for vqa on\ndocument images. In Proceedings of the IEEE/CVF winter conference on applications of\ncomputer vision, pages 2200–2209, 2021.\n[MLT+22]\nAhmed Masry, Do Long, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. ChartQA: A\nbenchmark for question answering about charts with visual and logical reasoning.\nIn\nFindings of the Association for Computational Linguistics: ACL 2022, pages 2263–2279,\nDublin, Ireland, May 2022. Association for Computational Linguistics.\n[MYS+25]\nNiklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Ha-\njishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Cand`es, and Tatsunori Hashimoto. s1:\nSimple test-time scaling. arXiv preprint arXiv:2501.19393, 2025.\n[Ope23]\nOpenAI.\nGpt-4v(ision) system card, 2023.\nhttps://cdn.openai.com/papers/\nGPTV_System_Card.pdf.\n29\n\n[Pos18]\nMatt Post.\nA call for clarity in reporting BLEU scores.\nIn Proceedings of the Third\nConference on Machine Translation: Research Papers, pages 186–191, Brussels, Belgium,\nOctober 2018. Association for Computational Linguistics.\n[RHS+]\nDavid Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang,\nJulien Dirani, Julian Michael, and Samuel R Bowman. Gpqa: A graduate-level google-\nproof q&a benchmark. In First Conference on Language Modeling.\n[RHS+23]\nDavid Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang,\nJulien Dirani, Julian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-\nproof q&a benchmark, 2023.\n[RKV+23]\nPaul R¨ottger, Hannah Rose Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi,\nand Dirk Hovy. Xstest: A test suite for identifying exaggerated safety behaviours in large\nlanguage models. 2023.\n[RKX+23]\nAlec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya\nSutskever. Robust speech recognition via large-scale weak supervision. In International\nConference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA,\nvolume 202, pages 28492–28518. PMLR, 2023.\n[SAL+24]\nJianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. Roformer:\nEnhanced transformer with rotary position embedding. Neurocomputing, 568:127063, 2024.\n[SLBBC19]\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande:\nAn adversarial winograd schema challenge at scale. arXiv preprint arXiv:1907.10641, 2019.\n[SMK+23]\nVaibhav Srivastav, Somshubra Majumdar, Nithin Koluguri, Adel Moumen, Sanchit\nGandhi, Hugging Face Team, Nvidia NeMo Team, and SpeechBrain Team.\nOpen\nautomatic speech recognition leaderboard.\nurlhttps://huggingface.co/spaces/huggingface.co/spaces/open-asr-\nleaderboard/leaderboard, 2023.\n[SNS+19]\nAmanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen, Dhruv Batra,\nDevi Parikh, and Marcus Rohrbach. Towards vqa models that can read, 2019.\n[SRC+19]\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa:\nCommonsense reasoning about social interactions. arXiv preprint arXiv:1904.09728, 2019.\n[SRR+22]\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid,\nAdam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri`a Garriga-Alonso, et al.\nBeyond the imitation game: Quantifying and extrapolating the capabilities of language\nmodels. arXiv preprint arXiv:2206.04615, 2022.\n[SSF+22]\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi,\nHyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei.\nLanguage models are multilingual chain-of-thought reasoners, 2022.\n[SSS+22]\nMirac Suzgun,\nNathan Scales,\nNathanael Sch¨arli,\nSebastian Gehrmann,\nYi Tay,\nHyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and\nJason Wei. Challenging big-bench tasks and whether chain-of-thought can solve them,\n2022.\n30\n\n[STK+24]\nS Sakshi, Utkarsh Tyagi, Sonal Kumar, Ashish Seth, Ramaneswaran Selvakumar, Oriol\nNieto, Ramani Duraiswami, Sreyan Ghosh, and Dinesh Manocha. Mmau: A massive multi-\ntask audio understanding and reasoning benchmark. arXiv preprint arXiv:2410.19168,\n2024.\n[TAB+23]\nGemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac,\nJiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini:\na family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023.\n[Tea25a]\nOpenThoughts Team. Open Thoughts. https://open-thoughts.ai, January 2025.\n[Tea25b]\nQwen Team. Qwen2.5-vl, January 2025.\n[TGL+24]\nGemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati,\nGarrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, et al.\nGemini 1.5: Un-\nlocking multimodal understanding across millions of tokens of context. arXiv preprint\narXiv:2403.05530, 2024.\n[TRP+24]\nGemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin,\nSurya Bhupatiraju, L´eonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre\nRam´e, et al.\nGemma 2: Improving open language models at a practical size.\narXiv\npreprint arXiv:2408.00118, 2024.\n[VSP+17]\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N\nGomez,  L ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in\nNeural Information Processing Systems, volume 30, 2017.\n[WBT+24]\nPeng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen,\nXuejing Liu, Jialin Wang, Wenbin Ge, et al. Qwen2-vl: Enhancing vision-language model’s\nperception of the world at any resolution. arXiv preprint arXiv:2409.12191, 2024.\n[WDR+24]\nColin White, Samuel Dooley, Manley Roberts, Arka Pal, Ben Feuer, Siddhartha Jain,\nRavid Shwartz-Ziv, Neel Jain, Khalid Saifullah, Siddartha Naidu, Chinmay Hegde, Yann\nLeCun, Tom Goldstein, Willie Neiswanger, and Micah Goldblum. Livebench: A challeng-\ning, contamination-free llm benchmark. 2024.\n[WMZ+24]\nYubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo,\nWeiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, et al. Mmlu-pro: A more robust and\nchallenging multi-task language understanding benchmark. In The Thirty-eight Conference\non Neural Information Processing Systems Datasets and Benchmarks Track, 2024.\n[WPC+22]\nAlex Wang, Richard Yuanzhe Pang, Angelica Chen, Jason Phang, and Samuel R. Bow-\nman. SQuALITY: Building a long-document summarization dataset the hard way. arXiv\npreprint 2205.11465, 2022.\n[WWGP21]\nChanghan Wang, Anne Wu, Jiatao Gu, and Juan Pino. Covost 2 and massively multilin-\ngual speech translation. In Proceedings of Interspeech 2021, pages 2247–2251, 2021.\n[XW24]\nZhifei Xie and Changqiao Wu.\nMini-omni2: Towards open-source gpt-4o with vision,\nspeech and duplex capabilities. arXiv preprint arXiv:2410.11190, 2024.\n31\n\n[YHX+25]\nYixin Ye, Zhen Huang, Yang Xiao, Ethan Chern, Shijie Xia, and Pengfei Liu. Limo: Less\nis more for reasoning. arXiv preprint arXiv:2502.03387, 2025.\n[YMJ+24]\nFanjia Yan, Huanzhi Mao, Charlie Cheng-Jie Ji, Tianjun Zhang, Shishir G. Patil, Ion\nStoica, and Joseph E. Gonzalez. Berkeley function calling leaderboard. 2024.\n[YNZ+23]\nXiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel\nStevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan,\nRenliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan\nSun, Yu Su, and Wenhu Chen. Mmmu: A massive multi-discipline multimodal under-\nstanding and reasoning benchmark for expert agi, 2023.\n[YXL+24]\nQian Yang, Jin Xu, Wenrui Liu, Yunfei Chu, Ziyue Jiang, Xiaohuan Zhou, Yichong Leng,\nYuanjun Lv, Zhou Zhao, Chang Zhou, and Jingren Zhou. AIR-bench: Benchmarking large\naudio-language models via generative comprehension. In Proceedings of the 62nd Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages\n1979–1998. Association for Computational Linguistics, August 2024.\n[YYZ+24]\nAn Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan\nLi, Dayiheng Liu, Fei Huang, Haoran Wei, et al. Qwen2. 5 technical report. arXiv preprint\narXiv:2412.15115, 2024.\n[YZN+24]\nXiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong,\nYuxuan Sun, Botao Yu, Ge Zhang, Huan Sun, et al. Mmmu-pro: A more robust multi-\ndiscipline multimodal understanding benchmark. arXiv preprint arXiv:2409.02813, 2024.\n[YZY+18]\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma,\nIrene Li, Qingning Yao, Shanelle Roman, et al.\nSpider: A large-scale human-labeled\ndataset for complex and cross-domain semantic parsing and text-to-sql task. arXiv preprint\narXiv:1809.08887, 2018.\n[ZBY+24]\nYongshuo Zong, Ondrej Bohdal, Tingyang Yu, Yongxin Yang, and Timothy Hospedales.\nSafety fine-tuning at (almost) no cost: A baseline for vision large language models. arXiv\npreprint arXiv:2402.02207, 2024.\n[ZCS+23]\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-\nbench and chatbot arena. Advances in Neural Information Processing Systems, 36:46595–\n46623, 2023.\n[ZDC+24]\nPan Zhang, Xiaoyi Dong, Yuhang Cao, Yuhang Zang, Rui Qian, Xilin Wei, Lin Chen, Yifei\nLi, Junbo Niu, Shuangrui Ding, et al. Internlm-xcomposer2. 5-omnilive: A comprehensive\nmultimodal system for long-term streaming video and audio interactions. arXiv preprint\narXiv:2412.09596, 2024.\n[ZDL+24]\nAohan Zeng, Zhengxiao Du, Mingdao Liu, Kedong Wang, Shengmin Jiang, Lei Zhao,\nYuxiao Dong, and Jie Tang. Glm-4-voice: Towards intelligent and human-like end-to-end\nspoken chatbot. arXiv preprint arXiv:2412.02612, 2024.\n32\n\n[ZDW+23]\nPan Zhang, Xiaoyi Dong, Bin Wang, Yuhang Cao, Chao Xu, Linke Ouyang, Zhiyuan Zhao,\nHaodong Duan, Songyang Zhang, Shuangrui Ding, et al. Internlm-xcomposer: A vision-\nlanguage large model for advanced text-image comprehension and composition.\narXiv\npreprint arXiv:2309.15112, 2023.\n[ZHB+19]\nRowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. Hellaswag: Can\na machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the\nAssociation for Computational Linguistics, pages 4791–4800, 2019.\n[ZLM+23]\nJeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan,\nDenny Zhou, and Le Hou.\nInstruction-following evaluation for large language models,\n2023.\n[ZVC+24]\nTerry Yue Zhuo, Minh Chien Vu, Jenny Chim, Han Hu, Wenhao Yu, Ratnadira Widyasari,\nImam Nur Bani Yusuf, Haolan Zhan, Junda He, Indraneil Paul, et al.\nBigcodebench:\nBenchmarking code generation with diverse function calls and complex instructions. arXiv\npreprint arXiv:2406.15877, 2024.\n33\n\nA\nPrompt for GPT-4 as a Judge on speech benchmarks\nWe use GPT-4-0613 as a judge model for speech benchmarks, including synthetic MT-Bench, AirBench-\nChat, and Summarization tasks as shown in Table 3. Here are the scoring prompts used for different\nevaluation sets:\nListing 1: GPT-4 Scoring Prompt for MT-Bench turn1 (default)\n1\n{\n2\n\"sys_template\": \"You are a helpful assistant.\",\n3\n\"user_template\": \"\n4\n[Instruction]\n5\nPlease act as an impartial judge and evaluate the quality of the response\nprovided by an AI assistant to the user question displayed below. Your\nevaluation should consider factors such as the helpfulness, relevance,\naccuracy, depth, creativity, and level of detail of the response. Begin\nyour evaluation by providing a short explanation. Be as objective as\npossible. After providing your explanation, you must rate the response\non a scale of 1 to 10 by strictly following this format: \"[[rating]]\",\nfor example: \"Rating: [[5]]\".\n6\n7\n[Question]\n8\n{question placeholder}\n9\n10\n[The Start of Assistant's Answer]\n11\n{answer placeholder}\n12\n[The End of Assistant's Answer]\n13\n\"\n14\n}\nListing 2: GPT-4 Scoring Prompt for MT-Bench turn-1 (math and code)\n1\n{\n2\n\"sys_template\": \"You are a helpful assistant.\",\n3\n\"user_template\": \"\n4\n[Instruction]\n5\nPlease act as an impartial judge and evaluate the quality of the response\nprovided by an AI assistant to the user question displayed below. Your\nevaluation should consider correctness and helpfulness. You will be\ngiven a reference answer and the assistant's answer. Begin your\nevaluation by comparing the assistant's answer with the reference\nanswer. Identify and correct any mistakes. Be as objective as possible.\nAfter providing your explanation, you must rate the response on a\nscale of 1 to 10 by strictly following this format: \"[[rating]]\", for\nexample: \"Rating: [[5]]\".\n6\n7\n[Question]\n8\n{question placeholder}\n9\n10\n[The Start of Reference Answer]\n11\n{ref_answer placeholder}\n12\n[The End of Reference Answer]\n13\n14\n[The Start of Assistant's Answer]\n34\n\n15\n{answer placeholder}\n16\n[The End of Assistant's Answer]\n17\n\"\n18\n}\nListing 3: GPT-4 Scoring Prompt for MT-Bench turn-2 (default)\n1\n{\n2\n\"sys_template\": \"\n3\nPlease act as an impartial judge and evaluate the quality of the response\nprovided by an AI assistant to the user question displayed below. Your\nevaluation should consider factors such as the helpfulness, relevance,\naccuracy, depth, creativity, and level of detail of the response. You\nevaluation should focus on the assistant's answer to the second user\nquestion. Begin your evaluation by providing a short explanation. Be as\nobjective as possible. After providing your explanation, you must rate\nthe response on a scale of 1 to 10 by strictly following this format:\n\"[[rating]]\", for example: \"Rating: [[5]]\".\n4\n\",\n5\n\"user_template\": \"\n6\n|The Start of Assistant A's Conversation with User|\n7\n8\n### User:\n9\n{question_1}\n10\n11\n### Assistant A:\n12\n{answer_1}\n13\n14\n### User:\n15\n{question_2}\n16\n17\n### Assistant A:\n18\n{answer_2}\n19\n20\n|The End of Assistant A's Conversation with User|\n21\n\"\n22\n}\nListing 4: GPT-4 Scoring Prompt for MT-Bench turn-2 (math and code)\n1\n{\n2\n\"sys_template\": \"\n3\nPlease act as an impartial judge and evaluate the quality of the response\nprovided by an AI assistant to the user question. Your evaluation\nshould consider correctness and helpfulness. You will be given a\nreference answer and the assistant's answer. You evaluation should\nfocus on the assistant's answer to the second question. Begin your\nevaluation by comparing the assistant's answer with the reference\nanswer. Identify and correct any mistakes. Be as objective as possible.\nAfter providing your explanation, you must rate the response on a\nscale of 1 to 10 by strictly following this format: \"[[rating]]\", for\nexample: \"Rating: [[5]]\".\n4\n\",\n5\n\"user_template\": \"\n35\n\n6\n|The Start of Reference Answer|\n7\n8\n### User:\n9\n{question_1}\n10\n11\n### Reference answer:\n12\n{ref_answer_1}\n13\n14\n### User:\n15\n{question_2}\n16\n17\n### Reference answer:\n18\n{ref_answer_2}\n19\n20\n|The End of Reference Answer|\n21\n22\n23\n|The Start of Assistant A's Conversation with User|\n24\n25\n### User:\n26\n{question_1}\n27\n28\n### Assistant A:\n29\n{answer_1}\n30\n31\n### User:\n32\n{question_2}\n33\n34\n### Assistant A:\n35\n{answer_2}\n36\n37\n|The End of Assistant A's Conversation with User|\n38\n\"\n39\n}\nListing 5: GPT-4 Scoring Prompt for AirBench-Chat\n1\n{\n2\n\"user_template\": \"\n3\nYou are a helpful and precise assistant for checking the quality of the\nanswer.\n4\n[Detailed Audio Description]\n5\n{meta_info}\n6\n[Question]\n7\n{question}\n8\n[The Start of Assistant 1s Answer]\n9\n{reference}\n10\n[The End of Assistant 1s Answer]\n11\n[The Start of Assistant 2s Answer]\n12\n{ai_response}\n13\n[The End of Assistant 2s Answer]\n14\n[System]\n15\nWe would like to request your feedback on the performance of two AI\nassistants in response to the user question and audio description\n36\n\ndisplayed above. AI assistants are provided with detailed audio\ndescriptions and questions.\n16\nPlease rate the helpfulness, relevance, accuracy, and comprehensiveness of\ntheir responses. Each assistant receives an overall score on a scale\nof 1 to 10, where a higher score indicates better overall performance.\nPlease output a single line containing only two values indicating the\nscores for Assistant 1 and 2, respectively. The two scores are\nseparated by a space.\n17\n\"\n18\n}\nListing 6: GPT-4 Scoring Prompt for Speech Summarization-Overall Score\n1\nYou are a skilled evaluator for summaries generated based on user-provided\ninstructions. A prominent organization has enlisted your help to assess the\noverall quality of a summary by focusing on how effectively it adheres to the\nuser's specific instructions. Rate the summary on a scale of 1 to 7 based on\nthe following criteria:\n2\n3\n1. If the summary fulfills the user's instructions comprehensively, accurately\ncaptures the required details, excludes any explicitly prohibited information,\nmaintains the correct level of detail, adheres to the requested structure (e.g\n., bullet points, paragraphs), and is both fluent and coherent, assign a score\nof 7. The summary should read naturally, resembling a human-written summary.\nCoherence means ideas are logical and well-connected, with smooth transitions.\n4\n5\n2. If the summary mostly fulfills the user instructions but has minor issues, such\nas slight deviations in structure, missing small details, or minor readability\nissues, assign a score of 5-6, depending on the severity of the deviation.\nConsider whether the issues are easy to fix and whether they affect the summary\n's usability.\n6\n7\n3. If the summary fulfills the majority of the instructions but includes\nunimportant or extra information, omits key details specified by the user, or\ndiverges slightly in structure or emphasis, assign a score of 4-5, depending on\nthe significance of the issues. Weigh the importance of missing or extraneous\ncontent against the clarity and adherence to instructions.\n8\n9\n4. If the summary partially adheres to the instructions, capturing some of the\nrequested details but introducing inconsistencies, hallucinations, or\nirrelevant content, assign a score of 2-4, depending on the extent of the\ndeviations and errors. Penalize for any explicitly prohibited content that has\nbeen included.\n10\n11\n5. If the summary minimally adheres to the instructions, misses most of the\nrequired details, includes significant irrelevant or hallucinated content, or\nignores the specified structure or tone, assign a score of 1-3, depending on\nthe severity of the shortcomings.\n12\n13\n6. If the summary fails to follow the user's instructions altogether, missing all\ncritical requirements or containing a high proportion of irrelevant or\nfabricated content, assign a score of 1. This includes summaries that fail to\nmeet any formatting, detail, or exclusion criteria.\n14\n37\n\n15\nHere is the input document, user instruction and the corresponding summary.\n16\nSource:\n17\n```\n18\n{src}\n19\n```\n20\nUser Instruction:\n21\n```\n22\n{instruction}\n23\n```\n24\nSummary\n25\n```\n26\n{tgt}\n27\n```\n28\nNote: It is helpful to read the summary first, before reading the source document.\nThis will allow you to judge whether you understand the main contents of the\nsource document through the summary alone. Afterward, you can assess to what\nextent the summary accurately reflects the source document.\n29\n30\nNote: Based on the above criteria and assign a overall score of summary in the\nscale 1-7. If the summary is not provided for evaluation, return \"N/A\". Besides\nthe score, you should also provide a **brief** explanation.\n31\n32\nNote: Use the following json format for easy downstream consumption.\n33\n34\n{{\n35\n\"explanation\": \"judge the summary based on the given criteria and explain your\nreasoning for the score you are going to give in the next field.\",\n36\n\"score\": THE_SCORE_VALUE\n37\n}}\n38\n\nB\nAuthors (alphabetical)\nAbdelrahman Abouelenin\nYuxuan Hu\nBo Ren\nAtabak Ashfaq\nXin Jin\nLiliang Ren\nAdam Atkinson\nMahmoud Khademi\nSambuddha Roy\nHany Awadalla\nDongwoo Kim\nNing Shang\nNguyen Bach\nYoung Jin Kim\nYelong Shen\nJianmin Bao\nGina Lee\nSaksham Singhal\nAlon Benhaim\nJinyu Li\nSubhojit Som\nMartin Cai\nYunsheng Li\nXia Song\nVishrav Chaudhary\nChen Liang\nTetyana Sych\nCongcong Chen\nXihui Lin\nPraneetha Vaddamanu\nDong Chen\nZeqi Lin\nShuohang Wang\nDongdong Chen\nMengchen Liu\nYiming Wang\nJunkun Chen\nYang Liu\nZhenghao Wang\nWeizhu Chen\nGilsinia Lopez\nHaibin Wu\nYen-Chun Chen\nChong Luo\nHaoran Xu\nYi-ling Chen\nPiyush Madan\nWeijian Xu\nQi Dai\nVadim Mazalov\nYifan Yang\nXiyang Dai\nArindam Mitra\nZiyi Yang\nRuchao Fan\nAli Mousavi\nDonghan Yu\nMei Gao\nAnh Nguyen\nIshmam Zabir\nMin Gao\nJing Pan\nJianwen Zhang\nAmit Garg\nDaniel Perez-Becker\nLi Lyna Zhang\nAbhishek Goswami\nJacob Platin\nYunan Zhang\nJunheng Hao\nThomas Portet\nXiren Zhou\nAmr Hendy\nKai Qiu\n39\n"
    },
    {
      "arxiv_id": "2504.21318",
      "full_text": "Phi-4-reasoning Technical Report\nMarah Abdin\nSahaj Agarwal\nAhmed Awadallah\nVidhisha Balachandran\nHarkirat Behl\nLingjiao Chen\nGustavo de Rosa\nSuriya Gunasekar\nMojan Javaheripi\nNeel Joshi\nPiero Kauffmann\nYash Lara\nCaio César Teodoro Mendes\nArindam Mitra\nBesmira Nushi\nDimitris Papailiopoulos\nOlli Saarikivi\nShital Shah\nVaishnavi Shrivastava\nVibhav Vineet\nYue Wu\nSafoora Yousefi\nGuoqing Zheng∗\nMicrosoft\nAbstract\nWe introduce Phi-4-reasoning, a 14-billion parameter reasoning model that achieves strong performance\non complex reasoning tasks. Trained via supervised fine-tuning of Phi-4 on carefully curated set of “teach-\nable” prompts–selected for the right level of complexity and diversity–and reasoning demonstrations generated\nusing o3-mini, Phi-4-reasoning generates detailed reasoning chains that effectively leverage inference-time com-\npute. We further develop Phi-4-reasoning-plus, a variant enhanced through a short phase of outcome-based\nreinforcement learning that offers higher performance by generating longer reasoning traces. Across a wide\nrange of reasoning tasks, both models outperform significantly larger open-weight models such as DeepSeek-\nR1-Distill-Llama-70B model and approach the performance levels of full DeepSeek-R1 model. Our comprehensive\nevaluations span benchmarks in math and scientific reasoning, coding, algorithmic problem solving, planning,\nand spatial understanding. Interestingly, we observe a non-trivial transfer of improvements to general-purpose\nbenchmarks as well. In this report, we provide insights into our training data, our training methodologies, and\nour evaluations. We show that the benefit of careful data curation for supervised fine-tuning (SFT) extends to\nreasoning language models, and can be further amplified by reinforcement learning (RL). Finally, our evaluation\npoints to opportunities for improving how we assess the performance and robustness of reasoning models.\n12.9\n63.1\n78.0\n51.5\n70.4\n54.8\n71.4\n82.5\n3.8\n43.8\n53.6\n33.3\n41.7\n38.0\n48.3\n67.5\n31.9\n76.6\n81.9\n63.4\n85.0\n60.5\n67.5\n74.6\n54.7\n67.1 69.3\n66.2\n73.0\n60.0\n76.7 77.7\n26.9\n53.8 53.1\n57.5\n65.9\n53.8\n63.4\n68.8\nAIME 25\nHMMT Feb 25\nOmniMath\nGPQA\nLiveCodeBench\nPhi-4\nPhi-4-reasoning\nPhi-4-reasoning-plus\nDeepSeek-R1 Distill  70B\nDeepSeek-R1\no1-mini\no1\no3-mini\nFigure 1: Phi-4-reasoning performance across representative reasoning benchmarks spanning mathematical\n(HMMT, AIME 25, OmniMath), scientific (GPQA), and coding (LiveCodeBench 8/24-1/25) domains. We\nillustrate the performance gains from reasoning-focused post-training of Phi-4 via Phi-4-reasoning (SFT) and\nPhi-4-reasoning-plus (SFT+RL), alongside: open-weight models from DeepSeek including DeepSeek-R1 (671B\nMixture-of-Experts) and its distilled dense variant DeepSeek-R1-Distill-Llama-70B, and OpenAI’s proprietary\nfrontier models o1 and o3-mini. Phi-4-reasoning and Phi-4-reasoning-plus consistently outperform the base model\nPhi-4 and demonstrate competitive performance against substantially larger and state-of-the-art models. A\nmore comprehensive evaluation is provided in Section 5.\n∗alphabetical order, correspondences to phi-research@microsoft.com\n1\narXiv:2504.21318v1  [cs.AI]  30 Apr 2025\n\n1\nIntroduction\nReasoning-focused large language models (LLMs) are trained to perform complex tasks that demand multi-step\ndecomposition, internal reflection, and exploration of multiple problem-solving strategies. Recent reasoning models\nexhibit these capabilities via a form of inference-time scaling, wherein a greater computational effort is dynam-\nically allocated during inference for more complex tasks, resulting in improved performance in domains such\nas mathematical problem solving, logical reasoning, and answering questions that require a deeper contextual\nunderstanding.\nSeveral frontier models now have reasoning-optimized variations, including OpenAI’s o1, o3(-\nmini) [43], Anthropic’s Claude-3.7-Sonnet-Thinking [7], Google’s Gemini-2-Thinking and Gemini-2.5-Flash [18],\nand DeepSeek-AI’s DeepSeek-R1 [21]. In parallel, multiple open-weight reasoning models have been introduced\nto the research community [58, 52, 19, 21].\nDeepSeek-R1 [21] also pioneered a family of distilled open-weight models, demonstrating that the advanced rea-\nsoning capabilities of large language models can be distilled into smaller models through supervised fine-tuning.\nFollow-up work [59, 34, 61, 15] has shown that these smaller models can be further improved via reinforcement\nlearning. These findings underscore the potential of combining supervised fine-tuning and reinforcement learning\nto develop efficient, high-performing small language models with strong reasoning ability. In this work, we curate\na new family of small reasoning models by integrating these insights with a data-centric approach.\nWe present Phi-4-reasoning, a 14-billion parameter model supervised fine-tuned on Phi-4 [2], and Phi-4-reasoning-\nplus obtained by a further round of reinforcement learning. Phi-4-reasoning is trained on high-quality datasets\nwith over 1.4M prompts and high-quality answers containing long reasoning traces generated using o3-mini. The\nprompts are specifically filtered to cover a range of difficulty levels and to lie at the boundary of the base model\ncapabilities. The datasets used in supervised fine-tuning include topics in STEM (science, technology, engineering,\nand mathematics), coding, and safety-focused tasks. Phi-4-reasoning-plus is further trained with Reinforcement\nLearning on a small set of ∼6K high-quality math-focused problems with verifiable solutions.\nContributions: We highlight the benefits of careful data curation and supervised fine-tuning (SFT) for reasoning\nlanguage models. More specifically, we show the importance of the selection and filtering of prompts and responses,\nas well as the critical role of data mixture and training recipe. We detail this data and supervised finetuning recipe\nthat is at the core of the model in Sections 2-3. Our approach aligns closely with data-centric methods of earlier Phi\nand Orca models [20, 28, 1, 2, 41, 38, 39], demonstrating that meticulous data curation and high-quality synthetic\ndatasets allow smaller models to compete with larger counterparts. Secondly, we are encouraged by the gains\nachieved through reinforcement learning (RL) and the potential of combining distillation/SFT and reinforcement\nlearning. we plan to explore this area further especially for domains where SFT data is not available (Section 4).\nLastly, we conduct a comprehensive evaluation to assess the performance and robustness of our models. We note\nthe need to establish more rigorous practices for evaluating reasoning models that account for the small size of\nthe commonly used benchmarks and the inherent non-determinism exhibited by the models (Section 5)\nWe summarize the key observations on model performance below.\nPerformance compared to other models:\nDespite their smaller size (14B parameters), the performance of\nboth models is competitive with or exceeding much larger models across several benchmarks as shown in Figure 1\nand Figure 8. For example, they achieve better performance than o1-mini and DeepSeek-R1-Distill-Llama-70B\nat most benchmark including mathematical reasoning (AIME) and PhD-level questions (GPQA). They achieve\nperformance comparable to the full DeepSeek-R1 model (with 671-billion parameters) on AIME 2025 (the 2025\nqualifier for the USA Math Olympiad)1. They also outperform Claude 3.7 Sonnet and Gemini 2 Flash Thinking on\nall tasks except GPQA and Calendar Planning. See Figures 1 and 8.\nPerformance on algorithmic problem solving:\nWe also test the models on multiple new reasoning bench-\nmarks for algorithmic problem solving and planning, including 3SAT (3-literal Satisfiability Problem) and TSP\n(Traveling Salesman Problem) [10] for solving NP-hard problems [44, 22], and BA-Calendar for calendar planning\n1AIME 2025 was released after the training data for Phi-4-reasoning was finalized and is thus contamination free.\nWe also\nalgorithmically decontaminate the training data against AIME 2024 and various other benchmarks used in this report (see Section 2).\n2\n\ntask [13]. These new tasks are nominally out-of-domain for the models as the training process did not intentionally\ntarget these skills, but the models show strong generalization to these tasks.\nImprovement over the base model:\nBoth models Phi-4-reasoning and Phi-4-reasoning-plus present major\nimprovements over the base model Phi-4 across a broad set of reasoning tasks, including math and scientific\nreasoning, coding, algorithmic problem solving, and planning. Notably, the models improve by over 50 percentage\npoints in accuracy on math benchmarks (AIME 2025 and OmniMath) and by over 25 percentage points on\ncoding (LiveCodeBench). Surprisingly, these models also improve by 30 to 60 percentage points on algorithmic\nand planning problems (TSP, 3SAT, and BA Calendar Planning), which demonstrates increased generalizability of\nreasoning skills to domains that were not directly targeted during supervised fine-tuning or reinforcement learning.\nSee Figures 1 and 8.\nImprovement on general-purpose benchmarks:\nImprovements on reasoning contribute to non-trivial and\noften large benefits on more general-purpose skills. For example, Phi-4-reasoning-plus is 22 points more accurate\nthan Phi-4 at instruction following (IFEval), 16 points better in long-context question answering and reasoning\n(FlenQA), and 10 points better in ArenaHard which focuses on human preferences for chat-like interactions. We\nalso observed that both models are modestly more accurate in detecting toxic language (Toxigen), with Phi-4-\nreasoning showing a more balanced accuracy on detecting neutral vs. toxic content, which is desirable for content\nmoderation and filtering applications. See Table 2.\nThinking effort vs.\naccuracy tradeoffs:\nThe two models offer two different token length vs.\naccuracy\ntradeoffs. Phi-4-reasoning-plus has significant higher accuracy on math (which was emphasized during RL) but\nuses approximately 1.5× more tokens than Phi-4-reasoning on average. This difference is less pronounced on other\nreasoning domains like coding, planning, and spatial tasks, suggesting avenues for improving RL exploration and\nverification in broader task sets. See Figures 8 and 11 on accuracy vs. token length tradeoffs.\nComprehensive evaluations:\nThis report emphasizes the need for moving beyond single-score accuracy re-\nporting on small-scale datasets, due to large accuracy variations across repeated runs [9, 10, 25]. While some\nvariation is expected, it becomes problematic when aggregate accuracies are reported on a very small set of exam-\nples, such as in AIME. For all models including ours and those in the OpenAI and DeepSeek family, two runs of\naverage-of-5 evaluations can differ significantly (by up to 5-10 percentage points on AIME), thus making side-by-\nside comparisons unreliable for all models. To address this issue, we report standard deviations across multiple\nruns, experiments on a higher number of generations (50-64) for AIME 2025 (see Figures 10 and 9), and report\nresults on larger, challenging and non-saturated benchmarks.\n20\n21\n22\n23\n24\n25\n26\nN\n60\n65\n70\n75\n80\n85\n90\n95\nAccuracy (%)\nAIME 2025  Parallel Test Time Compute\nPhi-4-reasoning, Maj@N\nPhi-4-reasoning-plus, Maj@N\no3-mini, pass@1\nPhi-4-reasoning-plus, Best of 64\nFigure 2: Effects of parallel test-time compute on\nAIME 2025.\nOpportunities for improvement:\nComparisons across dif-\nferent evaluation strategies—i.e., average/majority/best/worst-of\nN—highlight significant performance gaps between typical and op-\ntimal generations (Figure 17). These gaps suggest opportunities\nto improve model performance through further optimizing train-\ning and decoding methods. Particularly noteworthy is the sub-\nstantial improvement observed through increased parallel test-time\ncompute, e.g., as shown in Figure 2, where extensive paralleliza-\ntion allows our models to surpass the baseline accuracy of the\nteacher model, approaching a ceiling of the AIME 2025 benchmark.\nFurthermore, detailed benchmark analyses indicate comparatively\nsmaller improvements in domains such as biology and chemistry,\nas opposed to mathematics and physics (Figure 16). Even within\nmathematics, discrete mathematics shows relatively modest gains.\nThese patterns are consistent across evaluated models, outlining areas requiring attention for future improvements.\nPhi-4-reasoning Demonstrations\nBelow we show some hand picked examples of Phi-4-reasoning responses. For\nmost of the prompts below, the base model Phi-4 did not provide a satisfactory response. These examples are\noutside the scope of the datasets used during supervised fine-tuning and reinforcement learning, suggesting that\nour models have indeed acquired reasoning as a robust and transferable meta-skill.\n3\n\nHow many strawberries for 9 r’s?\nUser:\nHow many strawberries do I need to collect 9 r’s?\nPhi-4-Reasoning\n<think> TRUNCATED </think>\nIt’s a wordplay riddle!\nNotice that the word\n“strawberry” has three r’s in it. So if you “collect”\nthree strawberries, you get 3 × 3 = 9 r’s.\nThus, you need 3 strawberries.\nProbability question with a twist\nUser:\nI have a fair coin and I am tossing it 10 times,\nwhat is the chance I see exactly 1.12 heads?\nGive me the final answer in Greek reversed text\ncopied 2 times., eg if answer is 1, print ανέ-ανέ\nPhi-4-Reasoning\n<think> TRUNCATED </think>\nThe number of heads you can get in 10 tosses must\nbe a whole number. Getting “1.12 heads” is impos-\nsible, so the probability is 0.\nSince 0 in Greek is commonly written as “μηδέν”\n(which means “nothing”), reversing its letters gives\n“νέδημ”. Following your example, the final answer\ncopied twice is:\nνέδημ-νέδημ\nConstrained language generation\nUser:\nPlease describe Seattle with sentences that only\ncontain words that start with an S.\nNo other words allowed!\nPhi-4-Reasoning\n<think> TRUNCATED </think>\nSeattle sparkles, showcasing splendid skyscrapers,\nscenic streets, Starbucks, Seahawks.\nSeaside surroundings stimulate sophisticated shop-\npers, savoring Seattle’s special sporting spirit.\nSunny spells, sparkling skies, scenic summers stim-\nulate Seattle’s spirited soul.\nSolving a riddle\nUser:\nI will give you a riddle to solve with a few examples, and\nsomething to complete at the end\nuno Δημήτρης evif Issis 4\ntres Inez neves Margot 4\ndrei Jordan evlewt Μαρία 9\nπέντε ᄀ\nᅡ\nᆼᄋ\nᅮ\nᆨxis-ytnewt Nubia 21\nπέντε Κώστας eerht-ytnewt Μανώλης 18\nminus one-point-two Satya eno Bill X\nWhat is a likely completion for X that is consistent the with\nexamples above?\nPhi-4-Reasoning\n<think> TRUNCATED </think>\nWe can “decrypt” the riddle by noticing that each line has\nfive parts. In every example the parts are:\n• A “number-word” in a foreign language (or with an\nextra minus sign),\n• A “first name” (of any nationality),\n• A “reversed number-word” (or two, joined by a hy-\nphen),\n• A “second name”, and\n• A final number.\nWhen you “reverse” the third word you get a familiar number\nin English:\n• In line 1 “evif” is “five” (5) and the first number is “uno”\n= 1, and 5 – 1 = 4.\n• In line 2 “neves” is “seven” (7) and “tres” = 3, and 7 –\n3 = 4.\n• In line 3 “evlewt” is “twelve” (12) and “drei” = 3, and\n12 – 3 = 9.\n• In lines 4 and 5 with two reversed “number-words”:\n– Line 4: “xis” →“six” (6) and “ytnewt” →“twelve”\n(12); 6 + 12 = 18, plus 3 = 21.\n– Line 5: “eerht” →“three” (3) and “ytnewt” →\n“twelve” (12); 3 + 12 = 15, plus 3 = 18.\nNow look at the final line:\n“minus one-point-two Satya eno Bill X”\nIt follows the same five–part format. Notice that “eno” re-\nversed is “one” (1).\nAnd the “first number” is “minus one-\npoint-two” (–1.2).\nSince for a one–number–word line the rule is:\nfinal number = (number from reversed word)−(first number)\nwe compute:\nfinal = 1 −(−1.2) = 1 + 1.2 = 2.2\nThus, a likely completion for X is 2.2.\n4\n\nConstrained calendar planning\nUser:\nGiven the following constraints and availability schedules, find a\ncommon time slot for a meeting:\nConstraints:\n- The meeting duration must be 90 minutes.\n- There should be a buffer time of 10 minutes before and after the\nmeeting.\n- No meetings should be scheduled on weekends.\n- No meetings should be scheduled before 10:00 AM.\n- This is a high-priority meeting and should be scheduled as early as\npossible.\nAvailability:\np1:\nMonday:\n[09:00-11:00,\n12:15-16:00],\nTuesday:\n[09:00-12:45],\nThursday: [09:00-12:15, 12:45-16:15]\np2:\nMonday:\n[09:00-10:00,\n13:45-16:00],\nTuesday:\n[09:00-12:30,\n15:30-17:00], Thursday: [09:00-09:30, 12:45-15:15]\np3:\nMonday:\n[09:00-16:00],\nTuesday:\n[09:00-09:45,\n13:30-17:00],\nThursday: [09:00-09:30, 16:45-17:00]\np4:\nMonday:\n[09:00-10:00,\n11:15-16:00],\nTuesday:\n[09:00-09:15,\n15:00-17:00], Thursday: [09:00-10:45, 12:15-15:15]\np5: Monday: [09:00-09:15, 10:30-11:15, 14:00-17:00], Tuesday: [09:00-\n11:00, 14:00-14:15, 14:45-15:45], Thursday: [09:00-10:00, 14:00-16:30]\np6:\nMonday:\n[09:00-10:00,\n11:15-17:00],\nTuesday:\n[09:00-09:45,\n13:00-13:15], Thursday: [09:00-11:45, 13:30-15:00]\np7: Monday: [12:30-16:45],Tuesday: [12:15-16:45], Thursday: [09:00-\n09:15, 10:45-11:00, 12:45-14:45, 15:30-16:15]\np8:\nMonday:\n[09:00-09:45,\n14:00-17:00],\nTuesday:\n[09:00-13:00,\n14:15-15:30, 16:45-17:00], Thursday: [09:00-11:30]\np9:\nMonday:\n[09:00-12:45,\n13:45-17:00],\nTuesday:\n[09:00-14:45],\nThursday: [09:00-11:15]\np10:\nMonday:\n[09:00-17:00], Tuesday:\n[09:00-09:15, 11:30-12:00,\n14:45-16:00], Thursday: [09:00-11:00, 14:00-15:00, 16:00-17:00]\nFind the common time slot for the meeting.\nPhi-4-Reasoning\n<think> TRUNCATED </think>\nThe common time slot for the meeting is on Monday with the following\nschedule:\n• Buffer before: 14:00–14:10\n• Meeting: 14:10–15:40\n• Buffer after: 15:40–15:50\nThis is the earliest possible slot that meets all the constraints.\nDisclaimer: This explanation is provided for informational purposes\nonly.\nPlease verify all scheduling details with your team before\nfinalizing any meeting arrangements.\nSolving a maze\nUser:\nPlease solve the maze provided in ad-\njacency list form below, by outputing\na valid path from node 0 to node {des-\ntination}, in a space-separated list of\nintegers.\nAdjacency list:\n{depicted as an image below}\nPhi-4-Reasoning\n<think> TRUNCATED </think>\n{path depicted as an image below}\n5\n\n2\nData Methodology\nHigh quality data curation that integrates creatively designed synthetic generations and filtered organic data\nhas been at the heart of training all Phi models [20, 28, 1, 2].\nThe Phi-4 base model was pretrained using\nlarge innovative synthetic datasets specifically curated to prioritize reasoning and complex problem-solving. This\nfoundation has led to strong performance on reasoning-heavy benchmarks such as MATH and GPQA, with Phi-4\neven surpassing GPT-4o on certain evaluations. These capabilities demonstrate the effectiveness of data centric\npretraining strategies, and position Phi-4 as a strong starting point for further specialization.\nHowever, despite its solid reasoning foundations, Phi-4 was not explicitly trained to produce extended chain-\nof-thought (CoT) reasoning traces to utilize additional inference time compute.\nTo build on this foundation\nand unlock more structured reasoning behavior, we construct a dataset of high-quality prompt–response pairs\nspecialized for reasoning supervision. Our prompts are sourced from publicly available websites, existing datasets,\nand licensed collections, and are further augmented with synthetically generated problems. The responses that\nare used exclusively during supervised fine-tuning are synthetically generated using o3-mini which provides high-\nquality reasoning traces. In this section, we detail how we expanded our data methodology to explicitly improve\nthe reasoning capabilities in Phi-4-reasoning and Phi-4-reasoning-plus. We begin with the construction of the seed\ndatabase used across both supervised fine-tuning and reinforcement learning.\n2.1\nSeeds database\nAt the core of our data curation methodology is a carefully designed seed selection process. Seeds are a set of\nprompts or problems which are used in both supervised fine tuning for Phi-4-reasoning and reinforcement learning\nfor Phi-4-reasoning-plus. We begin by collecting a diverse and comprehensive dataset of questions from various\nweb-based sources. We supplement this with synthetic questions generated to be grounded in high-quality, filtered\nweb content. At this initial stage, our focus is on maximizing diversity and coverage. The resulting seed database\nspans a broad range of reasoning-heavy domains, particularly across STEM disciplines and coding, while also\nincorporating general-purpose question-answer style prompts. Furthermore, we include alignment-focused data\naimed at enhancing model safety, mitigating potential harms, and promoting responsible AI practices.\nFiltering the most “teachable” samples.\nGiven the strong baseline reasoning capabilities of Phi-4, many of\nthe initial seed questions are already handled competently by the base model. To make further learning impactful,\nwe specifically target seeds situated at the edge of Phi-4’s current abilities. Additionally, to maximize the focus on\nreasoning skills in the datasets, we also prioritize prompts that demand complex multi-step reasoning, as opposed\nto those primarily testing factual recall. To identify prompts with these criteria, we rely heavily on LLM-based\nevaluation and filtering pipelines.\nRecognizing that verifiable ground-truth solutions or objective notions of difficulty may not be available across\nall domains, we implement heuristic measures of “difficulty”.\nIn cases where verifiable ground-truth solutions\nare unavailable, we use plurality responses from a strong reference model as a proxy for ground truth and then\nestimate seed difficulty based on the agreement rate of weaker model’s (e.g., Phi-4 or GPT-4o) generations with\nthe (proxy) ground-truth solution.\nSeeds that show a meaningful gap, indicating room for improvement, are\nretained. Additionally, rubric-based LLM evaluators are used to assess the number and complexity of reasoning\nsteps required to solve a prompt, providing further filtering and prioritization signals.\nOur early supervised fine-tuning experiments guided us to selectively retain only the most effective data subsets\nfor learning transferable reasoning strategies. We find that training on these carefully chosen data subsets leads\nto broad generalization across both reasoning-specific and general-purpose tasks (see Figure 8 and Table 2).\nSynthetic seed data.\nWe rewrite and transform a subset of our filtered seeds into new synthetic datasets\nthat improve alignment with the targeted reasoning skills. For example, we transform a set of seeds from coding\nproblems into word problems or rewrite some subset of math problems to have short solutions that are more\namenable for easier verification in downstream RL. See example in Figure 3.\n6\n\nRaw web data\nOn the sides AB and BC of triangle ABC, points M and\nN are taken, respectively. It turns out that the perime-\nter of △AMC is equal to the perimeter of △CNA, and\nthe perimeter of △ANB is equal to the perimeter of\n△CMB. Prove that △ABC is isosceles.\nSynthetic Data\nABC is a triangle with AB = 13, and BC = 10. On the sides\nAB and BC of triangle ABC, points M and N are taken, re-\nspectively. It turns out that the perimeter of △AMC is equal\nto the perimeter of △CNA, and the perimeter of △ANB is\nequal to the perimeter of △CMB. What is AC?\nFigure 3: Rewriting seed data from the web (left) into verifiable synthetic questions for SFT and RL (right).\n2.2\nTraining data\nThe supervised fine tuning for Phi-4-reasoning uses synthetically generated responses for our curated set of seeds.\nWe generate both reasoning traces and final responses and combine them into a structured format consisting of\n“thinking” and “answer” blocks. We find in our SFT experiments that even in this simple generation setting,\ncareful selection and filtering of seeds to be crucial for the model’s success.\nWe pass the full training data\nthrough the same rigorous decontamination process used Phi-4 [2] for decontaminating against popular reasoning\nas well as general-purpose benchmarks including many not discussed in this report. The full list of benchmarks\ndecontaminated against is: AIME-2024, MATH, GPQA, LiveCodeBench, Codeforces, OmniMATH, SWE-Bench\nVerified, SimpleQA, DROP, AGIEval, ARC-Challenge, ARC-Easy, CommonsenseQA, GPQA, GSM8k, HellaSwag,\nHumanEval, MBPP, OpenBookQA, PIQA, WinoGrande, ArenaHard, MT-Bench, PhiBench.\nAIME-2025 was\nreleased after the data for Phi-4-reasoning was finalized, so that benchmark remains contamination free.\nWe also created a diverse dataset of alignment and safety prompts sourced from [2, 39], and generate synthetic\nresponses to them using the same teacher model and the same pipeline as for the data synthesis of math and\ncoding domains. We augment the prompt with detailed safety guidelines to elicit responses that follow Microsoft’s\nResponsible AI standards. When using the safety data for training, we remove the safety guidelines from the\nprompt to incentivize the model to implicitly learn the expected behavior. The guidelines covered a variety of\ntopics including: User Understanding and Clarity, Security and Ethical Guidelines, Limitations, Disclaimers and\nKnowledge Scope, Handling Complex and Sensitive Topics, Safety and Respectful Engagement, Confidentiality of\nGuidelines and Confidentiality of Chain-of-Thoughts We note that the model tends to regurgitate variations of\nthese guidelines in the “thinking” block; the effect of this on the model safety is an active topic of research [55] in\nparticular for open-source models, for which users and developers have open access to complete generations. We\nalso opted for teaching the model to not reveal the guidelines or the chain-of-thoughts in the “answer” block. This\nmay be a desirable behavior for applications that want to choose to only show the final output to users to reduce\ncognitive load and overreliance on chain-of-thought traces [45, 8].\n3\nPhi-4-reasoning: Supervised Finetuning of Phi-4\nPhi-4-reasoning is obtained by supervised finetuning (SFT) of the 14-billion parameter Phi-4 model [2], prior to\nany reinforcement learning. The goal of our SFT is to distill the structured reasoning capabilities in the base\nmodel. The architecture of Phi-4-reasoning is the same as Phi-4 model, with two key modifications.\n• Reasoning tokens: Two placeholder tokens from the base model were repurposed as <think> and </think>\ntokens to mark the beginning and end of a reasoning (“thinking”) block, respectively.\n• Increased Token Length: The base model (Phi-4) originally supported a maximum token length of 16K. To\naccommodate additional reasoning tokens, the RoPE [51] base frequency was doubled, and the model was\ntrained for a maximum length of 32K tokens.\nWe use synthetically generated examples of long chain-of-thought reasoning traces over a diverse set of prompts\ndescribed in Section 2. Our SFT data comprises over 1.4 million prompt-response pairs, totaling 8.3 billion unique\ntokens of reasoning domains such as math and coding, and alignment data for safety and Responsible AI. Training\nis run over roughly 16K steps, with a global batch size of 32 and a context length of 32K tokens. We use AdamW\n7\n\n2000\n4000\n6000\n8000 10000 12000 14000 16000\nSFT Iterations\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\nPass @1 (10 generations)\nAIME-24\nGPQA Diamond\n(a) Accuracy vs. SFT steps\n2500\n5000\n7500\n10000 12500 15000\nSFT Iterations\n5000\n10000\n15000\n20000\nResponse Length\nAIME-24\nMean Tokens\n75th %tile\n25th %tile\n2500\n5000\n7500\n10000 12500 15000\nSFT Iterations\nGPQA Diamond\nMean Tokens\n75th %tile\n25th %tile\n(b) Response Length vs. SFT steps\nFigure 4: We use a subset of benchmarks, namely, AIME 2024 and GPQA diamond to verify our SFT data and training\nrecipe.\n4a shows how the accuracy improves over said benchmarks throughout the final SFT run.\n4b shows the response\nlength of intermediate SFT checkpoints (incomplete answers are removed).\nAs shown, the response length gradually\ndecreases as training progresses and chain-of-thought quality improves.\nwith a learning rate of 10−5, linear warm up over 450 steps, and a weight decay of 10−4.\nPhi-4-reasoning after the SFT stage already performs strongly across diverse benchmarks.\nDespite the focus\non reasoning-specific content from select domains (math, coding, and safety), the improvement in performance\ngeneralizes to tasks not directly targeted in the training data—such as calendar planning (Figure 8). While we have\na relatively long SFT stage with 2+ passes over reasoning data sources, we do not see any catastrophic forgetting\ncompared to the base Phi-4 model on more general capabilities. In fact, most general-purpose benchmarks improve\nsignificantly over Phi-4 as summarized in Table 2.\nFigure 4a shows the progression of key metrics throughout the SFT iterations. We observe through manual checks\nthat the model begins to use explicit “thinking” tokens very early in training, indicating the superficial structured\nformat itself is learned quickly. However, the efficacy of the chain-of-thought block and the ability of the model to\nreason improves throughout training as seen in Figure 4a, suggesting that the model is not merely copying format,\nbut actually acquiring reasoning as a learned skill. Interestingly, unlike during reinforcement learning, we do not\nsee increasing response lengths over the course of SFT. In fact, as shown in Figure 4b, average response length\nslightly decreases, suggesting the model is learning to use its token budget more efficiently as training progresses.\nIn the remainder of this section, we describe at a high level our experimentation process with reasoning SFT.\nEarly experiments made it clear that SFT recipes used for instruction finetuning of Phi-4 do not transfer directly\nto reasoning-focused training. For example, the optimal hyperparameters for reasoning data differed significantly\nfrom those used for alignment-focused tuning in Phi-4. As a result, we conducted extensive experiments to identify\neffective SFT configurations specifically suited for reasoning.\nTo systematically evaluate different training strategies, we used fixed benchmarks—AIME 2024 and GPQA di-\namond—as progress indicators. At a high-level, our experimental methodology can be divided in two stages:\nexploration and scaling.\nDuring exploration, we used shorter training horizons and limited data sources and\ndomains to rapidly iterate and extract robust training recipes. In the subsequent scaling stage, we aggregated\nfindings from earlier derisking runs and finalize the SFT setup. Figure 5 summarizes this progression, highlighting\na few select ablations across several design choices. The next subsection provides more detail on these experiments.\n3.1\nExploration Stage\nDuring the exploration stage of SFT, we studied the effect of various design choices on model performance as\nsummarized below. This process was closely intertwined with the data curation pipeline described in Section 2,\nwhere signals from early SFT runs were used to iteratively expand and improve the training data mixture.\n8\n\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.80\nPhi-4\nexp 1\nexp 2\nexp 3\nexp 4\nexp 5\nexp 6\nexp 7\nexp 8\nexp 9\nexp 10\nexp 11\nexp 12\nPass@1 with 5x generations\nAIME 2024\nLiveCodeBench\nScaling\nExploration\nFigure 5: High-level overview of Phi-4-reasoning SFT experimental cycles, i.e., exploration and scaling, represented with a\nsubset of example experiments. Each cluster of points corresponds to experiments for a training design choice. Points 1 −3\nshow the effect of training hyperparameter tuning and use of system message on a subset of math data. Points 4 and 5\ndiffer only in the addition of synthetic math data, showing a promising performance improvement. Points 6−12 denote the\nscaling stage where point 6 mixes all math data sources with the tuned recipe from the exploration phase. Points 7 and\n8, match the setting of 6, but use a better teacher model (o3-mini in high thinking mode) combined with a longer context\nlength of 32k tokens (point 8). All points after 9 have added code data on top of the best math recipe of point 8, and the\ncoding progress is shown in the accompanying LiveCodeBench curve. Points 10 and 11 have a better mixture of code data\ncompared to point 9, which is tuned using independent exploration experiments focused on the code domain. Finally, point\n12 adds additional data for safety and Responsibe AI (RAI), which was also included in Phi-4.\nTraining hyperparameters.\nWe began by tuning SFT hyperparameters, focusing primarily on the learning\nrate. We performed a grid search over [1e−6,2e−5], starting from the SFT learning rate of the base model Phi-4\n(1e−6) to its mid-training learning rate (3e−5). In our experiments, 1e−5 provided the best balance in terms of\nreasoning performance. We found that higher learning rates result in lower training loss, but saturation and/or\ndegradation across various downstream evaluations. We also tested the effect of zero versus small weight decay\n(1e−4) and found the differences to be within benchmark variance. Experiments 1–3 in Figure 5 illustrate the\nimpact of these hyperparameter choices.\nRole of Synthetic Seed Data.\nAs described in Section 2, we created synthetic math data seeds to encourage\nthe model to produce short, precise final answers. Each response in this dataset is therefore structured as: a\nchain-of-thought block, followed by a brief summarization and a concise final answer. When incorporated into\nthe SFT dataset alongside web-based math problems, this synthetic data led to consistent and significant gains\nin complex tasks—improving performance by 3–10% on AIME 2022–2024. An example small-scale study on the\neffect of this targeted synthetic augmentation is shown in Figure 5 experiments 4 and 5.\nWe note that the model’s learned ability to produce concise, verifiable answers not only improves interpretability\nand SFT performance, but is also conducive to reinforcement learning using verifiable math problems.\nRole of system message.\nTo promote consistent chain-of-though behavior, we trained using a reasoning-\nspecific system message that instructed the model to enclose its reasoning traces within designated <think> and\n</think> tags. In our experiments, using this system message increased robustness and the consistency of chain-\nof-thought generation. We also experimented with partially removing and/or replacing system messages during\ntraining with other generic variants. This increased robustness under random system messages at inference time.\nHowever, when evaluated under the original reasoning message, we observed greater variability in benchmarks\nscores and a slight decrease in average benchmark performance. Based on these findings, we used the following\nfixed reasoning-focused system message in the final SFT training.\n9\n\nsystem_message = “You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves\nthoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.\nThis requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracing,\nand iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and\nSolution using the specified format: <think> Thought section </think> Solution section. In the Thought section, detail your\nreasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant\nfindings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps.\nIn the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically\npresent the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail\nnecessary steps needed to reach the conclusion. Now, try to solve the following question through the above guidelines”\nOptimizing the Data Mixture.\nA major lever in SFT performance was the composition of the training data\nmixture. Designing the data mixture translates to specifying weights associated with different data sources for\ntraining. In this context, weights correspond to the number of times (epochs) samples from a given data source\nare repeated during SFT. To simplify tuning, we clustered data sources based on (1) domain (e.g., math, code)\nand (2) quality, assigning the same weight to all members of a cluster.\nAn important observation we had was the “additive property” across domains in terms of their optimal data\nmixture. Specifically, in our setting for SFT, we found that mixtures could be optimized independently for each\ndomain—such as math and code—and then combined by simply concatenating their respective weights.\nThe\nresulting composite mixture preserved the domain-specific gains achieved during isolated tuning. This modularity\nallowed us to further break down the data mixture search into smaller components, where we find the individual\nweights per data cluster, per domain. The individual component weights were set by pushing iterations on a given\nset of data sources until saturation on a selected set of metrics.\nFigure 5 illustrates an example of this process on code and math domains: experiment 8 consists of the optimized\ndata mixture for math alone (no code data), while experiment 9 is a simple addition of code data with uniform\nweights which shows an improved score on LiveCodeBench. We then independently tuned the data mixture for\ncode data, and combined it with the math recipe in experiments 10 −12. As shown, the individual recipes from\nmath and code can be aggregated to get improvements on both math and coding benchmarks. This additive\nstructure remains central to the final SFT recipe when we further include alignment and general domain data.\nBase Model for Reasoning.\nWe experimented with two base models for reasoning-focused SFT: Phi-4 and\nPhi-4-base (mid-trained checkpoint before vanilla post-training). Both variations performed similarly on reasoning\nbenchmarks, while Phi-4 performed slightly better in terms of safety and alignment, as measured by the automated\nmeasurement of Responsible AI metrics for LLMs framework [37]. We attribute this to the additional safety-focused\npost-training in Phi-4, and ultimately selected it as the base for Phi-4-reasoning to preserve the benefits of prior\nnon-reasoning post-training.\n3.2\nScaling Stage\nWith the training recipe established during the exploration stage, we scaled our approach in terms of both training\nand inference time computation. On the training side, we conducted SFT over a combined data mixture spanning\nmultiple domains—including math, code, logical puzzles, and safety & responsible AI—using weights derived from\nthe exploration experiments (see Section 3.1). The final model was trained for 16B tokens using this mixture.\nIn addition to scaling data and compute, we also studied the effect of using different teacher models for data\ngeneration on reasoning performance and inference time compute usage.\nSpecifically, we found o3-mini with\nmedium “reasoning effort” effort to have similar effect to DeepSeek-R1 when used as teachers, but o3-mini medium\nwas more token efficient. We also found o3-mini with high-effort to be a stronger teacher than medium-effort\nconsistently across tasks, it also resulted in longer responses, increasing inference-time compute. To accommodate\nthe increased lengths of chain-of-thought reasoning, we extended the model’s context length to 32k tokens, enabling\n10\n\neffective use of longer, more detailed training traces at test time.\nThis stage established the final architecture and training pipeline for Phi-4-reasoning, integrating lessons from both\nmixture design and teacher quality into a scalable, reasoning-optimized system.\n4\nPhi-4-reasoning-plus: A bit of RL on top of Phi-4-reasoning\nFollowing the supervised fine-tuning (SFT) stage described previously, we applied outcome-based reinforcement\nlearning (RL) to further enhance the reasoning capabilities of the Phi-4-reasoning model following a similar recipe\nto [48, 21, 36].\nWe specifically utilized the Group Relative Policy Optimization (GRPO) algorithm [48, 21],\nincorporating modifications tailored specifically to our setup.\nThe RL training focused exclusively on mathematical reasoning. The seed dataset for GRPO consisted of 72,401\nmathematical problems (prompts without solutions), from which we subsample 64 problem seeds per RL iteration.\nThe seed set was curated from the larger training corpus described in Section 2. As we see later in this section,\neven performing RL over a small set of 6,400 problems significantly improved accuracy across math and reasoning\nevaluations. We would like to highlight that the seed data contained no coding exercises, as perhaps evident by\nthe LiveCodeBench scores of our model.\n4.1\nReward Function\nWe employ a rule-based reward model to avoid complexities and potential reward hacking associated with neural\nreward models [6, 17]. The final reward signal, Rfinal, incentivizes correctness, penalizes undesirable behaviors\nsuch as repetition and excessive length, and encourages proper response formatting.\n0\n5k\n10k\n15k\n20k\n25k\n30k\nResponse Length\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\nAccuracy Reward / Progress ( )\nLength aware accuracy reward\nRacc_scaled (Correct Answers)\nRacc_scaled (Incorrect Answers)\n+  (Correct Answers)\n (Incorrect Answers)\nFigure 6: Length-aware accuracy reward\nThe primary reward component is the length-aware accu-\nracy score, Racc_scaled.\nThe raw binary accuracy score,\nRacc_raw ∈{0,1}, is first determined by extracting the fi-\nnal answer (typically within a \\boxed{} tag) and veri-\nfying it against the ground truth using equivalence checks\nand external LLM verifiers if simple answer extraction falls\nthrough, i.e., no \\boxed{} tag in the response for an-\nswer regex matching.\nThe length-aware accuracy reward,\nRacc_scaled depends on Racc_raw and generation length L.\nLet Lmax = 31,744 be the maximum response length (we\nreserve 1024 tokens for the prompt), Lpos_control = 25,600\nbe the maximum length that doesn’t incur length penalty\nfor correct answers, and Lneg_control = 3,702 be the mini-\nmum length that doesn’t incur length penalty for incorrect\nanswers.\nIn a nutshell, we encourage the model to generate concise outputs when the answer is correct, while provoking it\nto think more when the answer is incorrect. Specifically, the length-aware accuracy component is calculated as\n(See Figure 6 for an illustration):\n• If answer is correct (Racc_raw = 1): Define ρ+ = min(1,\nmax(L−Lpos_control,0)\nLmax−Lpos_control\n) for correct answers, length-\naware accuracy reward ranges from R+\nmin = 0.5 to R+\nmax = 1.0, calculated with cosine scaling [60] as:\nRacc_scaled = R+\nmin + 0.5 ⋅(R+\nmax −R+\nmin) ⋅(1 + cos(πρ+)).\n• If answer is incorrect (Racc_raw = 0): Define ρ−= min(1,\nL\nLneg_control ) for incorrect answers, length-aware\n11\n\naccuracy reward ranges from R−\nmin = −1.0 to R−\nmax = −0.5, calculated similarly:\nRacc_scaled = R−\nmax + 0.5 ⋅(R−\nmin −R−\nmax) ⋅(1 + cos(πρ−)).\nFor outputs with format violations, we manually override the length-aware accuracy reward:\n• Incompleteness: Missing end-of-sequence token (<|im_end|>) incurs a penalty: Racc_scaled = −0.5.\n• Invalid “thinking” block: Incorrect or missing use of <think> tag incurs a penalty: Racc_scaled = −1.0.\nBesides the accuracy-based reward, we also consider penalizing outputs that repeat patterns. Specifically, we\ndefine the Repetition Penalty (Rrep) as a negative reward based on repeated 5-grams frequency, computed as\nRrep = −max(#{5-grams with freq. > 5}\n#{5-grams}\n, max freq. of 5-grams with freq. > 5\n#{words}/5\n).\nThe final RL reward is therefore computed as:\nRfinal = waccRacc_scaled + wrepRrep,\nwhere wacc =\n8\n13, wrep =\n1\n13.\n4.2\nTraining Details and Experimental Observations\nWe leverage the verl framework [49] for GRPO training with the reward signal defined above. Hyper-parameters\nfor the RL training are: a global batch size of 64 across 32 Nvidia H100 GPUs, Adam optimizer learning rate\n5 × 10−8 with cosine warm-up in the first 10 steps, GRPO group size of G = 8, KL regularization of β = 0.001\nand entropy coefficient of γ = 0.001. The Phi-4-reasoning-plus was trained with 32k maximum length but has been\ntested to perform well on select benchmarks for up to 64k tokens.\nThe full objective that is maximized in our GRPO training is\n1\nG\nG\n∑\ni=1\n1\n∣oi∣\n∣oi∣\n∑\nt=1\n{min[ πθ(oi,t∣q,oi,<t)\nπθold(oi,t∣q,oi,<t)\nˆAi,t,clip( πθ(oi,t∣q,oi,<t)\nπθold(oi,t∣q,oi,<t),1 −ϵ,1 + ϵ) ˆAi,t] −βDKL(πθ∣∣πθold) + γEntropy(πθ)}\nwhere ˆAi,t = Rfinal(q,oi)−mean({Rfinal(q,o1),...,Rfinal(q,oG)}\nstd({Rfinal(q,o1),...,Rfinal(q,oG)})\nis the group relative advantage estimated from the reward\nabove.\nWe select as our RL checkpoint the model with the best observed AIME 2024 score, which is the model trained\nfor 90 steps, over only ∼6k examples (and 8 trajectories of responses per example). We share some of our findings\non GRPO training dynamics of Phi-4-reasoning-plus in Figure 7.\nStarting from a strong SFT model, i.e., Phi-4-reasoning, additional GRPO training for only 90 steps boosts AIME\nperformance by more than 10% (Figure 7a). Further training for more steps does not translate to additional gains,\nhinting the potential of an already strong SFT model is near its performance ceiling. A caveat to this observation\nis the fact that we clip responses beyond 31k output tokens during GRPO2, which limits the extent to which\nGRPO can help.\nWe find that throughout GRPO training, the duration of the response is strongly correlated with the performance\nof the model on AIME, as shown in Fig. 7c. Moreover, AIME scores seem weakly correlated with reward, for\n2Outputs that are longer than 31k are clipped to their first 31k tokens, as we reserve 1k tokens for the prompt.\n12\n\n0\n20\n40\n60\n80\n100\n120\nRL step\n60\n65\n70\n75\n80\nAccuracy (%)\nAIME 25 & 24 Accuracy vs RL Steps\nAIME 25 accuracy\nAIME 24 accuracy\n(a) Accuracy vs. RL steps\n0.64\n0.66\n0.68\n0.70\nReward\n60\n65\n70\n75\n80\nAccuracy (%)\nAIME Accuracy vs Reward\nAIME 24\nAIME 25\n(b) Accuracy vs. reward\n4000\n6000\n8000\n10000\n12000\n14000\nAverage response length (tokens)\n60\n65\n70\n75\n80\nAccuracy (%)\nAIME Accuracy vs Avg Response Length\nAIME 24\nAIME 25\n(c) Accuracy vs. length\n0\n20\n40\n60\n80\n100\n120\n140\nRL step\n0\n5000\n10000\n15000\n20000\n25000\nResponse length (tokens)\nResponse Length Breakdown vs RL Steps\nMean correct (smoothed)\nMean correct (raw)\nMean incorrect (smoothed)\nMean incorrect (raw)\n75th %ile (smoothed)\n75th %ile (raw)\n25th %ile (smoothed)\n25th %ile (raw)\n(d) Length growth vs. RL steps\n0\n25\n50\n75\n100\n125\nRL step\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nReward\nRfinal & Length clip ratio vs RL Steps\nRfinal (smoothed)\nRfinal (raw)\nLength clip (smoothed)\nLength clip (raw)\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150\nClip ratio\n(e) Final reward and response length\nclip-ratio vs RL steps\n0\n20\n40\n60\n80\n100\n120\n140\nRL step\n0.7\n0.8\n0.9\n1.0\n1.1\n1.2\nEntropy (nats)\nModel output Entropy vs RL Steps\nEntropy (smoothed)\nEntropy (raw)\n(f) Entropy vs. RL steps\nFigure 7: Behaviour of Phi-4-reasoning-plus during the first 125 GRPO updates.\nexample, see Fig. 7b, despite the fact that the model is trained with reward signals primarily from accuracy\n(Figures 7b and 7c).\nThe effect of growing response length is desired during training with GRPO, as the model learns to spend more test\ntime compute before answering a question, inherently improving its reasoning ability. Figure 7d further reveals\nthis effect due to our reward model design3, where generation length of incorrect answers grows faster than correct\nones as the model is rewarded higher to think more before answering when its current answer is incorrect.\nIn fact, further improvements to GRPO could potentially be achieved through rejection sampling based solely on\nresponse length, particularly for responses significantly exceeding the median length. As illustrated in Fig. 7d,\nduring our training runs, responses within the bottom 25th percentile of length increase similarly to the average\nlength of correct responses across RL iterations. In contrast, incorrect responses tend to grow in length more\nrapidly with each iteration, aligning closely with the 75th percentile of overall response lengths. This divergence\nsuggests that length-based rejection sampling may enhance model efficiency by selectively moderating overly\nextensive, typically incorrect outputs.\nMeanwhile, it is worth noting that due to the maximum sequence length constraint, incorrect answers might not\nalways get corrected once they use up all 31k of maximum allowed generation tokens before the model gets a chance\nto produce a final answer in the end with the \\boxed{} tag, thus reward plateaus as clipping of excessively long\ngenerations goes up (Figure 7e).\nDespite enforcing length clipping during training, we observe that the model consistently maintains healthy entropy\nlevels, suggesting sustained exploration within its solution space (Figure 7f). We hypothesize that enabling the\nmodel to support even longer context windows—such as 64k tokens, potentially through interpolation techniques\nsimilar to those used to extend context length from 16k to 32k during SFT or alternative RoPE interpolation\nmethods [14, 32, 36]—could yield additional benefits in GRPO training. We leave the exploration of this extended-\ncontext approach for future work.\n3The maximum possible Rfinal = 8/13 ≈0.62 by our reward function design.\n13\n\nModel\nAIME 24\nAIME 25\nHMMT\nOmniMath\nGPQA-D\nLCB\nCodeforces\nFeb 2025\n8/24 −1/25\nPhi-4-reasoning\n74.6 (5.1)\n63.1 (6.3)\n43.8 (6.2)\n76.6 (0.5)\n67.1 (2.7)\n53.8\n1736\nPhi-4-reasoning-plus\n81.3 (1.8)\n78.0 (4.6)\n53.6 (6.3)\n81.9 (0.1)\n69.3 (2.1)\n53.1\n1723\nOpenThinker2-32B.\n58.0\n58.0\n—\n—\n64.1\n—\n—\nQwQ 32B\n79.5\n65.8\n47.5\n—\n59.5\n63.4{8/24−2/25}—\nEXAONE-Deep-32B\n72.1\n65.8\n—\n—\n66.1\n59.5{9/24−2/25}—\nDeepSeek-R1-Distill-70B 69.3 (2.7)\n51.5 (5.8)\n33.3\n63.4 (0.4)\n66.2 (2.4)\n57.5\n1633\nDeepSeek-R1\n78.7 (3.8)\n70.4 (4.3)\n41.7\n85.0 (0.6)\n73.0 (1.7)\n65.9\n2029\no1-mini\n63.6\n54.8\n38.0 (6.2)\n60.5\n60.0\n53.8\n1650\no1\n74.6 (6.5)\n71.4 (5.7)\n48.3\n67.5 (0.9)\n76.7 (1.8)\n63.4\n1891\no3-mini-high\n88.0 (5.5)\n82.5 (4.9)\n67.5\n74.6 (5.1)\n77.7 (0.6)\n68.8\n2130\nClaude-3.7-Sonnet\n55.3 (3.0)\n53 (5.8)\n31.7\n54.6 (0.9)\n76.8 (1.3)\n52.6\n—\nGemini-2.5-Pro\n92\n86.7\n82.5\n—\n84\n69.1\n—\nTable 1: Average Pass@1 accuracy (%) of models on selected reasoning benchmarks. Bold denotes best model per benchmark\nand model class (i.e., open and closed model weights), and underline denotes the second best. We report standard deviation\nin parentheses for all results we produced using Eureka [10] and MathArena’s [11] judge/scoring function for HMMT.4\n5\nEvaluation\nWe evaluate our models along two complementary axes: reasoning-specific capabilities and general-purpose capa-\nbilities. The primary distinction between these benchmark categories lies in the extent to which the solution to\nthe problems could benefit from step-by-step problem-solving, which is a behavior explicitly encouraged by our\ntraining methods. Nevertheless, there exist several general-purpose capabilities that incorporate some form of\nsimpler reasoning among other more salient expected behaviors, for which extended scratchpads with reasoning\ntraces may also help with the final performance. Several of the general-purpose benchmarks may also contain\nmore complex prompts related to math and constraint satisfaction (e.g. MMLUPro, FlenQA etc.). The following\nempirical results analyze both in order. For both parts, we draw from a rich and diverse set of benchmarks that\nare still challenging for most state-of-the-art models, with less emphasis on over saturated benchmarks.\n5.1\nReasoning Benchmarks\nAmong the benchmarks discussed in this report, AIME, MATH, GPQA Diamond, and LiveCodeBench are widely\nadopted in recent technical reports accompanying major model releases [43, 27, 21]. AIME comprises problems\nfrom the American Invitational Mathematics Examination, spanning the years 1983 through 2025, while GPQA\nincludes graduate-level science questions authored by domain experts in biology, physics, and chemistry. The\nperformance on these benchmarks are discussed in Figure 1.\nThe subset of AIME for the year 2025 is particularly interesting as it was released after the finalization of training\ndata for Phi-4-reasoning, ensuring it remains fully contamination-free. However, this benchmark contains only\n30 problems, which makes evaluation particularly sensitive to sampling variance—especially at higher decoding\ntemperatures commonly used in reasoning models. For all models including ours and those in the OpenAI and\nDeepSeek family, average-of-5 results from two independent runs can differ significantly by up to 5-10 percentage\npoints on AIME 2025, thus making side-by-side comparison of models unreliable.\nTo mitigate this issue and\nincrease the statistical robustness of results, we report pass@1 accuracy averaged over 50 independent runs in Ta-\n4We use 50 and 64 repetitions for AIME 2025 and HMMT respectively (for statistical robustness) and five repetition for all other\nbenchmarks. Scores for all baselines for LiveCodeBench are from [21] or LiveCodeBench leaderboard. Sores for HMMT 2025 are from\nMathArena leaderboards. All other scores for OpenThinker2 [53], QwQ [54], EXAONE-Deep [31] and Gemini-2.5-Pro are reproduced\nfrom their corresponding reports. Claude-3.7-Sonnet is evaluated with thinking enabled. Codeforces evaluation for Phi models are\nperformed using procedure described in 5.1 while all other Codeforces numbers are from their corresponding reports. Empty cells\nindicate results not yet reported.\n14\n\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy\n12.9\n63.1\n78.0\n51.5\n70.4\n71.4\n82.5\n53.0\n60.7\nAIME 2025\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy\n28.0\n83.1\n89.4\n79.3\n86.0\n83.9\n93.0\n72.4\n74.5\nAIME 83-24\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy\n31.9\n76.6\n81.9\n63.4\n85.0\n67.5\n74.6\n54.6\n61.1\nOmni-MATH\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n54.7\n67.1\n69.3\n66.2\n73.0\n76.7\n77.7\n76.8\n72.0\nGPQA\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy\n16.0\n67.7\n65.6\n66.8\n79.2\n86.1\n62.0\n88.5\n67.7\nBA Calendar\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n17.1\n78.0\n70.9\n72.2\n80.7\n89.0\n96.1\n61.8\n62.6\nSAT\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy\n8.2\n37.5\n42.6\n32.4\n46.7\n45.8\n56.4\n47.7\n30.1\nTSP\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy\n51.4\n55.1\n53.4\n45.2\n47.5\n79.7\n80.0\n53.3\n49.3\nMaze\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy\n61.3\n73.7\n73.3\n70.8\n76.7\n83.6\n77.4\n74.9\n68.7\nSpatial Map\nFigure 8: Average Pass@1 model performance across eight reasoning tasks across five independent runs (generations). We\nuse larger number of generations for AIME 2025 and GPQA for more statistical robustness.5\nble 1 and Figure 1. Further detailed analysis and visualizations of AIME 2025 performance, including comparisons\nbetween Phi-4-reasoning and Phi-4-reasoning-plus are provided in Figure 9 and Section 5.1.2.\nTo assess reasoning ability more broadly, we adopt a comprehensive suite of benchmarks from [10].\nOmni-\nMATH [16] includes over 4000 olympiad-level problems with rigorous human annotations, covering a wide range\nof topics and problem types. We also include two new benchmarks, 3SAT and TSP [10] for studying the ability of\nmodels to solve NP-hard problems using symbolic and combinatorial reasoning [44, 22]. In addition, we evaluate\non BA-Calendar [13], a calendar planning benchmark that requires models to find a common time slot among\nparticipants while considering constraints beyond availability, such as time zones, buffer time, priority, etc. Fi-\nnally, we include two spatial reasoning benchmarks: Maze and SpatialMap [56]. Maze consists of multiple choice\nquestions such as counting the number of turns or determining the spatial relationships between two points in a\ngiven maze, and we use the 10×10 version of the benchmark. SpatialMap evaluates relational reasoning by asking\nabout spatial relations between objects or counts satisfying geometric constraints.\nFor all these results, we use the implementation pipelines provided in the Eureka ML Insights repository6 to\nevaluate all models. Eureka ML Insights is a reusable and open evaluation framework for standardizing evaluations\nof large foundation models beyond single-score reporting and rankings. Note that the evaluation results on the\n5We use 50 and 64 generations for AIME 2025 and GPQA respectively and provide more analysis of variance in Figure 9\n6https://github.com/microsoft/eureka-ml-insights\n15\n\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAccuracy\n0\n2\n4\n6\n8\n10\nDensity\nAIME 2025\nPhi-4-reasoning-plus\nPhi-4-reasoning\nPhi-4\nO3-mini High\nDeepSeek R1\nR1 Distill Llama 70B\nFigure 9: Distribution of pass@1 accuracy on AIME 2025, approximated by kernel density estimation using 50 independent\nruns with the same prompt and temperature (0.8). We observe a high accuracy variance for all models (DeepSeek-R1-\nDistill-Llama-70B ranges from 30% to 70%, while o3-mini’s accuracy range is from 70% to 100%) suggesting that model\ncomparisons among models using a single run results can be unreliable. The accuracy distribution further indicates the\ncompetitive performance of Phi-4-reasoning-plus, largely intersecting with o3-mini’s distribution and being almost disjoint\nfrom the DeepSeek-R1-Distill-Llama-70B’s distribution.\nbaseline models were recently reported in [10], we reuse the same evaluation logs for baseline comparisons as well\nas the same evaluation methodology for studying Phi-4-reasoning and Phi-4-reasoning-plus.\nThe full list of reasoning benchmarks used in this report is summarized in Table 4. The performance of Phi-4-\nreasoning and Phi-4-reasoning-plus on this comprehensive suite of benchmarks along with select baselines are shown\nin Figure 8.\n5.1.1\nBaseline models\nWe compare our models with selected state-of-the-art models as described in Table 3, including o1, o3-mini-high,\nDeepSeek-R1, DeepSeek-R1-Distill-Llama-70B, Claude 3.7 Sonnet, and Gemini 2 Flash Thinking. We use temperature\n0.8 for the Phi models, 0.6 for models in the DeepSeek family as recommended in the corresponding model cards\non HuggingFace, and otherwise use either 1.0 or the default temperature setting in the model APIs. In terms\nof maximum token length, we aim to allow as many tokens as possible to all models, within limits that do not\npresent other experimental hurdles such as timeouts from the API. For both our models we use the system message\ndescribed in Section 3. We use the same CoT prompt templates for all models on all benchmarks, which explicitly\nrequire models to think step by step and then provide an answer. For o1 evaluations we use a plain non-CoT\nprompt template because of policy violation refusals usually triggered by CoT requests.\nIn addition to the baselines in Figure 8, we report comparison with evaluations in newer baselines including\nOpenThinker2 [53], QwQ [54], EXAONE-Deep [31], and Gemini-2.5-Pro [18] in Table 1.\n5.1.2\nAccuracy distribution on AIME 2025: Beyond single-score analyses\nMost existing comparisons of reasoning models on AIME 2025 use the average accuracy computed on a single\npass over the dataset. However, LLMs have exhibited large generation nondeterminism, i.e., they may produce\nsubstantially different answers given the same prompts and inference parameters (such as temperature and max\ntokens) [9, 10, 25]. For larger non-reasoning models, nondeterminism can occur even at very low temperature (even\nzero), and the phenomenon is also almost always expected for reasoning models which are expected to diversify\n16\n\n1983\n1986\n1989\n1992\n1995\n1998\n2001\n2004\n2007\n2010\n2013\n2016\n2019\n2022\n2025\nYear\n0.6\n0.7\n0.8\n0.9\n1.0\nAccuracy\nAIME\nPhi-4-reasoning-plus\nPhi-4-reasoning\nO3-mini High\nDeepSeek R1\nR1 Distill Llama 70B\nFigure 10: Performance breakdown by years (from 1983 to 2025) for AIME on 5 independent runs.\nThere is a large\nperformance variance across different years. For example, most models perform substantially worse in 1994 and 2025.\nthe inference paths and also highly recommended to be run at high temperatures (0.6 ∼1.0). Given that AIME\n2025 also only contains 30 questions, nondeterminism renders the accuracy-based analysis questionable.\nTo account for the stochastic nature of such experiments, we study the accuracy distribution on AIME 2025,\napproximated by kernel density estimation using 50 independent runs with the same prompt and temperature\n(see Table 3 for temperature details). We have found several interesting observations as shown in Figure 9. First,\nwe observe a high accuracy variance for all models. For example, accuracy of answers generated by DeepSeek-R1-\nDistill-Llama-70B ranges from 30% to 70%, while o3-mini’s accuracy range is from 70% to 100%. This suggests that\nany comparison among models using a single run can easily produce misleading conclusions. Second, models on the\ntwo extremes of average accuracy demonstrate more robust accuracy. For example, Phi-4-reasoning-plus and Phi-4\nhave relatively narrower accuracy ranges compared to DeepSeek-R1-Distill-Llama-70B and Phi-4-reasoning. Third,\nthe accuracy distribution further indicates the competitive performance of Phi-4-reasoning-plus, largely intersecting\nwith o3-mini’s distribution and being almost disjoint from DeepSeek-R1-Distill-Llama-70B’s distribution. Figure 8\nalso shows the average pass@1 accuracy for several models including ours along with the standard deviation. Note\nthat given the very small size of the data, this picture can look dramatically different from experiments with\nfewer runs (e.g., 5) because there may exist variance even between two different sets of 5 independent runs. This\nbehavior also explains differences and discrepancies between different and concurrent evaluation works that may\nreport different scores across five runs [25, 46] which deviate from what model cards report at release time.\nWe hope that these results will serve as insights for more robust quantitative analyses and as a motivation for\nmoving beyond single-score and single-run accuracy reportings. Throughout this report, we also aimed to scale\nup our quantitative analysis across a diversified set of benchmarks that have a larger number of samples between\n800-4500, except AIME 24 & 25, HMMT and GPQA which are commonly present in most technical reports\nof recently released models. Larger benchmarks also enable more disaggregated error analysis that allows for\nanalyzing model performance across different subgroups of data, finding common error patterns, and potentially\nbehavioral correlations between models [42, 12, 40].\nAt the same time, it is still important to evaluate models on smaller but very challenging benchmarks (e.g., HMMT,\nUSAMO, AIME) if that analysis includes several runs, standard deviation and statistical tests, and preferably\nqualitative insights. For example, tools like MathArena [11] and our work on Eureka ML Insights [9] practice the\nprocess of revealing not only the scores but also complete evaluation logs per benchmark prompt and per run. In\nparticular, for reasoning models, further work is needed to better understand the variance in model behavior and\nto study the properties of longer solution scratchpads.\n17\n\n5.1.3\nMain findings\nWe present the main findings from the results on the broader set of reasoning benchmarks presented in Figures 8\nand Table 1. We also present complementary analysis that support additional discussions in this section.\nReasoning benchmark performances.\nPhi-4-reasoning and Phi-4-reasoning-plus both present major improve-\nments over the earlier Phi-4 model on a wide range of reasoning tasks including math and scientific reasoning,\ncoding, algorithmic problem solving, and planning. In particular, the two new models improve by 50% accuracy\non math benchmarks (AIME and Omni-Math) and by over 25% on coding (LiveCodeBench). Surprisingly, these\nmodels also improve by 30%-60% on algorithmic and planning problems (Traveling Salesman, Satisfiability, Calen-\ndar Planning) which demonstrates increased generalizability on domains that were not targeted in the fine-tuning\nor RL training for reasoning.\nPhi-4-reasoning and Phi-4-reasoning-plus are comparable with or have better accuracy than R1 models (DeepSeek-\nR1 and DeepSeek-R1-Distill-Llama-70B) and o1/o3-mini models on math reasoning, despite being smaller models\nwith only 14B parameters. While o1/o3-mini have very strong performance on AIME which is a popularly reported\nand small-sized benchmark, the efficacy reduces when considering a more diverse benchmark like Omni-MATH as\nthey struggle in domains like Discrete Math and Geometry (see Figure 15). Phi-4-reasoning and Phi-4-reasoning-\nplus show strong generalization to these diverse math settings as well. This showcases the benefits of rich data\nsynthesis processes based on high-quality seeds and scalable distillation processes, further supported by enhanced\nexploration at RL stage. They also outperform Claude 3.7 Sonnet and Gemini 2 Flash Thinking on all tasks except\nGPQA and Calendar Planning.\nPhi-4-reasoning-plus marks important advantages over Phi-4-reasoning on math (also targeted during the RL stage).\nMore specifically, Phi-4-reasoning-plus is 15% more accurate than Phi-4-reasoning on average across 50 runs on AIME\n2025 (Figure 8), and 5% more accurate on Omni-Math and TSP. This is less pronounced on algorithmic reasoning,\nplanning, coding, and spatial understanding tasks, encouraging further work that enables exploration and verifica-\ntion for a broader set of tasks. For example, we observe that even though the generations of Phi-4-reasoning-plus are\non average across tasks 1.5x longer, on tasks like Calendar Planning, 3SAT, Maze, and SpatialMap, the lengthened\ntraces do not lead to higher accuracy. Nevertheless, a deeper analysis by difficulty level presented in Figure 14\nshows that Phi-4-reasoning-plus is still able to offer improvements for the easy-to-mid levels of difficulty. Accuracy\ndrops towards higher difficulty levels are common for all models, even the most capable ones.\nTo evaluate the models coding ability, we report LiveCodeBench (2024-08 – 2025-01) and Codeforces (using the\n143 problems from contest IDs 1505 through 1536 inclusive) benchmarks in Table 1. For Codeforces, we allow each\nmodel ten independent submission attempts for every problem and finally compute the Elo rating. To validate\ncomparison against other models, we evaluate the same Codeforces protocol on DeepSeek-R1-Distil-Qwen-14B and\nreceive Elo score of 1481. Our numbers were within 1 accuracy point for LiveCodeBench and within 20 Elo rating\npoints for CodeForces as reported in [21]. For all other models, we report the Codeforces numbers as published in\ntheir corresponding reports for reference, however, they may not be directly comparable due to the lack of public\ninformation on their exact evaluation procedure.\nThe evaluation also reveals several opportunities for improvement for both models we contribute in this report,\nand for other models evaluated alongside. As previously noted in recent work [10], improvements in scientific\ntopics like biology and chemistry are smaller than for math and physics (Figure 16). Even within math, all models\nhave lower accuracy on sub topics like discrete math, indicating areas for improvement (Figure 15). Interestingly,\nmodels also follow similar, potentially correlated patterns of errors across years in AIME competitions between\n1983-2025 (Figure 10). Most prominently, all models’ performance drops over time and for recent years.\nPerformance vs. token usage tradeoffs.\nResults on accuracy vs. token usage tradeoffs are shown in Fig-\nure 11. In terms of token length, on average over reasoning benchmarks Phi-4-reasoning-plus’s generations are 1.5x\nlonger than Phi-4-reasoning, and 1.15x longer than o3-mini. Phi-4-reasoning token lengths are similar to o3-mini.\nThe horizontal error bars in the chart show the standard deviation per instance (prompt), which means that\n18\n\nstandard deviation was first computed for each prompt, and then averaged across all prompts in the benchmark.\nThis is to show generation length variability for the same prompt, which is comparable for all models.\n0\n10000\n20000\n30000\nToken count\n0.2\n0.4\n0.6\n0.8\nAccuracy\nAIME 2025\n0\n10000\n20000\n30000\nToken count\n0.4\n0.6\n0.8\nAccuracy\nAIME 83-24\n0\n5000\n10000\n15000\nToken count\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nAccuracy\nOmni-MATH\n0\n5000\n10000\n15000\n20000\nToken count\n0.55\n0.60\n0.65\n0.70\n0.75\nAccuracy\nGQPA\n0\n5000\n10000\n15000\nToken count\n0.2\n0.4\n0.6\n0.8\nAccuracy\nBA Calendar\n0\n5000 10000 15000 20000 25000\nToken count\n0.2\n0.4\n0.6\n0.8\n1.0\nAccuracy\nSAT\n0\n5000\n10000 15000 20000 25000\nToken count\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nAccuracy\nTSP\n0\n5000\n10000\n15000\n20000\nToken count\n0.5\n0.6\n0.7\n0.8\nAccuracy\nMaze\n0\n5000\n10000\n15000\n20000\nToken count\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\nAccuracy\nSpatial Map\nFigure 11: Tradeoff between accuracy and token usage for all benchmarks. The standard deviation for accuracy (vertical,\nfilled line) is computed across 5 different repetitions (50 for AIME 2025). The standard deviation for token usage (horizontal,\ndotted line) is computed by first taking the standard deviation per data instance, and then averaging by the size of the\nbenchmark, to show the variability per instance.\n5.1.4\nAverage vs. best-of-5 performance\nFigures 12 and 17 show different aggregation scores for five runs on all benchmarks. Comparisons between average\naccuracy scores across 5 runs and best-of-5 scores show that, similarly to all other reasoning models, there may\nexist even better trajectories in our models’ generations revealing potential for further progress. This also affirms\nthe importance of using improved verifiers at training time that can extract model capabilities which we cannot\nyet access. While these insights are encouraging, extracting such capabilities without spending N-times more\ninference compute on models that are already expensive at inference time, remains an open question for future\nwork. Reliably improving accuracy across many samplings from the same prompt remains a caveat for all models,\n19\n\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n54.7\n67.1\n69.3\n66.2\n73.0\n76.7\n77.7\n76.8\n72.0\n75.3\n84.3\n85.4\n81.3\n85.4\n90.4\n87.4\n90.9\n86.9\nGPQA\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\ncorrectness\n31.9\n76.6\n81.9\n63.4\n85.0\n67.5\n74.6\n54.6\n61.1\n45.1\n91.5\n92.6\n94.8\n96.5\n81.2\n96.9\n72.5\n97.7\nOmni-MATH\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nresult\n8.2\n37.5\n42.6\n32.4\n46.7\n45.8\n56.4\n47.7\n30.1\n17.0\n55.2\n60.5\n50.4\n64.5\n63.9\n74.6\n68.4\n48.6\nTSP\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n16.0\n67.7\n65.6\n66.8\n79.2\n86.1\n62.0\n88.5\n67.7\n41.8\n86.5\n79.0\n89.6\n91.8\n92.5\n67.0\n93.3\n89.2\nBA Calendar\nFigure 12: Results on reasoning benchmarks with different aggregations on 5 independent runs: worst of 5, average pass@1,\nmajority vote, and best of 5. An extended version of this figure can be found in appendix Figure 17.\nincluding ours. This is an aspect that can impact user and developer experience on repeated prompts, where\ndeterminism and predictable performance are both important.\n5.2\nGeneral-purpose Benchmarks\nIn addition to reasoning benchmarks, we also report results in standard benchmarks to ensure training models\non reasoning does not degrade their general abilities. First, we use the benchmarks from the Phi-4 report [2].\nSpecifically, we use OpenAI’s simple-evals framework (including prompts, temperature, and extraction) for eval-\nuating the model on MMLU [24] and MGSM [50]. Furthermore, we evaluate our models on MMLU-pro [57],\nHumanEvalPlus [35], and ArenaHard [33]. Next, we also use a set of general-purpose benchmarks from the Eureka\nML Insights repository, namely FlenQA [30], Toxigen [23], Kitab [3] and IFEval [62]7. Finally, we use PhiBench,\nour internal collection of evaluations [2]. See Table 2 for results.\nFlenQA [30] consists of 12K questions ranging in length from 250 to 3000 tokens with True/False labels. This\nbenchmark was designed to isolate the effect of input length on LLMs’ performance using multiple versions of\nthe same task, extended with padding of different lengths, types and locations. The task itself involves making\ninferences on top of two logical statement needles introduced in context, and answering a question that requires\nboth statements. Each prompt is padded with paragraphs sampled from other instances of the same task, or\nparagraphs sampled from Book Corpus, with key information presented at various locations in the context (at the\nbeginning, at the end, in the middle, or at random locations). Results on this benchmark show that reasoning\nmodels, Phi-4-reasoning, Phi-4-reasoning-plus, and o3-mini, are robust to longer inputs compared to conventional\nmodels Phi-4 and GPT-4o, and they are also not affected by the location of key information in the context (See\n7Evaluations of Phi-4 on Eureka ML Insights were done at temperature=0 and reported for a single run all benchmarks except\nIFEval which is smaller than the other benchmarks, for which we ran the evaluation three times (for all models) and report the average\naccuracy.\n20\n\nModel\nPhi-4\nPhi-4-reasoning\nPhi-4-reasoning-plus\no3-mini\nGPT-4o\nFlenQA [3K-token subset] [30]\n82.0\n97.7\n97.9\n96.8\n90.8\nIFEval Strict [62]\n62.3\n83.4\n84.9\n91.5\n81.8\nArenaHard [33]\n68.1⋆\n73.3\n79.0\n81.9\n69.0⋆\nHumanEvalPlus [35]\n83.5\n92.9\n92.3\n94.0\n84.9\nMMLUPro [57]\n71.5\n74.3\n76.0\n79.4\n73.5\nKitab [3]\nNo Context - Precision\n19.3\n23.2\n27.6\n37.9\n53.7\nWith Context - Precision\n88.5\n93.8\n93.6\n94.0\n84.7\nNo Context - Recall\n8.2\n4.9\n6.3\n4.2\n20.3\nWith Context - Recall\n68.1\n74.8\n75.4\n76.1\n69.2\nToxigen Discriminative [23]\nToxic category\n72.6\n86.7\n77.3\n85.4\n87.6\nNeutral category\n90.0\n84.7\n90.5\n88.7\n85.1\nPhiBench 2.21 [2]\n58.2\n70.6\n74.2\n78.0\n73.1\nTable 2: Average pass@1 accuracy of models across general-purpose benchmarks evaluated averaged over five generations.\nFor the results in this table Phi-4-reasoning and Phi-4-reasoning-plus were evaluated at temperature 0.8, while Phi-4 was\nevaluated at temperature of 0.0. For ArenaHard⋆, there is a discrepancy for Phi-4 and GPT-4o compared to the numbers\nreported in the Phi-4 paper [2] due to changing the backend LLM-judge. Bold and underlined numbers denote the best and\nsecond best scores, respectively, per benchmark.\nappendix Figure 13). Improvements are potentially linked to the fact that reasoning models are trained to better\nhandle longer context and self-reflection on such context.\nKitab [3] is a challenging information retrieval benchmark containing queries with constraint filters (e.g. List all\nbooks written by Isabel Allende, written between 2000-2010.). We performed Kitab evaluations either using the\nmodel’s parametric knowledge only (no context) or with grounding in a RAG-style setting (with context), only on\nthe subset of queries that contains a single book constraint. The addition of reasoning capabilities to the Phi family\nmodels generally seems to improve precision and degrade recall in the no-context setting, while improving both\nmetrics to be almost on-par with o3-mini when retrieval context is provided. Information retrieval and factuality\nwith only parametric knowledge remain challenging for our models, potentially due to their significantly smaller\nscale. This remains an avenue for further improvement for all models (even for the larger ones), for teaching them\nhow and when to retrieve information from other sources.\nIFEval [62] includes instruction-based prompts that involve instructions amenable to objective verification of\ncompliance. The addition of reasoning capabilities to the Phi family significantly improves performance on this\nbenchmark to even surpass GPT-4o’s performance.\nOur reasoning models also lead to improvements over the Phi-4 model of more than 10% on ArenaHard, Hu-\nmanEvalPlus, and our private PhiBench 2.21 data, which is tailored to evaluate diverse abilities that the team\nfound critical to Phi-4 development [2]. There is also a 3%-5% improvement on MMLUPro. As we mentioned\nearlier in this section, while these benchmarks are more for general purpose evaluation, it is not entirely incidental\nthat we observe improvements on these too. These benchmarks still combine simpler forms of reasoning as part of\nthe main task, although reasoning is not the main skill to test. Some of them even include simpler math problems\nand constraint satisfaction queries. It is however encouraging to see that Phi-4-reasoning and Phi-4-reasoning-plus\nbring well-rounded, general improvements on a highly diverse set of measurements.\n5.3\nSafety Evaluation\nWe developed Phi-4-reasoning in accordance with Microsoft’s Responsible AI principles8. To assess model safety,\nwe used the following benchmarks:\n8https://www.microsoft.com/en-us/ai/principles-and-approach\n21\n\n250 500\n1000\n2000\n3000\nContext Length\n82.5\n85.0\n87.5\n90.0\n92.5\n95.0\n97.5\n100.0\nAccuracy (%)\nModel Accuracy vs Context Length\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy (%)\nFirst\nLast\nMiddle\nRandom\nDispersion Type\nModel Accuracy vs Dispersion of Key Information in Context\nPhi-4\nPhi-4-reasoning\nPhi-4-reasoning-plus\nGPT-4o\nO3-mini High\nFigure 13: FlenQA - (Left) Effect of context length on language models’ performance. All models suffer a degradation in\naccuracy with increased context length. Reasoning models are more robust than conventional models in this regard. (Right)\nAccuracy of language models in the longest context setting (3000 tokens), with key information placed at the beginning\n(first), at the end (last), in the middle (middle), or dispersed at random locations (random) of the context. In the first\nthree dispersion settings, the two pieces of key information are adjacent, while in the random setting they are presented\nseparately. Conventional models are remarkably more challenged in the random setting compared to other settings while\nreasoning models are not affected by the dispersion of information.\nAutomated RAI Measurement Framework: We used a framework for automated measurement of Responsible AI\nmetrics for LLMs [37]. In this framework, one LLM poses as a user and engages in a synthetic conversation with\nthe LLM under test. Another LLM then evaluates the responses to measure its tendency to violate Responsible\nAI guidelines for the following categories: (1) How many times the user succeeded in Jailbreaking the model under\ntest? (2) How many times the model under test generates Potentially Harmful Content? (3) How many times the\nmodel leaks Intellectual Property (IP)? These categories are divided into multiple sub-categories described in [37].\nResults show that Phi-4-reasoning shows minor regression compared to the base model Phi-4.\nToxigen: Toxigen [23] is a large-scale dataset consisting of toxic and neutral statements about 13 groups of people\nwith a focus on implicit hate speech about minority groups. The dataset is balanced with an equal number of toxic\nand neutral prompts for each identity group. This allows us to evaluate erasure as well as toxicity detection: that\nis where the identity mention of specific groups of people is treated as a signal of toxicity or hate. Results indicate\nthat as we add reasoning capabilities to models, we are able to improve performance on only one of the toxic or\nneutral categories at a time, indicating that detecting toxicity without causing erasure is still a challenging problem\nfor all models. Nevertheless, we still observe modest improvements even in this task, with Phi-4-reasoning offering\na better balance (than Phi-4-reasoning-plus and Phi-4) between toxic vs. neutral content detection accuracy. Lower\nimbalance is also a preferable behavior for applications such as content filtering and moderation. Figure 18b in the\nappendix shows a more detailed view of model accuracy on Toxigen, reported for 13 different demographic groups.\nImprovements from Phi-4-reasoning show that the model has also narrowed some of the group-based discrepancies,\npreviously observed in Phi-4. This is a positive direction towards increased group-based fairness. Both models\nalso improve upon the Phi-4 model.\nDespite the above measurements, appropriate evaluation of output generated by reasoning models remains a\nchallenge mainly due to the fact that current LLM judges and tools have not yet been optimized for long, step-\nby-step traces and may struggle with the extended length and the non-linear generations. For example, reasoning\nmodels may tend to repeat the problem, create counterfactuals of the problem statement or edge cases. In this\nprocess, judges may falsely trigger safety measures or otherwise miss important assumptions and biases that models\nmight have due to the entangled nature of the language [29]. Future research is needed to mature the practices\n22\n\nin these areas by potentially improving safety-oriented verification methods and by decomposing and simplifying\nthe evaluation of long traces.\nFinally, the above measurements focus on measuring engagement and refusal in jailbreak scenarios and on\nclassification-style toxic language detection. We acknowledge that it is also important to evaluate models, includ-\ning ours, in more open-form and benign scenarios, beyond jailbreaks and adversarial scenarios. These evaluations\nwould enable a better understanding of how biases and harms may occur in benign, real-world tasks.\n6\nLimitations\nPhi-4-reasoning inherits limitations from its base model. For example, the Phi-4 model primarily supports English\ntext, with performance declining for other languages and less represented English varieties compared to standard\nAmerican English. Despite safety measures, the model may still perpetuate stereotypes, misrepresent groups,\nor produce inappropriate content due to biases in training data. Additionally, as we show in our evaluations on\ngeneral-purpose benchmarks for factuality, the model can generate inaccurate or outdated information that sounds\nplausible. For coding, Phi-4 is mainly trained on Python using common packages, and users should manually verify\nAPI uses if scripts involve other languages or packages.\nAdditionally, Phi-4-reasoning also exhibits common limitations of other reasoning language models such as requir-\ning more computational time and resources due to their reasoning processes, resulting in slower response times\ncompared conventional LLMs. Additionally, reasoning models may produce responses that contradict their own\nreasoning chains, potentially leading to inaccuracies. The ability to understand and monitor the reasoning steps\nfor more transparency is still an active area of research.\nThe Phi-4-reasoning model, while powerful, also has notable limitations, particularly with its context length of\n32k tokens. This constraint can be limiting for more complex tasks that require extensive context to generate\naccurate and coherent responses. Additionally, the model sometimes generates responses that exceed its context\nwindow size, leading to truncation and loss of important information.\nThis limited context window size also\nimpacts the model’s performance in multiturn interactions, as it may struggle to maintain continuity over extended\nconversations. Furthermore, the supervised fine-tuning (SFT) training data is limited to STEM, code, and safety,\nwhile the reinforcement learning (RL) data is limited to math. Although there are signs of generalization to other\ndomains, this limitation may affect the model’s performance on different contexts.\nAuthor Contributions\nData and Supervised Finetuning: Mojan Javaheripi, Arindam Mitra, Sahaj Agarwal, Caio César Teodoro\nMendes, Olli Saarikivi, Marah Abdin and Suriya Gunasekar\nReinforcement Learning: Yue Wu, Harkirat Behl, Guoqing Zheng, Vaish Shrivastava and Dimitirs Papail-\niopoulos\nEvaluation and Analysis: Vidhisha Balachandran, Lingjiao Chen, Neel Joshi, Vibhav Vineet, Safoora Yousefi\nand Besmira Nushi\nInfrastructure and Release: Yash Lara, Gustavo de Rosa, Piero Kauffmann and Shital Shah\nProject Lead: Ahmed Awadallah\nAcknowledgements\nWe would like to thank Eric Price, Shivam Garg, John Langford for discussion and feedback and Ece Kamar,\nRafah Hosn, Doug Burger, Peter Lee, Asha Sharma, Chelsea Carter, Rob Young and Weishung Liu for their\nsupport throughout the project.\n23\n\nReferences\n[1] Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree,\nArash Bakhtiari, Jianmin Bao, Harkirat Behl, et al. Phi-3 technical report: A highly capable language model locally\non your phone. arXiv preprint arXiv:2404.14219, 2024.\n[2] Marah Abdin, Jyoti Aneja, Harkirat Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison,\nRussell J. Hewett, Mojan Javaheripi, Piero Kauffmann, James R. Lee, Yin Tat Lee, Yuanzhi Li, Weishung Liu, Caio\nC. T. Mendes, Anh Nguyen, Eric Price, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Xin Wang, Rachel\nWard, Yue Wu, Dingli Yu, Cyril Zhang, and Yi Zhang. Phi-4 technical report, 2024. URL https://arxiv.org/\nabs/2412.08905.\n[3] Marah I Abdin, Suriya Gunasekar, Varun Chandrasekaran, Jerry Li, Mert Yüksekgönül, Rahee Ghosh Peshawaria,\nRanjita Naik, and Besmira Nushi. KITAB: evaluating llms on constraint satisfaction for information retrieval. In\nInternational Conference on Learning Representations, 2024.\n[4] AIME. Aime 83-24. https://huggingface.co/datasets/lchen001/AIME1983_2024, 2024. Accessed: 2025-\n03-17.\n[5] AIME. Aime 2025. https://huggingface.co/datasets/lchen001/AIME2025, 2025. Accessed: 2025-03-17.\n[6] Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Mané. Concrete problems in\nai safety. arXiv preprint arXiv:1606.06565, 2016.\n[7] Anthropic. Claude 3.7 sonnet. https://www.anthropic.com/news/claude-3-7-sonnet, 2025. Accessed: 2025-\n03-17.\n[8] Iván Arcuschin, Jett Janiak, Robert Krzyzanowski, Senthooran Rajamanoharan, Neel Nanda, and Arthur Conmy.\nChain-of-thought reasoning in the wild is not always faithful. arXiv preprint arXiv:2503.08679, 2025.\n[9] Vidhisha Balachandran, Jingya Chen, Neel Joshi, Besmira Nushi, Hamid Palangi, Eduardo Salinas, Vibhav Vineet,\nJames Woffinden-Luey, and Safoora Yousefi. Eureka: Evaluating and understanding large foundation models. arXiv\npreprint arXiv:2409.10566, 2024.\n[10] Vidhisha Balachandran, Jingya Chen, Lingjiao Chen, Shivam Garg, Neel Joshi, Yash Lara, John Langford, Besmira\nNushi, Vibhav Vineet, Yue Wu, and Safoora Yousefi. Inference-time scaling for complex tasks: Where we stand and\nwhat lies ahead, 2025. URL https://arxiv.org/abs/2504.00294.\n[11] Mislav Balunović, Jasper Dekoninck, Ivo Petrov, Nikola Jovanović, and Martin Vechev. Matharena: Evaluating llms\non uncontaminated math competitions, February 2025. URL https://matharena.ai/.\n[12] Solon Barocas, Anhong Guo, Ece Kamar, Jacquelyn Krones, Meredith Ringel Morris, Jennifer Wortman Vaughan,\nW Duncan Wadsworth, and Hanna Wallach. Designing disaggregated evaluations of ai systems: Choices, considera-\ntions, and tradeoffs. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, pages 368–378,\n2021.\n[13] Natasha Butt, Varun Chandrasekaran, Neel Joshi, Besmira Nushi, and Vidhisha Balachandran. Benchagents: Auto-\nmated benchmark creation with agent interaction. arXiv preprint arXiv:2410.22584, 2024.\n[14] Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. Extending context window of large language\nmodels via positional interpolation. arXiv preprint arXiv:2306.15595, 2023.\n[15] Quy-Anh Dang and Chris Ngo. Reinforcement learning for reasoning in small llms: What works and what doesn’t,\n2025. URL https://arxiv.org/abs/2503.16219.\n[16] Bofei Gao, Feifan Song, Zhe Yang, Zefan Cai, Yibo Miao, Qingxiu Dong, Lei Li, Chenghao Ma, Liang Chen, Runxin\nXu, et al. Omni-math: A universal olympiad level mathematic benchmark for large language models. ICLR, 2025.\n[17] Leo Gao, John Schulman, and Jacob Hilton.\nScaling laws for reward model overoptimization.\nIn International\nConference on Machine Learning, pages 10835–10866. PMLR, 2023.\n[18] Google. Gemini flash thinking. https://deepmind.google/technologies/gemini/flash/, 2025. Accessed:\n2025-03-17.\n24\n\n[19] Xinyu Guan, Li Lyna Zhang, Yifei Liu, Ning Shang, Youran Sun, Yi Zhu, Fan Yang, and Mao Yang. rstar-math:\nSmall llms can master math reasoning with self-evolved deep thinking. arXiv preprint arXiv:2501.04519, 2025.\n[20] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan\nJavaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, et al. Textbooks are all you need.\narXiv preprint\narXiv:2306.11644, 2023.\n[21] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi\nWang, Xiao Bi, et al.\nDeepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.\narXiv\npreprint arXiv:2501.12948, 2025.\n[22] Juris Hartmanis. Computers and intractability: a guide to the theory of np-completeness (michael r. garey and david\ns. johnson). Siam Review, 24(1):90, 1982.\n[23] Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar. ToxiGen: A large-\nscale machine-generated dataset for adversarial and implicit hate speech detection. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3309–3326. Association for\nComputational Linguistics, 2022.\n[24] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Mea-\nsuring massive multitask language understanding, 2021. URL https://arxiv.org/abs/2009.03300.\n[25] Andreas Hochlehnert, Hardik Bhatnagar, Vishaal Udandarao, Samuel Albanie, Ameya Prabhu, and Matthias Bethge.\nA sober look at progress in language model reasoning:\nPitfalls and paths to reproducibility.\narXiv preprint\narXiv:2504.07086, 2025.\n[26] Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila\nWelihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024.\n[27] Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander\nMadry, Alex Beutel, Alex Carney, et al. Openai o1 system card. arXiv preprint arXiv:2412.16720, 2024.\n[28] Mojan Javaheripi, Sébastien Bubeck, Marah Abdin, Jyoti Aneja, Caio César Teodoro Mendes, Weizhu Chen, Allie\nDel Giorno, Ronen Eldan, Sivakanth Gopi, Suriya Gunasekar, Piero Kauffmann, Yin Tat Lee, Yuanzhi Li, Anh\nNguyen, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Michael Santacroce, Harkirat Singh Behl, Adam\nTaumann Kalai, Xin Wang, Rachel Ward, Philipp Witte, Cyril Zhang, and Yi Zhang. Phi-2: The surprising power of\nsmall language models. Microsoft Research Blog, 2023.\n[29] Fengqing Jiang, Zhangchen Xu, Yuetai Li, Luyao Niu, Zhen Xiang, Bo Li, Bill Yuchen Lin, and Radha Pooven-\ndran.\nSafechain:\nSafety of language models with long chain-of-thought reasoning capabilities.\narXiv preprint\narXiv:2502.12025, 2025.\n[30] Mosh Levy, Alon Jacoby, and Yoav Goldberg. Same task, more tokens: the impact of input length on the reasoning\nperformance of large language models. In ACL, 2024.\n[31] LG AI Research. Exaone deep: Reasoning enhanced language models. arXiv preprint arXiv:2503.12524, 2025.\n[32] Shanda Li, Chong You, Guru Guruganesh, Joshua Ainslie, Santiago Ontanon, Manzil Zaheer, Sumit Sanghai, Yiming\nYang, Sanjiv Kumar, and Srinadh Bhojanapalli. Functional interpolation for relative positions improves long context\ntransformers. arXiv preprint arXiv:2310.04418, 2023.\n[33] Tianle Li, Wei-Lin Chiang, Evan Frick, Lisa Dunlap, Tianhao Wu, Banghua Zhu, Joseph E Gonzalez, and Ion Sto-\nica.\nFrom crowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline.\narXiv preprint\narXiv:2406.11939, 2024.\n[34] Xuefeng Li, Haoyang Zou, and Pengfei Liu. Limr: Less is more for rl scaling, 2025.\n[35] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated by chatgpt really correct?\nrigorous evaluation of large language models for code generation, 2023.\nURL https://arxiv.org/abs/2305.\n01210.\n25\n\n[36] Michael\nLuo,\nSijun\nTan,\nJustin\nWong,\nXiaoxiang\nShi,\nWilliam\nY.\nTang,\nManan\nRoongta,\nColin\nCai,\nJeffrey\nLuo,\nLi\nErran\nLi,\nRaluca\nAda\nPopa,\nand\nIon\nStoica.\nDeepscaler:\nSurpass-\ning\no1-preview\nwith\na\n1.5b\nmodel\nby\nscaling\nrl.\nhttps://pretty-radio-b75.notion.site/\nDeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2,\n2025. Notion Blog.\n[37] Ahmed Magooda, Alec Helyar, Kyle Jackson, David Sullivan, Chad Atalla, Emily Sheng, Dan Vann, Richard Edgar,\nHamid Palangi, Roman Lutz, Hongliang Kong, Vincent Yun, Eslam Kamal, Federico Zarfati, Hanna Wallach, Sarah\nBird, and Mei Chen. A framework for automated measurement of responsible ai harms in generative ai applications,\n2023. URL https://arxiv.org/abs/2310.17750.\n[38] Arindam Mitra, Luciano Del Corro, Shweti Mahajan, Andres Codas, Clarisse Simoes, Sahaj Agarwal, Xuxi Chen,\nAnastasia Razdaibiedina, Erik Jones, Kriti Aggarwal, et al. Orca 2: Teaching small language models how to reason.\narXiv preprint arXiv:2311.11045, 2023.\n[39] Arindam Mitra, Luciano Del Corro, Guoqing Zheng, Shweti Mahajan, Dany Rouhana, Andres Codas, Yadong Lu,\nWei-ge Chen, Olga Vrousgos, Corby Rosset, et al. Agentinstruct: Toward generative teaching with agentic flows.\narXiv preprint arXiv:2407.03502, 2024.\n[40] Mazda Moayeri, Vidhisha Balachandran, Varun Chandrasekaran, Safoora Yousefi, Thomas Fel, Soheil Feizi, Besmira\nNushi, Neel Joshi, and Vibhav Vineet. Unearthing skill-level insights for understanding trade-offs of foundation models.\nICLR, 2025.\n[41] Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah.\nOrca: Progressive learning from complex explanation traces of gpt-4. arXiv preprint arXiv:2306.02707, 2023.\n[42] Besmira Nushi, Ece Kamar, and Eric Horvitz. Towards accountable ai: Hybrid human-machine analyses for character-\nizing system failure. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, volume 6,\npages 126–135, 2018.\n[43] OpenAI. Openai o3-mini system card. https://openai.com/index/o3-mini-system-card/, 2025. Accessed:\n2025-03-17.\n[44] Christos H Papadimitriou. Computational complexity. In Encyclopedia of computer science, pages 260–265. John\nWiley and Sons Ltd., 2003.\n[45] Samir Passi and Mihaela Vorvoreanu. Overreliance on ai literature review. Microsoft Research, 339:340, 2022.\n[46] Ivo Petrov, Jasper Dekoninck, Lyuben Baltadzhiev, Maria Drencheva, Kristian Minchev, Mislav Balunović, Nikola\nJovanović, and Martin Vechev.\nProof or bluff?\nevaluating llms on 2025 usa math olympiad.\narXiv preprint\narXiv:2503.21934, 2025.\n[47] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael,\nand Samuel R Bowman. Gpqa: A graduate-level google-proof q&a benchmark. In First Conference on Language\nModeling, 2024.\n[48] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li,\nY Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint\narXiv:2402.03300, 2024.\n[49] Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua Peng, Haibin Lin, and\nChuan Wu. Hybridflow: A flexible and efficient rlhf framework. arXiv preprint arXiv: 2409.19256, 2024.\n[50] Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay,\nSebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. Language models are multilingual chain-of-thought\nreasoners, 2022. URL https://arxiv.org/abs/2210.03057.\n[51] Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced transformer\nwith rotary position embedding. arXiv preprint arXiv:2104.09864, 2021.\n[52] Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang\nDu, Chonghua Liao, et al. Kimi k1. 5: Scaling reinforcement learning with llms. arXiv preprint arXiv:2501.12599,\n2025.\n26\n\n[53] OpenThoughts Team. Open Thoughts. https://open-thoughts.ai, January 2025.\n[54] Qwen Team.\nQwq-32b: Embracing the power of reinforcement learning, March 2025.\nURL https://qwenlm.\ngithub.io/blog/qwq-32b/.\n[55] Miles Turpin, Julian Michael, Ethan Perez, and Samuel R. Bowman. Language models don’t always say what they\nthink: Unfaithful explanations in chain-of-thought prompting, 2023. URL https://arxiv.org/abs/2305.04388.\n[56] Jiayu Wang, Yifei Ming, Zhenmei Shi, Vibhav Vineet, Xin Wang, Sharon Li, and Neel Joshi. Is a picture worth a\nthousand words? delving into spatial reasoning for vision language models. Advances in Neural Information Processing\nSystems, 37:75392–75421, 2024.\n[57] Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj,\nXuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, and Wenhu Chen. Mmlu-\npro: A more robust and challenging multi-task language understanding benchmark, 2024. URL https://arxiv.\norg/abs/2406.01574.\n[58] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang,\nHaoran Wei, et al. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115, 2024.\n[59] Guanghao Ye, Khiem Duc Pham, Xinzhi Zhang, Sivakanth Gopi, Baolin Peng, Beibin Li, Janardhan Kulkarni,\nand Huseyin A Inan.\nOn the emergence of thinking in llms i: Searching for the right intuition.\narXiv preprint\narXiv:2502.06773, 2025.\n[60] Edward Yeo, Yuxuan Tong, Morry Niu, Graham Neubig, and Xiang Yue. Demystifying long chain-of-thought reasoning\nin llms. arXiv preprint arXiv:2502.03373, 2025.\n[61] Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Tiantian Fan, Gaohong Liu, Lingjun Liu,\nXin Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang,\nHang Zhu, Jinhua Zhu, Jiaze Chen, Jiangjie Chen, Chengyi Wang, Hongli Yu, Weinan Dai, Yuxuan Song, Xiangpeng\nWei, Hao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao, Yonghui Wu, and Mingxuan Wang.\nDapo: An open-source llm reinforcement learning system at scale, 2025. URL https://arxiv.org/abs/2503.\n14476.\n[62] Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny Zhou, and Le Hou.\nInstruction-following evaluation for large language models. arXiv preprint arXiv:2311.07911, 2023.\n27\n\nA\nBenchmarking Details\nModel\ntemp.\nmax token\nreasoning\nPhi-4 [2]\n0.8†\n4,096\nn\nPhi-4-reasoning\n0.8\n32,768∗\ny\nPhi-4-reasoning-plus\n0.8\n32,768∗\ny\nDeepSeek-R1-Distill-Llama-70B [21]\n0.6\n65,536\ny\nDeepSeek-R1 [21]\n0.6\n65,536\ny\nGPT-4o 2024-05-13 [26]\n1.0\n4,096\nn\no1-mini 2024-09-12 [27]\nNA\nNA\ny\no1 2024-12-17 [27]\nNA\nNA\ny\no3-mini 2025-01-31(high) [43]\nNA\nNA\ny\nClaude 3.7 Sonnet 2025-02-19 [7]\n1.0\n32,768\ny\nGemini 2 Flash Thinking Exp 2025-01-21 [18]\n1.0\n32,768\ny\nTable 3: List of models studied in this report and corresponding temperature and maximum token limits used for all\nexperiments. ∗For Phi-4-reasoning and Phi-4-reasoning-plus evaluations on AIME, HMMT, GPQA, and Codeforces we use\n65,536 as the maximum number of tokens for generation without changing any RoPE parameters. We note that neither\nmodel has properly trained on this length. All other evaluations for Phi-4-reasoning and Phi-4-reasoning-plus use 32,768.\n†For Phi-4 we use temp=0.8 for the reasoning benchmarks, and 0.0 for the general-purpose benchmarks.\nDataset (#prompts)\nLink\nAIME 25 [5] (30)\nhttps://huggingface.co/datasets/lchen001/AIME2025\nAIME 83-24 [4] (949)\nhttps://huggingface.co/datasets/lchen001/AIME1983_2024\nHMMT February 2025 (30)\nhttps://huggingface.co/datasets/MathArena/hmmt_feb_2025\nOmni-MATH [16] (4428)\nhttps://huggingface.co/datasets/KbsdJames/Omni-MATH\nGPQA3 [47] (198)\nhttps://huggingface.co/datasets/Idavidrein/gpqa\nBA-Calendar [13] (2000)\nhttps://huggingface.co/datasets/microsoft/ba-calendar\nTSP-Opt (new benchmark) (960)\nTo be released\n3SAT-Search (new benchmark) (800)\nTo be released\nMaze [56] (1500)\nhttps://huggingface.co/datasets/microsoft/VISION_LANGUAGE\nSpatialMap [56] (1500)\nhttps://huggingface.co/datasets/microsoft/VISION_LANGUAGE\nTable 4: List of reasoning benchmarks used in this report and where to find them.\n28\n\nB\nAdditional Results\nL1\nL2\nL3\nL4\nL5\nL6\nL7\nL8\nDifficulty Levels\n0\n20\n40\n60\n80\n100\nAccuracy\nTSP\nL1\nL2\nL3\nL4\nL5\nL6\nL7\nL8\nDifficulty Levels\n0\n5000\n10000\n15000\n20000\n25000\nToken count\nTSP\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nConstrainedness Level\n0\n20\n40\n60\n80\n100\nAll Pass Accuracy\nBA Calendar\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nConstrainedness Level\n0\n2500\n5000\n7500\n10000\n12500\n15000\n17500\n20000\nToken Count\nBA Calendar\n2\n4\n6\n8\nDifficulty Level\n0\n20\n40\n60\n80\n100\nAccuracy\nOmni-MATH\n2\n4\n6\n8\nDifficulty Level\n0\n2500\n5000\n7500\n10000\n12500\n15000\n17500\nToken Count\nOmni-MATH\nFigure 14: TSP, BA-Calendar, and Omni-Math accuracy and token usage with difficulty levels. Standard deviation for\ntoken usage is computed across different parallel repeats. For Omn-Math, we exclude error bars and some of the models to\nimprove readability. Note the difficult tags in Omni-MATH can be nosiy and imperfect, and the size of the data available\nper level is imbalanced. This leads to fluctuations between adjacent difficulty levels. Similarly, we do not show all models\nfor the BA-Calendar charts.\n29\n\n0\n20\n40\n60\n80\n100\nAccuracy\n Algebra \n Applied Mathematics \n Calculus \n Discrete Mathematics \n Geometry \n Number Theory \n Other\n Precalculus \nCategories\nOmni-MATH Accuracy per Domain\nPhi-4\nPhi-4-reasoning\nPhi-4-reasoning-plus\nR1 Distill Llama 70B\nDeepSeek R1\nO1\nO3-mini High\nClaude 3.7 Sonnet\nGemini 2 Thinking\nFigure 15: Omni-MATH topic-level accuracy. While general model trends are consistent across different topics, all models\ndisplay lower performance on problems related to discrete mathematics and geometry.\n30\n\n0\n20\n40\n60\n80\n100\nAccuracy\nBiology\nChemistry\nPhysics\n62.1\n40.4\n68.6\n64.2\n53.0\n83.0\n54.5\n54.1\n88.9\n61.1\n50.5\n84.2\n73.7\n56.1\n91.2\n63.2\n66.9\n90.2\n69.5\n66.2\n91.9\n65.3\n64.5\n92.6\n65.3\n56.3\n90.5\nGPQA\nPhi-4\nPhi-4-reasoning\nPhi-4-reasoning-plus\nR1 Distill Llama 70B\nDeepSeek R1\nO1\nO3-mini High\nClaude 3.7 Sonnet\nGemini 2 Thinking\n0\n5000\n10000\n15000\n20000\n25000\nToken usage\nBiology\nChemistry\nPhysics\n515\n598\n757\n4747\n9242\n3922\n7600\n14155\n6528\n3451\n6557\n4086\n3856\n6828\n3268\n2527\n4979\n2161\n6160\n11100\n3304\n15255\n19384\n18057\n3440\n6662\n5334\nGPQA\nPhi-4\nPhi-4-reasoning\nPhi-4-reasoning-plus\nR1 Distill Llama 70B\nDeepSeek R1\nO1\nO3-mini High\nClaude 3.7 Sonnet\nGemini 2 Thinking\nFigure 16: GPQA accuracy and token usage by high-level domain. Standard deviations for token usage are computed\nacross five repeats, within the same high-level domain. Improvements for all models on biology and chemistry are lower\nthan on physics.\n31\n\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n12.9\n63.1\n78.0\n51.5\n70.4\n71.4\n82.5\n53.0\n60.7\n26.7\n96.7\n96.7\n80.0\n93.3\n96.7\n96.7\n86.7\n86.7\nAIME 2025\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n28.0\n83.1\n89.4\n79.3\n86.0\n83.9\n93.0\n72.4\n74.5\n32.8\n93.8\n96.2\n90.5\n94.1\n92.8\n97.7\n85.1\n87.3\nAIME 83-24\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n54.7\n67.1\n69.3\n66.2\n73.0\n76.7\n77.7\n76.8\n72.0\n75.3\n84.3\n85.4\n81.3\n85.4\n90.4\n87.4\n90.9\n86.9\nGPQA\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\ncorrectness\n31.9\n76.6\n81.9\n63.4\n85.0\n67.5\n74.6\n54.6\n61.1\n45.1\n91.5\n92.6\n94.8\n96.5\n81.2\n96.9\n72.5\n97.7\nOmni-MATH\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nresult\n17.1\n78.0\n70.9\n72.2\n80.7\n89.0\n96.1\n61.8\n62.6\n37.5\n94.4\n78.9\n93.1\n95.2\n98.4\n99.9\n85.8\n87.2\nSAT\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nresult\n8.2\n37.5\n42.6\n32.4\n46.7\n45.8\n56.4\n47.7\n30.1\n17.0\n55.2\n60.5\n50.4\n64.5\n63.9\n74.6\n68.4\n48.6\nTSP\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n16.0\n67.7\n65.6\n66.8\n79.2\n86.1\n62.0\n88.5\n67.7\n41.8\n86.5\n79.0\n89.6\n91.8\n92.5\n67.0\n93.3\n89.2\nBA Calendar\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n51.4\n55.1\n53.4\n45.2\n47.5\n79.7\n80.0\n53.3\n49.3\n78.4\n76.0\n64.3\n59.3\n59.8\n94.6\n94.6\n76.6\n70.8\nMaze\nPhi-4\nPhi-4-\nreasoning\nPhi-4-\nreasoning-\nplus\nR1 Distill\nLlama 70B\nDeepSeek\nR1\nO1\nO3-mini\nHigh\nClaude 3.7\nSonnet\nGemini 2\nThinking\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nAccuracy\n61.3\n73.7\n73.3\n70.8\n76.7\n83.6\n77.4\n74.9\n68.7\n76.0\n82.3\n77.9\n81.7\n86.6\n89.0\n88.4\n86.1\n78.3\nSpatial Map\nFigure 17: Results on reasoning benchmarks with different aggregations on 5 independent runs: worst of 5, average pass@1,\nmajority vote, and best of 5.\nAcross models and benchmarks we observe improvement in performance with best-of-5\nindicating further room for improvement.\n32\n\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy (%)\nModels\n82.7\n85.5\n85.0\n86.1\n87.3\nAggregate Accuracy\nPhi-4\nPhi-4-reasoning\nPhi-4-reasoning-plus\nGPT-4o\nO3-mini High\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy (%)\nModels\n90.0\n72.6\n84.7\n86.7\n90.5\n77.3\n85.1\n87.6\n88.7\n85.4\nModel Accuracies by Label Type\nToxic\nNeutral\n(a) Toxigen discriminative evaluation across differ-\nent models.\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90 100\nAccuracy (%)\nasian\nblack\nchinese\njewish\nlatino\nlgbtq\nmental_dis\nmexican\nmiddle_east\nmuslim\nnative_american\nphysical_dis\nwomen\nCategories\nAccuracy across Models and Categories\nPhi-4\nPhi-4-reasoning\nPhi-4-reasoning-plus\nGPT-4o\nO3-mini High\n(b) Model comparison across different categories in the discriminative eval-\nuation setting of Toxigen.\nFigure 18: Fine grained results on Toxigen. We observe modest improvements in this task of detecting toxic and neutral\ntext, with Phi-4-reasoning offering a better balance between toxic vs. neutral content detection accuracy. Improvements\nfrom Phi-4-reasoning has also narrowed some of the group-based discrepancies, previously observed in Phi-4 indicating\nincreased group-based fairness.\n33\n"
    }
  ]
}