{
  "1-1 (Weights)": "* \"Support Gemma v3. You can find the checkpoints [on Kaggle](https://www.kaggle.com/models/google/gemma-3/pytorch) and [Hugging Face](https://huggingface.co/models?other=gemma_torch)\"\n* \"- [Gemma 3](https://www.kaggle.com/models/google/gemma-3/pyTorch)\"\n* \"huggingface-cli download google/gemma-3-4b-it-pytorch\"",
  "1-1 (Weights)__evidence": [
    {
      "source": "[readme]",
      "quote": "* [March 12th, 2025 ðŸ”¥] Support Gemma v3. You can find the checkpoints [on Kaggle](https://www.kaggle.com/models/google/gemma-3/pytorch) and [Hugging Face](https://huggingface.co/models?other=gemma_torch)"
    },
    {
      "source": "[readme]",
      "quote": "- [Gemma 3](https://www.kaggle.com/models/google/gemma-3/pyTorch)"
    },
    {
      "source": "[readme]",
      "quote": "huggingface-cli download google/gemma-3-4b-it-pytorch"
    }
  ],
  "1-2 (Code)": "* \"This is the official PyTorch implementation of Gemma models.\"\n* \"We provide model and inference implementations using both PyTorch and PyTorch/XLA, and support running inference on CPU, GPU and TPU.\"\n* \"\"\"Inference-only Gemma 3 multimodal model implementation.\"\"\"\n* \"\"\"Inference-only Gemma model implementation.\"\"\"\n* \"\"\"Inference-only Gemma model implementation.\"\"\"",
  "1-2 (Code)__evidence": [
    {
      "source": "[readme]",
      "quote": "This is the official PyTorch implementation of Gemma models."
    },
    {
      "source": "[readme]",
      "quote": "We provide model and inference implementations using both PyTorch and PyTorch/XLA, and support running inference on CPU, GPU and TPU."
    },
    {
      "source": "[py_files/gemma/gemma3_model.py]",
      "quote": "\"\"\"Inference-only Gemma 3 multimodal model implementation.\"\"\""
    },
    {
      "source": "[py_files/gemma/model.py]",
      "quote": "\"\"\"Inference-only Gemma model implementation.\"\"\""
    },
    {
      "source": "[py_files/gemma/model_xla.py]",
      "quote": "\"\"\"Inference-only Gemma model implementation.\"\"\""
    }
  ],
  "1-3 (License)": "",
  "1-3 (License)__evidence": [],
  "1-4 (Paper)": "* \"[Gemma on Google AI](https://ai.google.dev/gemma)\"\n* \"https://developers.googleblog.com/en/gemma-explained-paligemma-architecture/\"",
  "1-4 (Paper)__evidence": [
    {
      "source": "[readme]",
      "quote": "* [Gemma on Google AI](https://ai.google.dev/gemma)"
    },
    {
      "source": "[py_files/gemma/siglip_vision/config.py]",
      "quote": "# https://developers.googleblog.com/en/gemma-explained-paligemma-architecture/"
    }
  ]
}