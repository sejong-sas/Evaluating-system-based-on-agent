{
  "1-5 (Architecture)": "- **Gemma 3**:\n\"\"\"Inference-only Gemma 3 multimodal model implementation.\"\"\"\n\"\"\"Gemma model config.\"\"\"\n# TODO(imayank): Decouple Gemma versions into separate files.\n\"\"\"Gemma model config.\"\"\"\n\"\"\"Returns the model config for the vision model of Gemma 3 andPaliGemma.\"\"\"",
  "1-5 (Architecture)__evidence": [
    {
      "source": "[readme]",
      "quote": "- **Gemma 3**:"
    },
    {
      "source": "[py_files/gemma/gemma3_model.py]",
      "quote": "\"\"\"Inference-only Gemma 3 multimodal model implementation.\"\"\""
    },
    {
      "source": "[py_files/gemma/config.py]",
      "quote": "\"\"\"Gemma model config.\"\"\""
    },
    {
      "source": "[files]",
      "quote": "# TODO(imayank): Decouple Gemma versions into separate files."
    },
    {
      "source": "py_files/gemma/siglip_vision/config.py",
      "quote": "\"\"\"Gemma model config.\"\"\""
    },
    {
      "source": "py_files/gemma/siglip_vision/config.py",
      "quote": "\"\"\"Returns the model config for the vision model of Gemma 3 andPaliGemma.\"\"\""
    }
  ],
  "1-6 (Tokenizer)": "tokenizer='tokenizer/gemma3_cleaned_262144_v2.spiece.model',",
  "1-6 (Tokenizer)__evidence": [
    {
      "source": "[py_files/gemma/config.py]",
      "quote": "tokenizer='tokenizer/gemma3_cleaned_262144_v2.spiece.model',"
    }
  ],
  "2-1 (Hardware)": "",
  "2-1 (Hardware)__evidence": [],
  "2-2 (Software)": "This is the official PyTorch implementation of Gemma models.\nWe provide model and inference implementations using both PyTorch and PyTorch/XLA, and support running inference on CPU, GPU and TPU.\nfrom google3.third_party.open_models_release.gemma_pytorch.gemma import config as gemma_config\n\"\"\"Preprocesses a list of PIL images for Siglip vision model using only PyTorch and PIL.\"\"\"\n# python scripts/run.py --device=cpu --ckpt=/path/to/your/pytorch_checkpoint/model.ckpt --output_len=2 --prompt=\"The name of the capital of Italy is\"\n# - Replace '/path/to/your/pytorch_checkpoint/model.ckpt' with the actual path to your checkpoint file.",
  "2-2 (Software)__evidence": [
    {
      "source": "[readme]",
      "quote": "This is the official PyTorch implementation of Gemma models."
    },
    {
      "source": "[readme]",
      "quote": "We provide model and inference implementations using both PyTorch and PyTorch/XLA, and support running inference on CPU, GPU and TPU."
    },
    {
      "source": "py_files/gemma/model_xla.py",
      "quote": "from google3.third_party.open_models_release.gemma_pytorch.gemma import config as gemma_config"
    },
    {
      "source": "py_files/gemma/siglip_vision/preprocessor.py",
      "quote": "\"\"\"Preprocesses a list of PIL images for Siglip vision model using only PyTorch and PIL.\"\"\""
    },
    {
      "source": "[py_files/scripts/run.py]",
      "quote": "# python scripts/run.py --device=cpu --ckpt=/path/to/your/pytorch_checkpoint/model.ckpt --output_len=2 --prompt=\"The name of the capital of Italy is\""
    },
    {
      "source": "[py_files/scripts/run.py]",
      "quote": "# - Replace '/path/to/your/pytorch_checkpoint/model.ckpt' with the actual path to your checkpoint file."
    }
  ]
}