{
  "1-1 (Weights)": "The quotes repeatedly state that “Gemma models are provided with open weights and permit responsible commercial use, allowing you to tune and deploy them in your own projects and applications.”  Distribution is handled through public hosting: “You can download Gemma 3 models from Kaggle and Hugging Face.”  The family is explicitly lightweight and open: “Our Gemma models are a family of lightweight, state-of-the-art open models built from the same research and technology used to create the Gemini family of models.”  Gemma 3 is offered in five parameter scales—“270 M, 1 B, 4 B, 12 B, and 27 B”—and the 4 B checkpoint is therefore one of the officially released sizes that can be fetched the same way as the others.  All sizes, including 4 B, have “Quantization-Aware Trained checkpoints” so that users can reduce precision while “preserving high-quality.”  The documentation explicitly advertises opportunities to “Customize Gemma open models,” and the project landing page is referenced as “Gemma open models <https://ai.google.dev/gemma>.”  Collectively, the quotes confirm public availability of the 4 B weights, download locations, the open-weights policy, commercial-use permission, and the presence of QAT checkpoints to facilitate deployment on smaller hardware.",
  "1-2 (Code)": "The public tooling emphasized in the quotes focuses on running and fine-tuning rather than end-to-end pre-training.  A usage stack is listed: “Run Gemma Overview | Hugging Face Transformers | Ollama | Gemma library | Keras | PyTorch | Gemma.cpp,” showing that reference implementations or wrappers exist in several ecosystems (Transformers, Keras, PyTorch, C++/Gemma.cpp, and the Ollama runtime).  Fine-tuning support is highlighted twice: “Tune using Gemma library,” and a warning that “Memory requirements for fine-tuning Gemma models are significantly higher than running inference,” implying that fine-tuning scripts or APIs accompany the release.  In addition to core model code, a safety component is open-sourced: “We released ShieldGemma — a series of state-of-the-art safety classifiers that developers can apply to detect and mitigate harmful content in AI model input and outputs.”  No quote explicitly mentions release of the original pre-training pipeline, data-processing scripts, or full training schedules, so only inference code, fine-tuning utilities, and safety classifier code are confirmed public.",
  "1-3 (License)": "The only licensing language provided appears twice, verbatim: “Gemma models are provided with open weights and permit responsible commercial use, allowing you to tune and deploy them in your own projects and applications.”  From this we can extract the following rights:\n(a) Use – explicitly allowed.\n(b) Modification (tuning) – explicitly allowed (“tune”).\n(c) Redistribution – implied by “open weights,” but not further detailed in the quotes.\n(d) Commercial use – explicitly allowed, though conditioned as “responsible commercial use.”\nNo additional clauses (e.g., ‘non-commercial’, ‘research only’, or ‘no derivatives’) are mentioned in the supplied excerpts, nor is a specific license name or version given.",
  "1-4 (Paper)": "Several references describe official and auxiliary documents.  Core technical material is announced as: “For more technical details on Gemma 3, see the Model Card and Technical Report.”  Two short descriptors present the overarching positioning: “Gemma: Open models based on gemini research and technology,” and “2024. Gemma: Open models based on gemini research and technology.”  Risk and safety work is summarized directly in the text: “To understand and reduce the risk profile for Gemma models, we conducted robust evaluations including manual red teaming, automated adversarial testing, and assessments of model capabilities for dangerous activities. These evaluations are outlined in our model cards for Gemma models and include:” (the list itself is not reproduced in the quotes).  The content-moderation add-on is documented in a separate paper or report: “ShieldGemma: Generative AI Content Moderation Based on Gemma,” with another note that “We released ShieldGemma — a series of state-of-the-art safety classifiers…”.  Benchmarking literature further cites Gemma participation: “We evaluate a wide range of proprietary and open-source LLMs including … Gemma … on IndicGenBench,” and “We perform experiments with … BLOOMZ … Gemma (Team et al., 2024)…,” confirming that Gemma results appear in external comparative studies.  Altogether, the quoted material confirms the existence of an official model card, a technical report for Gemma 3, safety-oriented papers (ShieldGemma), and multiple third-party research works that include Gemma in large-scale evaluations.",
  "1-1 (Weights)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "Gemma models are provided with open weights and permit responsible commercial use , allowing you to tune and deploy them in your own projects and applications."
    },
    {
      "source": "[pdf_text]",
      "quote": "You can download Gemma 3 models from Kaggle and Hugging Face ."
    },
    {
      "source": "[pdf_text]",
      "quote": "Gemma 3 models are available in 5 parameter sizes: 270M, 1B, 4B, 12B, and 27B."
    },
    {
      "source": "[pdf_text]",
      "quote": "For all Gemma 3 models, Quantization-Aware Trained checkpoints are provided, which allow quantizing (reducing the precision), while preserving high-quality."
    },
    {
      "source": "[pdf_text]",
      "quote": "Our Gemma models are a family of lightweight, state-of-the-art open models built from the same research and technology used to create the Gemini family of models."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "You can download Gemma 3 models from Kaggle and Hugging Face ."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "Gemma models are provided with open weights and permit responsible commercial use , allowing you to tune and deploy them in your own projects and applications."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/pytorch_gemma]",
      "quote": "*   Customize Gemma open models"
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/pytorch_gemma]",
      "quote": "*   [Gemma open models](https://ai.google.dev/gemma)"
    }
  ],
  "1-2 (Code)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "Run Gemma Overview Hugging Face Transformers Ollama Gemma library Keras PyTorch Gemma.cpp"
    },
    {
      "source": "[pdf_text]",
      "quote": "Tune using Gemma library"
    },
    {
      "source": "[pdf_text]",
      "quote": "Note: Memory requirements for fine-tuning Gemma models are significantly higher than running inference."
    },
    {
      "source": "[pdf_text]",
      "quote": "• We released ShieldGemma — a series of state-of-the-art safety classifiers that developers can apply to detect and mitigate harmful content in AI model input and outputs."
    }
  ],
  "1-3 (License)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "Gemma models are provided with open weights and permit responsible commercial use , allowing you to tune and deploy them in your own projects and applications."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "Gemma models are provided with open weights and permit responsible commercial use , allowing you to tune and deploy them in your own projects and applications."
    }
  ],
  "1-4 (Paper)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "For more technical details on Gemma 3, see the Model Card and Technical Report ."
    },
    {
      "source": "[pdf_text]",
      "quote": "For more technical details about previous Gemma models, see the following model card pages: Gemma 2 Model Card Gemma 1 Model Card"
    },
    {
      "source": "[pdf_text]",
      "quote": "We evaluate a wide range of proprietary and open-source LLMs including GPT-3.5, GPT-4, PaLM-2, mT5, Gemma, BLOOM and LLaMA on IndicGenBench in a variety of settings."
    },
    {
      "source": "[pdf_text]",
      "quote": "PaLI (Chen et al., 2022 ), BLIP (Li et al., 2023b ), LLaVA (Liu et al., 2024 ), OpenFlamingo (Awadalla et al., 2023 ), PaLIGemma (Beyer* et al., 2024 ) all follow similar techniques."
    },
    {
      "source": "[pdf_text]",
      "quote": "Beyer* et al. (2024) L. Beyer*, A. Steiner*, A. Susano Pinto*, ... PaliGemma: A versatile 3B VLM for transfer, 2024."
    },
    {
      "source": "[pdf_text]",
      "quote": "ShieldGemma: Generative AI Content Moderation Based on Gemma"
    },
    {
      "source": "[pdf_text]",
      "quote": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2"
    },
    {
      "source": "[pdf_text]",
      "quote": "We released ShieldGemma — a series of state-of-the-art safety classifiers that developers can apply to detect and mitigate harmful content in AI model input and outputs."
    },
    {
      "source": "[pdf_text]",
      "quote": "For example, we recently announced Gemma Scope, a new set of tools enabling researchers to “peer inside” the workings of our Gemma 2 model to see how it parses and completes tasks."
    },
    {
      "source": "[pdf_text]",
      "quote": "We only show performance for Gemma-7B-IT, BLOOMZ-7B, LLaMA-65B, GPT-4 and PaLM-2-L models here and report performance for the other models in appendix B.1."
    },
    {
      "source": "[pdf_text]",
      "quote": "Gemma: Open models based on gemini research and technology."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "For more technical details on Gemma 3, see the Model Card and Technical Report ."
    },
    {
      "source": "[sections/https://arxiv.org/abs/2404.16816]",
      "quote": "We evaluate a wide range of proprietary and open-source LLMs including GPT-3.5, GPT-4, PaLM-2, mT5, Gemma, BLOOM and LLaMA on IndicGenBench in a variety of settings."
    },
    {
      "source": "[sections/https://arxiv.org/html/2406.09175v1]",
      "quote": "PaLIGemma (Beyer* et al., 2024 ) all follow similar techniques."
    },
    {
      "source": "[sections/https://arxiv.org/html/2406.09175v1]",
      "quote": "Beyer* et al. (2024) L. Beyer*, A. Steiner*, A. Susano Pinto*, A. Kolesnikov*, X. Wang*, D. Salz, M. Neumann, I. Alabdulmohsin, M. Tschannen, E. Bugliarello, T. Unterthiner, D. Keysers, A. Gritsenko, X. Chen, S. Koppula, A. Grycner, M. Bauer, M. Bošnjak, F. Liu, N. Houlsby, M. Kumar, K. Rong, J. Eisenschlos, M. Minderer, P. Voigtlaender, I. Bica, I. Balazevic, J. Puigcerver, P. Papalampidi, O. Henaff, X. Xiong, R. Soricut, J. Harmsen, and X. Zhai*. PaliGemma: A versatile 3B VLM for transfer, 2024."
    },
    {
      "source": "[sections/https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf]",
      "quote": "Our Gemma models are a family of lightweight, state-of-the-art open models built from the same research and technology used to create the Gemini family of models."
    },
    {
      "source": "[sections/https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf]",
      "quote": "To understand and reduce the risk profile for Gemma models, we conducted robust evaluations including manual red teaming, automated adversarial testing, and assessments of model capabilities for dangerous activities."
    },
    {
      "source": "[sections/https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf]",
      "quote": "These evaluations are outlined in our model cards for Gemma models and include:"
    },
    {
      "source": "[sections/https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf]",
      "quote": "ShieldGemma: Generative AI Content Moderation Based on Gemma"
    },
    {
      "source": "[sections/https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf]",
      "quote": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2"
    },
    {
      "source": "[pdf_text]",
      "quote": "We perform experiments with a variety of open-source LLMs — mT5 (Xue et al., 2021), LLaMA (Tou- vron et al., 2023),6, BLOOMZ (Workshop et al., 2022), Gemma (Team et al., 2024); and proprietary LLMs — GPT-3.5, GPT-4 (OpenAI et al., 2023), and PaLM-2 (Anil et al., 2023)."
    },
    {
      "source": "[pdf_text]",
      "quote": "2024. Gemma: Open models based on gemini research and technol- ogy."
    }
  ],
  "1-5 (Architecture)": "The quotes indicate that the Gemma line is offered in several clearly defined sizes, specifically 270 M, 1 B, 4 B, 12 B and 27 B parameters. Within this family, the 4 B, 12 B and 27 B variants are highlighted for supporting prompt inputs as large as 128 K tokens—described as a sixteen-fold increase in context length over earlier Gemma releases. All Gemma 3 models ship with Quantization-Aware Trained checkpoints so that users can lower numerical precision while maintaining high quality. The project positions Gemma as a lightweight, state-of-the-art open-source model series that re-uses research and technology originally developed for the Gemini model family. Comparative experiments cited in the material place Gemma alongside other well-known open and proprietary LLMs, and one reference notes that a Gemma-7B instruction-tuned variant surpasses LLaMA-13B and LLaMA-65B on most evaluated tasks, reinforcing the claim of competitive performance.",
  "1-6 (Tokenizer)": "",
  "2-1 (Hardware)": "",
  "2-2 (Software)": "For Gemma pre-training, automated techniques were applied to filter personal information and other sensitive data out of the training corpus, reflecting a software-level effort to make the resulting models safer and more reliable.",
  "1-5 (Architecture)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "Gemma 3 models are available in 5 parameter sizes: 270M, 1B, 4B, 12B, and 27B."
    },
    {
      "source": "[pdf_text]",
      "quote": "Gemma 3 models (4B, 12B, and 27B) can handle prompt inputs up to 128K tokens, a\n16x larger context window than previous Gemma models."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "Gemma 3 models (4B, 12B, and 27B) can handle prompt inputs up to 128K tokens, a 16x larger context window than previous Gemma models."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "Gemma 3 models are available in 5 parameter sizes: 270M, 1B, 4B, 12B, and 27B."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "For all Gemma 3 models, Quantization-Aware Trained checkpoints are provided, which allow quantizing (reducing the precision), while preserving high-quality."
    },
    {
      "source": "[sections/Responsible AI Progress Report]",
      "quote": "Our Gemma models are a family of lightweight, state-of-the-art open models built from the same research and technology used to create the Gemini family of models."
    },
    {
      "source": "[pdf_text]",
      "quote": "We perform experiments with a variety of open-source LLMs — mT5 (Xue et al., 2021), LLaMA (Tou vron et al., 2023),6, BLOOMZ (Workshop et al., 2022), Gemma (Team et al., 2024); and proprietary LLMs — GPT-3.5, GPT-4 (OpenAI et al., 2023), and PaLM-2 (Anil et al., 2023)."
    },
    {
      "source": "[pdf_text]",
      "quote": "Gemma-7B instruction tuned model performs better than LLaMA-13B as well as LLaMA-65B on most tasks."
    }
  ],
  "1-6 (Tokenizer)__evidence": [],
  "2-1 (Hardware)__evidence": [],
  "2-2 (Software)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets."
    },
    {
      "source": "[sections/Responsible AI Progress Report]",
      "quote": "As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets. Additionally, we used extensive fine-tuning and reinforcement learning from human feedback to align our instruction-tuned models with responsible behaviors."
    }
  ],
  "2-3 (API)": "",
  "3-1 (Pre-training)": "The provided material paints a clear picture of how the Gemma 3 family – which explicitly includes a 4 B-parameter version – was pre-trained.  First, the range of available checkpoints is broad: 270 M, 1 B, 4 B, 12 B and 27 B parameters are all explicitly mentioned, giving practitioners multiple size options.  Second, the context window has been dramatically expanded; every Gemma 3 model, including the 4 B variant, can process up to 128 000 tokens, a sixteen-fold increase over earlier Gemma generations.  Third, multilingual capability is a key design goal: the model was “trained to support a large number of languages,” so it can address diverse text- and vision-based tasks for users in many locales.  Finally, the training pipeline incorporated automated data-filtering steps aimed at removing personal or otherwise sensitive information from the corpus, an explicit safety and reliability measure taken during pre-training.",
  "3-2 (Fine-tuning)": "Several fine-tuning-related details are explicitly supplied for Gemma.  The documentation warns that memory consumption during fine-tuning is “significantly higher than running inference,” signalling the need for larger GPUs or distributed setups when adapting the 4 B (and other) checkpoints.  Google distributes the Gemma weights under an open licence that permits “responsible commercial use,” explicitly encouraging users to “tune and deploy them” in their own products.  Practical customization avenues are highlighted: a bullet item literally says “Customize Gemma open models,” and an accompanying Colab notebook link demonstrates LoRA-based tuning in a hosted environment, lowering the barrier to experimentation.  Evidence of instruction-tuning effectiveness is given through a benchmark note stating that a Gemma-7B instruction-tuned model surpasses both LLaMA-13B and LLaMA-65B on most evaluated tasks, underscoring the benefits of post-training adaptation for performance.",
  "3-3 (Reinforcement Learning)": "",
  "2-3 (API)__evidence": [],
  "3-1 (Pre-training)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "Gemma 3 models (4B, 12B, and 27B) can handle prompt inputs up to 128K tokens, a 16x larger context window than previous Gemma models."
    },
    {
      "source": "[pdf_text]",
      "quote": "Gemma 3 is trained to support a large number of languages compared to previous Gemma versions, letting you take on more visual and text tasks in the languages your customers use."
    },
    {
      "source": "[pdf_text]",
      "quote": "Gemma 3 models are available in 5 parameter sizes: 270M, 1B, 4B, 12B, and 27B."
    },
    {
      "source": "[sections/Responsible AI Progress Report - Case study: Evaluating Gemma]",
      "quote": "As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets."
    },
    {
      "source": "[sections/https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf]",
      "quote": "As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets."
    }
  ],
  "3-2 (Fine-tuning)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "Note: Memory requirements for fine-tuning Gemma models are significantly higher than running inference."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "Gemma models are provided with open weights and permit responsible commercial use , allowing you to tune and deploy them in your own projects and applications."
    },
    {
      "source": "[sections/https://ai.google.dev/gemma/docs/core]",
      "quote": "Note: Memory requirements for fine-tuning Gemma models are significantly higher than running inference."
    },
    {
      "source": "[sections/https://r.jina.ai/https://ai.google.dev/gemma/docs/pytorch_gemma]",
      "quote": "*   Customize Gemma open models"
    },
    {
      "source": "[sections/https://r.jina.ai/https://ai.google.dev/gemma/docs/pytorch_gemma]",
      "quote": "*   [Fine-tune in Colab](https://colab.sandbox.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb)"
    },
    {
      "source": "[pdf_text]",
      "quote": "Gemma-7B instruction tuned model performs better than LLaMA-13B as well as LLaMA-65B on most tasks."
    }
  ],
  "3-3 (Reinforcement Learning)__evidence": [],
  "4-1 (Pre-training Data)": "The available information about the pre-training data for Gemma models is extremely limited. The single qualifying sentence states that, “As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets.” From this we can conclude that: (1) the data involved is specifically tied to the Gemma family of pre-trained models; (2) a safety-oriented objective guided decisions about the data; and (3) automated filtering techniques were applied to excise personal and otherwise sensitive information before or during pre-training. No further detail is provided in the quote about quantities, domains, languages, or the precise nature of the data sources—only that an automated sanitation step was integral to preparing the pre-training corpus so that the resulting Gemma models would be considered “safe and reliable.”",
  "4-2 (Fine-tuning Data)": "",
  "4-3 (Reinforcement Learning Data)": "",
  "4-4 (Data Filtering)": "All explicit information about data filtering for Gemma comes from the sentence, “As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets.” This establishes that: (a) data filtering was performed specifically for Gemma pre-trained models; (b) the motivation was safety and reliability; (c) the method was automated rather than manual; and (d) the target of the filtering was personal or sensitive information present in the raw training data. No other procedural or technical specifics (criteria thresholds, toolchain, human review, or impact metrics) are revealed in the provided quote.",
  "4-1 (Pre-training Data)__evidence": [
    {
      "source": "[title: Responsible AI Progress Report]",
      "quote": "As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets."
    },
    {
      "source": "[sections/https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf]",
      "quote": "As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets."
    }
  ],
  "4-2 (Fine-tuning Data)__evidence": [],
  "4-3 (Reinforcement Learning Data)__evidence": [],
  "4-4 (Data Filtering)__evidence": [
    {
      "source": "[title: Responsible AI Progress Report]",
      "quote": "As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets."
    },
    {
      "source": "[sections/https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf]",
      "quote": "As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets."
    }
  ],
  "__usage": {
    "fine_tuning": "used",
    "rl": "unknown"
  }
}