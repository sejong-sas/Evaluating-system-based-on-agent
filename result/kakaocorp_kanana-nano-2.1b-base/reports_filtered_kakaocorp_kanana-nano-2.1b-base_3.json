{
  "2-3 (API)": "",
  "3-1 (Pre-training)": "The Kanana-series models, including kanana-nano-2.1b-base, underwent a pre-training process that emphasized compute efficiency while maintaining strong performance in both Korean and English. According to the report, the pre-training strategy combined several specific techniques: (1) high-quality data filtering to ensure that only suitable training data were retained, (2) a staged pre-training schedule rather than a single monolithic run, (3) depth up-scaling to increase model capacity in later stages, and (4) a combination of pruning and distillation to reduce computational cost without sacrificing accuracy. These elements together constitute the core methodology by which the model achieved its bilingual capabilities and competitive results.",
  "3-2 (Fine-tuning)": "After the main pre-training, the authors performed a post-training phase that incorporated supervised fine-tuning. This step was designed to further align the kanana-nano-2.1b-base model with user-centric tasks, leveraging explicitly labeled examples to refine the model’s responses. Alongside this, they carried out preference optimization, indicating an additional layer where user or evaluator preferences were used to shape the model’s output behaviour for more seamless interaction.",
  "3-3 (Reinforcement Learning)": "Within the same post-training suite described in the report, preference optimization is highlighted. Although the quote does not name a specific RL algorithm, the wording implies a reinforcement-style procedure—optimizing the model according to preference feedback so that it better satisfies user interaction criteria. This situates preference optimization as the reinforcement component complementing the supervised fine-tuning step, collectively enhancing the conversational quality of kanana-nano-2.1b-base.",
  "2-3 (API)__evidence": [],
  "3-1 (Pre-training)__evidence": [
    {
      "source": "[sections/https://arxiv.org/abs/2502.18934]",
      "quote": "We introduce Kanana, a series of bilingual language models that demonstrate exceeding performance in Korean and competitive performance in English. The report details the techniques employed during pre-training to achieve compute-efficient yet competitive models, including high quality data filtering, staged pre-training, depth up-scaling, and pruning and distillation."
    }
  ],
  "3-2 (Fine-tuning)__evidence": [
    {
      "source": "[sections/https://arxiv.org/abs/2502.18934]",
      "quote": "Furthermore, the report outlines the methodologies utilized during the post-training of the Kanana models, encompassing supervised fine-tuning and preference optimization, aimed at enhancing their capability for seamless interaction with users."
    }
  ],
  "3-3 (Reinforcement Learning)__evidence": [
    {
      "source": "[sections/https://arxiv.org/abs/2502.18934]",
      "quote": "Furthermore, the report outlines the methodologies utilized during the post-training of the Kanana models, encompassing supervised fine-tuning and preference optimization, aimed at enhancing their capability for seamless interaction with users."
    }
  ]
}