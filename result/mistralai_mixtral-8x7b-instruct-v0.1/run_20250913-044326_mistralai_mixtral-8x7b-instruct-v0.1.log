
======== 1/1 â–¶ mistralai/Mixtral-8x7B-Instruct-v0.1 ========
ğŸ“ Directory to create/use: mistralai_mixtral-8x7b-instruct-v0.1
ğŸ“ Output path: mistralai_mixtral-8x7b-instruct-v0.1
1ï¸âƒ£ HF: True, GH: False
ğŸ” Candidate rejected: ggerganov/llama.cpp (score=-6, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 2, 'path_hits': 1, 'bad_keywords': 23, 'from_hf_link': 0, 'version_conflict': 0})
ğŸ” Candidate rejected: vllm-project/vllm (score=-7, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 1, 'path_hits': 2, 'bad_keywords': 14, 'from_hf_link': 0, 'version_conflict': 0})
ğŸ” Candidate rejected: SillyTavern/SillyTavern (score=-10, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 0, 'path_hits': 0, 'bad_keywords': 2, 'from_hf_link': 0, 'version_conflict': 0})
âœ… Resolved GH repo: mistralai/mistral-inference (score=7, detail={'org_affinity': 9, 'name_hits': 0, 'readme_hits': 2, 'path_hits': 0, 'bad_keywords': 9, 'from_hf_link': 0, 'version_conflict': 0})
âœ… HF model: mistralai/mixtral-8x7b-instruct-v0.1 (found at priority: 1)
ğŸ“„ Reports saved/merged (HF): mistralai_mixtral-8x7b-instruct-v0.1\reports_fulltext_huggingface_mistralai_mixtral-8x7b-instruct-v0.1.json
âœ… JSON file saved: mistralai_mixtral-8x7b-instruct-v0.1\huggingface_mistralai_mixtral-8x7b-instruct-v0.1.json
ğŸ“„ Reports merged to: mistralai_mixtral-8x7b-instruct-v0.1\reports_fulltext_mistralai_mixtral-8x7b-instruct-v0.1.json (HF sources)
âœ… Saved group 1 result: mistralai_mixtral-8x7b-instruct-v0.1\huggingface_filtered_mistralai_mixtral-8x7b-instruct-v0.1_1.json
âœ… Saved group 2 result: mistralai_mixtral-8x7b-instruct-v0.1\huggingface_filtered_mistralai_mixtral-8x7b-instruct-v0.1_2.json
âœ… Saved group 3 result: mistralai_mixtral-8x7b-instruct-v0.1\huggingface_filtered_mistralai_mixtral-8x7b-instruct-v0.1_3.json
âœ… Saved group 4 result: mistralai_mixtral-8x7b-instruct-v0.1\huggingface_filtered_mistralai_mixtral-8x7b-instruct-v0.1_4.json
âœ… Saved final merged result: mistralai_mixtral-8x7b-instruct-v0.1\huggingface_filtered_final_mistralai_mixtral-8x7b-instruct-v0.1.json
âœ… GH repo: mistralai/mistral-inference
ğŸ“„ Reports saved/merged (GH): mistralai_mixtral-8x7b-instruct-v0.1\reports_fulltext_github_mistralai_mistral-inference.json
â„¹ï¸ Merge skipped: could not determine a single target HF model id.
âœ… GitHub JSON file saved: mistralai_mixtral-8x7b-instruct-v0.1\github_mistralai_mistral-inference.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 3, '1-2 (Code)': 3, '1-3 (License)': 4, '1-4 (Paper)': 2}, 'kept': {'1-1 (Weights)': 3, '1-2 (Code)': 3, '1-3 (License)': 3, '1-4 (Paper)': 2}}
âœ… Saved group 1 result: mistralai_mixtral-8x7b-instruct-v0.1\github_filtered_mistralai_mistral-inference_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 5, '2-1 (Hardware)': 2, '2-2 (Software)': 3}, 'kept': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 5, '2-1 (Hardware)': 2, '2-2 (Software)': 2}}
âœ… Saved group 2 result: mistralai_mixtral-8x7b-instruct-v0.1\github_filtered_mistralai_mistral-inference_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 1, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 1, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}}
âœ… Saved group 3 result: mistralai_mixtral-8x7b-instruct-v0.1\github_filtered_mistralai_mistral-inference_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 1}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 1}}
âœ… Saved group 4 result: mistralai_mixtral-8x7b-instruct-v0.1\github_filtered_mistralai_mistral-inference_4.json
âœ… Saved final merged result: mistralai_mixtral-8x7b-instruct-v0.1\github_filtered_final_mistralai_mistral-inference.json
ğŸ” HF tags found arXiv IDs: []
ğŸ”„ Simplified query: 'mixtral 0.1'
ğŸ” Tavily search: mixtral 0.1 paper
  â†’ arXiv link found: https://arxiv.org/pdf/2401.04088
ğŸ” Tavily search: mixtral 0.1 technical report
  â†’ arXiv link found: https://arxiv.org/pdf/2401.04088
ğŸ›°ï¸ Tavily candidates: ['2401.04088']
ğŸ”¬ Verifying 1 Tavily candidate(s) with GPTâ€¦
  â€¢ Candidate: 2401.04088
    - GPT verdict: âœ… match (The candidate paper describes the Mixtral 8x7B â€“ Instruct model with version v0.1, which exactly matches the target version (major version 0 and minor 0.1, with a difference of 0). Therefore, it satis)
âœ… GPT-verified IDs: ['2401.04088']
ğŸ“¦ Final merged arXiv IDs: ['2401.04088']
ğŸ“„ PDF saved: mistralai_mixtral-8x7b-instruct-v0.1\arxiv_2401.04088.pdf
âœ… Full paper text saved: mistralai_mixtral-8x7b-instruct-v0.1\arxiv_fulltext_mistralai_mixtral-8x7b-instruct-v0.1.json
ğŸ“„ Reports merged to: mistralai_mixtral-8x7b-instruct-v0.1\reports_fulltext_mistralai_mixtral-8x7b-instruct-v0.1.json
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 2, '1-2 (Code)': 2, '1-3 (License)': 3, '1-4 (Paper)': 1}, 'kept': {'1-1 (Weights)': 2, '1-2 (Code)': 2, '1-3 (License)': 3, '1-4 (Paper)': 1}}
âœ… Saved group 1 : mistralai_mixtral-8x7b-instruct-v0.1\arxiv_filtered_mistralai_mixtral-8x7b-instruct-v0.1_1.json
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 3, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 1}, 'kept': {'1-5 (Architecture)': 3, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 1}}
âœ… Saved group 2 : mistralai_mixtral-8x7b-instruct-v0.1\arxiv_filtered_mistralai_mixtral-8x7b-instruct-v0.1_2.json
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 1, '3-1 (Pre-training)': 3, '3-2 (Fine-tuning)': 2, '3-3 (Reinforcement Learning)': 2}, 'kept': {'2-3 (API)': 1, '3-1 (Pre-training)': 3, '3-2 (Fine-tuning)': 2, '3-3 (Reinforcement Learning)': 2}}
âœ… Saved group 3 : mistralai_mixtral-8x7b-instruct-v0.1\arxiv_filtered_mistralai_mixtral-8x7b-instruct-v0.1_3.json
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 1, '4-2 (Fine-tuning Data)': 2, '4-3 (Reinforcement Learning Data)': 1, '4-4 (Data Filtering)': 0}, 'kept': {'4-1 (Pre-training Data)': 1, '4-2 (Fine-tuning Data)': 2, '4-3 (Reinforcement Learning Data)': 1, '4-4 (Data Filtering)': 0}}
âœ… Saved group 4 : mistralai_mixtral-8x7b-instruct-v0.1\arxiv_filtered_mistralai_mixtral-8x7b-instruct-v0.1_4.json
âœ… Saved final merged: mistralai_mixtral-8x7b-instruct-v0.1\arxiv_filtered_final_mistralai_mixtral-8x7b-instruct-v0.1.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 2, '1-2 (Code)': 0, '1-3 (License)': 2, '1-4 (Paper)': 0}, 'kept': {'1-1 (Weights)': 2, '1-2 (Code)': 0, '1-3 (License)': 2, '1-4 (Paper)': 0}}
âœ… Saved group 1 : mistralai_mixtral-8x7b-instruct-v0.1\reports_filtered_mistralai_mixtral-8x7b-instruct-v0.1_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}, 'kept': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}}
âœ… Saved group 2 : mistralai_mixtral-8x7b-instruct-v0.1\reports_filtered_mistralai_mixtral-8x7b-instruct-v0.1_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 2, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 2, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}}
âœ… Saved group 3 : mistralai_mixtral-8x7b-instruct-v0.1\reports_filtered_mistralai_mixtral-8x7b-instruct-v0.1_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}}
âœ… Saved group 4 : mistralai_mixtral-8x7b-instruct-v0.1\reports_filtered_mistralai_mixtral-8x7b-instruct-v0.1_4.json
âœ… Saved final merged: mistralai_mixtral-8x7b-instruct-v0.1\reports_filtered_final_mistralai_mixtral-8x7b-instruct-v0.1.json
ğŸ§± Pretrained (base) model found by heuristic: mistralai/mixtral-8x7b-v0.1
ğŸ“„ Reports saved/merged (HF): mistralai_mixtral-8x7b-instruct-v0.1\reports_fulltext_huggingface_mistralai_mixtral-8x7b-v0.1.json
âœ… JSON file saved: mistralai_mixtral-8x7b-instruct-v0.1\huggingface_mistralai_mixtral-8x7b-v0.1.json
âœ… Saved mistralai_mixtral-8x7b-instruct-v0.1\pretrain_hf_mistralai_mixtral-8x7b-v0.1.json
ğŸ” Candidate rejected: open-compass/MixtralKit (score=-3, detail={'org_affinity': -6, 'name_hits': 1, 'readme_hits': 1, 'path_hits': 1, 'bad_keywords': 9, 'from_hf_link': 0, 'version_conflict': 0})
ğŸ” Candidate rejected: zysNLP/quick-mixtral (score=3, detail={'org_affinity': -6, 'name_hits': 1, 'readme_hits': 1, 'path_hits': 0, 'bad_keywords': 0, 'from_hf_link': 0, 'version_conflict': 0})
âœ… Resolved GH repo: mistralai/mistral-inference (score=4, detail={'org_affinity': 9, 'name_hits': 0, 'readme_hits': 1, 'path_hits': 0, 'bad_keywords': 9, 'from_hf_link': 0, 'version_conflict': 0})
ğŸ“„ Reports saved/merged (GH): mistralai_mixtral-8x7b-instruct-v0.1\reports_fulltext_github_mistralai_mistral-inference.json
â„¹ï¸ Merge skipped: could not determine a single target HF model id.
âœ… GitHub JSON file saved: mistralai_mixtral-8x7b-instruct-v0.1\github_mistralai_mistral-inference.json
âš ï¸ GH fetch/dispatch failed: cannot import name 'filter_pretrain_gh' from 'pretrain_github_Dispatcher' (c:\Users\user\Desktop\lab git\lab git\Evaluating-system-based-on-agent\code\pretrain_github_Dispatcher.py)
ğŸ” HF tags found arXiv IDs: []
ğŸ”„ Simplified query: 'mixtral 0.1'
ğŸ” Tavily search: mixtral 0.1 paper
  â†’ arXiv link found: https://arxiv.org/pdf/2401.04088
ğŸ” Tavily search: mixtral 0.1 technical report
  â†’ arXiv link found: https://arxiv.org/pdf/2401.04088
ğŸ›°ï¸ Tavily candidates: ['2401.04088']
ğŸ”¬ Verifying 1 Tavily candidate(s) with GPTâ€¦
  â€¢ Candidate: 2401.04088
    - GPT verdict: âœ… match (The paper introduces Mixtral 8x7B â€“ which is the primary, official technical report for the model â€“ and its version (v0.1) aligns with the target model's version under the given rules.)
âœ… GPT-verified IDs: ['2401.04088']
ğŸ“¦ Final merged arXiv IDs: ['2401.04088']
ğŸ“„ PDF saved: mistralai_mixtral-8x7b-instruct-v0.1\arxiv_2401.04088.pdf
âœ… Full paper text saved: mistralai_mixtral-8x7b-instruct-v0.1\arxiv_fulltext_mistralai_mixtral-8x7b-v0.1.json
âœ… Saved: mistralai_mixtral-8x7b-instruct-v0.1\pretrain_arxiv_mistralai_mixtral-8x7b-v0.1.json
âœ… Saved pretrain reports: mistralai_mixtral-8x7b-instruct-v0.1\pretrain_reports_mistralai_mixtral-8x7b-v0.1.json
ğŸ“ Starting openness evaluation...
ğŸ“ Saved evaluation result: mistralai_mixtral-8x7b-instruct-v0.1\openness_score_mistralai_mixtral-8x7b-instruct-v0.1.json
âœ… Openness evaluation complete. Result file: mistralai_mixtral-8x7b-instruct-v0.1\openness_score_mistralai_mixtral-8x7b-instruct-v0.1.json
âœ… Saved model ID: mistralai_mixtral-8x7b-instruct-v0.1\identified_model.txt
â³ **Time taken for this model: 1665.73 seconds**
ğŸ§¾ Log saved to: mistralai_mixtral-8x7b-instruct-v0.1\run_20250913-044326_mistralai_mixtral-8x7b-instruct-v0.1.log
