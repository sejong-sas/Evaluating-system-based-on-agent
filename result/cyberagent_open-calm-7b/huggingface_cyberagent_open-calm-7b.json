{
    "model_id": "cyberagent/open-calm-7b",
    "files": [
        ".gitattributes",
        "README.md",
        "config.json",
        "generation_config.json",
        "pytorch_model-00001-of-00002.bin",
        "pytorch_model-00002-of-00002.bin",
        "pytorch_model.bin.index.json",
        "special_tokens_map.json",
        "tokenizer.json",
        "tokenizer_config.json"
    ],
    "readme": "---\nlicense: cc-by-sa-4.0\ndatasets:\n- wikipedia\n- cc100\n- mc4\nlanguage:\n- ja\ntags:\n- japanese\n- causal-lm\ninference: false\n---\n# OpenCALM-7B\n\n## Model Description\n\nOpenCALM is a suite of decoder-only language models pre-trained on Japanese datasets, developed by CyberAgent, Inc.\n\n## Usage\n\n```python\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\"cyberagent/open-calm-7b\", device_map=\"auto\", torch_dtype=torch.float16)\ntokenizer = AutoTokenizer.from_pretrained(\"cyberagent/open-calm-7b\")\n\ninputs = tokenizer(\"AIによって私達の暮らしは、\", return_tensors=\"pt\").to(model.device)\nwith torch.no_grad():\n    tokens = model.generate(\n        **inputs,\n        max_new_tokens=64,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9,\n        repetition_penalty=1.05,\n        pad_token_id=tokenizer.pad_token_id,\n    )\n    \noutput = tokenizer.decode(tokens[0], skip_special_tokens=True)\nprint(output)\n```\n\n## Model Details\n\n|Model|Params|Layers|Dim|Heads|Dev ppl|\n|:---:|:---: |:---:|:---:|:---:|:---:|\n|[cyberagent/open-calm-small](https://huggingface.co/cyberagent/open-calm-small)|160M|12|768|12|19.7|\n|[cyberagent/open-calm-medium](https://huggingface.co/cyberagent/open-calm-medium)|400M|24|1024|16|13.8|\n|[cyberagent/open-calm-large](https://huggingface.co/cyberagent/open-calm-large)|830M|24|1536|16|11.3|\n|[cyberagent/open-calm-1b](https://huggingface.co/cyberagent/open-calm-1b)|1.4B|24|2048|16|10.3|\n|[cyberagent/open-calm-3b](https://huggingface.co/cyberagent/open-calm-3b)|2.7B|32|2560|32|9.7|\n|[cyberagent/open-calm-7b](https://huggingface.co/cyberagent/open-calm-7b)|6.8B|32|4096|32|8.2|\n\n* **Developed by**: [CyberAgent, Inc.](https://www.cyberagent.co.jp/)\n* **Model type**: Transformer-based Language Model\n* **Language**: Japanese\n* **Library**: [GPT-NeoX](https://github.com/EleutherAI/gpt-neox)\n* **License**: OpenCALM is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License ([CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)). When using this model, please provide appropriate credit to CyberAgent, Inc.\n  * Example (en): This model is a fine-tuned version of OpenCALM-XX developed by CyberAgent, Inc. The original model is released under the CC BY-SA 4.0 license, and this model is also released under the same CC BY-SA 4.0 license. For more information, please visit: https://creativecommons.org/licenses/by-sa/4.0/\n  * Example (ja): 本モデルは、株式会社サイバーエージェントによるOpenCALM-XXをファインチューニングしたものです。元のモデルはCC BY-SA 4.0ライセンスのもとで公開されており、本モデルも同じくCC BY-SA 4.0ライセンスで公開します。詳しくはこちらをご覧ください: https://creativecommons.org/licenses/by-sa/4.0/\n\n\n## Training Dataset\n\n* Wikipedia (ja)\n* Common Crawl (ja)\n\n## Author\n\n[Ryosuke Ishigami](https://huggingface.co/rishigami)\n\n## Citations\n\n```bibtext\n@software{gpt-neox-library,\n  title = {{GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch}},\n  author = {Andonian, Alex and Anthony, Quentin and Biderman, Stella and Black, Sid and Gali, Preetham and Gao, Leo and Hallahan, Eric and Levy-Kramer, Josh and Leahy, Connor and Nestler, Lucas and Parker, Kip and Pieler, Michael and Purohit, Shivanshu and Songz, Tri and Phil, Wang and Weinbach, Samuel},\n  url = {https://www.github.com/eleutherai/gpt-neox},\n  doi = {10.5281/zenodo.5879544},\n  month = {8},\n  year = {2021},\n  version = {0.0.1},\n}\n```",
    "config": "{\n  \"_name_or_path\": \"open-calm-7b\",\n  \"architectures\": [\n    \"GPTNeoXForCausalLM\"\n  ],\n  \"bos_token_id\": 0,\n  \"eos_token_id\": 0,\n  \"hidden_act\": \"gelu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 16384,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 2048,\n  \"model_type\": \"gpt_neox\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"rotary_emb_base\": 10000,\n  \"rotary_pct\": 1.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.27.0.dev0\",\n  \"use_cache\": true,\n  \"use_parallel_residual\": false,\n  \"vocab_size\": 52224\n}\n",
    "generation_config": "{\n  \"_from_model_config\": true,\n  \"bos_token_id\": 0,\n  \"eos_token_id\": 0,\n  \"transformers_version\": \"4.27.0.dev0\"\n}\n",
    "license_file": "",
    "py_files": {}
}