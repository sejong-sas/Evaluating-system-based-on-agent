{
  "repo": "zhongwanjun/AR-LSAT",
  "full_texts": [
    {
      "arxiv_id": "https://arxiv.org/pdf/2104.06598.pdf",
      "full_text": "AR-LSAT: Investigating Analytical Reasoning of Text\nWanjun Zhong1∗, Siyuan Wang3∗, Duyu Tang2, Zenan Xu1∗, Daya Guo1∗\nYining Chen2, Jiahai Wang1, Jian Yin1, Ming Zhou4 and Nan Duan2\n1 The School of Data and Computer Science, Sun Yat-sen University.\n2 Microsoft Research 3 Fudan University, China 4SINOVATION VENTURES\n{zhongwj25, xuzn, guody5}@mail2.sysu.edu.cn\n{wangjiah@mail,issjyin@mail}.sysu.edu.cn\n{dutang,nanduan,yining.chen}@microsoft.com\nwangsy18@fudan.edu.cn; zhouming@chuangxin.com\nAbstract\nAnalytical reasoning is an essential and chal-\nlenging task that requires a system to ana-\nlyze a scenario involving a set of particu-\nlar circumstances and perform reasoning over\nit to make conclusions.\nIn this paper, we\nstudy the challenge of analytical reasoning\nof text and introduce a new dataset consist-\ning of questions from the Law School Ad-\nmission Test from 1991 to 2016.\nWe ana-\nlyze what knowledge understanding and rea-\nsoning abilities are required to do well on this\ntask. Furthermore, to address this reasoning\nchallenge, we design two different baselines:\n(1) a Transformer-based method which lever-\nages the state-of-the-art pre-trained language\nmodels and (2) Analytical Reasoning Machine\n(ARM), a logical-level reasoning framework\nextracting symbolic knowledge (e.g, partici-\npants, facts, logical functions) to deduce legit-\nimate solutions. In our experiments, we ﬁnd\nthat the Transformer-based models struggle to\nsolve this task as their performance is close to\nrandom guess and ARM achieves better perfor-\nmance by leveraging symbolic knowledge and\ninterpretable reasoning steps.\nResults show\nthat both methods still lag far behind human\nperformance, which leave further space for fu-\nture research. 1\n1\nIntroduction\nAnalytical reasoning assesses the problem-solving\nability to understand knowledge (e.g., partici-\npants, facts, rules), and reasoning over that knowl-\nedge to determine a solution. Analytical reason-\ning is known to involved when doing everyday\ntasks, and engages high-level cognitive mecha-\nnisms of humans (Williams et al., 2019). Although\n∗Work done while this author was an intern at Microsoft\nResearch.\n1The data and code are provided in https://github.\ncom/zhongwanjun/AR-LSAT.\n[Grouping Game] Passage：\nSeven directors -A, B, C, D, E, F, and G- serves on \nthe X committee or the Y committee.\nQuestion：\nIf D and F both serve on the X committee, Fact\nthen which one of the following could be true?\nOptions：\nA. A and C both serve on the X committee. \nB.\nA and E both serve on the Y committee.\nC.\nB and G both serve on the X committee.\nD. C and E both serve on the Y committee. √\nE.\nG and E both serve on the X committee.\nRules to Logical Expressions\nR-1: 𝐴 𝑜𝑛 𝑋 →𝐵 𝑜𝑛 𝑌\nR-2: 𝐶 𝑜𝑛 𝑋 →𝐷 𝑜𝑛 𝑌&ሺ𝐸 𝑜𝑛 𝑌ሻ\nR-3: 𝑃𝑜𝑠𝑖𝑡𝑖𝑜𝑛 𝑜𝑓 𝐹്𝑃𝑜𝑠𝑖𝑡𝑖𝑜𝑛 𝑜𝑓 𝐺\nR-4: 𝑃𝑜𝑠𝑖𝑡𝑖𝑜𝑛 𝑜𝑓 𝐸്𝑃𝑜𝑠𝑖𝑡𝑖𝑜𝑛 𝑜𝑓 𝐴\nR-5: 𝐺 𝑜𝑛 𝑋 →𝐵 𝑜𝑛 𝑋\nFact\n𝐷 𝑜𝑛 𝑋&ሺ𝐹 𝑜𝑛 𝑋ሻ\nIf A serves on X, then B serves on Y. R-1\nIf C serves on X, then D and E serve on Y. R-2\nF serves on a different committee with G. R-3\nE serves on a different committee with A. R-4\nIf G serves on X, so does B. R-5\nRules\nParticipants\n𝐴, 𝐵, 𝐶, 𝐷, 𝐸, 𝐹, 𝐺\nPositions\n𝑋, 𝑌\nሺ𝐶 𝑜𝑛 𝑋ሻ&ሺ𝐷 𝑜𝑛 𝑋ሻ confict with R-2\n ሺ𝐴 𝑜𝑛 𝑌ሻ&ሺ𝐸 𝑜𝑛 𝑌ሻ confict with R-4\n 𝐺 𝑜𝑛 𝑋&ሺ𝐹 𝑜𝑛 𝑋ሻ confict with R-3\n 𝐺 𝑜𝑛 𝑋&ሺ𝐹 𝑜𝑛 𝑋ሻ confict with R-3\nFigure 1: An example of the required reasoning pro-\ncess to do well on the AR task. The input is a passage,\na question and multiple options, and the output is the\nmost plausible answer.\nTransformer-based pre-trained language models in-\ncluding BERT (Devlin et al., 2018), GPT-2 (Rad-\nford et al., 2019) and RoBERTa (Liu et al., 2019)\nhave achieved state-of-the-art performance on a va-\nriety of NLP tasks, they still struggle to perform\ndeep reasoning beyond shallow-level semantic un-\nderstanding of literal clues. For example, Talmor\net al. (2020) show that pre-trained models fail on\nhalf of eight reasoning tasks that require symbolic\noperations. We hope to challenge current systems\nand take a step towards analytical reasoning.\nIn this paper, we study the challenge of analyt-\narXiv:2104.06598v2  [cs.CL]  15 Apr 2021\n\nical reasoning (AR). We introduce a new dataset\nAR-LSAT from the Law School Admission Test2\n(LSAT) from 1991 to 2016. to facilitate research\non this area. An example of analytical reasoning in\nLSAT is given in Figure 1, whose task is to separate\nparticipants (i.e., A,B, etc.) into two positions (i.e.,\nX committee and Y committee) under certain con-\nstraints. Solving the problem requires a system to\nunderstand the knowledge in the context including\nparticipants, positions, rules expressed in natural\nlanguage (e.g., “If G serves on X, so does B\") and\nfacts (e.g., “D and F both serve on the X commit-\ntee\"). Then, it needs to deduct logical expressions\n(e.g., “G on X →B on X\") from the rules, and\ndraw inference before making conclusions.\nIn this paper, we analyze the knowledge under-\nstanding and reasoning ability required for solv-\ning this task and present two base approaches for\nthis challenge: (1) Transformer-based approach\nthat applies pretrained language models to encode\nthe input context into distributed representation for\nclassiﬁcation. (2) Analytical Reasoning Machine\n(ARM), a logical-level framework that ﬁrst extracts\nsymbolic knowledge (i.e., participants, rules, facts)\nfrom the context, and further maps them into exe-\ncutable logical functions (e.g., “IfThen\", “Before\")\nto assess whether a solution can satisfy mentioned\nrules and then deduce legitimate solutions for mak-\ning prediction. This framework sheds a light on\nthe logical-level reasoning procedure required for\nthis task, and each step can be further developed in\nfuture for better performance or expandability.\nExperiments show that the Transformer-based\napproach struggles to learn this task, which indi-\ncates that this task is very challenging for current\nmodels as it requires the complex reasoning abil-\nity far beyond implicit reasoning over the literal\nclues. ARM performs relatively better than the\nTransformer-based approach with higher accuracy\nand better interpretability. The performance of\nboth approaches lag far behind human performance,\nwhich leaves a huge space for further research.\nThe contributions of our paper are two-fold.\n• We introduce a new dataset AR-LSAT to fa-\ncilitate research on analytical reasoning.\n• We present two approaches for this task: a\nTransformer-based approach and a logical-\nlevel reasoning framework that utilizes sym-\nbolic knowledge to perform reasoning.\n2https://en.wikipedia.org/wiki/Law_\nSchool_Admission_Test\n2\nRelated Works\nThere is an increasing trend on machine reason-\ning research in recent years. The reasoning ability\ninvestigated are partitioned into several major as-\npects, including (1) logical reasoning; (2) common-\nsense reasoning; (3) mathematical reasoning and\n(4) multi-hop reasoning.\nLogical Reasoning\nThe task of Natural Lan-\nguage Inference (NLI) (Dagan et al., 2005; Bow-\nman et al., 2015; Wang et al., 2018; Williams et al.,\n2018; Welleck et al., 2018; Khot et al., 2018; Nie\net al., 2019; Bhagavatula et al., 2019; Liu et al.,\n2020a) requires the models to detect the logical en-\ntailment relationship of two sentences. There have\nbeen Machine Reading Comprehension (MRC)\ndatasets (Rajpurkar et al., 2016; Welbl et al., 2017;\nYang et al., 2018a; Huang et al., 2019b) that ex-\namine the ability of logical reasoning. LogiQA\n(Liu et al., 2020b) and ReClor (Yu et al., 2020) are\nsourced from examination in realistic scenario and\nexamine a range of logical reasoning skills.\nCommonsense Reasoning\nThere are many re-\ncent benchmarks that assess the commonsense rea-\nsoning capabilities from different aspects, like so-\ncial (Rashkin et al., 2018), physics (Talmor et al.,\n2018; Zellers et al., 2019), or temporal (Zhou et al.,\n2019). There exist several MRC datasets that re-\nquire commonsense knowledge (Ostermann et al.,\n2018; Zhang et al., 2018; Huang et al., 2019a).\nMathematical Reasoning\nThere are many exist-\ning datasets (Kushman et al., 2014; Hosseini et al.,\n2014; Koncel-Kedziorski et al., 2015; Clark et al.,\n2016; Ling et al., 2017) focus on mathematical\nword problems. Ling et al. (2017) builds a dataset\nthat encourages generating answer rationales be-\nyond simply selecting the correct answer. DROP\n(Dua et al., 2019) is a benchmark MRC dataset\nrequiring mathematical reasoning. Saxton et al.\n(2019) focuses on algebraic generalization.\nMulti-hop Reasoning\nMulti-hop reasoning over\ntextual data (Talmor and Berant, 2018; Welbl et al.,\n2018; Yang et al., 2018b; Inoue et al., 2020) require\na model to reason over multiple paragraphs before\nmaking prediction.\nTo the best of our knowledge, there has not an\nexisting benchmark dataset that completely focuses\non the analytical reasoning over textual data. We\nintroduce a new dataset to ﬁll this gap and to foster\nresearch on this area.\n\n[Ordering Game] Passage\nA professor must determine the order in which five of her students -\nFernando, Ginny, Hakim, Juanita, and Kevin- will perform in a recital. \nGinny perform earlier than Fernando. R-1\nKevin perform earlier than Hakim and Juanita. R-2\nHakim perform either immediately before or immediately \nafter Fernando. R-3\nRules to Logical Expressions\nR-1: 𝑃𝑜𝑠. 𝑜𝑓 𝐺𝑖𝑛𝑛𝑦൏𝑃𝑜𝑠. 𝑜𝑓 𝐹𝑒𝑟𝑛𝑎𝑛𝑑𝑜\nR-2: ሺ𝑃𝑜𝑠. 𝑜𝑓 𝐾𝑒𝑣𝑖𝑛൏𝑃𝑜𝑠. 𝑜𝑓 𝐻𝑎𝑘𝑖𝑚ሻ &\nሺ𝑃𝑜𝑠. 𝑜𝑓 𝐾𝑒𝑣𝑖𝑛൏𝑃𝑜𝑠. 𝑜𝑓 𝐽𝑢𝑎𝑛𝑖𝑡𝑎ሻ\nR-3: 𝑃𝑜𝑠. 𝑜𝑓 𝐻𝑎𝑘𝑖𝑚ൌ𝑃𝑜𝑠. 𝑜𝑓 𝐹𝑒𝑟𝑛𝑎𝑛𝑑𝑜൅1 |\n   𝑃𝑜𝑠. 𝑜𝑓 𝐻𝑎𝑘𝑖𝑚ൌ𝑃𝑜𝑠. 𝑜𝑓 𝐹𝑒𝑟𝑛𝑎𝑛𝑑𝑜െ1\nFact\nUncertain\nPositions\n1௦௧, 2௡ௗ, 3௥ௗ, 4௧௛, 5௧௛\nParticipants\nሺ𝐹𝑒𝑟𝑛𝑎𝑛𝑑𝑜, 𝐺𝑖𝑛𝑛𝑦, 𝐻𝑎𝑘𝑖𝑚, 𝐽𝑢𝑎𝑛𝑖𝑡𝑎, 𝐾𝑒𝑣𝑖𝑛ሻ\nOptions\nA. Ginny, Fernando, Hakim, Kevin, Juanita ×R-2\nB.\nGinny, Juanita, Kevin, Hakim, Fernando ×R-2\nC.\nGinny, Kevin, Hakim, Juanita, Fernando ×R-3\nD. Kevin, Ginny, Juanita, Fernando, Hakim√\nE.\nKevin, Juanita, Fernando, Hakim, Ginny ×R-1\nQuestion\nWhich one of the following could be the order the students perform?\n[Assignment Game] Passage\nFive cashiers-Adams, Bates, Cox, Drake, and Edwards-each of \nwhom works alone on exactly one day, Monday through Friday\nAdams will work only on Tuesday or Thursday.  R-1\nBates will not work on Monday or Wednesday.   R-2\nCox works on Friday.   F-1\nEdwards don’t work next to Drake R-3\n.\nRules to Logical Expressions\nR-1: 𝐴𝑑𝑎𝑚𝑠 𝑜𝑛 𝑇𝑢𝑒𝑠. | 𝐴𝑑𝑎𝑚𝑠 𝑜𝑛 𝑇ℎ𝑢𝑟.\nR-2: ൓𝐵𝑎𝑡𝑒𝑠 𝑜𝑛 𝑀𝑜𝑛.  𝐵𝑎𝑡𝑒𝑠 𝑜𝑛 𝑊𝑒𝑑. ሻ \nR-3: 𝑃𝑜𝑠. 𝑜𝑓 𝐸𝑑𝑤𝑎𝑟𝑑𝑠്𝑃𝑜𝑠. 𝑜𝑓 𝐷𝑟𝑎𝑘𝑒൅1\nPositions\n𝑀𝑜𝑛. , 𝑇𝑢𝑒𝑠. , 𝑊𝑒𝑑. , 𝑇ℎ𝑢𝑟. , 𝐹𝑟𝑖. \nParticipants\nሺ𝐴𝑑𝑎𝑚𝑠, 𝐵𝑎𝑡𝑒𝑠, 𝐶𝑜𝑥, 𝐷𝑟𝑎𝑘𝑒, 𝐸𝑑𝑤𝑎𝑟𝑑𝑠ሻ\nOptions\nA. Edwards, Bates, Adams, Drake, Cox ×R-1\nB.\nDrake, Adams, Bates, Edwards, Cox ×R-2\nC.\nEdwards, Adams, Cox, Bates, Drake ×F-1\nD. Edwards, Adams, Drake, Bates, Cox √\nE.\nDrake, Edwards, Bates, Adams, Cox ×R-3\nQuestion\nWhich one of the following is a possible work schedule?\nFact\n𝐶𝑜𝑥 𝑜𝑛 𝐹𝑟𝑖.\nFigure 2: Examples of ordering game and assignment game in AR task. Facts and Rules are highlighted in orange\nand blue, respectively. Example of grouping game is shown in Figure 1. × indicates conﬂict.\n3\nTask and Dataset\nIn this section, we describe the task of analytical\nreasoning, introduce the dataset AR-LSAT we col-\nlected from the Law School Admission Test and\nmake analysis about the required reasoning skills.\n3.1\nTask: Analytical Reasoning of Text\nTaking a passage, a question, and multiple options\nas the input, a system is required to select the\nmost plausible answer as the output. Each passage\ndescribes a reasoning game belonging to various\ntypes. According to Kolby (2016), there are three\ndominant game types in LSAT: ordering games,\ngrouping games, and assignment games, which\nare described as follows and examples are given in\nFigures 1 and 2:\n• Ordering games are to order participants\nbased on given facts and rules.\n• Grouping games are to separate participants\ninto groups with given facts and rules.\n• Assignment games are to assign characteris-\ntics to the participants with given rules, like\nassigning schedules for people.\n3.2\nDataset Collection: AR-LSAT\nWe collect data from nearly 90 LSAT exams from\n1991 to 2016 and select questions from the ana-\nlytical reasoning part to construct the dataset, and\nname it AR-LSAT. Each exam in LSAT consists\nof 101 multiple choice questions, 24 of which are\nAR questions. We ﬁnally leave up the questions\nwith 5 answer options.\nNumber of questions\n2,046\nAverage length of passages\n99.3\nAverage length of questions\n19.1\nAverage length of answers\n6\nNumber of options\n5\nRatio of ordering game\n42.5%\nRatio of grouping game\n38.75%\nRatio of assignment game\n18.75%\nTable 1: Data statistics of AR-LSAT dataset.\n3.3\nData Analysis\nAs mentioned above, the questions of AR-LSAT\ncome from exams in realistic scenario. Each pas-\nsage describes a reasoning game belongs to three\ndominant type: (1) ordering game, (2) grouping\ngame and (3) assignment game. We manually an-\nalyze and summarize the ratio of each type of rea-\nsoning game in AR-LSAT. The corresponding data\nstatistics and ratios are shown in Table 1. Moreover,\nthe questions in AR-LSAT are further challenging\nas them require the system to have different kinds\nof reasoning skills. We manually categorize and an-\nalyze question types that are common in AR-LSAT\ndataset. The detailed description of question types\nis shown in Table 2. We also notice that the three\nmost common question types: “acceptable solu-\ntion\", “could be true/false\" and “must be true/false\"\nassociate with most of the passages. There also\nexist challenging questions, like “calculation\" and\n“substitution\" problems. The examples of question\ntypes are given in Appendix C.\n3.4\nChallenges\nIn this part, we point out the reasoning ability re-\nquired for solving AR questions, and put forward\n\nQuestion Type\nDescription\nAcceptable solution (15.6%)\nidentify a feasible solution that can satisfy all the rules\nComplete list (3.5%)\nidentify a complete and accurate list of participants under given condition\nCould be true/false (26.8%)\nselect answer that could be true/false under given condition\nMust be true/false (26.4%)\nselect answer that must be true/false under given condition\nNegation (14.7%)\nquestions that contain negation\nSubstitution (4.3%)\nidentify a new rule that can substitute one of the old rules for the desiring result\nCondition for determined solution (3.5%)\nidentify a new rule so that the feasible solution is determined\nCalculation (3%)\ncalculate possible participants in a group\nEarliest/latest position (1.3%)\nidentify the earliest/latest position that a speciﬁc participant can be assigned to\nMaximum/minimum members (1.3%)\nidentify the possible maximum/minimum number of participants in a speciﬁc group\nTable 2: The ratio and description of each question type in the test set of the AR-LSAT dataset.\nthe challenges that systems should face. As we can\nobserve from the examples in Figure 1 and Figure\n2, solving AR questions needs systems to under-\nstand the complex scenario and perform reasoning\nover it, and has no special needs for external knowl-\nedge. In conclusion, AR questions test a range of\nreasoning skills:\n1) Comprehending the knowledge including par-\nticipants of events, facts, and rules described\nin the context.\n2) Extracting machine-understandable logical\nfunctions (expressions) from the rules. For\nexample, the rule “If A serves on X, then B\nserves on Y.\" needs to be transferred as logi-\ncal expression “A on X →B on Y\",\n3) Making deductions to derive legitimate solu-\ntions that satisfy extracted logical functions.\n4) Selecting the answer that satisﬁes all the rules\nwith the deducted legitimate solutions. In the\nexamples, a system should eliminate options\nthat conﬂict with rules and select the option\nthat accords with legitimate solutions.\nTherefore, this task requires the machine to per-\nform explicit complex reasoning, far beyond just\nunderstanding the literal clues presented in the text.\n4\nApproaches\nIn this section, we describe our two base ap-\nproaches: (1) Transformer-based approach and (2)\nAnalytical Reasoning Machine (ARM).\n4.1\nTransformer-based Approach\nIn this approach, we view the analytical rea-\nsoning challenge as a multiple-choice question\nanswering problem.\nWe employ state-of-the-\nart pre-trained Transformer-based language mod-\nels (i.e.,\nBERT (Devlin et al., 2018),\nXL-\nNet (Yang et al., 2019), RoBERTa (Liu et al.,\n2019), and ALBERT (Lan et al., 2019)) for\nclassiﬁcation as they achieve impressive perfor-\nmance on a wide variety of tasks.\nSpeciﬁ-\ncally, we take the concatenated sequence X =\n{[CLS], passage, [SEP], question, option}\nas\nthe input, where [CLS] is the ending special to-\nken and [SEP] is used to split two types of in-\nput.\nThe representation of the sequence H =\nfTransformer(X) is further fed into a two-layer\nperceptron fMLP for classiﬁcation pθ(X)\n=\nσ(fMLP (H)), where σ is an activation function.\nThe model parameters θ of the Transformer and\nMLP layer are ﬁne-tuned with cross-entropy loss\non the training set.\n4.2\nAnalytical Reasoning Machine (ARM)\nIn this part, we describe the logical-level frame-\nwork, Analytical Reasoning Machine (ARM),\nwhich extracts symbolic knowledge from the con-\ntext and perform reasoning over the knowledge to\ndraw conclusions. Figure 3 gives an overview of\nthe ARM framework. We propose to break down\nthe reasoning process into four stages: (1) extract-\ning arguments (i.e., the participants, positions, facts\nand rules) from the context (§ 4.2.1); (2) interpret-\ning rules into a set of logical constraint functions,\nwhose arguments are selected from participants and\npositions (§ 4.2.2); (3) reasoning with the logical\nfunctions and ﬁnally generating a group of legit-\nimate assignments (solutions) that satisfy all the\nrules (§ 4.2.3); (4) selecting the most plausible op-\ntion by matching the legitimate assignments and\noptions (§ 4.2.4).\nARM sheds a light on the logical-level reasoning\nprocedure for analytical reasoning and each proce-\ndure can be further developed for both performance\nand expandability.\n4.2.1\nArguments Extraction\nIn order to understand the context and formalize\nthe problem, the ﬁrst step is to extract the par-\n\n𝟒. 𝐀𝐧𝐬𝐰𝐞𝐫 𝐒𝐞𝐥𝐞𝐜𝐭𝐢𝐨𝐧\nParticipant\nA, B, C, D, E, F, G\nPosition\nX, Y\nFacts\nD and F both serve on X \nRules\nIf A serves on the X, then B serves on Y \nIf C serves on the X, then D and E \nserve on the Y.\nF serves on a different committee with G.\nE serves on a different committee with A.\nIf G serves on the X, so does B.\n𝑓଴ൌ𝐼𝑓𝑇ℎ𝑒𝑛\n𝑇𝑜𝐴, 𝑋\n, 𝑇𝑜𝐵, 𝑌\n𝑓ଵൌ𝐼𝑓𝑇ℎ𝑒𝑛\n𝑇𝑜𝐶, 𝑋\n, 𝑇𝑜𝐷, 𝑌; 𝑇𝑜ሺ𝐸, 𝑌ሻ\n𝑓ଶൌ𝐷𝑖𝑓𝑓𝑒𝑟𝑒𝑛𝑡ሺ𝐹, 𝐺ሻ\n𝑓ଷൌ𝐷𝑖𝑓𝑓𝑒𝑟𝑒𝑛𝑡ሺ𝐸, 𝐴ሻ\n𝑓ସൌ𝐼𝑓𝑇ℎ𝑒𝑛ሺ𝑇𝑜𝐺, 𝑋\n, ሼ𝑇𝑜ሺ𝐵, 𝑋ሻሽሻ\n𝑎଴\n𝑎ଵ\n𝑎ଶ\n𝑎ଷ\n𝑓଴\n𝑓଴\n𝑓଴\n𝑓ଵ\n𝑓ଵ\n𝑓ଵ\n…\n𝑓௡\n𝑓௡\n𝑎௠ି௟\n𝑎௠\n…\n𝐥𝐞𝐠𝐢𝐭𝐢𝐦𝐚𝐭𝐞 𝐚𝐬𝐬𝐢𝐠𝐧𝐦𝐞𝐧𝐭𝐬\n𝟑. 𝐋𝐞𝐠𝐢𝐭𝐢𝐦𝐚𝐭𝐞 𝐀𝐬𝐬𝐢𝐠𝐧𝐦𝐞𝐧𝐭𝐬 𝐃𝐞𝐝𝐮𝐜𝐭𝐢𝐨𝐧\nA\nB\nC\nD\nE\nF\nG\nX\n-\n-\n-\nT\n-\nT\n-\nY\n-\n-\n-\nF\n-\nF\n-\n𝐈𝐧𝐢𝐭𝐢𝐚𝐥 𝐚𝐬𝐬𝐢𝐠𝐧𝐦𝐞𝐧𝐭 𝐚𝟎\n𝟏. 𝐀𝐫𝐠𝐮𝐦𝐞𝐧𝐭𝐬 𝐄𝐱𝐭𝐫𝐚𝐜𝐭𝐢𝐨𝐧\n𝐎𝐩𝐭𝐢𝐨𝐧𝐬\n𝟐. 𝐅𝐮𝐧𝐜𝐭𝐢𝐨𝐧 𝐄𝐱𝐭𝐫𝐚𝐜𝐭𝐢𝐨𝐧\n𝐏𝐚𝐬𝐬𝐚𝐠𝐞 𝐚𝐧𝐝 𝐐𝐮𝐞𝐬𝐭𝐢𝐨𝐧\nFigure 3: An overview of our approach. The original example is given in Figure 1. It extracts arguments from the\ncontext (§ 4.2.1). Then it extracts logical functions from rules (§ 4.2.2). Afterwards, it conducts deduction to ﬁnd\nlegitimate assignments (§ 4.2.3). Lastly, it matches the options and legitimate assignments for prediction (§ 4.2.4).\nticipants, positions, facts and rules expressed in\nnatural language from the passage and hypoth-\nesis of the question. An assignment represents\na solution that assigns participants to positions,\nand has a group of values of three possible states:\n(True, False, Unknown) representing whether a par-\nticipant is assigned to a position. The rules de-\nscribe the constraints of assignments while the\nfacts describe determined initial assignments ex-\nplicitly mentioned in the context. We take the ex-\nample in Figure 3 as a running example to show the\nextracted participants, positions, facts and rules.\nSpeciﬁcally, we extract the entities with a neural\nNamed Entity Recognition (NER) model (Peters\net al., 2017) and group the extracted entities into\nparticipants or positions. Rules and facts are iden-\ntiﬁed by whether a sentence mentions determined\nassignment. We parse groups of entities that appear\ntogether in the leading sentence of the passage as\ngroups of participants or positions, where partici-\npants always appear before positions.\n4.2.2\nLogical Function Extraction\nWe introduce a set of predeﬁned logical functions\nto express the constraints in the rules, which is the\nfoundation of the reasoning process. A function\nconsists of arguments and a executor, whose input\nis an assignment and the output is a Bool value\nindicates whether the assignment satisﬁes the con-\nstraint. The detailed deﬁnition of each function\nis listed in Appendix B. As the fragment shown\nin Table 3, the logical functions include following\nbasic types:\nRelational Function\nThe relational functions,\nwhose arguments involve participants or posi-\ntions, represent the constraints of the relation-\nship between them. For example, the function\nBefore(Ginny, Fernando) indicates that Ginny\nshould be in the position before Fernando in the\nordering game. To(A, X) indicates that participant\nA should be assigned to position X.\nCompositional Function\nA compositional func-\ntion expresses the relationship between two sets of\nfunctions, like the conditional rule (if-then rule)\nand the if-and-only-if rule.\nThe arguments of\ncompositional functions involve two sets of sub-\nfunctions. For example, the rule “If A serves on the\nX, then B serves on the Y.\" should be expressed as\nIfThen({To(A, X)}, {To(B, Y )}).\nCounting Function\nThe counting functions fo-\ncus on the calculation problem of participants un-\nder speciﬁc constraints. The arguments of counting\nfunctions involve a participant and a number. For\nexample, LastPos(A, 3) checks whether the partic-\nipant A is assigned to the last 3 positions.\nBased on the extracted arguments, we formalize\nthe rules into logical functions. One straightfor-\nward way is to design a symbolic parsing method.\nFor each function, we follow NSM (Liang et al.,\n2016) that uses trigger words to match a potential\nfunction. For example, the function Before can be\ntriggered by words “before\" and “earlier\". Then\nwe select arguments (i.e., participants, positions,\nand numbers) based on their relative positions to\nthe trigger word. The relational and counting func-\ntions can be constituted into compositional func-\ntions based on predeﬁned grammar patterns. For\nexample, for the grammar pattern “If P, then Q\",\nEach function is grouped into the function set F1\nif it occurs in P, or the function set F2 if it occurs\nin Q. F1 and F2 are taken as the arguments of the\nfunction IfThen.\nFurthermore, to handle the uncertain cases and\nimprove the coverage of extracted functions, we\nbuild a neural semantic parsing model based on a\npre-trained language model RoBERTa (Liu et al.,\n2019). It takes the sentence and two parsed ar-\n\nType\nFunction\nArgs\nDescription\nRelational\nFunctions\nBefore/After\nparticipant1\nparticipant2\nWhether participant1 is in the\nposition before/after participant2.\nSame/Different\nWhether participant1 is in the\nsame/different position with participant2.\nTo\nparticipant1\nposition1\nWhether participant1 is assigned\nto position1.\nCompositional\nFunctions\nIfThen\nfunction set F1\nfunction set F2\nIf functions in F1 satisﬁed,\nthen functions in F2 satisﬁed.\nCounting\nFunctions\nFirstPos/LastPos\nparticipant1,\nnumber m\nWhether participant1 is assigned\nto the ﬁrst/last m positions.\nTable 3: A fragment of the logical constraint function deﬁnition.\nguments in the sentence as the input and predicts\ntheir potential function type. Speciﬁcally, given\na rule as the input X, we follow Xu et al. (2020)\nand modify the input by adding special tokens “@”\nand “#” before and after the ﬁrst and second parsed\narguments respectively. Then we encode sentence\nX with RoBERTa model as follows:\nH = RoBERTa(X).\n(1)\nAfterwards, we take the representation of the ﬁrst\n“@” and “#” for classiﬁcation.\nfunction = argmax(classiﬁer([H@; H#])),\n(2)\nwhere [;] denotes concatenation, and the classi-\nﬁer is a linear layer followed by a softmax func-\ntion. , and p is the possibilities distribution over\nclass number. Since there is no annotated data of\ncorresponding logical functions, we need to con-\nstruct the training data automatically. The training\ndata consist of (1) positive instances: all the {in-\nput: (rule, arguments); label: function} pairs that\nextracted by the symbolic parsing method from\nthe training set; (2) negative instances: the same\nnumber of instances that have arguments with no\nfunction related.\n4.2.3\nLegitimate Assignments Deduction\nGiven the extracted logical constraint functions\nand the initial assignment, we conduct reasoning\nto ﬁnd the legitimate assignments that satisfy all\nthe constraints. The process is formulated into\na tree-based reasoning algorithm. As shown in\nFigure 4, each node in a tree corresponds to an\nassignment and each edge indicates a logical func-\ntion. A node v with path {e0, e1, ..., ei} from the\nroot indicates that its assignment satisﬁes functions\n{f0, f1, ..., fi}. Suppose we have n constraint func-\ntions, we need to ﬁnd all the leaf nodes with depth\nn. These leaf nodes satisfy all the functions and\nthus become legitimate assignments.\n(2) 𝑭𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝑬𝒙𝒆𝒄𝒖𝒕𝒊𝒐𝒏 \n𝒕𝒐 𝒇𝒊𝒏𝒅 𝒄𝒐𝒏𝒇𝒍𝒊𝒄𝒕\nA\nB\nC\nD\nE\nF\nG\nX\n-\n-\n-\nT\n-\nT\n-\nY\n-\n-\n-\nF\n-\nF\n-\n𝐼𝑛𝑖𝑡𝑖𝑎𝑙 𝑎𝑠𝑠𝑖𝑔𝑛𝑚𝑒𝑛𝑡 𝑎଴\n𝑓଴ൌ𝐼𝑓𝑇ℎ𝑒𝑛\n𝑇𝑜𝐴, 𝑋\n, 𝑇𝑜𝐵, 𝑌\n(1) 𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒆 \n𝒑𝒐𝒔𝒔𝒊𝒃𝒍𝒆 \n𝒂𝒔𝒔𝒊𝒈𝒏𝒎𝒆𝒏𝒕𝒔\nA\nB\nC\nD\nE\nF\nG\nX\nT\nF\n-\nT\n-\nT\n-\nY\nF\nT\n-\nF\n-\nF\n-\nA\nB\nC\nD\nE\nF\nG\nX\nF\nT\n-\nT\n-\nT\n-\nY\nT\nF\n-\nF\n-\nF\n-\nA\nB\nC\nD\nE\nF\nG\nX\nF\nF\n-\nT\n-\nT\n-\nY\nT\nT\n-\nF\n-\nF\n-\nA\nB\nC\nD\nE\nF\nG\nX\nT\nT\n-\nT\n-\nT\n-\nY\nF\nF\n-\nF\n-\nF\n-\n𝑎ଵ\n𝑎ଶ\n𝑎ଷ\n𝑎ସ\n𝑎଴\n𝑓଴\n𝑓଴\n𝑓଴\n𝑎ଵ\n𝑎ଶ\n𝑎ଷ\nConflict with 𝑓଴\n𝑎଴\n𝑹𝒆𝒂𝒔𝒐𝒏𝒊𝒏𝒈 𝑻𝒓𝒆𝒆 𝑬𝒙𝒕𝒆𝒏𝒔𝒊𝒐𝒏\n𝑨𝒔𝒔𝒊𝒈𝒏𝒎𝒆𝒏𝒕 𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒐𝒏\n𝑭𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒇𝟎\n𝐷𝑒𝑝𝑡ℎൌ1\nFigure 4: An example of the reasoning process. Newly\nadded participants in f0 are highlighted. (1) and (2)\nconducted recursively until depth = n. (T/F/−) =\n(True/False/Unknown)\nTherefore, we introduce how to construct the\ncomplete reasoning tree by the following steps:\n1) Firstly, we start with the root, which is the cer-\ntain initial assignment decided by facts. For\nthe function f0, we generate all possible as-\nsignments related to newly added arguments\nin f0. As shown in the example in Figure 4,\nfor the function IfThen(To(A, X), To(B, Y )),\nwe generate all possible assignments related\nto the new participants A and B.\n2) We execute f0 to ﬁnd all the legitimate\nassignments that satisfy f0 as a group of\nchildren of the root.\nIn the same exam-\nple, we keep the assignments that meets\n\nIfThen(To(A, X), To(B, Y )).\n3) Then we select each child as a new root and\nselect function f1 for further extension of the\nreasoning tree.\nThese processes are recursively conducted until\ndepth n, which means that all the functions are\nused to construct the reasoning tree. The tree-based\nmanner reduces the computational complexity and\ncan be further accelerated by ranking the functions.\nThe procedure is summarized into pseudo-code in\nAppendix A. Therefore, this algorithm has advan-\ntages of performing explicit interpretable reasoning\nover the extracted functions.\n4.2.4\nAnswer Selection\nPrevious steps understand the passage and the ques-\ntion. In this part, we introduce how to analyze the\noptions, and match the options with the deducted\nlegitimate assignments beyond word-level for mak-\ning a ﬁnal prediction. Speciﬁcally, we can derive\ntwo types of information from an option:\n1) Assignment-based option indicates an as-\nsignment. For example, “A and C both serve\non the X committee\" can be interpreted as:\n{(A, X) = True; (C, X) = True}. For this\ntype, we match the parsed option assignment\nwith all the legitimate assignments and calcu-\nlate an assignment-based matching score.\n2) Function-based option indicates an option\nrepresenting a logical function, like “The\nsedan is serviced earlier in the week than the\nroadster\", which can be parsed into the func-\ntion “Before(sedan, roadster)\". We execute\nthe option-based function on the legitimate\nassignments to ﬁnd the satisﬁable option and\ncalculate a function-based matching score.\nThese two types of scores are combined for making\na conclusion. The question types and score calcu-\nlating methods are summarized in the Appendix C.\n5\nExperiments\nIn this section, we focus on evaluating the pre-\nsented methods on AR-LSAT. We split the data\ninto (train/dev./test) = (1, 585/231/230). We also\nhold out a small test set for human evaluation.\nMoreover, case study illustrates the reasoning pro-\ncess of the ARM method by an explicit example.\nLastly, we make error analysis to point out chal-\nlenges in this task.\n5.1\nModel Comparison\nHuman Performance\nSince the dataset is based\non a test designed for undergraduate students, we\nselect nearly 100 instances in the AR-LSAT dataset\nand ask 10 undergraduate college students major-\ning in literature, commerce and law to answer these\nquestions. In order to prevent the training bias, we\nselect students who have not received LSAT pro-\nfessional training before. We take their averaged\nperformance as human performance and report it\nin Table 5.\nTransformer-based Methods\nWe take various\npowerful Transformer-based pre-trained language\nmodels, including BERT (Devlin et al., 2018), XL-\nNet (Yang et al., 2019), RoBERTa (Liu et al., 2019),\nand the recent ALBERT (Lan et al., 2019)), as\nthe backbones of the Transformer-based methods\nand investigate their performance on the AR-LSAT\ndataset. The implementation details of these mod-\nels are given in Appendix D.\nARM\nTo evaluate the performance of arguments\nextraction, we manually annotate the correct par-\nticipants and positions in the development set as\nlabels and report the accuracy and recall of in Table\n4. For function extraction, we deﬁne a API set to\ninclude roughly 20 types of logical functions like\nBefore, After, To, IfThen and realize their executors.\nThe detailed deﬁnition of functions can be found\nin Appendix B.\nAcc. (%)\nRecall (%)\nParticipants\n96.17\n92.88\nPositions\n84.42\n85.79\nTable 4: Performance of extraction of participants and\npositions on the development set.\nMethods\nDev.\nAcc (%)\nTest\nAcc (%)\nHuman Performance\n-\n59.7%\nRandom Guess\n20.0%\n20.0%\nBERT\n23.4%\n21.4%\nXLNet\n23.8%\n22.5%\nRoBERTa\n24.2%\n23.1%\nALBERT\n24.4%\n23.0%\nARM\n34.2%\n30.9%\nTable 5: The performance on the AR-LSAT dataset.\n\nPassage: A professor must determine the order in which five of her students — Fernando, Ginny, Hakim, Juanita, and Kevin — will perform in an upcoming \npiano recital. Each student performs one piece, and no two performances overlap. The following constraints apply: Ginny must perform earlier than Fernando. \nKevin must perform earlier than Hakim and Juanita. Hakim must perform either immediately before or immediately after Fernando.\nQuestion:  If Juanita performs earlier than Ginny, then which one of the following could be true?\nOptions: ሺ𝐴ሻ Fernando performs fourth. √ሺ𝐵ሻ Ginny performs second.  ሺ𝐶ሻ Hakim performs third. ሺ𝐷ሻ Juanita performs third.  ሺ𝐸ሻ Kevin performs second\nParticipants & Positions\nFernando, Ginny, Hakim, Juanita, Kevin\nfirst, second, third, fourth, fifth\nRules &\nFunctions\n(1) Ginny must perform earlier than Fernando. \n(2) Kevin must perform earlier than Hakim and Juanita. \n(3) Hakim must perform either immediately before or \nimmediately after Fernando.\n(4) Juanita performs earlier than Ginny\nሺ1ሻ𝐵𝑒𝑓𝑜𝑟𝑒 ሺ𝐺𝑖𝑛𝑛𝑦, 𝐹𝑒𝑟𝑛𝑎𝑛𝑑𝑜ሻ\nሺ2ሻ𝐴𝑛𝑑 ሺሼ𝐵𝑒𝑓𝑜𝑟𝑒 ሺ𝐾𝑒𝑣𝑖𝑛, 𝐻𝑎𝑘𝑖𝑚ሻሽ, ሼ𝐵𝑒𝑓𝑜𝑟𝑒ሺ𝐾𝑒𝑣𝑖𝑛, 𝐽𝑢𝑎𝑛𝑖𝑡𝑎ሻሽሻ\nሺ3ሻ𝑂𝑟 ሺሼ𝑁𝑒𝑥𝑡 ሺ𝐻𝑎𝑘𝑖𝑚, 𝐹𝑒𝑟𝑛𝑎𝑛𝑑𝑜ሻሽ, ሼ𝐿𝑎𝑠𝑡 ሺ𝐻𝑎𝑘𝑖𝑚, 𝐹𝑒𝑟𝑛𝑎𝑛𝑑𝑜ሻሽሻ\nሺ4ሻ𝐵𝑒𝑓𝑜𝑟𝑒 ሺ𝐽𝑢𝑎𝑛𝑖𝑡𝑎, 𝐺𝑖𝑛𝑛𝑦ሻ\nLegal Assignments\nOption Scores\n𝑨 𝟏\n𝐵 െ1\n𝐶 െ1\n𝐷 െ1\n𝐸 െ1\n𝟏𝒔𝒕\n𝟐𝒏𝒅\n𝟑𝒓𝒅\n𝟒𝒕𝒉\n𝟓𝒕𝒉\nFernando\nF\nF\nF\nT\nF\nGinny\nF\nF\nT\nF\nF\nHakim\nF\nF\nF\nF\nT\nJuanita\nF\nT\nF\nF\nF\nKevin\nT\nF\nF\nF\nF\n𝟏𝒔𝒕\n𝟐𝒏𝒅\n𝟑𝒓𝒅\n𝟒𝒕𝒉\n𝟓𝒕𝒉\nFernando\nF\nF\nF\nF\nT\nGinny\nF\nF\nT\nF\nF\nHakim\nF\nF\nF\nT\nF\nJuanita\nF\nT\nF\nF\nF\nKevin\nT\nF\nF\nF\nF\nFigure 5: A case study on the AR-LSAT dataset. Our system correctly extracts participants, positions, and rules\nfrom the context. Afterwards, it interprets rules into logical functions. After deduction, our system ﬁnds legitimate\nassignments and makes the correct prediction. Rules are highlighted in blue.\nResults\nIn Table 5, we report the performance\nof different methods and human performance on\nthe development and test set. Firstly, we observe\nthat the Transformer-based models struggle to do\nwell on this task, and achieve close performance\nwith random guess. This observation indicates that\nanalytical reasoning is extremely challenging for\ncurrent neural pre-trained language models as it\nrequires the ability of complex reasoning. In addi-\ntion, ARM with context understanding and explicit\nreasoning process outperforms Transformer-based\nmethod with 34.2% accuracy on the development\nset and 30.9% accuracy on the test set. It is also\nnoticed that the performance of both our system\nand baselines are still far from human performance,\nleaving signiﬁcant opportunities for further explo-\nration.\n5.2\nCase Study\nWe present a case study in Figure 5 to illustrate\nthe reasoning process of the ARM framework with\ninterpretable results. ARM extracts correct argu-\nments from the context, and interprets the rules\ninto logical constraint functions. Afterwards, it per-\nforms deduction to ﬁnd legitimate solutions. Lastly,\nit matches the options with the legitimate solutions\nand calculates a score for each option. Option A\nachieves the highest score because it accords with\nlegitimate assignments. This analysis demonstrates\nthat ARM has better explicit interpretable reason-\ning ability.\n5.3\nError Analysis\nWe randomly select 50 instances that are wrongly\npredicted by ARM from the development set and\nmanually summarize the major error types.\nThe dominant error type is that some rules with\ncomplex semantics are not covered by current con-\nstraint logical function set. For example, given a\nrule “Each crew member does at least one task dur-\ning the installation.\" , we should map “At least\" to\nfunction AtLeastNum.\nThe second type of errors is caused by failing to\nextract correct participants or positions by the NER\nmodel and predeﬁned matching pattern.\nThe third error type is caused by the lack of ba-\nsic commonsense knowledge, which is required for\nunderstanding the concept in the rules. For exam-\nple, when a passage mentioned “Six entertainers\nshould be scheduled at 9:00 A.M., 2:00 P.M., etc\"\nand the rule is “Some participants should be sched-\nuled in the morning.\", the system fails to match the\nmorning with a speciﬁc time zone.\n5.4\nDiscussion\nWe would like to further highlight important direc-\ntions to facilitate research on analytical reasoning.\nOne of the major challenges lies in deep un-\nderstanding of the knowledge in the context, like\nparsing the rules into logically equivalent symbolic\nfunctions. Deriving machine-understandable func-\ntions from natural language is an essential step\ntowards deeper understanding and reasoning. Al-\nthough supervised semantic parsing has achieved\n\npromising progress in recent years, obtaining com-\nplete human-annotated logical functions is imprac-\ntical for this task. Therefore, further study can fo-\ncus on function extraction with no annotated func-\ntions or small amount of annotated functions.\nFurthermore, a better inference engine built upon\nlogical functions is also essential because AR ques-\ntions require deeper reasoning abilities far beyond\njust understanding the literal clues. Standard sym-\nbolic systems like expert systems can provide ex-\nplicit reasoning, but they are difﬁcult to deal with\nuncertainty in data. Although neural-based meth-\nods are more ﬂexible at dealing with uncertainty,\nthey still struggle to perform interpretable and ex-\nplicit reasoning. It is promising to better integrate\nneural and symbolic systems to improve this task\nwith deeper reasoning ability.\n6\nConclusion\nIn this paper, we study the challenging task of ana-\nlytical reasoning and introduce a dataset AR-LSAT\nto facilitate research on analytical reasoning. We\nanalyze the knowledge understanding and reason-\ning ability required for this task and present two\nbasic approaches: a Transformer-based approach\nand a logical-level reasoning framework, named\nAnalytical Reasoning Machine (ARM). ARM ex-\ntracts symbolic knowledge, including participants,\nfacts and rules mentioned in the context and ex-\ntract logical functions from the rules. Afterwards,\nit performs deep reasoning to ﬁnd all the legiti-\nmate solutions to the problem posed and ﬁnally\nmakes a prediction. ARM sheds a light on the\nreasoning procedure for analytical reasoning, and\neach component can be further developed. Ex-\nperiments show that this task is very challenging\nfor current Transformer-based pre-trained language\nmodels and ARM outperforms them with better per-\nformance and interpretability. Further discussions\nare made to shed light on important future direc-\ntions.\nReferences\nChandra Bhagavatula, Ronan Le Bras, Chaitanya\nMalaviya, Keisuke Sakaguchi, Ari Holtzman, Han-\nnah Rashkin, Doug Downey, Scott Wen tau Yih, and\nYejin Choi. 2019. Abductive commonsense reason-\ning.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nIn Proceedings of the 2015 Conference on Empirical\nMethods in Natural Language Processing (EMNLP).\nAssociation for Computational Linguistics.\nPeter Clark, Oren Etzioni, Tushar Khot, Ashish Sab-\nharwal, Oyvind Tafjord, Peter Turney, and Daniel\nKhashabi. 2016. Combining retrieval, statistics, and\ninference to answer elementary science questions.\nIn Proceedings of the AAAI Conference on Artiﬁcial\nIntelligence, volume 30.\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2005.\nThe pascal recognising textual entailment\nchallenge. pages 177–190.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nDheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel\nStanovsky, Sameer Singh, and Matt Gardner. 2019.\nDrop:\nA reading comprehension benchmark re-\nquiring discrete reasoning over paragraphs. arXiv\npreprint arXiv:1903.00161.\nFelix A Gers, Jürgen Schmidhuber, and Fred Cummins.\n1999. Learning to forget: Continual prediction with\nlstm.\nMohammad Javad Hosseini,\nHannaneh Hajishirzi,\nOren Etzioni, and Nate Kushman. 2014. Learning\nto solve arithmetic word problems with verb catego-\nrization. In Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 523–533.\nLifu Huang, Ronan Le Bras, Chandra Bhagavatula, and\nYejin Choi. 2019a. Cosmos qa: Machine reading\ncomprehension with contextual commonsense rea-\nsoning. arXiv preprint arXiv:1909.00277.\nLifu Huang, Ronan Le Bras, Chandra Bhagavatula, and\nYejin Choi. 2019b. Cosmos QA: Machine reading\ncomprehension with contextual commonsense rea-\nsoning. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n2391–2401, Hong Kong, China. Association for\nComputational Linguistics.\nNaoya Inoue, Pontus Stenetorp, and Kentaro Inui. 2020.\nR4C: A benchmark for evaluating RC systems to get\nthe right answer for the right reason. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 6740–6750, On-\nline. Association for Computational Linguistics.\nTushar Khot, Ashish Sabharwal, and Peter Clark. 2018.\nSciTail: A textual entailment dataset from science\nquestion answering. In AAAI.\nJeff Kolby. 2016. Master The LSAT: Includes 4 Ofﬁ-\ncial LSATs! (Nova’s Master the LSAT). Nova Press\n(August 17, 2016).\n\nRik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish\nSabharwal, Oren Etzioni, and Siena Dumas Ang.\n2015. Parsing algebraic word problems into equa-\ntions. Transactions of the Association for Computa-\ntional Linguistics, 3:585–597.\nNate Kushman, Yoav Artzi, Luke Zettlemoyer, and\nRegina Barzilay. 2014.\nLearning to automatically\nsolve algebra word problems. In Proceedings of the\n52nd Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n271–281.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2019. Albert: A lite bert for self-supervised learn-\ning of language representations.\narXiv preprint\narXiv:1909.11942.\nChen Liang, Jonathan Berant, Quoc Le, Kenneth D For-\nbus, and Ni Lao. 2016. Neural symbolic machines:\nLearning semantic parsers on freebase with weak su-\npervision. arXiv preprint arXiv:1611.00020.\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-\nsom. 2017. Program induction by rationale genera-\ntion: Learning to solve and explain algebraic word\nproblems. arXiv preprint arXiv:1705.04146.\nHanmeng Liu, Leyang Cui, Jian Liu, and Yue Zhang.\n2020a.\nNatural language inference in context–\ninvestigating contextual reasoning over long texts.\narXiv preprint arXiv:2011.04864.\nJian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang,\nYile Wang, and Yue Zhang. 2020b. Logiqa: A chal-\nlenge dataset for machine reading comprehension\nwith logical reasoning. Proceedings of the Twenty-\nNinth International Joint Conference on Artiﬁcial In-\ntelligence.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nYixin Nie, Adina Williams, Emily Dinan, Mohit\nBansal, Jason Weston, and Douwe Kiela. 2019. Ad-\nversarial nli: A new benchmark for natural language\nunderstanding. ArXiv, abs/1910.14599.\nSimon Ostermann, Michael Roth, Ashutosh Modi, Ste-\nfan Thater, and Manfred Pinkal. 2018.\nSemeval-\n2018 task 11: Machine comprehension using com-\nmonsense knowledge. In Proceedings of the 12th In-\nternational Workshop on semantic evaluation, pages\n747–757.\nJeffrey Pennington, Richard Socher, and Christopher\nManning. 2014.\nGloVe: Global vectors for word\nrepresentation. In Proceedings of the 2014 Confer-\nence on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 1532–1543,\nDoha,\nQatar. Association for Computational Linguistics.\nMatthew E Peters, Waleed Ammar, Chandra Bhagavat-\nula, and Russell Power. 2017. Semi-supervised se-\nquence tagging with bidirectional language models.\narXiv preprint arXiv:1705.00108.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016.\nSquad: 100,000+ questions\nfor machine comprehension of text. arXiv preprint\narXiv:1606.05250.\nHannah\nRashkin,\nMaarten\nSap,\nEmily\nAllaway,\nNoah A Smith, and Yejin Choi. 2018. Event2mind:\nCommonsense inference on events, intents, and re-\nactions. arXiv preprint arXiv:1805.06939.\nDavid Saxton, Edward Grefenstette, Felix Hill, and\nPushmeet Kohli. 2019. Analysing mathematical rea-\nsoning abilities of neural models.\narXiv preprint\narXiv:1904.01557.\nAlon Talmor and Jonathan Berant. 2018. The web as\na knowledge-base for answering complex questions.\nIn NAACL-HLT.\nAlon Talmor, Yanai Elazar, Yoav Goldberg, and\nJonathan Berant. 2020. olmpics-on what language\nmodel pre-training captures. Transactions of the As-\nsociation for Computational Linguistics, 8:743–758.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2018. Commonsenseqa: A ques-\ntion answering challenge targeting commonsense\nknowledge. arXiv preprint arXiv:1811.00937.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R. Bowman. 2018.\nGLUE: A multi-task benchmark and analysis plat-\nform for natural language understanding.\nCoRR,\nabs/1804.07461.\nJohannes Welbl, Pontus Stenetorp, and Sebastian\nRiedel. 2017. Constructing datasets for multi-hop\nreading comprehension across documents.\nJohannes Welbl, Pontus Stenetorp, and Sebastian\nRiedel. 2018. Constructing datasets for multi-hop\nreading comprehension across documents. Transac-\ntions of the Association for Computational Linguis-\ntics, 6:287–302.\nSean Welleck, Jason Weston, Arthur Szlam, and\nKyunghyun Cho. 2018. Dialogue natural language\ninference.\nAdina Williams, Nikita Nangia, and Samuel Bowman.\n2018. A broad-coverage challenge corpus for sen-\ntence understanding through inference. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume\n1 (Long Papers), pages 1112–1122, New Orleans,\n\nLouisiana. Association for Computational Linguis-\ntics.\nChad C Williams, Mitchel Kappen, Cameron D Has-\nsall, Bruce Wright, and Olave E Krigolson. 2019.\nThinking theta and alpha: Mechanisms of intuitive\nand analytical reasoning.\nNeuroImage, 189:574–\n580.\nZenan Xu, Daya Guo, Duyu Tang, Qinliang Su,\nLinjun Shou, Ming Gong, Wanjun Zhong, Xi-\naojun Quan, Nan Duan, and Daxin Jiang. 2020.\nSyntax-enhanced pre-trained model. arXiv preprint\narXiv:2012.14116.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for\nlanguage understanding. In Advances in neural in-\nformation processing systems, pages 5753–5763.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam Cohen, Ruslan Salakhutdinov, and Christo-\npher D. Manning. 2018a. Hotpotqa: A dataset for\ndiverse, explainable multi-hop question answering.\nProceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-\ngio, William W Cohen, Ruslan Salakhutdinov, and\nChristopher D Manning. 2018b.\nHotpotqa:\nA\ndataset for diverse, explainable multi-hop question\nanswering. arXiv preprint arXiv:1809.09600.\nWeihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi\nFeng. 2020.\nReclor:\nA reading comprehension\ndataset requiring logical reasoning. arXiv preprint\narXiv:2002.04326.\nRowan Zellers, Ari Holtzman, Yonatan Bisk, Ali\nFarhadi, and Yejin Choi. 2019. Hellaswag: Can a\nmachine really ﬁnish your sentence? arXiv preprint\narXiv:1905.07830.\nSheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng\nGao, Kevin Duh, and Benjamin Van Durme. 2018.\nRecord: Bridging the gap between human and ma-\nchine commonsense reading comprehension. arXiv\npreprint arXiv:1810.12885.\nBen Zhou, Daniel Khashabi, Qiang Ning, and Dan\nRoth. 2019.\n\" going on a vacation\" takes longer\nthan\" going for a walk\":\nA study of tempo-\nral commonsense understanding.\narXiv preprint\narXiv:1909.03065.\nA\nPseudo-code of Legitimate\nAssignments Deduction\nRequire: A set of constraint functions F = {f0, f1, ..., fn}\nand an initial assignment a0\n1: function CONSTRUCTTREE(node,functions,depth,n)\n2:\nif depth == n then:\n3:\nreturn\n4:\nend if\n5:\nfunction = functions[depth]\n6:\nold_pars = node.participants\n7:\nold_assign = node.assignment\n8:\nnew_pars = ﬁnd_new_participant(function, old_pars)\n9:\nall_assign = gen_all_assign(old_assign, new_pars)\n10:\nsatisﬁed = ﬁnd_satisﬁed(all_assign, function)\n11:\ndepth = depth+1\n12:\nchildren = update_notes(node, satisﬁed, new_pars)\n13:\nfor child in children do\n14:\nCONSTRUCTTREE(child, functions, depth, n)\n15:\nend for\n16: end function\n17: root = Node(a0)\n18: depth = 0\n19: n = length of F\n20: complete_tree = CONSTRUCTTREE(root, F, depth, n)\n21: legitimate = nodes in complete_tree with depth n\n22: return legitimate\nB\nFunction Deﬁnition\nIn this part, we present the detailed description and\ntrigger words for each logical constraint functions\nin Table 7.\nC\nQuestion Type\nIn this part, we list common question types in the\nAR-LSAT datasets and give examples in Table 6.\nWe further introduce how we calculate a score for\ndominant question type with a group of legitimate\nassignments.\n1) Must be true/false: this question type needs\nto select answer that must be true in all the as-\nsignments. We match all the assignments with\nthe option. If one option accords/conﬂicts\nwith one assignment, the single matching\nscore will be 1/-1, otherwise the score will\nbe 0. We then calculate the sum of all the\nmatching scores as the ﬁnal score.\n2) Could be true/false: this question type needs\nto select answer that could be true in one of\nthe legitimate assignments. We match all the\nassignments with the option. If one option\naccords/conﬂicts with one assignment, the sin-\ngle matching score will be 1/-1, otherwise the\nscore will be 0. We then calculate the maxi-\nmum matching scores as the ﬁnal score. The\n\nQuestion Type\nExample\nAcceptable solution\nWhich one of the following could be the schedule of the students’ reports?\nComplete list\nWhich one of the following could be a complete and accurate list of\nthe books placed on the bottom shelf?\nCould be true/false with condition\nIf Himalayans are not featured on day 7. which one of the following could be true?\nMust be true/false with condition\nIf Theresa tests G on the second day. then which one of the following must be true?\nNegation\nP CANNOT be performed at?\nSubstitution\nWhich one of the following. if substituted for the condition that Waite’s audition\nmust take place earlier than the two recorded auditions.\nwould have the same effect in determining the order of the auditions?\nCondition for unique solution\nThe assignment of parking spaces to each of the new employees is fully and uniquely\ndetermined if which one of the following is true?\nCalculation\nHow many of the students are there who could be the one assigned to 1921?\nEarliest/latest position\nIf Zircon performs in an earlier slot than Yardsign. which one of the following\nis the earliest slot in which Wellspring could perform?\nMaximum/minimum members\nWhat is the minimum number of solos in which Wayne performs a traditional piece?\nTable 6: Question types of AR-LSAT dataset.\nAcceptable solution question type also use this\nmethod to calculate score.\n3) Maximum number of participants in a po-\nsition: this question type needs to calculate\nthe maximum possible number of participants\nin a speciﬁed position (group). We calculate\nthe maximum number of participants in all the\nlegetimate assignments and calculate the abso-\nlute difference with the number in the option\nas the ﬁnal score.\n4) Find the earliest position of a participant:\nthis question type needs to calculate the earli-\nest possible position of a speciﬁc participant.\nWe calculate the index of the earliest position\nof the participant in all the legitimate assign-\nments and calculate the absolute difference\nwith the number in the option as the ﬁnal\nscore.\n5) Count the number of possible positions\nthat a participant can be assigned in: for\nthis question type, we count all the non-\nrepetitive assignments of the speciﬁc partici-\npant and calculate the absolute difference with\nthe number in the option as the ﬁnal score.\nD\nBaseline Models\nD.1\nDescriptions\n• LSTM (Gers et al., 1999) is a classical RNN-\nbased model.\nWe apply Bi-LSTM with\nGloVE (Pennington et al., 2014) embedding.\n• BERT (Devlin et al., 2018) is a transformer-\nbased model pre-trained on BooksCorpus and\nWikipedia with two unsupervised learning\ntask: Masked LM and Nest Sentence Predic-\ntion.\n• XLNet (Yang et al., 2019) is also a\ntransformer-based model,\npre-trained on\nBooksCorpus, Wikipedia, Giga5, ClueWeb\n2012-B and Common Crawl with Permuta-\ntion Language Modeling.\n• RoBERTa (Liu et al., 2019) is a transformer-\nbased model with the same model structure as\nBERT but trained on a larger corpus and on a\ndifferent training setting.\n• ALBERT (Lan et al., 2019) is a most recent\ntransformer-based pre-trained model.\nAL-\nBERT uses parameter-reduction techniques\nthat support large-scale conﬁgurations.\nD.2\nImplementation Details\nFor all the baselines, we employ cross-entropy loss\nas the loss function and select AdamW as the opti-\nmizer for model training/ ﬁne-tuning. These base-\nlines add a simple classiﬁcation layer on the top of\nthem and take the the last hidden state as the input.\nFor all the Transformer-based models, we employ\nbase model as the backbone.\n\nType\nFunction\nArguments\nDescription\nTrigger Words\nRelational\nFunctions\nBefore\nparticipant 1\nparticipant 2\nwhether participant 1 is in the\nposition before participant 2\nbefore, above,\nprecede, earlier\nAfter\nwhether participant 1 is in the\nposition after participant 2\nafter, larger, higher\nbigger, older\nLast\nwhether participant 1 is in the\nlast position of participant 2\nimmediately before,\nlast\nNext\nwhether participant 1 is next\nto participant 2\nimmediately after,\nnext\nAdjacent\nwhether participant 1 is\nneighboring to participant 2\nneighboring,\nadjacent\nDifferent\nwhether participant 1 in the different\nposition with participant 2\ndifferent\nSame\nwhether the ﬁrst participant in the same\nposition with the second participant\nsame, also\nBeforeEqual\nwhether participant 1 before\nor equals to the position of participant 2\nno later\nAfterEqual\nwhether participant 1 after or equals\nto the position of participant 2\nno earlier\nTo\nparticipant\nposition\nWhether the participant is\nassigned to the position\nto, on, give, in\nCompos.\nFunctions\nIfThen\nfunction set 1\nfunction set 2\nIf rules in rule set 1 satisﬁed,\nthen rules in rule set 2 satisﬁed\nIf... then, If ... , ...\nIFF\nRules in rule set 1 satisﬁed if and\nonly if rules in rule set 2 satisﬁed\nif and only if\nAnd\nRules in rule set 1 satisﬁed and\nrules in the rule set 2 satisﬁed\nand\nOr\nRules in rule set 1 satisﬁed or\nrules in rule set 2 satisﬁed\nor\nUnless\nRules in rule set 1 satisﬁed unless\nrules in rule set 2 satisﬁed\nunless\nNeither\nNeither rules in rule set 1 satisﬁed\nnor rules in rule set 2 satisﬁed\nNeither ... nor ...\nCounting\nFunctions\nFirstPos\nparticipant\nnumber\nWhether the participant is in the\nlast (number) positions\none of the\nlast (number)\nLastPos\nWhether the participant is in the\nﬁrst (number) positions\none of the\nﬁrst (number)\nTable 7: Detailed function descriptions and corresponding trigger words\n"
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2108.00648.pdf",
      "full_text": "[image]\n[image]\narXiv Is Hiring a DevOps Engineer\nWork on one of the world's most important websites and make an\nimpact on open science.\nView Jobs\nSkip to main content\n[image]\narXiv Is Hiring a DevOps Engineer\nView Jobs\nWe gratefully acknowledge support from the Simons Foundation,\nmember institutions, and all contributors. Donate\n[image] > cs > arXiv:2108.00648\nHelp | Advanced Search\nAll fields Title Author Abstract Comments Journal reference ACM\nclassification MSC classification Report number arXiv identifier DOI\nORCID arXiv author ID Help pages Full text\nSearch\n[image]\n[image]\n\nGO\n\nquick links\n•  Login\n•  Help Pages\n•  About\nComputer Science >\n\nComputation and Language\narXiv:2108.00648 (cs)\n[Submitted on 2 Aug 2021]\nTitle:From LSAT: The Progress\nand Challenges of Complex\nReasoning\nAuthors:Siyuan Wang, Zhongkun Liu, Wanjun Zhong, Ming Zhou,\nZhongyu Wei, Zhumin Chen, Nan Duan\nView a PDF of the paper titled From LSAT: The Progress and\nChallenges of Complex Reasoning, by Siyuan Wang and 5 other\nauthors\nView PDF\nAbstract:Complex reasoning aims to draw a correct\ninference based on complex rules. As a hallmark of\nhuman intelligence, it involves a degree of explicit\nreading comprehension, interpretation of logical\nknowledge and complex rule application. In this\npaper, we take a step forward in complex reasoning\nby systematically studying the three challenging\nand domain-general tasks of the Law School\nAdmission Test (LSAT), including analytical\nreasoning, logical reasoning and reading\ncomprehension. We propose a hybrid reasoning\nsystem to integrate these three tasks and achieve\nimpressive overall performance on the LSAT tests.\nThe experimental results demonstrate that our\nsystem endows itself a certain complex reasoning\nability, especially the fundamental reading\ncomprehension and challenging logical reasoning\ncapacities. Further analysis also shows the\neffectiveness of combining the pre-trained models\nwith the task-specific reasoning module, and\n\nintegrating symbolic knowledge into discrete\ninterpretable reasoning steps in complex reasoning.\nWe further shed a light on the potential future\ndirections, like unsupervised symbolic knowledge\nextraction, model interpretability, few-shot learning\nand comprehensive benchmark for complex\nreasoning.\nComments: 17 pages, 5 figures submitted for consideration of publication t\nProcessing, 2021\nSubjects:\nComputation and Language (cs.CL)\nCite as:\narXiv:2108.00648 [cs.CL]\n \n(or arXiv:2108.00648v1 [cs.CL] for this version)\n \nhttps://doi.org/10.48550/arXiv.2108.00648\nFocus to learn more\narXiv-issued DOI via DataCite\nSubmission history\nFrom: Siyuan Wang [view email]\n[v1] Mon, 2 Aug 2021 05:43:03 UTC (708 KB)\nFull-text links:\nAccess Paper:\nView a PDF of the paper titled From LSAT: The Progress and\nChallenges of Complex Reasoning, by Siyuan Wang and 5\nother authors\n•  View PDF\n•  TeX Source\n•  Other Formats\n[image] view license\nCurrent browse context:\ncs.CL\n< prev   |   next >\n\nnew | recent | 2021-08\nChange to browse by:\ncs\nReferences & Citations\n•  NASA ADS\n•  Google Scholar\n•  Semantic Scholar\nDBLP - CS Bibliography\nlisting | bibtex\nSiyuan Wang\nWanjun Zhong\nMing Zhou\nZhongyu Wei\nZhumin Chen\n…\na export BibTeX citation Loading...\nBibTeX formatted citation\n×\nloading...\nData provided by:\nBookmark\n[image] [image]\nBibliographic Tools\nBibliographic and Citation\nTools\nBibliographic Explorer Toggle\n\nBibliographic Explorer (What is the Explorer?)\nConnected Papers Toggle\nConnected Papers (What is Connected Papers?)\nLitmaps Toggle\nLitmaps (What is Litmaps?)\nscite.ai Toggle\nscite Smart Citations (What are Smart Citations?)\nCode, Data, Media\nCode, Data and Media\nAssociated with this Article\nalphaXiv Toggle\nalphaXiv (What is alphaXiv?)\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\nDagsHub Toggle\nDagsHub (What is DagsHub?)\nGotitPub Toggle\nGotit.pub (What is GotitPub?)\nHuggingface Toggle\nHugging Face (What is Huggingface?)\nLinks to Code Toggle\nPapers with Code (What is Papers with Code?)\nScienceCast Toggle\nScienceCast (What is ScienceCast?)\nDemos\nDemos\nReplicate Toggle\nReplicate (What is Replicate?)\nSpaces Toggle\nHugging Face Spaces (What is Spaces?)\nSpaces Toggle\nTXYZ.AI (What is TXYZ.AI?)\n\nRelated Papers\nRecommenders and Search\nTools\nLink to Influence Flower\nInfluence Flower (What are Influence Flowers?)\nCore recommender toggle\nCORE Recommender (What is CORE?)\nAbout arXivLabs\narXivLabs: experimental\nprojects with community\ncollaborators\narXivLabs is a framework that allows collaborators to develop and\nshare new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have\nembraced and accepted our values of openness, community,\nexcellence, and user data privacy. arXiv is committed to these\nvalues and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's\ncommunity? Learn more about arXivLabs.\n\nWhich authors of this paper are endorsers? | Disable MathJax (What\nis MathJax?)\nAbout\nHelp\n\nContact\n\nSubscribe\nCopyright\nPrivacy Policy\nWeb Accessibility Assistance\narXiv Operational Status \n\nGet status notifications via \n\nemail or \n\nslack\n"
    }
  ]
}