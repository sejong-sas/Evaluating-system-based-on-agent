{
    "repo": "zhongwanjun/AR-LSAT",
    "branch": "main",
    "files": [
        ".gitignore",
        "ARM/data_analysis/extract_cp_ner_dp_results.py",
        "ARM/data_analysis/extract_participant_modify_context_preprocessed.py",
        "ARM/data_analysis/rule_pattern.py",
        "ARM/pipeline/API.py",
        "ARM/pipeline/answer_question_by_tree.py",
        "ARM/pipeline/extract_program_argument.py",
        "ARM/pipeline/modify_option.py",
        "ARM/pipeline/nl2fact_rule.py",
        "ARM/pipeline/rule_pattern.py",
        "ARM/pipeline/rule_update_table.py",
        "LICENSE",
        "LSTM/main_large.py",
        "LSTM/model.py",
        "LSTM/run_lsatlstm.sh",
        "LSTM/utils_multiple_choice.py",
        "README.md",
        "Transformer-based Model/main_large.py",
        "Transformer-based Model/run_roberta_large.sh",
        "Transformer-based Model/utils_multiple_choice.py",
        "complete_lsat_data/test_ar.json",
        "complete_lsat_data/test_lr.json",
        "complete_lsat_data/test_rc.json",
        "complete_lsat_data/train_ar.json",
        "complete_lsat_data/train_lr.json",
        "complete_lsat_data/train_rc.json",
        "complete_lsat_data/val_ar.json",
        "complete_lsat_data/val_lr.json",
        "complete_lsat_data/val_rc.json",
        "data/AR_DevelopmentData.json",
        "data/AR_TestData.json",
        "data/AR_TrainingData.json",
        "img.png"
    ],
    "license_files": {
        "LICENSE": "MIT License\n\nCopyright (c) 2022 Wanjun Zhong\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
    },
    "readme": "# AR-LSAT\nThe data and code for the paper [AR-LSAT: Investigating Analytical Reasoning of Text](https://arxiv.org/pdf/2104.06598.pdf), and [complete data](https://github.com/zhongwanjun/AR-LSAT/tree/main/complete_lsat_data) for the paper [From LSAT: The Progress and Challenges of Complex Reasoning](https://arxiv.org/abs/2108.00648.pdf).\n\nIf you find this paper or this code useful, please cite this paper:\n```angular2html\n@misc{zhong2021arlsat,\n      title={AR-LSAT: Investigating Analytical Reasoning of Text}, \n      author={Wanjun Zhong and Siyuan Wang and Duyu Tang and Zenan Xu and Daya Guo and Jiahai Wang and Jian Yin and Ming Zhou and Nan Duan},\n      year={2021},\n      eprint={2104.06598},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n@article{wang2022lsat,\n  title={From lsat: The progress and challenges of complex reasoning},\n  author={Wang, Siyuan and Liu, Zhongkun and Zhong, Wanjun and Zhou, Ming and Wei, Zhongyu and Chen, Zhumin and Duan, Nan},\n  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},\n  year={2022},\n  publisher={IEEE}\n}\n```\n-----\n## Data\n### Data Example\n\n![avatar](img.png)\n\n### Data format\n```\n[\n    {\n        \"id\": ....\n        \"passage\": ...\n        \"questions\": [\n            {\n                \"id\": ...\n                \"fatherId\": ...\n                \"question\": ...\n                \"options\": ...\n                \"answer\": ...\n            }\n    }\n]\n```\n## Transformer-based System\n```angular2html\ncd Transformer-based Model\nbash run_roberta_large.sh\n```\nNote: \n1. you need to modify the file name in utils_multiple_choice.py\n2. you can change different backbone by modifying the --model_name_or_path in the run_roberta_large.sh script\n3. for running the LSTM based baseline, pls refer to the same steps\n## Analytical Reasoning Machine\n1. Step 1: extract named entity recognition (NER), Constinuency Parsing (CP) and Dependency Parsing (DP) results from the original files:\n2. Step 2: extract participants, positions from the context\n3. Step 3: run pipeline for the dev and test set.\n```angular2html\n1. \n    cd data_analysis\n    python extract_cp_ner_dp_results.py\n2. \n    cd data_analysis\n    python extract_participant_modify_context_preprocessed.py\n3.\n    cd pipeline\n    python nl2fact_fule.py\n    \n```\nNormally, this pipeline will get the precision:\n\n| Data | Accuracy |\n|--------|:--------:|\n| Development | 34.2 |\n| Test | 30.9 |\n",
    "py_files": {
        "ARM/data_analysis/extract_cp_ner_dp_results.py": "import json\r\nimport os\r\nimport nltk\r\nfrom tqdm import tqdm\r\nimport re\r\nfrom tqdm import tqdm\r\nimport sys\r\nfrom rule_pattern import RulePattern\r\nfrom collections import Counter\r\nRP = RulePattern()\r\nbasic_dir = \"../../data/\"\r\ndatap = os.path.join(basic_dir, 'AR_DevelopmentData.json')\r\noutp = os.path.join(basic_dir, 'cp_ner_dp_results/AR_DevelopData_cp_ner_dp_results.json')\r\ndata = json.load(open(datap, 'r'))\r\ndef clean_doc(doc):\r\n    # doc = ' '+doc\r\n    # doc = doc.replace('—', ' — ')\r\n    # doc = doc.replace('—', ' — ')\r\n    doc = doc.replace('\\u2014',' \\u2014 ')\r\n    return doc\r\nall_passages = []\r\nfor passage in tqdm(data):\r\n    # passages = exam['sections'][0]['passages']\r\n\r\n    # for pidx,passage in enumerate(passages):\r\n    doc = clean_doc(passage['passage'])#incase the first word is a number\r\n    passage['passage'] = doc\r\n    ques = passage['questions']\r\n    sens = nltk.sent_tokenize(doc)\r\n\r\n    sen_tokens, sen_ent_res, sen_dps = RP.get_cp_ner_results(sens)\r\n    passage['sentences'] = sens\r\n    passage['sentence_cp_results'] = []\r\n    passage['sentence_ner_results'] = []\r\n    passage['sentence_dp_results'] = []\r\n    for idx in range(len(sens)):\r\n\r\n        passage['sentence_cp_results'].append(sen_tokens[idx])#['hierplane_tree']['root'])\r\n        passage['sentence_ner_results'].append(sen_ent_res[idx])\r\n        passage['sentence_dp_results'].append(sen_dps)\r\n\r\n    #analyze keywords in question and answer\r\n    ques_text = [que['question'] for que in ques]\r\n    ques_tokens, ques_ent_res, ques_dps = RP.get_cp_ner_results(ques_text)\r\n    all_ques_kws = []\r\n    all_opt_kws = []\r\n    for idx in range(len(ques)):\r\n        passage['questions'][idx]['question_cp_results'] =  ques_tokens[idx]#['hierplane_tree']['root']\r\n        passage['questions'][idx]['question_ner_results'] = ques_ent_res[idx]\r\n        passage['questions'][idx]['question_dp_results'] = ques_dps[idx]\r\n\r\n        options = ques[idx]['options']\r\n        # print(options)\r\n        opt_tokens, opt_ent_res, opt_dps = RP.get_cp_ner_results(options)\r\n        passage['questions'][idx]['option_cp_results'] = opt_tokens#[token['hierplane_tree']['root'] for token in opt_tokens]\r\n        passage['questions'][idx]['option_ner_results'] = opt_ent_res\r\n        passage['questions'][idx]['option_dp_results'] = opt_dps\r\n\r\n\r\n    all_passages.append(passage)\r\n\r\nwith open(outp,'w',encoding='utf8') as outf:\r\n    json.dump(all_passages,outf)\r\n\r\n\r\n\r\n\r\n\r\n",
        "ARM/data_analysis/extract_participant_modify_context_preprocessed.py": "import json\r\nimport os\r\nimport nltk\r\nimport re\r\nfrom tqdm import tqdm\r\nfrom copy import deepcopy\r\nimport sys\r\nimport copy\r\nfrom rule_pattern import RulePattern\r\nfrom collections import Counter\r\nRP = RulePattern()\r\ndef rank_entities(entities):\r\n    quantity_ents = []\r\n    rest_ents = []\r\n    flag = False\r\n    for group in [RP.simple_order,RP.orders, RP.numbers, RP.week_words, RP.month_words]:\r\n        if any([ent in group for ent in entities]) or any([ent.isnumeric() for ent in entities]):\r\n            for ent in entities:\r\n                if ent in group.keys():\r\n                    quantity_ents.append((ent, group[ent]))\r\n                elif ent.isnumeric():\r\n                    quantity_ents.append((ent, int(ent)))\r\n                else:\r\n                    rest_ents.append((ent, None))\r\n            flag = True\r\n            break\r\n    ranked_quan_ent = sorted(quantity_ents, key=lambda k: k[1])\r\n    all_entities = [ent[0] for ent in ranked_quan_ent + rest_ents] if flag else entities\r\n    return all_entities\r\n\r\nbasic_dir = '../../data'\r\ndatap = os.path.join(basic_dir, 'AR_TestData_cp_ner_dp_results.json')#'cp_ner_dp_results/AR_DevelopmentData_cp_ner_dp_results.json')\r\noutp =  os.path.join(basic_dir, 'new_data/ar_test_analyze_condition.json')#'model_data/ar_val_analyze_condition.json')\r\npassages = json.load(open(datap, 'r',encoding='utf8'))\r\n\r\nall_passages = []\r\nall_output_for_model = []\r\nans2label = {'A':0,'B':1,'C':2,'D':3,'E':4}\r\nfor pidx,passage in enumerate(passages):\r\n    doc = passage['passage']#incase the first word is a number\r\n\r\n    ques = passage['questions']\r\n    sens = [sen for sen in passage['sentences']]\r\n\r\n\r\n    conditions = {'participant_group':[],'position_group':[]}\r\n    # print('--------------------------------------------------')\r\n    # print(sens)\r\n    sen_tokens, sen_ent_res = passage['sentence_cp_results'],passage['sentence_ner_results']\r\n    sen_num = len(sens)\r\n    all_kws = []\r\n    all_sen_kws = []\r\n    #extract conditions\r\n    doc_ent_group,doc_num2ent,all_tokens = [],[],[]\r\n    start_idx = 0\r\n    passages[pidx]['sentence_keywords']=[]\r\n    for idx in range(len(sens)):\r\n        sen, tokens,ent_res = sens[idx],sen_tokens[idx],sen_ent_res[idx]\r\n        re_pattern_sen_kws = RP.found_key_words_leading_sen(sen, tokens, ent_res,start_idx)\r\n        if idx<3:\r\n            all_tokens.extend(sen_tokens[idx]['tokens'])\r\n            entity_group = re_pattern_sen_kws['entity_group']\r\n\r\n            quantity2group = re_pattern_sen_kws['range_quantity_pairs']\r\n\r\n            if entity_group:\r\n                doc_ent_group.extend(entity_group.copy())\r\n\r\n            doc_num2ent.extend(quantity2group)\r\n            start_idx = len(all_tokens)\r\n\r\n        sen_kws = RP.found_key_words_common(sen,tokens,ent_res)\r\n        sen_kws['entity_group'] = copy.deepcopy(re_pattern_sen_kws['entity_group'])\r\n        sen_kws['quantity_pairs'] = copy.deepcopy(re_pattern_sen_kws['quantity_pairs'])\r\n\r\n        all_sen_kws.append(sen_kws)\r\n        passages[pidx]['sentence_keywords'].append(sen_kws)\r\n        cond_ent = RP.combine_cond_keywords(sen_kws)\r\n        for group in cond_ent['entity_group']:\r\n            all_kws.extend(group['entities'])\r\n    # print(doc_ent_group)\r\n    # input()\r\n    participants, columns,modified_doc = RP.extract_participants_columns(doc_ent_group, doc_num2ent, all_tokens,doc)\r\n    columns = rank_entities(list(columns))\r\n    participants = rank_entities(participants)\r\n    print(doc)\r\n    if participants == columns:\r\n        # print(participants)\r\n        try:\r\n            columns = [list(RP.orders.keys())[idx] for idx in range(len(participants))]\r\n        except Exception as e:\r\n            print(e)\r\n\r\n    participants = [tmp for tmp in participants if tmp]\r\n    columns = [tmp for tmp in columns if tmp]\r\n    print(participants, columns)\r\n    print('------------------')\r\n    # participants, columns = RP.extract_participants_columns(doc_ent_group, doc_num2ent, all_tokens)\r\n    #analyze keywords in question and answer\r\n    ques_text = [que['question'] for que in ques]\r\n\r\n    all_ques_kws = []\r\n    all_opt_kws = []\r\n    for idx in range(len(ques)):\r\n        # que_kws = RP.extract_question_keywords(ques[idx]['question'],ques_tokens[idx],ques_ent_res[idx])\r\n        que_kws = RP.found_key_words_common(ques[idx]['question'],ques[idx]['question_cp_results'],ques[idx]['question_ner_results'])\r\n        clean_que_kws = RP.combine_common_keywords(que_kws)\r\n        all_ques_kws.append(que_kws)\r\n        passages[pidx]['questions'][idx]['question_keywords'] = clean_que_kws\r\n        all_kws.extend(clean_que_kws['filtered_keywords'])\r\n        # print(ques[idx]['question'])\r\n        # print(clean_que_kws)\r\n        options = ques[idx]['options']\r\n        # print(options)\r\n        opt_tokens, opt_ent_res = ques[idx]['option_cp_results'],ques[idx]['option_ner_results']#RP.get_cp_ner_results(options)\r\n        opt_kws = []\r\n        passages[pidx]['questions'][idx]['options_keywords'] = []\r\n        #output for model\r\n        # if doc!=modified_doc:\r\n        #     print(doc,'\\n',modified_doc,'\\n','---------------------')\r\n\r\n        # modified_options = RP.modify_option(options)\r\n        # print(options,'\\n',modified_options)\r\n\r\n        all_output_for_model.append({'context':doc,'question':ques[idx]['question'],'answers':options,'label':ans2label[ques[idx]['answer']],\r\n                                     'rows':list(participants),'columns':list(columns),'id_string':ques[idx]['id'],'tags':ques[idx]['tags']})\r\n        for opt_idx in range(len(options)):\r\n            # tmp_kws = RP.extract_option_keywords(options[opt_idx],opt_tokens[opt_idx],opt_ent_res[opt_idx])\r\n            tmp_kws = RP.found_key_words_common(options[opt_idx],opt_tokens[opt_idx],opt_ent_res[opt_idx])\r\n            clean_tmp_kws = RP.combine_common_keywords(tmp_kws)\r\n            opt_kws.append(clean_tmp_kws)\r\n            all_opt_kws.append(opt_kws)\r\n            passages[pidx]['questions'][idx]['options_keywords'].append(opt_kws)\r\n            all_kws.extend(clean_tmp_kws['filtered_keywords'])\r\n        # print('*********************')\r\n    #calculate the frequency of mentioned entities to see which are important\r\n    count = Counter(all_kws)\r\n    #information summarization\r\n    passages[pidx]['conditions'] = {}\r\n    passages[pidx]['conditions']['participants'] = participants\r\n    passages[pidx]['conditions']['columns'] = columns\r\n    passages[pidx]['entity_frequency'] = count\r\n    passages[pidx]['rules'] = sens\r\n\r\n\r\n\r\nwith open(outp,'w',encoding='utf8') as outf:\r\n    json.dump(all_output_for_model,outf)\r\n\r\nwith open(outp.replace('.json','beautiful.json'),'w',encoding='utf8') as outf:\r\n    json.dump(all_output_for_model,outf,indent=4)\r\n\r\n\r\n\r\n\r\n\r\n",
        "ARM/data_analysis/rule_pattern.py": "import re\nimport inflect\nimport nltk\nimport numpy as np\nimport json\n# from allennlp.predictors.predictor import Predictor\n# import allennlp_models.tagging\n# import allennlp_models.structured_prediction\nclass RulePattern():\n\n    def __init__(self):\n        super(RulePattern, self).__init__()\n        numbers = {\n            #'an':1,\n            'zero': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10, 'eleven': 11,'twelve': 12\n        }\n        orders = {\n            'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5, 'sixth': 6, 'seventh': 7,\n            'eighth': 8, 'ninth': 9, 'tenth': 10, 'eleventh': 11, 'twelfth': 12,'thirteenth':13,\n            'fourteenth':14,'fifteenth':15,'sixteenth':16,'last':17,\n        }\n        simple_order = {\n            '1st':1, '2nd':2,'3rd':3,'4th':4,'5th':5,'6th':6,'7th':7,'8th':8,'9th':9\n        }\n        self.numbers = numbers.copy()\n        for num in numbers.items():\n            self.numbers[num[0].capitalize()] = num[1]\n        self.orders = orders.copy()\n        self.simple_order = simple_order.copy()\n        for num in orders.items():\n            self.orders[num[0].capitalize()] = num[1]\n        self.pos_useful_tag = ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJR', 'JJS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',\n                               'V', 'PDT', 'PRP', 'RBR', 'RBS']\n        self.entity_tag = ['NN', 'NNS', 'NNP', 'NNPS']\n        self.week_words = {'Monday':1, 'Tuesday':2, 'Wednesday':3, 'Thursday':4, 'Friday':5, 'Saturday':6, 'Sunday':7}\n        self.month_words = {\n        \"January\":1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10,\n            'November':11, 'December':12\n        }\n        self.num_words = ['first','second','three','four','five','six','seven','']\n        self.no_use_single_words = ['The', 'She', 'He', 'They', 'It', 'Them', 'Their', 'A', 'On', 'In', 'To', 'Where',\n                                    'There','Each','If','following','Neither','Except']\n\n        self.all_num_dict = [self.numbers,self.orders,self.simple_order,self.week_words,self.month_words]\n        self.quantity_words = ['once','each','twice','a']\n        self.keywords = ['circular']\n        number_joint = '|'.join(list(self.numbers.keys()))\n        self.entity_patterns = ['(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9 ]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:. ]{1,}(( [0-9])*))|([$,0-9]+( [a-z]+)))',#'(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9. ]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:. ]{1,}(( [0-9])*))|([$,0-9]+( [a-z]+)))',#(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9.]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:. ]{1,}(( [0-9])*))|([$,0-9]+( [a-z]+)))',\n                               '(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9. ]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:. ]{1,}(( [0-9])*))|([$,0-9]+( [a-z]+)))',\n                               # '([A-Za-z0-9]+, ){2,}and ([0-9A-Za-z ]+)'\n                               '([A-Za-z ]+, ){2,}and ([A-Za-z ]+)',\n                                '(— |: )([A-Za-z ]+) (and|or) ([A-Za-z ]+)']#higher participant performance\n            #'((a [0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9.]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:]{1,}( [0-9])*)|([$,0-9]+( [a-z]+)))'#higher col performance\n        #'(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9.]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*[a-zA-Z0-9.]{1,}( [0-9])*'\n            #'(([0-9:]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9.]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*[a-zA-Z0-9.]{1,}( [0-9])*'\n        #'((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9]{1,})( [0-9])*, ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*[a-zA-Z0-9]{1,}( [0-9])*'\n        self.quantity_pattern = '( |— )(|{number}|[0-9]+)+ ([a-zA-Z]+)[ —.,](({number}|[0-9])+[ ,.])*'.format(number=number_joint)\n        self.range_pattern = '[a-zA-Z ]*({order}|{number}|{week}|([0-9]+))+ (\\([a-z]+\\) )*(through|to) [a-zA-Z ]*({order}|{number}|{week}|([0-9]+.))+'.format(\n            number=number_joint,order='|'.join(list(orders.keys())+list(simple_order.keys())),week='|'.join(list(self.week_words.keys())),month='|'.join(list(self.month_words.keys())))\n        self.number_pattern = '({simple_order}|{order}|{number}|{week}|{month}|([0-9]+))+'.format(number=number_joint,simple_order='|'.join(list(simple_order.keys())),order='|'.join(list(self.orders.keys())),week='|'.join(list(self.week_words.keys())),month='|'.join(list(self.month_words.keys())))\n        #'((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9]{1,}), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*[a-zA-Z0-9]{1,}'\n        # self.predictor_ner = Predictor.from_path(\n        #     \"https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz\",cuda_device=0)\n        # self.predictior_cp = Predictor.from_path(\n        #     \"https://storage.googleapis.com/allennlp-public-models/elmo-constituency-parser-2020.02.10.tar.gz\",cuda_device=0)\n        # self.predictior_dp = Predictor.from_path('https://storage.googleapis.com/allennlp-public-models/biaffine-dependency-parser-ptb-2020.04.06.tar.gz',cuda_device=0)\n        # self.openie_predictor = Predictor.from_path(\n        #     \"https://s3-us-west-2.amazonaws.com/allennlp/models/openie-model.2018-08-20.tar.gz\")\n        # self.srl_predictor = Predictor.from_path(\n        #     \"https://s3-us-west-2.amazonaws.com/allennlp/models/srl-model-2018.05.25.tar.gz\")\n        self.stemm = nltk.PorterStemmer()\n        self.tokenizer = nltk.word_tokenize\n        self.inflect = inflect.engine()\n\n\n    def modify_option(self,options):\n        match_pattern = '([A-Za-z0-9]+, ){1,}([a-zA-Z0-9]*)'\n        modified_options=[]\n        for option in options:\n            all_res = re.finditer(match_pattern,option)\n            for res in all_res:\n                parts = res.group().split(', ')\n                for idx in range(len(parts)):\n                    if 'and' in parts[idx]:\n                        parts[idx] = ' and the {} is'.format(list(self.orders.keys())[idx])\n                    else:\n                        parts[idx] = 'the {} is {}'.format(list(self.orders.keys())[idx],parts[idx])\n                replace_str = ', '.join(parts)\n                option = option.replace(res.group(),replace_str)\n            modified_options.append(option)\n        return modified_options\n\n\n    def find_wspan(self,text,tokens,cspan,start_idx):\n        start = None\n        end = None\n        cand = []\n        for i in range(len(tokens)):\n            if tokens[i] in text:\n                if start:\n                    end+=1\n                else:\n                    start,end = i,i\n            else:\n                if start:\n                    start_dis = abs(cspan[0]-len(' '.join(tokens[:start])))\n                    end_dis = abs(cspan[1]-len(' '.join(tokens[:end+1])))\n                    cand.append((start,end,(start_dis+end_dis)/2))\n                    start,end=None,None\n        if start:\n            start_dis = abs(cspan[0] - len(' '.join(tokens[:start])))\n            end_dis = abs(cspan[1] - len(' '.join(tokens[:end + 1])))\n            cand.append((start, end, (start_dis + end_dis) / 2))\n\n        cand = sorted(cand,key=lambda x:x[2],reverse=False)\n        return (start_idx+cand[0][0],start_idx+cand[0][1]+1)\n\n\n    def extract_entity_pattern(self,text, tokens,sen_start_idx):\n\n        ent_groups = []\n        all_ent = []\n        repeat_group = []\n        for idx,entity_pattern in enumerate(self.entity_patterns):\n            entity_parts = re.finditer(entity_pattern, text)\n            if entity_parts:\n                for entity_part in entity_parts:\n                    tmp = str(entity_part.group()).replace(', ', '#')\n                    # print(tmp)\n                    tmp = str(tmp).replace('and ', '#')\n                    tmp = str(tmp).replace('or ', '#')\n                    tmp = tmp.split('#')\n                    while '' in tmp:\n                        tmp.remove('')\n                    count = 0\n                    # print(tmp)\n                    for widx,item in enumerate(tmp):\n                        if self.exist(item,all_ent):\n                            count+=1\n                        item = item.replace('—','').strip()\n                        if len(item.split(' '))>4:#if length of some word larger than 4,drop this instance\n                            count+=len(tmp)\n                    if count>=(2/3)*len(tmp):#if the number of entities in current group already found larger than 2/3 of the total entities in the group, continue\n                        repeat_group.append({'entities': tmp,\n                                           'span': self.find_wspan(entity_part.group(), tokens, entity_part.span(),\n                                                                   sen_start_idx)})\n                        continue\n                    else:\n                        ent_groups.append({'entities': tmp,\n                                           'span': self.find_wspan(entity_part.group(), tokens, entity_part.span(),\n                                                                   sen_start_idx)})\n\n\n                    all_ent.extend(tmp)\n            # sorted_repeat_group = sorted(repeat_group,key=lambda k:len(k['entities']),reverse=True)\n\n            # if idx>0 and ent_groups:\n\n            if len(ent_groups)>1:\n                break\n\n        return ent_groups\n\n\n    def extract_quantity(self, text, tokens,start_idx):\n        results = re.finditer(self.quantity_pattern,text)\n        re_quantity = []\n        for match in results:\n            re_quantity.append({'text':match.group().strip(' ,.—') ,'span':self.find_wspan(match.group(),tokens, match.span(),start_idx)})\n        range_results = re.finditer(self.range_pattern,text)\n        range_quantity = []\n        for match in range_results:\n            range_quantity.append({'text':match.group().strip(' ,.—') ,'span':self.find_wspan(match.group(),tokens, match.span(),start_idx)})\n        return re_quantity,range_quantity\n\n    def match_number_entity(self,quantity,ent_groups):\n        for qua_idx,qua in enumerate(quantity):\n            qua_pos = qua['span']\n            min_dis, min_idx = 9999,None\n            for gidx,group in enumerate(ent_groups):\n                group_pos = group['span']\n                dis = group_pos[0] - qua_pos[1]\n                if qua_pos[0] in list(range(group_pos[0],group_pos[1])):\n                    dis = 0\n                if (dis>=0 and dis<min_dis):\n                    min_idx = gidx\n                    min_dis = dis\n\n            quantity[qua_idx]['match_entity_group'] = ent_groups[min_idx] if (ent_groups and min_idx!=None) else None\n        return quantity\n\n    def extract_participants(self, leaf_nodes):\n        nouns = []\n        quantity = []\n        numbers = []\n        for idx, node in enumerate(leaf_nodes):\n            #calculate nouns and quantity\n            flag = False\n            if node['nodeType'] in self.entity_tag:\n                #middle of the sequence\n                if idx != 0 and idx != len(leaf_nodes) - 1:\n                    if (leaf_nodes[idx - 1]['word'] in ['—', ',', 'and']) or (\n                            leaf_nodes[idx + 1]['word'] in [',']):\n                        flag = True\n                    elif leaf_nodes[idx-1]['nodeType']=='CD':\n                        quantity.append((leaf_nodes[idx-1]['word'],leaf_nodes[idx]['word'],idx))\n                #start of sequence\n                elif idx == 0:\n                    if (leaf_nodes[idx + 1]['word'] in [',']):\n                        flag = True\n                #end of the sequence\n                elif idx == len(leaf_nodes) - 1:\n                    if (leaf_nodes[idx - 1]['word'] in ['—', ',', 'and']):\n                        flag = True\n                    elif leaf_nodes[idx-1]['nodeType']=='CD':\n                        quantity.append((leaf_nodes[idx-1]['word'],leaf_nodes[idx]['word'],idx))\n                if flag==False:\n                    if node['word'] in list(self.month_words.keys())+list(self.week_words.keys()):\n                        if idx==0:\n                            quantity.append(('null',node['word'],idx))\n                        else:\n                            quantity.append((leaf_nodes[idx - 1]['word'], leaf_nodes[idx]['word'], idx))\n                        flag = True\n                if flag:\n                    nouns.append((node['word'],idx))\n            #if the word is number, find useful sorrounding context\n            if node['nodeType']=='CD' or (node['word'].lower() in self.quantity_words):\n                start=0 if idx==0 else idx-1\n                for j in range(idx,0):\n                    if leaf_nodes[j]['nodeType'] in list(self.entity_tag)+['CD'] or leaf_nodes[j]['word'] in [',','.','—']:\n                        start = j\n                        break\n                for j in range(idx+1,len(leaf_nodes)):\n                    if leaf_nodes[j]['nodeType'] in list(self.entity_tag)+['CD'] or leaf_nodes[j]['word'] in [',','.','—']:\n                        end = j\n                        break\n\n                numbers.append(([leaf['word'] for leaf in leaf_nodes[start:end+1]],node['word'],idx))\n\n        results = {'nouns':nouns, 'quantity':quantity,'numbers':numbers}\n        return results\n\n    def get_noun(self,tree,nps):\n        if isinstance(tree, dict):\n            if \"children\" not in tree:\n                if (tree['nodeType'] in self.entity_tag):\n                    nps.append(tree['word'])\n                # if tree['nodeType'] in [\"NNP\",\"NN\"]:\n                    # print(tree['word'])\n                    # print(tree)\n                    # nps.append(tree)\n\n            elif \"children\" in tree:\n                # cls.get_NP(tree['children'], nps)\n                if (tree['nodeType'] in self.entity_tag):\n                    # print(tree['word'])\n                    # nps.append(tree['word'])\n                    self.get_noun(tree['children'], nps)\n                else:\n                    self.get_noun(tree['children'], nps)\n        elif isinstance(tree, list):\n            for sub_tree in tree:\n                self.get_noun(sub_tree, nps)\n\n        return nps\n\n    def check_contain_num(self,tree):\n        if isinstance(tree, dict):\n            if \"children\" not in tree:\n                if tree['nodeType'] == 'CD':\n                    return True\n                else:\n                    return False\n            else:\n                return self.check_contain_num(tree['children'])\n        elif isinstance(tree, list):\n            ans = False\n            for sub_tree in tree:\n                ans = ans | self.check_contain_num(sub_tree)\n            return ans\n\n    def get_np_has_number(self,tree, nps, subtree):\n        if isinstance(tree, dict):\n            if \"children\" not in tree:\n                if tree['nodeType'] == \"NP\":\n                    # print(tree['word'])\n                    # print(tree)\n                    nps.append(tree['word'])\n            elif \"children\" in tree:\n                if tree['nodeType'] == \"NP\":\n                    # print(tree['word'])\n                    #                 print(tree['word'],check_contain_num(tree))\n                    if self.check_contain_num(tree):\n                        nps.append(tree['word'])\n                        subtree.append(tree)\n\n                #                     get_np_has_number(tree['children'], nps,subtree)\n                else:\n                    self.get_np_has_number(tree['children'], nps, subtree)\n        elif isinstance(tree, list):\n            for sub_tree in tree:\n                self.get_np_has_number(sub_tree, nps, subtree)\n        return nps, subtree\n\n    def combine_cond_keywords(self,keywords):\n        #combine keywords especially for condition extraction\n        for i,group in enumerate(keywords['entity_group']):\n            for j,ent1 in enumerate(group['entities']):\n                ent1 = ent1.strip().replace(', or', '')\n                keywords['entity_group'][i]['entities'][j] = ent1\n                for k,ent2 in enumerate(keywords['entity']):\n                    if ent1 in ent2:\n                        keywords['entity_group'][i]['entities'][j]=ent2\n        return keywords\n\n    def combine_common_keywords(self,keywords):\n        #combine keywords for common noun phrase extraction and entity extration\n        for i,ent2 in enumerate(keywords['entity']):\n            for j,useless_wd in enumerate(self.no_use_single_words):\n                if (useless_wd+' ') in ent2:\n                    keywords['entity'][i] = keywords['entity'][i].strip(useless_wd+' ')\n        for i, ent1 in enumerate(keywords['noun']):\n            for j, ent2 in enumerate(keywords['entity']):\n                if ent1 in ent2:\n                    keywords['noun'].pop(i)\n                    break\n        kws = list(set(keywords['noun']+keywords['entity']))\n        for i,kw in enumerate(kws):\n            if kw in self.no_use_single_words:\n                kws.pop(i)\n            if ',' in kws:\n                tmp = kws[i]\n                kws.pop(i)\n                kws.extend(tmp.split(','))\n        keywords['filtered_keywords'] = kws\n        return keywords\n\n    def extract_question_keywords(self, text, tokens, ent_res):\n        keywords = {'noun': [], 'text':text, 'entity':[]}\n        all_ents = self.extract_entity_allennlp(ent_res['words'], ent_res['tags'])\n        keywords['entity'].extend(all_ents)\n        tree = tokens['hierplane_tree']['root']\n        nps = []\n        nps = self.get_NP(tree,nps)\n        keywords['noun'] = nps\n        return keywords\n\n    def extract_option_keywords(self, text, tokens, ent_res):\n        return self.extract_question_keywords(text,tokens,ent_res)\n\n    def found_key_words_common(self, claim, tokens, ent_res):\n        key_words = {'noun': [], 'text': claim, 'entity':[]}\n        tree = tokens['hierplane_tree']['root']\n        nps, subtrees = [],[]\n        nps, subtrees = self.get_np_has_number(tree,nps,subtrees)\n        key_words['quantity_noun_phrase'] = nps\n        # key_words['quantity_subtree'] = subtrees\n        all_ents = self.extract_entity_allennlp(ent_res['words'], ent_res['tags'])\n        key_words['entity'].extend(all_ents)\n        nps = []\n        tree = tokens['hierplane_tree']['root']\n        nps = self.get_noun(tree, nps)\n        key_words['noun'] = nps\n        return key_words\n\n    def mapnum2int(self,num):\n        # print(num)\n        for d in self.all_num_dict:\n            if num in d.keys():\n                return (d[num],d)\n\n        return int(num),None\n\n    def exist(self,item1, lst):\n        for item2 in lst:\n            if item1.strip() in item2.strip() or item2.strip() in item1.strip():\n                return True\n\n    def extract_columns_from_range(self,quantity,doc):\n\n        nums = re.finditer(self.number_pattern,quantity)\n        all_nums = []\n        num_dict = None\n        start,end=9999,-1\n        print(nums)\n        for num in nums:\n            # print(num)\n            start = min(start, num.span()[0])\n            end = max(end, num.span()[1])\n            num,num_dict = self.mapnum2int(num.group())\n            all_nums.append(num)\n            num_dict = num_dict\n        min_num,max_num = min(all_nums),max(all_nums)\n        columns = []\n        if num_dict:\n            for item in num_dict.items():\n                if item[1]>=min_num and item[1]<=max_num and item[0].lower() not in columns:\n                    columns.append(item[0])\n        else:\n            columns = [str(num) for num in range(min_num,max_num+1)]\n\n        if start<9999 and end!=-1:\n            modified_doc = doc.replace(quantity[start:end],', '.join(columns))\n        else:\n            modified_doc = doc\n        return columns, modified_doc\n\n    def found_key_words_leading_sen(self, claim,tokens, ent_res,sid):\n        #extract entity and quantity especially for two leading sentences for condition extractions\n        #use regex pattern to extract entities and quantity\n        key_words = { 'text': claim, 'quantity_pairs': [], 'entity': []}\n        nps = []\n\n        # tree = tokens['hierplane_tree']['root']\n        # leaf_nodes = self.get_noun(tree, nps)\n        # results = self.extract_participants(leaf_nodes)\n        # key_words['noun'].extend(results['nouns'])#.extend(results['quantity'])\n        # key_words['numbers'] = results['numbers']\n\n        all_ents = self.extract_entity_allennlp(ent_res['words'], ent_res['tags'])\n        key_words['entity'].extend(all_ents)\n\n        ent_groups = self.extract_entity_pattern(claim,tokens['tokens'],sid)\n        key_words['entity_group'] = ent_groups\n\n        # add_keywords = self.combine_cond_keywords(key_words)\n        quantity,range_quantity = self.extract_quantity(claim,tokens['tokens'],sid)\n        # print(claim, '\\n')\n        # print(tokens['tokens'])\n        # print('quantity is:',quantity,'\\n')\n        # print('entity_group is: ',ent_groups,'\\n')\n        quantity = self.match_number_entity(quantity,ent_groups)\n        range_quantity = self.match_number_entity(range_quantity,ent_groups)\n\n        # print('matched quantity is :',quantity)\n        # print('---------------------------------------')\n        key_words['quantity_pairs'] = quantity\n        key_words['range_quantity_pairs'] = range_quantity\n\n\n        return key_words\n\n    def manage_multiple_group(self,ent_groups,words):\n        participants = ent_groups[0]['entities'].copy()\n        start_span = ent_groups[0]['span']\n        columns = []\n        col_flag = False\n        for g in ent_groups[1:]:\n            # print(words[start_span[1]:g['span'][0]+1])\n            if any([item in words[start_span[1]:g['span'][0]+1] for item in ['to','at','on','for']]):\n                columns.extend(g['entities'])\n                col_flag = True\n            elif any([item in words[start_span[1]:g['span'][0]+1] for item in ['and','or','with']]):\n                if col_flag==True:\n                    columns.extend(g['entities'])\n                else:\n                    participants.extend(g['entities'])\n            else:\n                columns.extend(g['entities'])\n                col_flag=True\n            start_span = g['span']\n        if len(columns)==0:\n            columns = ent_groups[-1]['entities']\n        return participants,columns\n\n    def clean_ent(self,ents):\n        no_use_words = ['—',':','.']+[' '+tmp+' ' for tmp in ['a','the','case','bonus','shelf','court']+list(self.numbers.keys()) + self.no_use_single_words]\n        for eidx,ent in enumerate(ents):\n            ents[eidx] = ' '+ents[eidx]\n            for wd in no_use_words:\n                ents[eidx] = ents[eidx].replace(wd,' ')\n            ents[eidx] = ents[eidx].strip()\n        return ents\n\n    def extract_participants_columns(self,ent_groups,range_quantity,words,doc):\n\n        columns = []\n        participants = []\n        modified_doc = doc\n\n        if range_quantity:\n            for rq in range_quantity:\n                column,modified_doc = self.extract_columns_from_range(rq['text'],modified_doc)\n                columns.extend(column)\n            if len(ent_groups)>=2:\n                participants, tmp_columns = self.manage_multiple_group(ent_groups, words)\n                columns.extend(tmp_columns)\n            elif len(ent_groups)==1:\n                participants = ent_groups[0]['entities']\n            else:\n                participants = columns\n        elif len(ent_groups) >= 2:\n            participants, columns = self.manage_multiple_group(ent_groups,words)\n        elif len(ent_groups) == 1:\n            participants = ent_groups[0]['entities']\n            columns = ent_groups[0]['entities']\n        # print(participants)\n        participants = self.clean_ent(participants)\n        columns = self.clean_ent(columns)\n        participants = set(participants)\n        columns = set(columns)\n        same = list(set.intersection(participants,columns))\n        new_columns = [c for c in columns if (c not in same) ]\n        participants = list(participants)\n        if len(new_columns)==0:\n            new_columns = columns\n\n        # print('participants',participants,'\\n')\n        # print('columns',columns,'\\n')\n        # for idx,col in enumerate(columns):\n        #     columns[idx] = list(set(col))\n        return participants,new_columns,modified_doc\n\n    def get_cp_ner_results(self,texts):\n        tokens = self.predictior_cp.predict_batch_json(inputs=[{'sentence':text} for text in texts])\n        dps = self.predictior_dp.predict_batch_json(inputs=[{'sentence':text} for text in texts])\n        ent_res = []\n        for text in texts:\n\n            try:\n                tmp_res = self.predictor_ner.predict(text)\n                ent_res.append(tmp_res)\n            except Exception as e:\n                print(text)\n                ent_res.append({'words':[],'tags':[]})\n        # ent_res = self.predictor_ner.predict_batch_json(inputs=[{'sentence':text} for text in texts])\n        # print(tokens[0].keys())\n        for i in range(len(tokens)):\n            del tokens[i]['class_probabilities']\n        return tokens,ent_res,dps\n    \n    @classmethod\n    def check_contain_upper(cls, password):\n        pattern = re.compile('[A-Z]+')\n        match = pattern.findall(password)\n        if match:\n            return True\n        else:\n            return False\n\n\n    @classmethod\n    def tokenize_sentence(self, sentence):\n        tokens = nltk.word_tokenize(sentence)\n        return tokens\n\n    def normalize_tags(self, tagged):\n        n_tagged = []\n        for t in tagged:\n            if t[1] == \"NP-TL\" or t[1] == \"NP\":\n                n_tagged.append((t[0], \"NNP\"))\n                continue\n            if t[1].endswith(\"-TL\"):\n                n_tagged.append((t[0], t[1][:-3]))\n                continue\n            if t[1].endswith(\"S\"):\n                n_tagged.append((t[0], t[1][:-1]))\n                continue\n            n_tagged.append((t[0], t[1]))\n        return n_tagged\n        # Extract the main topics from the sentence\n\n\n\n    @classmethod\n    def get_NP(cls, tree, nps):\n        if isinstance(tree, dict):\n            if \"children\" not in tree:\n                if tree['nodeType'] in [\"NNP\",\"NN\"]:\n                    # print(tree['word'])\n                    # print(tree)\n                    nps.append(tree['word'])\n            elif \"children\" in tree:\n                if tree['nodeType'] in [\"NNP\",\"NN\"]:\n                    # print(tree['word'])\n                    nps.append(tree['word'])\n                    cls.get_NP(tree['children'], nps)\n                else:\n                    cls.get_NP(tree['children'], nps)\n        elif isinstance(tree, list):\n            for sub_tree in tree:\n                cls.get_NP(sub_tree, nps)\n\n        return nps\n\n\n    @classmethod\n    def get_subjects(cls, tree):\n        subject_words = []\n        subjects = []\n        for subtree in tree['children']:\n            if subtree['nodeType'] == \"VP\" or subtree['nodeType'] == 'S' or subtree['nodeType'] == 'VBZ':\n                subjects.append(' '.join(subject_words))\n                subject_words.append(subtree['word'])\n            else:\n                subject_words.append(subtree['word'])\n        return subjects\n\n\n\n    @classmethod\n    def search_entity_with_tags(cls, tags, words):\n        if ('B-V' in tags):\n            verb_idx = tags.index('B-V')\n        else:\n            return [], []\n        subj, obj = [], []\n        flag = False\n        for idx in range(0, verb_idx):\n            tag = tags[idx]\n            if (tag != 'I-V'):\n                if (tag.find('B-') != -1):\n                    subj.append(words[idx])\n                elif (tag.find('I-') != -1):\n                    if (len(subj) != 0):\n                        subj[-1] += ' %s' % words[idx]\n\n        for idx in range(verb_idx + 1, len(tags)):\n            tag = tags[idx]\n            if (tag != 'I-V'):\n                if (tag.find('B-') != -1):\n                    obj.append(words[idx])\n                elif (tag.find('I-') != -1):\n                    if (len(obj) != 0):\n                        obj[-1] += ' %s' % words[idx]\n\n        return subj, obj\n\n    def analyze_srl_result(self, srl_result):\n        srls, words = srl_result['verbs'], srl_result['words']\n        triples = []\n        for srl in srls:\n            verb, des, tags = srl['verb'], srl['description'], srl['tags']\n            verb = verb\n            subj, obj = self.search_entity_with_tags(tags, words)\n            triples.append({'verb': verb, 'subject': subj, 'object': obj})\n        return triples\n\n    def found_openie_srl(self, texts):\n        openie_results = self.openie_predictor.predict_batch_json(inputs=[{'sentence': text} for text in texts])\n        srl_results = self.srl_predictor.predict_batch_json(inputs=[{'sentence': text} for text in texts])\n        openie_triples = [self.analyze_srl_result(tmp) for tmp in openie_results]\n        srl_triples = [self.analyze_srl_result(tmp) for tmp in srl_results]\n        return openie_results, srl_results, openie_triples, srl_triples\n\n    def infer_important_words(self, words, pos_tags):\n        # obtain pos tag\n        attn_words = []\n\n        def hasNumbers(inputString):\n            return bool(re.search(r'\\d', inputString))\n\n        for idx in range(len(pos_tags)):\n            tag = pos_tags[idx]\n            if (tag in self.pos_useful_tag):\n                attn_words.append(words[idx])\n            elif (hasNumbers(words[idx])):\n                attn_words.append(words[idx])\n\n        # if (len(src_loc) > 0 or len(dest_loc) > 0):\n        #     print(\n        #         'All location candidate is: {}\\n The src_loc is: {} The dest_loc is: {}\\n'.format(all_loc_cdd, src_loc,\n        #                                                                                           dest_loc))\n\n        return attn_words\n    @classmethod\n    def extract_entity_allennlp(cls, words, tags):\n        all_ents = []\n        all_ents_test = []\n        flag = True\n        # for i, tag in enumerate(tags):\n        #     if(tag!='O'):\n        #         all_ents_test.append(words[i])\n        tmp = []\n\n        for i, tag in enumerate(tags):\n            flag = True if (cls.check_contain_upper(words[i])) else False\n            if (tag != 'O' or flag):\n                tmp.append(words[i])\n            if (len(tmp) != 0 and ((tag == 'O' and flag == False) or i == (len(tags) - 1))):\n                all_ents.append(' '.join(tmp))\n                tmp = []\n\n        # assert(' '.join(all_ents_test)==' '.join(all_ents)),'{}, {}, {}, {}'.format(all_ents,all_ents_test,words,tags)\n        return all_ents\n\n    @classmethod\n    def judge_upper(self, text):\n        bigchar = re.findall(r'[A-Z]', text)\n        return (len(bigchar) > 0)\n\n\n\n\n\n",
        "ARM/pipeline/API.py": "from rule_update_table import *\r\nfrom rule_pattern import RulePattern\r\nRP = RulePattern()\r\n\r\nclass API():\r\n    def __init__(self):\r\n        super(API,self).__init__()\r\n\r\n        self.non_triggers = {}\r\n        # self.non_triggers['greater'] = ['more', 'than', 'above', 'exceed', 'over','older','taller','bigger','larger','greater','higher']#,'RBR', 'JJR']\r\n        # self.non_triggers['less'] = ['less', 'than', 'below', 'under','smaller']#,'RBR', 'JJR']\r\n\r\n        # non_triggers['less'] = ['RBR', 'JJR', 'less', 'than', 'below', 'under','smaller']\r\n        # self.non_triggers['after'] = ['after','followed']#non_triggers['before']\r\n        self.non_triggers['to'] = [['lecture'],['given'],['lectures'],['to'],['from'],['on'],[['so'], ['does']]]\r\n        self.non_triggers['different'] = ['different']\r\n        self.non_triggers['last'] = [[['immediately'],['before','preceding']]]\r\n        self.non_triggers['after_equal'] = [[['no'], ['earlier']]]\r\n        self.non_triggers['adjacent'] = [['neighbouring']]\r\n        self.non_triggers['before'] = ['before', 'above', 'precede', 'earlier']\r\n        self.non_triggers['next'] = [[['next', 'adjacent'], ['to']], ['followed'],['follow'],[['immediately','directly'],['after']]]\r\n        self.non_triggers['after'] = ['after'] + ['older','taller','bigger','larger','greater','higher']\r\n        # self.non_triggers['must'] = ['must']\r\n        self.non_triggers['same'] = [['same'],['also']]\r\n\r\n        self.non_triggers['before_equal'] = [[['no'],['later']]]\r\n        # self.non_triggers['or'] = ['or']\r\n        # self.non_triggers['not'] = ['not', 'nor','no', 'never', \"didn't\", \"won't\", \"wasn't\", \"isn't\",\r\n        #                           \"haven't\", \"weren't\", \"won't\", 'neither', 'none', 'unable',\r\n        #                           'fail', 'different', 'outside', 'unable', 'fail','cannot','except']\r\n        self.non_triggers['last_num'] = [[['one'],['of'],['the'],['last']]]\r\n        # print(self.non_triggers['last_num'])\r\n        self.non_triggers['first_num'] = [[['one'], ['of'], ['the'], ['first']]]\r\n        for k,v in self.non_triggers.items():\r\n            if not isinstance(v[0],list):\r\n                self.non_triggers[k] = [[t] for t in v]\r\n        self.APIs = {}\r\n        self.APIs['greater'] = {\r\n            'function': None,\r\n            'tostr': lambda arg1, arg2: 'greater({}, {})'.format(arg1, arg2)\r\n        }\r\n        self.APIs['less'] = {\r\n            'function': None,\r\n            'tostr': lambda arg1, arg2: 'less({}, {})'.format(arg1, arg2)\r\n        }\r\n        self.APIs['before'] = {\r\n            'function': None,\r\n            'tostr': lambda arg1, arg2: 'before({}, {})'.format(arg1, arg2)\r\n        }\r\n        self.APIs['after'] = {\r\n            'function': None,\r\n            'tostr': lambda arg1, arg2: 'after({}, {})'.format(arg1, arg2)\r\n        }\r\n        self.APIs['to'] = {\r\n            'function': None,\r\n            'tostr': lambda par, col: 'assign_to({}, {})'.format(par, col)\r\n        }\r\n        self.APIs['must'] = {\r\n            'function': None,\r\n            'tostr': lambda ent, text: 'must({}, {})'.format(ent, text)\r\n        }\r\n\r\n        self.APIs['same'] = {\r\n            'function': None,\r\n            'tostr': lambda ent1, ent2: 'same({}, {})'.format(ent1, ent2)\r\n        }\r\n\r\n        self.APIs['next'] = {\r\n            'function': None,\r\n            'tostr': lambda ent1, ent2: 'next_to({}, {})'.format(ent1, ent2)\r\n        }\r\n    def neighbour_par_col(self,par_occur,col_occur,position):\r\n        for idx in range(len(par_occur)):\r\n            par_occur[idx]['distance'] = -(min(position) - par_occur[idx]['position'][1]) if par_occur[idx]['position'][1] >= min(position) else \\\r\n                par_occur[idx]['position'][0] - max(position)\r\n\r\n        for idx in range(len(col_occur)):\r\n            col_occur[idx]['distance'] = -(min(position) - col_occur[idx]['position'][1]) if col_occur[idx]['position'][\r\n                                                                                              1] >= min(position) else \\\r\n                col_occur[idx]['position'][0] - max(position)\r\n\r\n        all_ent = par_occur + col_occur\r\n        sorted_par = sorted(par_occur, key=lambda k: abs(k['distance']))\r\n        sorted_col = sorted(col_occur, key=lambda k: abs(k['distance']))\r\n        sorted_ent = sorted(all_ent, key=lambda k: abs(k['distance']))\r\n        # print('sorted entities is',sorted_ent)\r\n        # print(sorted_par)\r\n        # print(sorted_col)\r\n        return sorted_par,sorted_col,sorted_ent\r\n\r\n\r\n    def select_arguments(self,sorted_par, sorted_col, sorted_ent, position, tokens, mode):\r\n        arg1, arg2 = None,None\r\n        if mode == 'pfp':# participant, function_name, participant\r\n            for tmp in sorted_par:\r\n                if tmp['distance']<0 and arg1==None:\r\n                    arg1 = tmp#['participant']\r\n                elif tmp['distance']>0 and arg2==None:\r\n                    arg2 = tmp#['participant']\r\n            return arg1,arg2\r\n        elif mode=='pfc/cfp':\r\n            for tmp in sorted_ent:\r\n                if tmp['distance'] < 0 and not arg1 and ((arg2 and arg2['type']!=tmp['type']) or not arg2):#and not arg1:\r\n                    arg1 = tmp\r\n                if tmp['distance'] > 0 and not arg2 and ((arg1 and arg1['type']!=tmp['type']) or not arg1):\r\n                    arg2 = tmp\r\n            return arg1, arg2\r\n        elif mode=='cfc/pfp':\r\n            for tmp in sorted_par:\r\n                if tmp['distance'] < 0 and arg1 == None:\r\n                    arg1 = tmp  # ['participant']\r\n                elif tmp['distance'] > 0 and arg2 == None:\r\n                    arg2 = tmp  # ['participant']\r\n            tmp_arg1, tmp_arg2 = None, None\r\n            for tmp in sorted_col:\r\n                if tmp['distance'] < 0 and tmp_arg1 == None:\r\n                    tmp_arg1 = tmp  # ['participant']\r\n                elif tmp['distance'] > 0 and tmp_arg2 == None:\r\n                    tmp_arg2 = tmp  # ['participant']\r\n\r\n            if (arg1 and arg2) and not (tmp_arg1 and tmp_arg2):\r\n                return arg1,arg2\r\n            elif (tmp_arg1 and tmp_arg2) and not (arg1 and arg2):\r\n                return tmp_arg1,tmp_arg2\r\n            elif arg1 and arg2 and tmp_arg1 and tmp_arg2:\r\n                if abs(tmp_arg1['distance'])+abs(tmp_arg2['distance']) < abs(arg1['distance'])+abs(arg2['distance']):\r\n                    return arg1, arg2\r\n                else:\r\n                    return tmp_arg1, tmp_arg2\r\n            else:\r\n                return None,None\r\n\r\n        elif mode== 'pfc':#participant, function, column\r\n            for tmp in sorted_par:\r\n                if tmp['distance']<0 and arg1==None:\r\n                    arg1 = tmp#['participant']\r\n            for tmp in sorted_col:\r\n                if tmp['distance']>0 and arg2==None:\r\n                    arg2 = tmp#['participant']\r\n            return arg1,arg2\r\n        elif mode=='eft':# entity (participant/column), function, sub-text\r\n            for tmp in sorted_ent:\r\n                if tmp['distance']>0:\r\n                    arg1 = tmp['participant']\r\n                    break\r\n            pos = tokens[max(position):].find(',')\r\n            pos_2 = tokens[max(position):].find('.')\r\n            pos = min(pos,pos_2)\r\n            sub_text = tokens[max(position):pos+1]\r\n            return arg1, ' '.join(sub_text)\r\n        elif mode=='efe':#entity, function, entity\r\n            # print(sorted_ent)\r\n            for tmp in sorted_ent:\r\n                if tmp['distance']<0 and not arg1:\r\n                    arg1 = tmp#['participant']\r\n                if tmp['distance']>0 and not arg2:\r\n                    arg2 = tmp#['participant']\r\n            return arg1,arg2\r\n        elif mode=='pp/cc':\r\n            leading_type = None\r\n            for tmp in sorted_ent:\r\n                if not leading_type:\r\n                    arg1 = tmp#['participant']\r\n                    leading_type = tmp['type']\r\n                elif leading_type and tmp['type']==leading_type:\r\n                   arg2 = tmp\r\n            return arg1,arg2\r\n\r\n        elif mode =='common':\r\n            for tmp in sorted_ent:\r\n                arg1 = tmp if arg1==None else arg1\r\n                arg2 = tmp if (arg1!=None and arg2==None) else arg2\r\n            return arg1,arg2\r\n\r\n    def select_arg_pairs(self,sorted_par,sorted_col,sorted_ent, position, tokens, mode='pfc/cfp'):\r\n        arg_pairs = []\r\n        cand_arg1, cand_arg2 = [], []\r\n        neigbor_end_pos = [0,len(tokens)]\r\n        stop_pos = [0,len(tokens)]+[i for i,x in enumerate(tokens) if x==','] + [i for i,x in enumerate(tokens) if x=='.']\r\n        ranked_stop_pos = sorted(stop_pos)\r\n        for pid,pos in enumerate(ranked_stop_pos[:-1]):\r\n            if pos < min(position) and ranked_stop_pos[pid+1] > max(position):\r\n                neigbor_end_pos[0]=pos\r\n                neigbor_end_pos[1]=ranked_stop_pos[pid+1]+1\r\n                break\r\n        # print(tokens)\r\n        # print(neigbor_end_pos)\r\n        if mode == 'pfc/cfp':\r\n            for tmp in sorted_ent:\r\n                if tmp['distance'] < 0 and tmp['position'][1]<=neigbor_end_pos[1] and tmp['position'][0]>=neigbor_end_pos[0] :\r\n                    cand_arg1.append(tmp)\r\n                if tmp['distance']>0 and tmp['position'][1]<=neigbor_end_pos[1] and tmp['position'][0]>=neigbor_end_pos[0]:\r\n                    cand_arg2.append(tmp)\r\n            for arg1 in cand_arg1:\r\n                for arg2 in cand_arg2:\r\n                    if arg1['type']!=arg2['type']:\r\n                        arg_pairs.append((arg1,arg2))\r\n        elif mode=='pfp/cfc':\r\n            for tmp in sorted_ent:\r\n                if tmp['distance'] < 0 and tmp['position'][1]<=neigbor_end_pos[1] and tmp['position'][0]>=neigbor_end_pos[0] :\r\n                    cand_arg1.append(tmp)\r\n                if tmp['distance']>0 and tmp['position'][1]<=neigbor_end_pos[1] and tmp['position'][0]>=neigbor_end_pos[0]:\r\n                    cand_arg2.append(tmp)\r\n            for arg1 in cand_arg1:\r\n                for arg2 in cand_arg2:\r\n                    if arg1['type']==arg2['type'] and arg1['participant']!=arg2['participant']:\r\n                        arg_pairs.append((arg1,arg2))\r\n        #fee case\r\n        if not arg_pairs:\r\n            for tmp in sorted_ent:\r\n                if tmp['position'][1]<neigbor_end_pos[1] and tmp['position'][0]>neigbor_end_pos[0] :\r\n                    cand_arg1.append(tmp)\r\n            for arg1 in cand_arg1:\r\n                for arg2 in cand_arg1:\r\n                    if arg1['type'] != arg2['type']:\r\n                        r = arg1 if arg1['type']=='row' else arg2\r\n                        c = arg2 if arg2['type']=='column' else arg1\r\n                        if ((r,c) not in arg_pairs) and arg1['participant']!=arg2['participant']:\r\n                            arg_pairs.append((r,c))\r\n        for i, pair in enumerate(arg_pairs):\r\n            # print(pair)\r\n            start_pos = min(list(pair[0]['position'])+list(pair[1]['position']))\r\n            end_pos = max(list(pair[0]['position'])+list(pair[1]['position']))\r\n            if ',' in tokens[start_pos:end_pos+1]:\r\n                arg_pairs.pop(i)\r\n        return arg_pairs\r\n\r\n\r\n    def func_to(self, par_occur, col_occur, tokens, position, table, contain_negation,all_rows,all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        # arg1, arg2 = self.select_arguments(sorted_par, sorted_col, sorted_ent, position, tokens, 'pfc/cfp')\r\n        arg_pairs = self.select_arg_pairs(sorted_par,sorted_col,sorted_ent, position, tokens,'pfc/cfp')\r\n        # print('argument pairs',arg_pairs)\r\n        return_func = []\r\n\r\n        for pair in arg_pairs:\r\n            rule1 = TO(pair[0], pair[1], contain_negation, all_rows, all_columns)\r\n            # print(rule1)\r\n\r\n            return_func.append(rule1)\r\n        return return_func\r\n        # if arg1 and arg2:\r\n        #     row_idx = arg1['idx'] if arg1['type'] == 'row' else arg2['idx']\r\n        #     col_idx = arg1['idx'] if arg1['type'] == 'column' else arg2['idx']\r\n        #     v = False if contain_negation else True\r\n        #     table[row_idx][col_idx] = v\r\n        # return table, {'function': 'to', 'arguments': (arg1, arg2)}  # self.APIs['to']['tostr'](arg1, arg2)\r\n\r\n    def func_next(self,par_occur,col_occur, tokens, position, table, contain_negation, all_rows, all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg1, arg2 = self.select_arguments(sorted_par, sorted_col, sorted_ent, position, tokens, 'cfc/pfp')\r\n        if arg1 and arg2:\r\n            rule = NEXT(arg1,arg2, contain_negation,all_rows,all_columns)\r\n            return [rule]\r\n        else:\r\n            return []\r\n\r\n    def func_adjacent(self,par_occur,col_occur, tokens, position, table, contain_negation, all_rows, all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg1, arg2 = self.select_arguments(sorted_par, sorted_col, sorted_ent, position, tokens, 'cfc/pfp')\r\n        if arg1 and arg2:\r\n            rule = ADJACENT(arg1,arg2, contain_negation,all_rows,all_columns)\r\n            return [rule]\r\n        else:\r\n            return []\r\n\r\n    def func_last(self,par_occur,col_occur, tokens, position, table, contain_negation, all_rows, all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg1, arg2 = self.select_arguments(sorted_par, sorted_col, sorted_ent, position, tokens, 'cfc/pfp')\r\n        if arg1 and arg2:\r\n            rule = LAST(arg1,arg2, contain_negation,all_rows,all_columns)\r\n            return [rule]\r\n        else:\r\n            return []\r\n\r\n    def func_after(self,par_occur,col_occur, tokens, position, table, contain_negation, all_rows, all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg_pairs = self.select_arg_pairs(sorted_par, sorted_col, sorted_ent, position, tokens, 'pfp/cfc')\r\n        # print('argument pairs',arg_pairs)\r\n        return_func = []\r\n\r\n        for pair in arg_pairs:\r\n            rule1 = AFTER(pair[0], pair[1], contain_negation, all_rows, all_columns)\r\n            # print(rule1)\r\n\r\n            return_func.append(rule1)\r\n        return return_func\r\n    def func_before_equal(self, par_occur, col_occur, tokens, position, table, contain_negation, all_rows, all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg_pairs = self.select_arg_pairs(sorted_par, sorted_col, sorted_ent, position, tokens, 'pfp/cfc')\r\n        # print('argument pairs',arg_pairs)\r\n        return_func = []\r\n        for pair in arg_pairs:\r\n            rule1 = BeforeEqual(pair[0], pair[1], contain_negation, all_rows, all_columns)\r\n            # print(rule1)\r\n\r\n            return_func.append(rule1)\r\n        return return_func\r\n\r\n    def func_after_equal(self, par_occur, col_occur, tokens, position, table, contain_negation, all_rows,\r\n                          all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg_pairs = self.select_arg_pairs(sorted_par, sorted_col, sorted_ent, position, tokens, 'pfp/cfc')\r\n        # print('argument pairs',arg_pairs)\r\n        return_func = []\r\n        for pair in arg_pairs:\r\n            rule1 = BeforeEqual(pair[1], pair[0], contain_negation, all_rows, all_columns)\r\n            # print(rule1)\r\n\r\n            return_func.append(rule1)\r\n        return return_func\r\n\r\n        # arg1, arg2 = self.select_arguments(sorted_par, sorted_col, sorted_ent, position, tokens, 'cfc/pfp')\r\n        # if arg1 and arg2:\r\n        #     rule = AFTER(arg1,arg2, contain_negation,all_rows,all_columns)\r\n        #     return [rule]\r\n        # else:\r\n        #     return []\r\n    def func_before(self, par_occur, col_occur, tokens, position, table, contain_negation, all_rows, all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg_pairs = self.select_arg_pairs(sorted_par, sorted_col, sorted_ent, position, tokens, 'pfp/cfc')\r\n        # print('argument pairs',arg_pairs)\r\n        return_func = []\r\n\r\n        for pair in arg_pairs:\r\n            rule1 = BEFORE(pair[0], pair[1], contain_negation, all_rows, all_columns)\r\n            # print(rule1)\r\n\r\n            return_func.append(rule1)\r\n        return return_func\r\n\r\n        # arg1, arg2 = self.select_arguments(sorted_par, sorted_col, sorted_ent, position, tokens, 'cfc/pfp')\r\n        # if arg1 and arg2:\r\n        #     rule = AFTER(arg1,arg2, contain_negation,all_rows,all_columns)\r\n        #     return [rule]\r\n        # else:\r\n        #     return []\r\n    def func_different(self, par_occur, col_occur, tokens, position, table, contain_negation,all_rows,all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg1, arg2 = self.select_arguments(sorted_par, sorted_col, sorted_ent, position, tokens, 'pp/cc')\r\n        if arg1 and arg2:\r\n            rule = DIFFERENT(arg1,arg2,contain_negation,all_rows,all_columns)\r\n            return [rule]\r\n        else:\r\n            return []\r\n\r\n    def func_same(self, par_occur, col_occur, tokens, position, table, contain_negation,all_rows,all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        arg1, arg2 = self.select_arguments(sorted_par, sorted_col, sorted_ent, position, tokens, 'pp/cc')\r\n        if arg1 and arg2:\r\n            rule = SAME(arg1, arg2, contain_negation, all_rows, all_columns)\r\n            return [rule]\r\n        else:\r\n            return []\r\n\r\n    def func_if_then(self,if_func,then_func,all_rows,all_columns):\r\n        ifthen_rule = IFTHEN(if_func,then_func,all_rows,all_columns)\r\n        return [ifthen_rule]\r\n\r\n    def func_last_num(self, par_occur, col_occur, tokens, position, table, contain_negation,all_rows,all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        if max(position)!=len(tokens)-1:\r\n            num = tokens[max(position)+1]\r\n        else:\r\n            return []\r\n        if num in RP.numbers.keys():\r\n            num = RP.numbers[num]\r\n\r\n            # print(num,tokens,position)\r\n            close_ent = None\r\n            for ent in sorted_ent:\r\n                if ent['distance']<0 and ent['type']=='row':\r\n                    close_ent = ent\r\n                    break\r\n            if close_ent and num:\r\n                rule = LastNum(close_ent,num,all_rows,all_columns)\r\n                return [rule]\r\n            else:\r\n                return []\r\n        else:\r\n            return self.func_to(par_occur, col_occur, tokens, position, table, contain_negation, all_rows, all_columns)\r\n\r\n    def func_first_num(self, par_occur, col_occur, tokens, position, table, contain_negation,all_rows,all_columns):\r\n        sorted_par, sorted_col, sorted_ent = self.neighbour_par_col(par_occur, col_occur, position)\r\n        if max(position) != len(tokens) - 1:\r\n            num = tokens[max(position) + 1]\r\n        else:\r\n            return []\r\n        if num in RP.numbers.keys():\r\n            num = RP.numbers[num]\r\n            close_ent = None\r\n            for ent in sorted_ent:\r\n                if ent['distance']<0 and ent['type']=='row':\r\n                    close_ent = ent\r\n                    break\r\n            if close_ent and num:\r\n                # print(num)\r\n                rule = FirstNum(close_ent,num,all_rows,all_columns)\r\n                return [rule]\r\n            else:\r\n                return []\r\n        else:\r\n            return self.func_to(par_occur, col_occur, tokens, position, table, contain_negation,all_rows,all_columns)\r\n\r\n\r\n\r\n#non_triggers['istype_s_n'] = ['is', 'are', 'were', 'was', 'be', 'within', 'one', 'of']\r\n#non_triggers['istype_n_s'] = ['is', 'are', 'were', 'was', 'be', 'within', 'one', 'of']\r\n#non_triggers['count'] = ['there', 'num', 'amount', 'have', 'has', 'had', 'are', 'more']\r\n#non_triggers['max'] = [k for k, v in triggers.iteritems() if v == 'max']\r\n#non_triggers['argmax'] = [k for k, v in triggers.iteritems() if v == 'argmax']\r\n#non_triggers['and'] = ['and', 'while', 'when', ',', 'neither', 'none', 'all', 'both']\r\n#non_triggers['neither'] = ['neither', 'none', 'not', \"'nt\", 'both']\r\n",
        "ARM/pipeline/answer_question_by_tree.py": "import re,copy,nltk\r\nfrom modify_option import analyze_question\r\nimport numpy as np\r\nfrom scipy.special import softmax\r\nnumbers = {\r\n            'zero': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10, 'eleven': 11,'twelve': 12\r\n        }\r\nnegation_words = [wd for wd in ['not', 'nor', 'no', 'never', \"didn't\", \"won't\", \"wasn't\", \"isn't\",\r\n                                      \"haven't\", \"weren't\", \"won't\", 'neither', 'none', 'unable', 'outside',\r\n                                      'unable', 'fail', 'cannot', 'except', 'CANNOT','EXCEPT','Neither','neither','false']]\r\n\r\ndef find_nearest_ent(kws,question,rows,columns):\r\n    for item in kws:\r\n        pos = question.find(item)\r\n        min_dis, min_ent = 99999, None\r\n        for ent in rows + columns:\r\n            ent_pos = question.find(ent, pos)\r\n            if ent_pos != -1:\r\n                dis = abs(ent_pos - pos)\r\n                if dis < min_dis:\r\n                    min_dis = dis\r\n                    min_ent = ent\r\n            if min_ent:\r\n                return min_ent\r\n        return min_ent\r\ndef choose_question_type(question,leaf_nodes,rows,columns,problem_type,question_tags,all_rules):\r\n    if 'must be true' in question or any(['must be true' in tag for tag in question_tags]):\r\n        Q = MUSTTRUE(problem_type,question,leaf_nodes,all_rules)\r\n    elif 'must be false' in question or any(['must be false' in tag for tag in question_tags]):\r\n        Q = MUSTFALSE(problem_type, question, leaf_nodes, all_rules)\r\n    elif 'maximum' in question:\r\n        pos = question.find('maximum')\r\n        min_dis,min_ent = 99999, None\r\n        for ent in rows+columns:\r\n            ent_pos = question.find(ent,pos)\r\n            if ent_pos!=-1:\r\n                dis = abs(ent_pos-pos)\r\n                if dis < min_dis:\r\n                    min_dis = dis\r\n                    min_ent = ent\r\n        Q = MAXIMUM(problem_type,question,leaf_nodes,all_rules,min_ent)\r\n    elif any([item for item in ['How many','count','number of'] if item in question]):\r\n        Q = None\r\n        min_ent = find_nearest_ent(['How many','count','number of'],question,rows,columns)\r\n        if min_ent:\r\n            Q = COUNT(problem_type,question, leaf_nodes, all_rules,min_ent)\r\n        if not Q:\r\n            Q = QuestionType(problem_type, question, leaf_nodes,all_rules)\r\n    elif any([item for item in ['list','order'] if item in question]):\r\n        Q = QuestionType(problem_type,question,leaf_nodes,all_rules)\r\n    elif any([item for item in ['could be false'] if item in question]) or any(['could be false' in tag for tag in question_tags]):\r\n        Q = CouldFalse(problem_type, question, leaf_nodes,all_rules)\r\n    elif any([item for item in ['earliest'] if item in question]):\r\n        Q = None\r\n        min_ent = find_nearest_ent(['earliest'], question, rows, columns)\r\n        if min_ent:\r\n            Q = EARLIEST(problem_type,question,leaf_nodes,all_rules,min_ent,columns)\r\n        if not Q:\r\n            Q = QuestionType(problem_type, question, leaf_nodes, all_rules)\r\n    else:\r\n        Q = MUSTTRUE(problem_type, question, leaf_nodes,all_rules)\r\n    #judge based on tags:\r\n    # if any(['must be true' in tag for tag in question_tags]):\r\n    #     Q = MUSTTRUE(problem_type, question, leaf_nodes)\r\n    # elif any(['could be true' in tag for tag in question_tags]):\r\n    #     Q = QuestionType(problem_type, question, leaf_nodes)\r\n    return Q\r\n\r\n\r\nclass QuestionType():\r\n    def __init__(self,problem_type,question,leaf_nodes,rules):\r\n        super(QuestionType, self).__init__()\r\n        self.problem_type = problem_type\r\n        self.question = question\r\n        self.leaf_nodes = leaf_nodes\r\n        self.useful_part = self.extract_useful_part()\r\n        self.polarity = self.contain_negation()\r\n        self.all_rules = rules\r\n\r\n\r\n    def contain_negation(self):\r\n        # print(self.useful_part)\r\n        if ([wd for wd in negation_words if wd in self.useful_part+' ']):\r\n            v = False\r\n        else:\r\n            v = True\r\n        return v\r\n\r\n    def select_answers(self,answers, opt_assigns, opt_funcs):\r\n        # print(self.polarity)\r\n        all_assign_scores = []\r\n        for i,opt_assign in enumerate(opt_assigns):\r\n            ans = answers[i]\r\n            score = self.score_calculating(opt_assign,ans)\r\n            all_assign_scores.append((score,i))\r\n\r\n        # print(sorted_score)\r\n        all_func_score = []\r\n        for i, opt_func in enumerate(opt_funcs):\r\n            score = self.func_score_calculating(opt_func)\r\n            all_func_score.append((score,i))\r\n\r\n        # all_pure_opt_score = []\r\n        # for i, opt_assign in enumerate(opt_assigns):\r\n        #     score = []\r\n        #     for assign in opt_assign:\r\n        #         tmp_score = 0\r\n        #         assign = [(item['row'], item['column'], item['value']) for item in assign]\r\n        #         for func in self.all_rules:\r\n        #             if func.satisfy(assign):\r\n        #                 tmp_score+=1\r\n        #                 # print(type(func),score)\r\n        #             else:\r\n        #                 tmp_score -= 1\r\n        #         if self.all_rules:\r\n        #             score.append(tmp_score/len(self.all_rules))\r\n        #         else:\r\n        #             score.append(0)\r\n        #     score = max(score) if score else 0\r\n        #     # print(opt_assign,score)\r\n        #     all_pure_opt_score.append((score,i))\r\n        # overall_score = []\r\n\r\n        overall_score = [(all_assign_scores[i][0]+all_func_score[i][0],i) for i in range(len(all_assign_scores))]\r\n        # if all([all_assign_scores[i][0]==0 for i in range(len(all_assign_scores))]):\r\n        #     overall_score = all_func_score\r\n        # else:\r\n        #     overall_score = all_assign_scores\r\n        # overall_score = [(all_func_score[i][0], i) for i in range(len(all_assign_scores))]\r\n        if self.polarity:\r\n            sorted_score = sorted(overall_score, key=lambda k: k[0], reverse=True)\r\n        else:\r\n            sorted_score = sorted(overall_score, key=lambda k: k[0], reverse=False)\r\n        return sorted_score\r\n\r\n    def extract_useful_part(self):\r\n        attention_word = ['then', 'which', 'what',',']\r\n        self.question = self.question.replace(':',' ')\r\n        for attn_word in attention_word:\r\n            if attn_word in self.question:\r\n                return self.question[self.question.find(attn_word) + len(attn_word):]\r\n            else:\r\n                return self.question\r\n\r\n    def func_node_score(self,opt_func):\r\n        all_node_score = []\r\n        for nid, node in enumerate(self.leaf_nodes):\r\n            node_score = []\r\n            for func in opt_func:\r\n                res = 1 if func.satisfy(node.assignment) else -1\r\n                node_score.append(res)\r\n            if node_score:\r\n                node_score = sum(node_score)\r\n            else:\r\n                node_score = 0\r\n            all_node_score.append(node_score)\r\n        return all_node_score\r\n\r\n    def func_score_calculating(self,opt_func):\r\n        all_node_score = self.func_node_score(opt_func)\r\n        if all_node_score:\r\n            return max(all_node_score)\r\n        else:\r\n            return 0\r\n\r\n    def assign_node_score(self,opt_assign,answer=None):\r\n        all_score = []\r\n        for aid, single_assign in enumerate(opt_assign):\r\n            nodes_score = []\r\n            for nid, node in enumerate(self.leaf_nodes):\r\n                tmp_score = 0\r\n                for item in single_assign:\r\n                    t = (item['row'], item['column'], item['value'])\r\n                    neg_t = (item['row'], item['column'], False) if item['value'] else (\r\n                    item['row'], item['column'], True)\r\n                    if t in node.assignment:\r\n                        tmp_score += 1\r\n                    elif neg_t in node.assignment:\r\n                        tmp_score -= 1\r\n                if single_assign:\r\n                    tmp_score = tmp_score / len(single_assign)\r\n                else:\r\n                    tmp_score = 0\r\n                # if tmp_score > max_score:\r\n                #     max_score = tmp_score\r\n                #     max_idx = nid\r\n                nodes_score.append(tmp_score)\r\n\r\n            all_score.append((nodes_score))\r\n        return all_score\r\n\r\n    def score_calculating(self,opt_assign,answer=None):\r\n        all_nodes_score = self.assign_node_score(opt_assign,answer)\r\n        all_score = [max(score) for score in all_nodes_score if score]\r\n        if all_score:\r\n            return max(all_score)\r\n        else:\r\n            return 0\r\n\r\nclass CouldFalse(QuestionType):\r\n    def __init__(self,problem_type,question,leaf_nodes,all_rules):\r\n        super(CouldFalse, self).__init__(problem_type,question,leaf_nodes,all_rules)\r\n\r\n    def score_calculating(self, opt_assign,answer=None):\r\n        max_score, max_idx = -999, None\r\n        # print(opt_assign)\r\n        all_nodes_score = self.assign_node_score(opt_assign,answer)\r\n        all_score = [min(score) for score in all_nodes_score if score]\r\n        return min(all_score) if all_score else 0\r\n    def func_score_calculating(self,opt_func):\r\n        all_score = self.func_node_score(opt_func)\r\n        return sum(all_score)\r\n\r\nclass MUSTTRUE(QuestionType):\r\n    def __init__(self,problem_type,question,leaf_nodes,all_rules):\r\n        super(MUSTTRUE, self).__init__(problem_type,question,leaf_nodes,all_rules)\r\n\r\n    def score_calculating(self, opt_assign,answer=None):\r\n        max_score, max_idx = -999, None\r\n        # print(opt_assign)\r\n        all_nodes_score = self.assign_node_score(opt_assign,answer)\r\n        all_score = [sum(score)/len(score) for score in all_nodes_score if score]\r\n\r\n        return max(all_score) if all_score else 0\r\n    def func_score_calculating(self,opt_func):\r\n        all_score = self.func_node_score(opt_func)\r\n        if all_score:\r\n            return sum(all_score)/len(all_score)\r\n        else:\r\n            return 0\r\n\r\nclass MUSTFALSE(QuestionType):\r\n    def __init__(self, problem_type, question, leaf_nodes, all_rules):\r\n        super(MUSTFALSE, self).__init__(problem_type, question, leaf_nodes, all_rules)\r\n\r\n    def score_calculating(self, opt_assign, answer=None):\r\n        max_score, max_idx = -999, None\r\n        # print(opt_assign)\r\n        all_nodes_score = self.assign_node_score(opt_assign, answer)\r\n        all_score = [sum(score) / len(score) for score in all_nodes_score if score]\r\n\r\n        return max(all_score) if all_score else 0\r\n\r\n    def func_score_calculating(self, opt_func):\r\n        all_score = self.func_node_score(opt_func)\r\n        if all_score:\r\n            return sum(all_score) / len(all_score)\r\n        else:\r\n            return 0\r\n\r\nclass MAXIMUM(QuestionType):\r\n    def __init__(self,problem_type,question,leaf_nodes,all_rules,ent):\r\n        super(MAXIMUM, self).__init__(problem_type,question,leaf_nodes,all_rules)\r\n        self.ent = ent\r\n    def score_calculating(self,opt_assign,answer):\r\n        words = nltk.word_tokenize(answer)\r\n        number = None\r\n        for word in words:\r\n            if word in numbers.keys():\r\n                number = numbers[word]\r\n                break\r\n        ent_counts = []\r\n        if number is not None:\r\n            for node in self.leaf_nodes:\r\n                count = 0\r\n                # print(len(node.assignment))\r\n                # print(len(list(set(node.assignment))))\r\n                for item in node.assignment:\r\n                    if self.ent in item and item[2]:\r\n                        count += 1\r\n                ent_counts.append(count)\r\n        # print(ent_counts)\r\n        if ent_counts:\r\n            max_num = max(ent_counts)\r\n        else:\r\n            max_num = 0\r\n        if number:\r\n            dis = abs(max_num-number)\r\n            score = -dis\r\n        else:\r\n            score = -999\r\n        return score\r\n\r\nclass EARLIEST(QuestionType):\r\n    def __init__(self,problem_type,question,leaf_nodes,all_rules,ent,columns):\r\n        super(EARLIEST, self).__init__(problem_type,question,leaf_nodes,all_rules)\r\n        self.ent = ent\r\n        self.columns = columns\r\n    def score_calculating(self,opt_assign,answer=None):\r\n        words = nltk.word_tokenize(answer)\r\n        number = None\r\n        for word in words:\r\n            if word in numbers.keys():\r\n                number = numbers[word]\r\n                break\r\n        min_col = 999\r\n        if number is not None:\r\n            for node in self.leaf_nodes:\r\n                for item in node.assignment:\r\n                    if self.ent==item[0] and item[2]:\r\n                        col = self.columns.index(item[1])\r\n                        if col < min_col:\r\n                            min_col = col\r\n        if number and min_col!=999:\r\n            dis = abs(min_col+1-number)\r\n            score = -dis\r\n        else:\r\n            score = 0\r\n        return score\r\n\r\nclass COUNT(QuestionType):\r\n    def __init__(self,problem_type,question,leaf_nodes,all_rules,ent):\r\n        super(COUNT, self).__init__(problem_type,question,leaf_nodes,all_rules)\r\n        self.ent = ent\r\n\r\n    def score_calculating(self,opt_assign,answer):\r\n        words = nltk.word_tokenize(answer)\r\n        number = None\r\n        for word in words:\r\n            if word in numbers.keys():\r\n                number = numbers[word]\r\n                break\r\n        ent_counts = []\r\n        all_occur = []\r\n        if number is not None:\r\n            for node in self.leaf_nodes:\r\n                count = []\r\n                # print(len(node.assignment))\r\n                # print(len(list(set(node.assignment))))\r\n                for item in node.assignment:\r\n                    if self.ent in item and item[2]:\r\n                        count.append(item)\r\n                all_occur.extend(count)\r\n                ent_counts.append(len(count))\r\n        if self.problem_type == 'ordering':\r\n            occur_set = list(set(all_occur))\r\n            pred = len(occur_set)\r\n        elif self.problem_type == 'grouping':\r\n            if ent_counts:\r\n                pred = max(ent_counts)\r\n            else:\r\n                pred = 0\r\n        if number:\r\n            dis = abs(pred-number)\r\n            score = -dis\r\n        else:\r\n            score = -999\r\n        return score\r\n\r\n\r\n\r\n",
        "ARM/pipeline/extract_program_argument.py": "import sys\r\nsys.path.append('/home/v-wanzho/v-wanzho/LSAT/code')\r\nimport json\r\nimport os\r\nfrom rule_pattern import RulePattern\r\nsys.path.append('/home/v-wanzho/v-wanzho/LSAT/code/data_analysis')\r\nfrom program_search.API import non_triggers\r\n# RP = RulePattern()\r\nno_use = ['the','a']\r\ndef extract_program(info):\r\n    return ''\r\n\r\n\r\n'''\r\ndef parse_func_cp_tree(tree,sentence,words,tags):\r\n    func2pos = {}\r\n    for k,v in non_triggers.items():\r\n        if isinstance(v[0],list):\r\n            flags = []\r\n            tmp_pos = []\r\n            for v_sub in v:\r\n                for trigger in v_sub:\r\n                    if trigger in ['RBR','RBS','JJR','JJS']:\r\n                        pos = [x_idx for x_idx,x in enumerate(tags) if trigger==x]\r\n                        if pos:\r\n                            flag = True\r\n                            tmp_pos.append()\r\n                            break\r\n\r\n                    else:\r\n                        pos = [x_idx for x_idx, x in enumerate(words) if trigger in x.lower()]\r\n                        if ' '+trigger+' ' in ' '+sentence+' ':\r\n                            flag = True\r\n                            break\r\n                    flags.append(flag)\r\n            if all(flags):\r\n                if k not in func2pos:\r\n                    func2pos[k] = pos\r\n\r\n        else:\r\n            flag = False\r\n            for trigger in v:\r\n\r\n'''\r\ndef same(x1,x2):\r\n    x1 = x1.lower()\r\n    x2 = x2.lower()\r\n    if x1 in no_use or x2 in no_use:\r\n        return False\r\n    return ((x1==x2) or (x1 in x2 and len(x1)>=2) or (x2 in x1 and len(x2)>=2))\r\n\r\n\r\ndef find_wspan(text,tokens,cspan):\r\n    start = None\r\n    end = None\r\n    cand = []\r\n    for i in range(len(tokens)):\r\n        if tokens[i] in text:\r\n            if start:\r\n                end+=1\r\n            else:\r\n                start,end = i,i\r\n        else:\r\n            if start:\r\n                start_dis = abs(cspan[0]-len(' '.join(tokens[:start])))\r\n                end_dis = abs(cspan[1]-len(' '.join(tokens[:end+1])))\r\n                cand.append((start,end,(start_dis+end_dis)/2))\r\n                start,end=None,None\r\n    if start:\r\n        start_dis = abs(cspan[0] - len(' '.join(tokens[:start])))\r\n        end_dis = abs(cspan[1] - len(' '.join(tokens[:end + 1])))\r\n        cand.append((start, end, (start_dis + end_dis) / 2))\r\n\r\n    cand = sorted(cand,key=lambda x:x[2],reverse=False)\r\n    return (cand[0][0],cand[0][1]+1)\r\n\r\ndef match_words_tags_func(sentence,words,tags):\r\n    sentence = sentence.replace('—',' ')\r\n    sentence = sentence.replace('.','')\r\n    func2pos = {}\r\n    for k,v in non_triggers.items():\r\n        if isinstance(v[0], list):\r\n            flags = []\r\n            tmp_pos = []\r\n            for v_sub in v:\r\n                flag=False\r\n\r\n                for trigger in v_sub:\r\n                    if trigger in ['RBR', 'RBS', 'JJR', 'JJS']:\r\n                        pos = [x_idx for x_idx, x in enumerate(tags) if trigger == x]\r\n                        if pos:\r\n                            flag = True\r\n                            tmp_pos.extend(pos)\r\n\r\n                    else:\r\n                        if ' ' + trigger + ' ' in ' ' + sentence + ' ':\r\n                            pos = [x_idx for x_idx, x in enumerate(words) if same(x,trigger)]\r\n                            flag = True\r\n                            tmp_pos.extend(pos)\r\n                flags.append(flag)\r\n            if all(flags):\r\n                if k not in func2pos:\r\n                    func2pos[k] = tmp_pos\r\n        else:\r\n            tmp_pos = []\r\n            for trigger in v:\r\n                if trigger in ['RBR', 'RBS', 'JJR', 'JJS']:\r\n                    pos = [x_idx for x_idx, x in enumerate(tags) if trigger == x]\r\n                    tmp_pos.extend(pos)\r\n                else:\r\n                    if ' ' + trigger + ' ' in ' ' + sentence.lower() + ' ':\r\n                        pos = [x_idx for x_idx, x in enumerate(words) if same(x, trigger)]\r\n                        tmp_pos.extend(pos)\r\n\r\n            if tmp_pos:\r\n                func2pos[k] = tmp_pos\r\n\r\n    pos2func = [[] for _ in range(len(words))]\r\n    for k,v in func2pos.items():\r\n        for v_sub in v:\r\n            pos2func[v_sub].append(k)\r\n    return func2pos,pos2func\r\n\r\n\r\ndef map_charid_to_token_id(text,tokens):\r\n    start_idx = 0\r\n    token2charid = {}\r\n    charid2token = {}\r\n    for tidx,token in enumerate(tokens):\r\n        pos = text.find(token,start_idx)\r\n        if pos!=-1:\r\n            token2charid[tidx] = list(range(pos,pos+len(token)))\r\n        start_idx = pos+len(token)\r\n    for items in token2charid.items():\r\n        for v in items[1]:\r\n            charid2token[v] = items[0]\r\n    # for cidx in range(len(text)):\r\n    #     if cidx not in charid2token.keys():\r\n    #         tmp_idx = cidx-1\r\n    #         while tmp_idx not in charid2token.keys():\r\n    #             tmp_idx-=1\r\n    #         charid2token[cidx] = charid2token[tmp_idx]\r\n\r\n    return token2charid,charid2token\r\n\r\n\r\nimport re\r\nbasic_dir = '../data/'\r\ndatap =  os.path.join(basic_dir, 'cp_ner_dp_results/AR_DevelopmentData_cp_ner_dp_results.json')\r\ndata = json.load(open(datap,'r',encoding='utf8'))\r\ncond_datap = os.path.join(basic_dir, 'analyze_data/AR_DevelopmentData_analyze_condition.json')\r\ncond_data = json.load(open(cond_datap,'r',encoding='utf8'))\r\nfor pidx,passage in enumerate(data):\r\n    for sidx,sen_cp in enumerate(passage['sentence_cp_results']):\r\n        func2pos, pos2func = match_words_tags_func(passage['sentences'][sidx],sen_cp['tokens'],sen_cp['pos_tags'])\r\n        # print(sen_cp['tokens'],'\\n')\r\n        # print(sen_cp['pos_tags'],'\\n')\r\n        participants,columns = cond_data[pidx]['conditions']['participants'], cond_data[pidx]['conditions']['columns']\r\n        results = [(sen_cp['tokens'][i],sen_cp['pos_tags'][i],pos2func[i]) for i in range(len(sen_cp['tokens']))]\r\n        print(passage['sentences'][sidx])\r\n        print(results,'\\n')\r\n        print(participants,columns)\r\n        t2c,c2t = map_charid_to_token_id(passage['sentences'][sidx],[wd[0] for wd in results])\r\n        # print(c2t)\r\n        func_name = {}\r\n        for widx,res in enumerate(results):\r\n            if res[2]:\r\n                names = res[2]\r\n                for name in names:\r\n                    pos = t2c[widx]\r\n                    if name not in func_name.keys():\r\n                        func_name[name] = [[widx]]\r\n                    else:\r\n                        func_pos = func_name[name]\r\n                        flag = True\r\n                        for idx,p in enumerate(func_pos):\r\n                            dis = abs(max(p)-widx)\r\n                            if dis == 1:\r\n                                func_name[name][idx].append(widx)\r\n                                flag=False\r\n                        if flag:\r\n                            func_name[name].append([widx])\r\n\r\n        par_occur = []\r\n        for participant in participants:\r\n            par_results = re.finditer(participant, passage['sentences'][sidx])\r\n            if par_results:\r\n                for res in par_results:\r\n                    tmp = {'participant': res.group(), 'position': (c2t[min(res.span())], c2t[max(res.span()) - 1])}\r\n                    par_occur.append(tmp)\r\n\r\n        col_occur = []\r\n        for col in columns:\r\n            col_results = re.finditer(col, passage['sentences'][sidx])\r\n            if col_results:\r\n                for res in col_results:\r\n                    tmp = {'participant': res.group(), 'position': (c2t[min(res.span())], c2t[max(res.span()) - 1])}\r\n                    col_occur.append(tmp)\r\n        print(par_occur)\r\n        print(func_name)\r\n        input()",
        "ARM/pipeline/modify_option.py": "import json\r\nimport os\r\nimport nltk\r\nimport re\r\nfrom tqdm import tqdm\r\nimport sys\r\nfrom rule_pattern import RulePattern\r\nfrom collections import Counter\r\nRP = RulePattern()\r\n# list(number_of_exams) -> dict ('sections') (list of sections,select 0) -> dict(passages)\r\n# -> list (number of passages) -> dict(['id',\r\n# 'questions', 'fatherId', 'passageId', 'passage', 'passageWithLabel'])\r\n\r\norders = {\r\n            'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5, 'sixth': 6, 'seventh': 7,\r\n            'eighth': 8, 'ninth': 9, 'tenth': 10, 'eleventh': 11, 'twelfth': 12,'thirteenth':13,\r\n            'fourteenth':14,'fifteenth':15,'sixteenth':16\r\n        }\r\nweek_words = {'Monday':1, 'Tuesday':2, 'Wednesday':3, 'Thursday':4, 'Friday':5, 'Saturday':6, 'Sunday':7}\r\nmonth_words = {\r\n\"January\":1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10,\r\n    'November':11, 'December':12\r\n}\r\ndef clean_doc(doc):\r\n    doc = ' '+doc\r\n    doc = doc.replace('—', ' — ')\r\n    doc = doc.replace('—', ' — ')\r\n    doc = doc.replace('\\u2014',' ')\r\n    return doc\r\n\r\n\r\ndef analyze_question(question):\r\n    attention_word = ['then','which','what']\r\n    useful_parts = []\r\n    for attn_word in attention_word:\r\n        if attn_word in question:\r\n            useful_parts.append(question[question.find(attn_word)+len(attn_word):])\r\n        else:\r\n            useful_part = question\r\n    useful_parts = sorted(useful_parts,key=lambda k:len(k),reverse=True)\r\n    if useful_parts:\r\n        if (len(useful_parts[0])<len(question)):\r\n            useful_part = useful_parts[0]\r\n\r\n    possible_columns = extract_quantity(question)\r\n    return useful_part,possible_columns\r\n\r\ndef rewrite(parts,rewrite_list):\r\n    # print(parts,rewrite_list)\r\n    for idx in range(len(parts)):\r\n        if 'and' in parts[idx]:\r\n            tmp = parts[idx].replace('and', '')\r\n            parts[idx] = ' and the {} is {}'.format(rewrite_list[idx], tmp)\r\n        else:\r\n            parts[idx] = 'the {} is {}'.format(rewrite_list[idx], parts[idx])\r\n    return parts\r\n\r\ndef extract_quantity(text):\r\n    range_results = re.finditer(RP.range_pattern,text)\r\n    range_quantity = []\r\n    for match in range_results:\r\n        range_quantity.append({'text':match.group() ,'span':match.span()})\r\n\r\n    all_possible_columns = []\r\n    for rang in range_quantity:\r\n        nums = re.finditer(RP.number_pattern,rang['text'])\r\n        all_nums = []\r\n        num_dict = None\r\n        start, end = 9999, -1\r\n        for num in nums:\r\n            # print(num)\r\n            start = min(start, num.span()[0])\r\n            end = max(end, num.span()[1])\r\n            num, num_dict = RP.mapnum2int(num.group())\r\n            all_nums.append(num)\r\n            num_dict = num_dict\r\n\r\n        min_num, max_num = min(all_nums), max(all_nums)\r\n        columns = []\r\n        if num_dict:\r\n            for item in num_dict.items():\r\n                if item[1] >= min_num and item[1] <= max_num and item[0].lower() not in columns:\r\n                    columns.append(item[0])\r\n        else:\r\n            columns = list(range(min_num, max_num + 1))\r\n        all_possible_columns.append(columns)\r\n    all_possible_columns = sorted(all_possible_columns,key=lambda k: len(k))\r\n    return all_possible_columns\r\n\r\n\r\ndef modify_option_based_on_pattern(question,answers,rows,columns):\r\n    col_ent_occur = []\r\n    row_ent_occur = []\r\n    modified_options = []\r\n    match_pattern = '([A-Za-z0-9 ]+, ){1,}([a-zA-Z0-9 ]*)'\r\n    question,possible_columns = analyze_question(question)\r\n    if len(possible_columns)>=1:\r\n        possible_columns = possible_columns[0]\r\n    type = 'columns'\r\n    if rows!=columns:\r\n        for col in columns:\r\n            if col in question:\r\n                col = col.replace('$','\\$')\r\n                res = re.search(col,question)\r\n                # print(col,question,res)\r\n                col_ent_occur.append({'span':col,'start':res.span()[0]})\r\n        sorted_col = sorted(col_ent_occur,key=lambda k : k['start'])\r\n        for row in rows:\r\n            if row in question:\r\n                res = re.search(row,question)\r\n                row_ent_occur.append({'span':row,'start':res.span()[0]})\r\n        sorted_row = sorted(row_ent_occur,key=lambda k : k['start'])\r\n\r\n        if len(sorted_col) > len(sorted_row):\r\n            sorted_ent = sorted_col\r\n            type = 'columns'\r\n        else:\r\n            sorted_ent = sorted_row\r\n            type = 'rows'\r\n    else:\r\n        sorted_ent = [{'span':tmp} for tmp in list(orders.keys())]\r\n        type = 'order'\r\n\r\n    order_flag = any([tmp in list(orders.keys()) for tmp in sorted_ent])\r\n\r\n    for option in answers:\r\n        all_res = re.finditer(match_pattern,option)\r\n        for res in all_res:\r\n            parts = res.group().split(', ')\r\n\r\n            if len(parts)<=len(sorted_ent):\r\n                parts = rewrite(parts,[tmp['span'] for tmp in sorted_ent])\r\n            elif possible_columns and len(parts)<=len(possible_columns):\r\n                    parts = rewrite(parts,possible_columns)\r\n            elif len(sorted_ent)==1 and order_flag==False:\r\n                parts = rewrite(parts, [sorted_ent[0]['span'] for i in range(len(parts))])\r\n            else:\r\n                parts = rewrite(parts, list(orders.keys()))\r\n\r\n            replace_str = ', '.join(parts)\r\n            option = option.replace(res.group(),replace_str)\r\n        modified_options.append(option)\r\n    return modified_options\r\n\r\ndef modify_option(options):\r\n    match_pattern = '([A-Za-z0-9 ]+, ){1,}([a-zA-Z0-9 ]*)' #'([A-Za-z0-9]+, ){1,}([a-zA-Z0-9]*)'\r\n    modified_options=[]\r\n    for option in options:\r\n        all_res = re.finditer(match_pattern,option)\r\n        for res in all_res:\r\n            parts = res.group().split(', ')\r\n            for idx in range(len(parts)):\r\n                if 'and' in parts[idx]:\r\n                    tmp = parts[idx].replace('and','')\r\n                    parts[idx] = ' and the {} is {}'.format(list(orders.keys())[idx],tmp)\r\n                else:\r\n                    parts[idx] = 'the {} is {}'.format(list(orders.keys())[idx],parts[idx])\r\n            replace_str = ', '.join(parts)\r\n            option = option.replace(res.group(),replace_str)\r\n        modified_options.append(option)\r\n    return modified_options\r\n\r\n\r\ndef replace_participants(context,par2ent,participants):\r\n\r\n    for par in participants:\r\n        context = context.replace(par,par2ent[par])\r\n\r\n    return context\r\n\r\n'''\r\nans2label = {'A':0,'B':1,'C':2,'D':3,'E':4}\r\nbasic_dir = '../data'\r\ndatap = os.path.join(basic_dir, 'model_data/ar_val_analyze_condition.json')\r\noutp =  os.path.join(basic_dir, 'modified_model_data/ar_val_modify_context.json')\r\ninstances = json.load(open(datap, 'r'))\r\nmodified_instances = []\r\nfor ins_idx, instance in enumerate(instances):\r\n    context = instance['context']\r\n\r\n    question = instance['question']\r\n    answers = instance['answers']\r\n    label = instance['label']\r\n    id_string = instance['id_string']\r\n    rows = instance['rows']\r\n    columns = instance['columns']\r\n\r\n    modified_answers = modify_option_based_on_pattern(question,answers,rows,columns)\r\n    # ent_for_replace = ['Alice', 'Bob', 'Charles', 'Daniel', 'Eugene', 'Frank', 'Gary',\r\n    #                    'Henry', 'Icey', 'Joe', 'Keith', 'Louis', 'Marie', 'Neko']\r\n    # par2ent = {}\r\n    # for i in range(len(rows)):\r\n    #     par2ent[rows[i]] = ent_for_replace[i]\r\n    # new_participants = list(par2ent.values())\r\n\r\n    # modified_context = replace_participants(context,par2ent,rows)\r\n    # modified_question = replace_participants(context,par2ent,rows)\r\n    # modified_answers = [replace_participants(ans,par2ent,rows) for ans in modified_answers]\r\n    # instances[ins_idx]['modified_context'] = context\r\n    # instances[ins_idx]['modified_question'] = question\r\n    # instances[ins_idx]['modified_rows'] = new_participants\r\n    instances[ins_idx]['modified_answers'] = modified_answers\r\n    # print(context,modified_context)\r\n    # print(question, modified_question)\r\n    # print(answers, modified_answers)\r\n    # print('-------------------------------')\r\n    # input()\r\n    # if modified_answers!=answers:\r\n    #     print('context:',context)\r\n    #     print('question: ',question)\r\n    #     print('answer',answers)\r\n    #     print('modified_context',modified_answers)\r\n    #     print('participants',rows)\r\n    #     print('assignment',columns)\r\n    #     input()\r\n\r\n\r\n\r\nwith open(outp,'w',encoding='utf8') as outf:\r\n    json.dump(instances,outf)\r\n\r\n'''\r\n\r\n\r\n\r\n",
        "ARM/pipeline/nl2fact_rule.py": "import json\r\nimport os\r\n# nltk.download('punkt')\r\nimport re\r\n\r\nimport nltk\r\n\r\nfrom API import API\r\n\r\nAPI = API()\r\n# nltk.download('punkt')\r\n# nltk.download('averaged_perceptron_tagger')\r\nimport copy\r\nimport sys\r\nfrom answer_question_by_tree import QuestionType,choose_question_type\r\nfrom rule_pattern import RulePattern\r\nfrom rule_update_table import *#RuleTree,Node,merge_funcs_with_or,merge_funcs_with_iff,merge_option_functions\r\nRP = RulePattern()\r\n# list(number_of_exams) -> dict ('sections') (list of sections,select 0) -> dict(passages)\r\n# -> list (number of passages) -> dict(['id',\r\n# 'questions', 'fatherId', 'passageId', 'passage', 'passageWithLabel'])\r\n\r\norders = {\r\n    'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5, 'sixth': 6, 'seventh': 7,\r\n    'eighth': 8, 'ninth': 9, 'tenth': 10, 'eleventh': 11, 'twelfth': 12, 'thirteenth': 13,\r\n    'fourteenth': 14, 'fifteenth': 15, 'sixteenth': 16\r\n}\r\nweek_words = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5, 'Saturday': 6, 'Sunday': 7}\r\nmonth_words = {\r\n    \"January\": 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7, 'August': 8, 'September': 9,\r\n    'October': 10,\r\n    'November': 11, 'December': 12\r\n}\r\nnegation_words = [wd + ' ' for wd in ['not', 'nor', 'no', 'never', \"didn't\", \"won't\", \"wasn't\", \"isn't\",\r\n                                      \"haven't\", \"weren't\", \"won't\", 'neither', 'none', 'unable',\r\n                                      'fail', 'different', 'outside', 'unable', 'fail', 'cannot', 'except', 'CANNOT']]\r\n\r\nall_num_words = []\r\nfor dic in RP.all_num_dict:\r\n    all_num_words.extend(list(dic.keys()))\r\ndef clean_doc(doc):\r\n    doc = ' ' + doc\r\n    doc = doc.replace('—', ' — ')\r\n    doc = doc.replace('—', ' — ')\r\n    doc = doc.replace('\\u2014', ' ')\r\n    return doc\r\n\r\n\r\ndef extract_facts_rules(sentences, rows, columns):\r\n    # sentences = nltk.sent_tokenize(context)\r\n    all_fact_flag = [False] * len(sentences)\r\n    rules, facts = [], []\r\n    tmp_rows = rows\r\n    tmp_columns = [] if rows == columns else columns\r\n    par_counts,col_counts = [0],[0]\r\n    for idx, sen in enumerate(sentences[1:]):\r\n        par_exist = [tmp for tmp in tmp_rows if tmp in sen]\r\n        col_exist = [tmp for tmp in tmp_columns if tmp in sen]\r\n        par_count = len(par_exist)\r\n        par_counts.append(par_count)\r\n        col_count = len(col_exist)\r\n        col_counts.append(col_count)\r\n        # print('exist situation: ',par_exist,col_exist)\r\n        if par_count >= 1 and col_count >= 1:\r\n            all_fact_flag[idx + 1] = True\r\n        elif (par_count >= 2 and col_count == 0) or (col_count >= 2 and par_count == 0):\r\n            all_fact_flag[idx + 1] = False\r\n        # else:\r\n        fact_kws = ['if ', 'If ', 'Then ', 'then ']\r\n        for kw in fact_kws:\r\n            if kw in sen:\r\n                all_fact_flag[idx + 1] = False\r\n                break\r\n\r\n        words = nltk.word_tokenize(sen)\r\n        tags = nltk.pos_tag(words)\r\n        func2pos, pos2func = match_words_tags_func(sen, words, tags,\r\n                                                   limit=[k for k in API.non_triggers.keys() if k != 'to'])\r\n        if func2pos.keys():\r\n            all_fact_flag[idx+1] = False\r\n\r\n    for idx, flag in enumerate(all_fact_flag):\r\n        if (par_counts[idx]>=2/3*len(rows) or col_counts[idx]>=2/3*len(columns)) and len(columns)>2:\r\n            continue\r\n        if idx == 0:  # skip the first sentence\r\n            continue\r\n        if flag:\r\n            facts.append(idx)\r\n        else:\r\n            rules.append(idx)\r\n    return facts, rules\r\n\r\ndef extract_if_then(sentence):\r\n    iff_kws = ['if and only if','if but only if']\r\n    if_kws = ['If ','if ']\r\n    then_kws = ['then','Then','so does','which','when','who',',','.']\r\n    flag = False\r\n    if_pos,then_pos = 0,None\r\n    iff_flag = False\r\n    for kw in iff_kws:\r\n        tmp_sentence = sentence.replace(',','')\r\n        if kw in tmp_sentence:\r\n            start_pos = tmp_sentence.find(kw)\r\n            end_pos = start_pos+len(kw) if start_pos!=-1 else 0\r\n            iff_flag = True\r\n            return iff_flag,flag,start_pos,end_pos,tmp_sentence\r\n    for kw in if_kws:\r\n        if kw in sentence:\r\n            if_pos = sentence.find(kw)\r\n            for tkw in then_kws:\r\n                if tkw in sentence[if_pos+len(kw):]:\r\n                    then_pos = sentence.find(tkw,if_pos+len(kw))\r\n                    break\r\n            flag = True\r\n            break\r\n    if not then_pos:\r\n        then_pos = len(sentence)\r\n    # print('instance analysis: ',sentence,flag,sentence[if_pos:then_pos], sentence[then_pos:])\r\n    return iff_flag,flag,if_pos,then_pos,sentence #sentence[if_pos:then_pos], sentence[then_pos:],if_pos,then_pos\r\n\r\n\r\n\r\n\r\ndef same(x1, x2):\r\n    no_use = ['the', 'a']\r\n    x1 = x1.lower()\r\n    x2 = x2.lower()\r\n    if x1 in no_use or x2 in no_use:\r\n        return False\r\n    return (x1 == x2)  # or (x1 in x2 and len(x1)>=2) or (x2 in x1 and len(x2)>=2))\r\n\r\n\r\ndef find_wspan(text, tokens, cspan):\r\n    start = None\r\n    end = None\r\n    cand = []\r\n    for i in range(len(tokens)):\r\n        if tokens[i] in text:\r\n            if start:\r\n                end += 1\r\n            else:\r\n                start, end = i, i\r\n        else:\r\n            if start:\r\n                start_dis = abs(cspan[0] - len(' '.join(tokens[:start])))\r\n                end_dis = abs(cspan[1] - len(' '.join(tokens[:end + 1])))\r\n                cand.append((start, end, (start_dis + end_dis) / 2))\r\n                start, end = None, None\r\n    if start:\r\n        start_dis = abs(cspan[0] - len(' '.join(tokens[:start])))\r\n        end_dis = abs(cspan[1] - len(' '.join(tokens[:end + 1])))\r\n        cand.append((start, end, (start_dis + end_dis) / 2))\r\n\r\n    cand = sorted(cand, key=lambda x: x[2], reverse=False)\r\n    return (cand[0][0], cand[0][1] + 1)\r\n\r\n\r\ndef match_words_tags_func(sentence, words, tags, limit=None):\r\n    # sentence = sentence.replace('—',' ')\r\n    # sentence = sentence.replace('.','')\r\n    func2pos = {}\r\n    for k, vv in API.non_triggers.items():\r\n        if limit:\r\n            if k not in limit:\r\n                continue\r\n        for v in vv:\r\n            if any([isinstance(tmp, list) for tmp in v]):\r\n                flags = []\r\n                tmp_pos = []\r\n                for v_sub in v:\r\n                    flag = False\r\n                    for trigger in v_sub:\r\n                        if trigger in ['RBR', 'RBS', 'JJR', 'JJS']:\r\n                            pos = [x_idx for x_idx, x in enumerate(tags) if trigger == x]\r\n                            if pos:\r\n                                flag = True\r\n                                tmp_pos.extend(pos)\r\n\r\n                        else:\r\n                            if ' ' + trigger + ' ' in ' ' + sentence + ' ':\r\n                                pos = [x_idx for x_idx, x in enumerate(words) if same(x, trigger)]\r\n                                flag = True\r\n                                tmp_pos.extend(pos)\r\n                    flags.append(flag)\r\n                if all(flags):\r\n                    tmp_pos = sorted(tmp_pos)\r\n                    pos_pair = []\r\n                    for id,p in enumerate(tmp_pos):\r\n                        if id == 0:\r\n                            pos_pair.append([p])\r\n                        else:\r\n                            if p - pos_pair[-1][-1] == 1:\r\n                                pos_pair[-1].append(p)\r\n                            else:\r\n                                pos_pair.append([p])\r\n                    for id,pair in enumerate(pos_pair):\r\n                        if len(pair)<len(v):\r\n                            pos_pair.pop(id)\r\n\r\n                    if k not in func2pos:\r\n                        func2pos[k] = pos_pair\r\n                    else:\r\n                        func2pos[k].extend(pos_pair)\r\n            else:\r\n                tmp_pos = []\r\n                for trigger in v:\r\n                    if trigger in ['RBR', 'RBS', 'JJR', 'JJS']:\r\n                        pos = [x_idx for x_idx, x in enumerate(tags) if trigger == x]\r\n                        tmp_pos.append(pos)\r\n                    else:\r\n                        if ' ' + trigger + ' ' in ' ' + sentence.lower() + ' ':\r\n                            pos = [x_idx for x_idx, x in enumerate(words) if same(x, trigger)]\r\n                            tmp_pos.append(pos)\r\n\r\n                if tmp_pos:\r\n                    func2pos[k] = tmp_pos\r\n\r\n    pos2func = [[] for _ in range(len(words))]\r\n    # print(func2pos.items())\r\n    for k, vv in func2pos.items():\r\n        for v in vv:\r\n            for v_sub in v:\r\n                if len(pos2func[v_sub])==0:\r\n                    pos2func[v_sub].append(k)\r\n    # for item in pos2func:\r\n    #     if len(item)>1:\r\n\r\n    return func2pos, pos2func\r\n\r\n\r\ndef map_charid_to_token_id(text, tokens):\r\n    # print(text,tokens)\r\n    start_idx = 0\r\n    token2charid = {}\r\n    charid2token = {}\r\n    for tidx, token in enumerate(tokens):\r\n        pos = text.find(token, start_idx)\r\n        if pos != -1:\r\n            token2charid[tidx] = list(range(pos, pos + len(token)))\r\n            start_idx = pos + len(token)\r\n    for items in token2charid.items():\r\n        for v in items[1]:\r\n            charid2token[v] = items[0]\r\n    for cidx in range(len(text)):\r\n        if cidx not in charid2token.keys():\r\n            if cidx!=0:\r\n                charid2token[cidx] = charid2token[cidx - 1]\r\n            else:\r\n                charid2token[cidx] = 0\r\n\r\n    return token2charid, charid2token\r\n\r\n\r\ndef analyze_fact(fact, rows, columns, table):\r\n    # print(fact)\r\n    parts = fact.split(';')\r\n    for part in parts:\r\n        par_exist = [idx for idx, tmp in enumerate(rows) if tmp in part]\r\n        col_exist = [idx for idx, tmp in enumerate(columns) if tmp in part]\r\n        if any([wd in part for wd in negation_words]):\r\n            v = False\r\n        else:\r\n            v = True\r\n        for par in par_exist:\r\n            for col in col_exist:\r\n                # print(rows[par],columns[col],v)\r\n                table[par][col] = v\r\n    return table\r\n\r\ndef new_analyze_fact(fact,rows,columns,old_assignments):\r\n    parts = fact.split(';')\r\n    all_assignments = old_assignments\r\n    can_found_exist = [False for i in range(len(parts))]\r\n\r\n    for p,part in enumerate(parts):\r\n        par_exist = []#[tmp for idx, tmp in enumerate(rows) if tmp in part]\r\n        col_exist = []#[tmp for idx, tmp in enumerate(columns) if tmp in part]\r\n        for idx,tmp in enumerate(rows):\r\n            if tmp in part:\r\n                par_exist.append((tmp,part.find(tmp)))\r\n        for idx,tmp in enumerate(columns):\r\n            if tmp in part:\r\n                col_exist.append((tmp,part.find(tmp)))\r\n        sorted_par_exist = sorted(par_exist,key=lambda k:k[1])\r\n        and_pos = []\r\n        if ' and ' in part:\r\n            and_pos = [m.start() for m in re.finditer(' and ', part)]#part.find_all(' and ')#A in X and B in Y\r\n        and_pos = [0]+and_pos+[len(part)] if and_pos else [0,len(part)]\r\n        par_and_pos = []\r\n        sorted_col_exist = sorted(col_exist, key=lambda k: k[1])\r\n        for idx,par in enumerate(sorted_par_exist):\r\n            for j,pos in enumerate(and_pos[1:]):\r\n                if par[1] in range(and_pos[j],pos):\r\n                    par_and_pos.append((and_pos[j],pos))\r\n                    break\r\n        assert(len(par_and_pos)==len(sorted_par_exist))\r\n\r\n        if par_exist and col_exist:\r\n            can_found_exist[p] = True\r\n            if any([wd in part for wd in negation_words]):\r\n                v = False\r\n            else:\r\n                v = True\r\n            for pid,par in enumerate(sorted_par_exist):\r\n                #if multiple column is split by or, should be split into multiple assignment\r\n                should_split = [False for i in range(len(sorted_col_exist))]\r\n                split_pair = []\r\n                for i, col in enumerate(sorted_col_exist[1:]):\r\n                    inner_part = part[sorted_col_exist[i][1]:col[1]+1]\r\n                    if ' or ' in inner_part:\r\n                        split_pair.append((i-1,i))\r\n                        should_split[i] = should_split[i-1] = True\r\n                old = []\r\n                for i, flag in enumerate(should_split):\r\n                    if flag==False and (sorted_col_exist[i][1] in range(par_and_pos[pid][0],par_and_pos[pid][1])):\r\n                        old.append((par[0],sorted_col_exist[i][0],v))\r\n                if all_assignments:\r\n                    for i in range(len(all_assignments)):\r\n                        all_assignments[i].extend(old)\r\n                else:\r\n                    all_assignments=[old]\r\n\r\n                for pair in split_pair:\r\n                    cache = []\r\n                    if all_assignments:\r\n                        for a in all_assignments:\r\n                            cache.append(a+[(par[0],sorted_col_exist[pair[0]][0],v)])\r\n                            cache.append(a+[(par[0],sorted_col_exist[pair[1]][0],v)])\r\n                    else:\r\n                        cache.append([(par[0],sorted_col_exist[pair[0]][0],v)])\r\n                        cache.append([(par[0], sorted_col_exist[pair[1]][0], v)])\r\n                    all_assignments = cache\r\n    #find conflict\r\n    conflict_flag = False\r\n    # print(all_assignments)\r\n    for i,assign in enumerate(all_assignments):\r\n        for item in assign:\r\n            neg_item = list(copy.deepcopy(item))\r\n            neg_item[2] = False if item[2] else True\r\n            if tuple(neg_item) in assign:\r\n                all_assignments.pop(i)\r\n                conflict_flag = True\r\n                break\r\n            if item[2]:\r\n                for col in columns:\r\n                    if (tuple([item[0],col,True]) in assign and item[1]!=col):\r\n                        all_assignments.pop(i)\r\n                        conflict_flag = True\r\n                        break\r\n            if conflict_flag:\r\n                break\r\n\r\n    return all_assignments,conflict_flag, any(can_found_exist)\r\n\r\ndef assign_table_with_facts(rows, columns, facts):\r\n    # table = [[None for col in columns] for row in rows]\r\n    old_assignments = []\r\n    add_rules = []\r\n    for fact in facts:\r\n        old_assignments,conflict_flag,can_found_exist = new_analyze_fact(fact, rows, columns, old_assignments)\r\n        if not can_found_exist:\r\n            add_rules.append(fact)\r\n        if conflict_flag and not old_assignments:\r\n            return [],[]\r\n\r\n        # print('The fact is: ',fact)\r\n        # print(table)\r\n\r\n    if rows == columns:\r\n        for i,assign in enumerate(old_assignments):\r\n            for row in rows:\r\n                old_assignments[i].append((row,row,True))\r\n    # print(table)\r\n    return old_assignments,add_rules\r\n\r\n\r\n\r\ndef find_par_col_occur(text, char2token, tokens_func_res, participants, columns):\r\n    results = tokens_func_res\r\n    c2t = char2token\r\n    func_name2pos = {}\r\n    for widx, res in enumerate(results):\r\n        if res[2]:\r\n            names = res[2]\r\n            for name in names:\r\n                # pos = t2c[widx]\r\n                if name not in func_name2pos.keys():\r\n                    func_name2pos[name] = [[widx]]\r\n                else:\r\n                    func_pos = func_name2pos[name]\r\n                    flag = True\r\n                    for idx, p in enumerate(func_pos):\r\n                        dis = abs(max(p) - widx)\r\n                        if dis == 1:\r\n                            func_name2pos[name][idx].append(widx)\r\n                            flag = False\r\n                    if flag:\r\n                        func_name2pos[name].append([widx])\r\n\r\n    par_occur = []\r\n    for pidx, participant in enumerate(participants):\r\n        par_results = re.finditer(participant, text)\r\n        if par_results:\r\n            for res in par_results:\r\n                # print(c2t)\r\n                if res.group():\r\n                    tmp = {'participant': res.group(),\r\n                           'position': (c2t[min(res.span())], c2t[max(res.span()) - 1]),\r\n                           'type': 'row', 'idx': pidx}\r\n                    par_occur.append(tmp)\r\n\r\n    col_occur = []\r\n    for cidx, col in enumerate(columns):\r\n        col_results = re.finditer(col, text)\r\n        if col_results:\r\n            for res in col_results:\r\n                tmp = {'participant': res.group(),\r\n                       'position': (c2t[min(res.span())], c2t[max(res.span()) - 1]),\r\n                       'type': 'column', 'idx': cidx}\r\n                col_occur.append(tmp)\r\n    return par_occur, col_occur, func_name2pos\r\n\r\n\r\ndef derive_functions_from_rules(rows_cp_results, rules, rows, columns, table):\r\n    rule_functions = []\r\n    for sidx, rule_cp in enumerate(rows_cp_results):\r\n        functions = []\r\n        func2pos, pos2func = match_words_tags_func(rules[sidx], rule_cp['tokens'], rule_cp['pos_tags'])\r\n        # print(sen_cp['tokens'],'\\n')\r\n        # print(sen_cp['pos_tags'],'\\n')\r\n        participants, columns = rows, columns\r\n        results = [(rule_cp['tokens'][i], rule_cp['pos_tags'][i], pos2func[i]) for i in\r\n                   range(len(rule_cp['tokens']))]\r\n\r\n        t2c, c2t = map_charid_to_token_id(rules[sidx], [wd[0] for wd in results])\r\n        # print(c2t)\r\n\r\n        par_occur, col_occur, func_name2pos = find_par_col_occur(rules[sidx], c2t, results, rows, columns)\r\n\r\n\r\n        for func, positions in func_name2pos.items():\r\n            for pos in positions:\r\n                if par_occur or col_occur:\r\n                    func_str = getattr(API, 'func_{}'.format(func))(par_occur, col_occur, rule_cp['tokens'],\r\n                                                                    pos, table)\r\n                    functions.append(func_str)\r\n\r\n    rule_functions.extend(functions)\r\n    return rule_functions\r\n\r\n\r\nfrom modify_option import analyze_question\r\n\r\n\r\ndef select_ent(part, rows, columns):\r\n    part = str(part)\r\n    for ridx, row in enumerate(rows):\r\n        if part in row or row in part:\r\n            return 'row', ridx, row\r\n    for cidx, col in enumerate(columns):\r\n        if part in col or col in part:\r\n            return 'col', cidx, col\r\n    return None, None\r\n\r\n\r\ndef search_exist_ent(phrase, rows, columns):\r\n    part = str(phrase)\r\n    all_exist = []\r\n    for ridx, row in enumerate(rows):\r\n        if row in part:\r\n            all_exist.append(('row', ridx, part.find(row), row))\r\n    for cidx, col in enumerate(columns):\r\n        if col in part:\r\n            all_exist.append(('col', cidx, part.find(col), col))\r\n    return all_exist\r\n\r\n\r\ndef modify_table_for_option(parts, mapping_ents, rows, columns, table, contain_negation=True):\r\n    for pidx, part in enumerate(parts):\r\n        ent_type, eidx = select_ent(part, rows, columns)\r\n        map_ent = mapping_ents[pidx]\r\n        map_ent_type, map_eidx = select_ent(map_ent, rows, columns)\r\n        if (ent_type and map_ent_type) and ent_type != map_ent_type:\r\n            assign_row = eidx if ent_type == 'row' else map_eidx\r\n            assign_col = map_eidx if map_ent_type == 'col' else eidx\r\n            # print(table)\r\n            # print(rows,columns)\r\n            # print(assign_row,assign_col,part,map_ent)\r\n            table[assign_row][assign_col] = False if contain_negation else True\r\n\r\n    return table\r\n\r\n\r\ndef match_qa_func_and_modify_table(question, option, rows, columns, table):\r\n    functions = []\r\n    related_triggers = ['to', 'next', 'same']\r\n    qa_pair = question + ' ' + option\r\n    # print(qa_pair)\r\n    words = nltk.word_tokenize(qa_pair)\r\n    neg_count = 0\r\n    for wd in words:\r\n        if wd in negation_words:\r\n            neg_count += 1\r\n    negation = True if neg_count % 2 == 1 else False\r\n    tags = nltk.pos_tag(words)\r\n    func2pos, pos2func = match_words_tags_func(qa_pair, words, tags)#, limit=related_triggers)\r\n    results = [(words[i], tags[i], pos2func[i]) for i in range(len(words))]\r\n    t2c, c2t = map_charid_to_token_id(qa_pair, [wd[0] for wd in results])\r\n    par_occur, col_occur, func_name2pos = find_par_col_occur(qa_pair, c2t, results, rows, columns)\r\n\r\n    for func, positions in func_name2pos.items():\r\n        for pos in positions:\r\n            if par_occur or col_occur:\r\n                func_str = getattr(API, 'func_{}'.format(func))(par_occur, col_occur, words, pos,\r\n                                                                              table, negation, rows,columns)\r\n\r\n                functions.extend(func_str)\r\n                # table, func_str = getattr(API, 'func_{}'.format(func))(par_occur, col_occur, words, pos,\r\n                #                                                               table, negation)\r\n    #find all the assignment under searched functions\r\n    all_assignment = []\r\n    # print(functions)\r\n    for func in functions:\r\n        tmp = []\r\n        tmp_assign = func.find_option_assignment()\r\n        if all_assignment:\r\n            for i,cond in enumerate(tmp_assign):\r\n                for j, pre in enumerate(all_assignment):\r\n                    tmp.append(cond+pre)\r\n        else:\r\n            tmp = tmp_assign\r\n        all_assignment = tmp\r\n    # all_assignment = list(set(all_assignment))\r\n    # print(all_assignment)\r\n\r\n    return all_assignment,functions\r\n\r\n\r\ndef analyze_option_with_pattern(option, rows, columns, sorted_que_ents, possible_que_columns,question):\r\n    possible_assignment = []\r\n    backup_flag = False\r\n    match_pattern_1 = '([A-Za-z0-9\\' ]+: [$,A-Za-z0-9\\' ]+; )+[:$,A-Za-z0-9\\' ]+'  # Jackson: Y; Larabee: W; Paulson: X; Torillo: Z\r\n    match_pattern_2 = '([A-Za-z0-9\\' ]+: [$,A-Za-z0-9\\' ]+ )+[:$,A-Za-z0-9\\' ]+'  # Raimes: Frank Sicoli: Gina, Hiro, Kevin Thompson: Laurie\r\n    match_pattern_3 = '([A-Za-z0-9\\' ]+(,|;) ){2,}([a-zA-Z0-9\\' ]+)'  # 2, 3, 4, 5 or 2;3;4;5\r\n    res1 = re.search(match_pattern_1, option)\r\n    if res1:\r\n        match_content = res1.group()\r\n        parts = match_content.split('; ')\r\n        for part in parts:\r\n            if part.split(': ')==2:\r\n                subj, obj = part.split(': ')\r\n                subj_ents, obj_ents = [], []\r\n                for s in re.split('(,|(and))\\s', subj):  # subj.split(','):\r\n                    s_ent = select_ent(s.strip(), rows, columns)\r\n                    if s_ent[0]:\r\n                        subj_ents.append(s_ent)\r\n                for o in obj.split(','):\r\n                    o_ent = select_ent(o.strip(), rows, columns)\r\n                    if o_ent[0]:\r\n                        obj_ents.append(o_ent)\r\n                # subj_ents = search_exist_ent(subj,rows,columns)\r\n                # obj_ents = search_exist_ent(obj,rows,columns)\r\n                for ent1 in subj_ents:\r\n                    for ent2 in obj_ents:\r\n                        possible_assignment.append((ent1, ent2))\r\n        if possible_assignment:\r\n            return possible_assignment,backup_flag\r\n\r\n    res2 = re.search(match_pattern_2, option)\r\n    if res2:  # Raimes: Frank Sicoli: Gina, Hiro, Kevin Thompson: Laurie\r\n        match_content = res2.group()\r\n        parts = match_content.split(': ')\r\n        all_ents = []\r\n        # print(parts)\r\n        for part in parts:\r\n            ents = search_exist_ent(part, rows, columns)\r\n            all_ents.append(ents)\r\n        # print(all_ents)\r\n        if all_ents[0]:\r\n            subjs = all_ents[0]\r\n            for eidx, ents in enumerate(all_ents[1:]):\r\n                if ents:\r\n                    sorted_ents = sorted(ents, key=lambda k: k[2])\r\n                    if eidx != len(all_ents) - 2:\r\n                        objs = sorted_ents[:-1]\r\n                    else:\r\n                        objs = sorted_ents\r\n                    for subj in subjs:\r\n                        for obj in objs:\r\n                            possible_assignment.append((subj, obj))\r\n                    subjs = [sorted_ents[-1]]\r\n                else:\r\n                    subjs = []\r\n        # print('possible assignment',possible_assignment)\r\n        if possible_assignment:\r\n            return possible_assignment,backup_flag\r\n\r\n    res3 = re.finditer(match_pattern_3, option)\r\n    order_flag = any([tmp in list(orders.keys()) for tmp in sorted_que_ents])\r\n    if res3:\r\n        for res in res3:\r\n\r\n            # parts.extend(res.group().split(', '))\r\n            parts = re.split('[,;]\\s', res.group())  # res.group().split(', ')\r\n\r\n            if len(parts) <= len(sorted_que_ents):\r\n                objs = [tmp['span'] for tmp in sorted_que_ents]\r\n            elif possible_que_columns and len(parts) <= len(possible_que_columns):\r\n                objs = possible_que_columns\r\n            elif len(sorted_que_ents) == 1 and order_flag == False:\r\n                objs = [sorted_que_ents[0]['span'] for i in range(len(parts))]\r\n            else:\r\n                objs = list(orders.keys())\r\n\r\n            for pidx, part in enumerate(parts):\r\n                subsubj = part.split(' and ')\r\n                for s in subsubj:\r\n                    sent = select_ent(s, rows, columns)\r\n                    obj = select_ent(objs[pidx], rows, columns)\r\n                    possible_assignment.append((sent, obj))\r\n\r\n        if not possible_assignment:\r\n            row_ent_occur, col_ent_oocur = extract_par_col(option,rows,columns)\r\n            for r in row_ent_occur:\r\n                for c in col_ent_oocur:\r\n                    possible_assignment.append((r['span'],c['span']))\r\n                    backup_flag = True\r\n        return possible_assignment,backup_flag\r\n\r\n\r\ndef modify_table_with_assignment(table, assignments, contain_negation):\r\n    for assign in assignments:\r\n        subj, obj = assign\r\n        if subj[0] and obj[0] and subj[0] != obj[0]:\r\n            # print(subj,obj)\r\n            assign_row = subj[1] if subj[0] == 'row' else obj[1]\r\n            assign_col = obj[1] if obj[0] == 'col' else subj[1]\r\n            # print(assign_row, assign_col)\r\n            table[assign_row][assign_col] = False if contain_negation else True\r\n            # print(table)\r\n    return table\r\n\r\n\r\ndef assign_table_with_qa(table, question, answers, rows, columns):\r\n    col_ent_occur = []\r\n    row_ent_occur = []\r\n    match_pattern = '([A-Za-z0-9 ]+, ){1,}([a-zA-Z0-9 ]*)'\r\n    # extract question and extract possible columns based on range \"Monday to Friday\"\r\n    modified_question, possible_columns = analyze_question(question)\r\n    contain_negation = False\r\n    for wd in negation_words:\r\n        if wd in modified_question:\r\n            contain_negation = True\r\n\r\n    if len(possible_columns) >= 1:\r\n        possible_columns = possible_columns[0]\r\n    if rows != columns:\r\n        for col in columns:\r\n            if col in question:\r\n                col = col.replace('$', '\\$')\r\n                res = re.search(col, question)\r\n                # print(col,question,res)\r\n                col_ent_occur.append({'span': col, 'start': res.span()[0]})\r\n        sorted_col = sorted(col_ent_occur, key=lambda k: k['start'])\r\n        for row in rows:\r\n            if row in question:\r\n                res = re.search(row, question)\r\n                row_ent_occur.append({'span': row, 'start': res.span()[0]})\r\n        sorted_row = sorted(row_ent_occur, key=lambda k: k['start'])\r\n\r\n        if len(sorted_col) > len(sorted_row):\r\n            sorted_ent = sorted_col\r\n        else:\r\n            sorted_ent = sorted_row\r\n    else:\r\n        sorted_ent = [{'span': tmp} for tmp in list(orders.keys())]\r\n\r\n    # order_flag = any([tmp in list(orders.keys()) for tmp in sorted_ent])\r\n    option_based_tables = []\r\n    for answer in answers:\r\n        ans_table = copy.deepcopy(table)\r\n        # print('the question and answer are: ', question, answer)\r\n        possible_assignment = analyze_option_with_pattern(answer, rows, columns, sorted_ent, possible_columns)\r\n        if not possible_assignment:\r\n            ans_table, functions = match_qa_func_and_modify_table(modified_question, answer, rows, columns, ans_table)\r\n        else:\r\n            ans_table = modify_table_with_assignment(ans_table, possible_assignment, contain_negation)\r\n\r\n        option_based_tables.append(ans_table)\r\n    return option_based_tables\r\n\r\ndef find_assgiments_for_qa(table, question, answers, rows, columns):\r\n    col_ent_occur = []\r\n    row_ent_occur = []\r\n    match_pattern = '([A-Za-z0-9 ]+, ){1,}([a-zA-Z0-9 ]*)'\r\n    # extract question and extract possible columns based on range \"Monday to Friday\"\r\n    modified_question, possible_columns = analyze_question(question)\r\n    contain_negation = False\r\n    for wd in negation_words:\r\n        if wd in modified_question:\r\n            contain_negation = True\r\n    # v = False if contain_negation else True\r\n    if len(possible_columns) >= 1:\r\n        possible_columns = possible_columns[0]\r\n    if rows != columns:\r\n        for col in columns:\r\n            if col in question:\r\n                col = col.replace('$', '\\$')\r\n                res = re.search(col, question)\r\n                # print(col,question,res)\r\n                col_ent_occur.append({'span': col, 'start': res.span()[0]})\r\n        sorted_col = sorted(col_ent_occur, key=lambda k: k['start'])\r\n        for row in rows:\r\n            if row in question:\r\n                res = re.search(row, question)\r\n                row_ent_occur.append({'span': row, 'start': res.span()[0]})\r\n        sorted_row = sorted(row_ent_occur, key=lambda k: k['start'])\r\n\r\n        if len(sorted_col) > len(sorted_row):\r\n            sorted_ent = sorted_col\r\n        else:\r\n            sorted_ent = sorted_row\r\n    else:\r\n        sorted_ent = [{'span': tmp} for tmp in list(orders.keys())]\r\n\r\n    # order_flag = any([tmp in list(orders.keys()) for tmp in sorted_ent])\r\n    option_based_assignments = []\r\n    option_functions = []\r\n    for answer in answers:\r\n        functions = []\r\n        ans_table = copy.deepcopy(table)\r\n        # print('the question and answer are: ', question, answer)\r\n        possible_assignment,backup_flag = analyze_option_with_pattern(answer, rows, columns, sorted_ent, possible_columns,modified_question)\r\n        if not possible_assignment or (possible_assignment and backup_flag):\r\n            qa_assignments,functions = match_qa_func_and_modify_table(modified_question.strip(), answer, rows, columns, ans_table)\r\n            if not qa_assignments and not functions:\r\n                qa_assignments = [[]]\r\n                if possible_assignment and backup_flag:\r\n                    for assign in possible_assignment:\r\n                        subj, obj = assign\r\n                        qa_assignments[-1].append({'row': subj, 'column': obj, 'value': True})\r\n                else:\r\n                    row_ent_occur, col_ent_oocur = extract_par_col(question + ' ' + answer, rows, columns)\r\n                    for r in row_ent_occur:\r\n                        for c in col_ent_oocur:\r\n                            qa_assignments[-1].append({'row':r['span'], 'column':c['span'],'value':True})\r\n\r\n            # ans_table, functions = match_qa_func_and_modify_table(question, answer, rows, columns, ans_table)\r\n        elif possible_assignment and not backup_flag:\r\n            qa_assignments = [[]]\r\n            for assign in possible_assignment:\r\n                subj, obj = assign\r\n                if subj[0] and obj[0] and subj[0] != obj[0]:\r\n                    # print(subj,obj)\r\n                    assign_row = subj[2] if subj[0] == 'row' else obj[2]\r\n                    assign_col = obj[2] if obj[0] == 'col' else subj[2]\r\n                    qa_assignments[-1].append({'row':assign_row,'column':assign_col,'value':True})\r\n                    # print(assign_row, assign_col)\r\n            # qa_assignments = modify_table_with_assignment(possible_assignment, contain_negation)\r\n        if not qa_assignments and backup_flag:\r\n            qa_assignments = [[]]\r\n            for assign in possible_assignment:\r\n                subj, obj = assign\r\n                qa_assignments[-1].append({'row': subj, 'column': obj, 'value': True})\r\n\r\n        option_functions.append(functions)\r\n        option_based_assignments.append(qa_assignments)\r\n\r\n    # print('option based assignment',option_based_assignments)\r\n    return option_based_assignments, option_functions\r\ndef extract_par_col(text,rows,columns):\r\n    col_ent_occur,row_ent_occur = [], []\r\n    for col in columns:\r\n        if col in text:\r\n            col = col.replace('$', '\\$')\r\n            res = re.search(col, text)\r\n            # print(col,question,res)\r\n            col_ent_occur.append({'span': col, 'start': res.span()[0]})\r\n    sorted_col = sorted(col_ent_occur, key=lambda k: k['start'])\r\n    for row in rows:\r\n        if row in text:\r\n            res = re.search(row, text)\r\n            row_ent_occur.append({'span': row, 'start': res.span()[0]})\r\n    sorted_row = sorted(row_ent_occur, key=lambda k: k['start'])\r\n    return sorted_row,sorted_col\r\n\r\ndef rank_entities(entities):\r\n    quantity_ents = []\r\n    rest_ents = []\r\n    flag = False\r\n    for group in [RP.orders, RP.numbers, RP.week_words, RP.month_words]:\r\n        if any([ent in group for ent in entities]) or any([ent.isnumeric() for ent in entities]):\r\n            for ent in entities:\r\n                if ent in group.keys():\r\n                    quantity_ents.append((ent, group[ent]))\r\n                elif ent.isnumeric():\r\n                    quantity_ents.append((ent, int(ent)))\r\n                else:\r\n                    rest_ents.append((ent, None))\r\n            flag = True\r\n            break\r\n    ranked_quan_ent = sorted(quantity_ents, key=lambda k: k[1])\r\n    all_entities = [ent[0] for ent in ranked_quan_ent + rest_ents] if flag else entities\r\n    return all_entities\r\n\r\ndef fact_in_question(question):\r\n    ifflag, if_flag, if_pos , then_pos,question = extract_if_then(question)\r\n    # print(flag,subsen_if,subsen_then)\r\n    if if_flag:\r\n        return question[if_pos+len('If '):then_pos]#if_pos,then_pos#subsen_if#,subsen_then\r\n    else:\r\n        return None#,None\r\nimport rule_update_table\r\nfrom importlib import import_module\r\ndef derive_rules( rule, rows, columns,neural_func=None):\r\n    # rule = rule.replace('later','after')\r\n    functions = []\r\n    if ', so does' in rule:\r\n        rule = rule.replace(', so does',' so does')\r\n    rule = rule.strip()\r\n    ifflag, ifthenflag, ifpos, thenpos,rule = extract_if_then(rule)\r\n    if_func, then_func = [],[]\r\n    # print(rule)\r\n    words = nltk.word_tokenize(rule)\r\n    tags = nltk.pos_tag(words)\r\n    func2pos, pos2func = match_words_tags_func(rule, words, tags)\r\n    neg_count = 0\r\n    for wd in words:\r\n        if wd in negation_words:\r\n            neg_count += 1\r\n    negation = True if neg_count % 2 == 1 else False\r\n    results = [(words[i], tags[i], pos2func[i]) for i in range(len(words))]\r\n    # print(rule,words)\r\n    t2c, c2t = map_charid_to_token_id(rule, words)\r\n\r\n    ifpos = c2t[ifpos]\r\n    thenpos = c2t[thenpos-1]\r\n    par_occur, col_occur, func_name2pos = find_par_col_occur(rule, c2t, results, rows, columns)\r\n    # print(par_occur,col_occur,func_name2pos)\r\n    all_positions = []\r\n    for func, positions in func_name2pos.items():#derive position for each function\r\n        positions_pair = []\r\n        for i,pos in enumerate(positions):\r\n            if i==0:\r\n                positions_pair.append(pos)\r\n            else:\r\n                if pos[0]-positions_pair[-1][-1]==1:\r\n                    positions_pair[-1].extend(pos)\r\n                else:\r\n                    positions_pair.append(pos)\r\n        for pos in positions_pair:\r\n            if par_occur or col_occur:\r\n\r\n                funcs = getattr(API, 'func_{}'.format(func))(par_occur, col_occur, words, pos,\r\n                                                                              original_assignments, negation, rows,columns)\r\n                # functions.extend(funcs)\r\n                # print('functions: ',funcs)\r\n                for tmp in funcs:\r\n                    all_positions.append(pos)\r\n                # funcs = merge_funcs_with_or(funcs,words)\r\n                if ifthenflag:\r\n                    ifpart = list(range(ifpos,thenpos))\r\n                    thenpart = list(range(thenpos,len(rule)))\r\n                    if min(pos) in ifpart or max(pos) in ifpart:\r\n                        if_func.extend(funcs)\r\n                    elif min(pos) in thenpart or max(pos) in thenpart:\r\n                        then_func.extend(funcs)\r\n                else:\r\n                    functions.extend(funcs)\r\n    if ifflag:\r\n        functions = merge_funcs_with_iff(functions,words,ifpos,thenpos,all_positions)\r\n    elif 'neither' in words:\r\n        functions = merge_funcs_with_neither(functions,words,all_positions)\r\n    elif 'or' in words:\r\n        functions = merge_funcs_with_or(functions, words,all_positions)\r\n    else:\r\n        functions = merge_funcs_with_and(functions,words,all_positions)\r\n\r\n    functions = merge_funcs_with_unless(functions,words,all_positions)\r\n    if ifthenflag and if_func and then_func:\r\n        # print(if_func)\r\n        # print(then_func)\r\n        ifthenrule = getattr(API, 'func_if_then')(if_func, then_func, rows, columns)\r\n        # print(ifthenrule)\r\n        functions.extend(ifthenrule)\r\n\r\n    return functions\r\n\r\ndef process_order_word(text,all_cols):\r\n    if any([wd in RP.orders.keys() for wd in all_cols]):\r\n        text=text.replace('last',all_cols[-1])\r\n    return text\r\n\r\ndef process_text(text,all_pars,all_cols):\r\n    text = process_order_word(text,all_cols)\r\n    return text\r\n\r\ndef analyze_question_type(tags,rows,columns):\r\n    question_type = None\r\n    for tag in tags:\r\n        if 'ordering' in tag:\r\n            question_type = 'ordering'\r\n        elif 'grouping' in tag:\r\n            question_type = 'grouping'\r\n    if not question_type:\r\n        if any([(col in all_num_words or col.isnumeric()) for col in columns]):\r\n            question_type = 'ordering'\r\n            # return question_type\r\n    if not question_type:\r\n        question_type = 'grouping'\r\n        return question_type\r\n    if len(rows)>len(columns) :\r\n        question_type = 'grouping'\r\n    return question_type\r\n\r\n\r\n\r\n\r\n\r\ndef print_table(table, rows, columns):\r\n    print('\\t', columns)\r\n    # print(table)\r\n    for idx, row in enumerate(rows):\r\n        print(row, table[idx])\r\nfrom collections import Counter\r\ndef transfer_rule_result(rule_res):\r\n    ruleid2funcs = {}\r\n    ruleid2rule = {}\r\n    funcset = []\r\n    for ins in rule_res:\r\n        # print(ins)\r\n        label = ins['labels'][0]\r\n        rule_id = '{}_{}'.format(ins['doc_id'],ins['rule_id'])\r\n        kw = ins['keywords'][0]\r\n        rule=ins['rule']\r\n        funcset.append(label)\r\n        if label!='NULL':\r\n            func = {'function':label,'arg1':{'text':kw['text_of_key1'],'position':(kw['begin_of_key1'],kw['end_of_key1'])},\r\n                    'arg2':{'text':kw['text_of_key2'],'position':(kw['begin_of_key2'],kw['end_of_key2'])}}\r\n\r\n            if rule_id not in ruleid2funcs.keys():\r\n                ruleid2funcs[rule] = []\r\n                ruleid2rule[rule] = ins['rule']\r\n\r\n            ruleid2funcs[rule].append(func)\r\n\r\n\r\n    return ruleid2funcs,ruleid2rule\r\ndoc_visit = []\r\nans2label = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\r\nbasic_dir = '../data'\r\n# basic_dir = 'D:\\PycharmProject\\LSAT_rule\\data'\r\n# rule_res_p = os.path.join(basic_dir, 'neural-rule-extraction/ar_val_rule_extraction_88.41%.json')\r\ndatap = os.path.join(basic_dir, 'new_data/ar_test_analyze_condition.json')\r\n# cp_dp_ner_path = os.path.join(basic_dir, 'AR_DevelopmentData_cp_ner_dp_results.json')\r\noutp = os.path.join(basic_dir, 'new_data/ar_test_modify_context.json')\r\n# cp_dp_ner_results = json.load(open(cp_dp_ner_path, 'r'))\r\n# rule_res = json.load(open(rule_res_p,'r'))\r\ninstances = json.load(open(datap, 'r'))\r\nmodified_instances = []\r\ndoc_index = 0\r\ndoc_visit.append(instances[0]['context'])\r\nall_output = [{'context':instances[0]['context'],'questions':[]}]\r\nall_label = []\r\nall_predict = []\r\nsentence_count=0\r\n# ruleid2funcs, ruleid2rule = transfer_rule_result(rule_res)\r\n\r\nfor ins_idx, instance in enumerate(instances):\r\n    context = instance['context']\r\n\r\n    if (context in doc_visit) == False:\r\n        doc_visit.append(context)\r\n        doc_index += 1\r\n        all_output.append({'context':instance['context'],'questions':[]})\r\n        sentence_count = 0\r\n\r\n    sentence_count+=1\r\n\r\n    sentences = nltk.sent_tokenize(context)\r\n    all_sentence = []\r\n    for sen in sentences:\r\n        all_sentence.extend(nltk.sent_tokenize(sen))\r\n    # sentences = cp_dp_ner_results[doc_index]['sentences']\r\n    # sentence_cp_results = cp_dp_ner_results[doc_index]['sentence_cp_results']\r\n\r\n    #read information: including participants and positions\r\n    question = instance['question']\r\n    answers = instance['answers']\r\n    label = instance['label']\r\n    all_label.append(label)\r\n    id_string = instance['id_string']\r\n    #rows indicate participants, columns indicate positions\r\n    rows = instance['rows']\r\n    columns = instance['columns']\r\n\r\n    #rank participants and columns based on predefined orders: like first, second, third etc.\r\n    columns = rank_entities(columns)\r\n    rows = rank_entities(rows)\r\n    #if participants are the same with positions, substitude positions to orders, like (A,B) -> (first, second)\r\n    if rows == columns:\r\n        columns = [list(RP.orders.keys())[idx] for idx in range(len(rows))]\r\n\r\n    #analyze the type of questions and process text\r\n    question_type = analyze_question_type(instance['tags'],rows,columns)\r\n    question = process_text(question,rows,columns)\r\n    answers = [process_text(ans,rows,columns) for ans in answers]\r\n    sentences = [process_text(sen,rows,columns) for sen in sentences]\r\n\r\n    #extract fact and rules from sentences based on (text, participants, columns)\r\n    fact_ids, rule_ids = extract_facts_rules(sentences, rows, columns)\r\n    #extract fact (hypothetics) in the question\r\n    inner_question_fact = fact_in_question(question)\r\n    facts = [sentences[id] for id in fact_ids]\r\n    if inner_question_fact:\r\n        facts.append(inner_question_fact)\r\n    rules = [sentences[id] for id in rule_ids]\r\n    all_output[-1]['columns'] = columns\r\n    all_output[-1]['rows'] = rows\r\n    all_output[-1]['facts'] = facts\r\n    all_output[-1]['rules'] = rules\r\n    all_output[-1]['questions'].append({'question':question,'answers':answers,'type':instance['tags']})\r\n\r\n    #extract initial assignment by fact\r\n    original_assignments, add_rules = assign_table_with_facts(rows, columns, facts)\r\n    #if the initial assignment can not be found, take the fact as a rule\r\n    rules = rules + add_rules\r\n    # rule_cp_results = [sentence_cp_results[idx] for idx in rule_ids]\r\n\r\n    #extract logical functions from the rules\r\n    all_rule_func = []\r\n    # print(\r\n    for rule_id, rule in enumerate(rules):\r\n\r\n        rid = '{}_{}'.format(doc_index,rule_id)\r\n        # if rule in ruleid2funcs.keys():\r\n        #     neural_funcs = ruleid2funcs[rule]\r\n        # else:\r\n        #     neural_funcs  = []\r\n        rule_func = derive_rules(rule,rows,columns)#,neural_funcs)\r\n        all_rule_func.extend(rule_func)\r\n\r\n    #construct rule tree based on extracted functions\r\n    rule_tree = RuleTree(rows,columns,all_rule_func,original_assignments,question_type)\r\n    leaf_nodes, each_level_node = rule_tree.obtain_root_and_construct_tree()\r\n    #all the leaf node (possible assignments)\r\n    # print('all the possible solution: {}'.format(len(leaf_nodes)))\r\n    # for lid,level in enumerate(each_level_node):\r\n    #     print(lid+1,len(level))\r\n\r\n    #extract option-based assignments and functions from each option\r\n    option_based_assignments,option_functions = find_assgiments_for_qa(original_assignments,question,answers,rows,columns)#assign_table_with_qa(table,question,answers,rows,columns)\r\n    option_functions = merge_option_functions(option_functions)\r\n\r\n    #choose question type and calculate scores for each option\r\n    Question = choose_question_type(question,leaf_nodes,rows,columns,question_type,instance['tags'],all_rule_func)#QuestionType(question,leaf_nodes)\r\n    sorted_score = Question.select_answers(answers,option_based_assignments,option_functions)\r\n    # print(sorted_score)\r\n\r\n    max_score, prediction = sorted_score[0]\r\n    if all(x[0] == sorted_score[0][0] for x in sorted_score):#all([tmp[0]==0 for tmp in sorted_score]):\r\n        prediction = 0\r\n\r\n    all_predict.append(prediction)\r\n    # print(max_score,prediction,label,doc_index,sentence_count)\r\n\r\ncompare = [all_predict[idx] == all_label[idx] for idx in range(len(all_label))]\r\nprint('Overall precision',sum(compare) / len(compare))\r\n\r\n#\r\n# with open(outp,'w',encoding='utf8') as outf:\r\n#     json.dump(all_output,outf,indent=4)\r\n",
        "ARM/pipeline/rule_pattern.py": "import re\nimport inflect\nimport nltk\nimport numpy as np\nimport json\n# from allennlp.predictors.predictor import Predictor\n# import allennlp_models.tagging\n# import allennlp_models.structured_prediction\nclass RulePattern():\n\n    def __init__(self):\n        super(RulePattern, self).__init__()\n        numbers = {\n            #'an':1,\n            'zero': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10, 'eleven': 11,'twelve': 12\n        }\n        orders = {\n            'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5, 'sixth': 6, 'seventh': 7,\n            'eighth': 8, 'ninth': 9, 'tenth': 10, 'eleventh': 11, 'twelfth': 12,'thirteenth':13,\n            'fourteenth':14,'fifteenth':15,'sixteenth':16,'last':17,\n        }\n        simple_order = {\n            '1st':1, '2nd':2,'3rd':3,'4th':4,'5th':5,'6th':6,'7th':7,'8th':8,'9th':9\n        }\n        self.numbers = numbers.copy()\n        for num in numbers.items():\n            self.numbers[num[0].capitalize()] = num[1]\n        self.orders = orders.copy()\n        self.simple_order = simple_order.copy()\n        for num in orders.items():\n            self.orders[num[0].capitalize()] = num[1]\n        self.pos_useful_tag = ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJR', 'JJS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',\n                               'V', 'PDT', 'PRP', 'RBR', 'RBS']\n        self.entity_tag = ['NN', 'NNS', 'NNP', 'NNPS']\n        self.week_words = {'Monday':1, 'Tuesday':2, 'Wednesday':3, 'Thursday':4, 'Friday':5, 'Saturday':6, 'Sunday':7}\n        self.month_words = {\n        \"January\":1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10,\n            'November':11, 'December':12\n        }\n        self.num_words = ['first','second','three','four','five','six','seven','']\n        self.no_use_single_words = ['The', 'She', 'He', 'They', 'It', 'Them', 'Their', 'A', 'On', 'In', 'To', 'Where',\n                                    'There','Each','If','following','Neither','Except']\n\n        self.all_num_dict = [self.numbers,self.orders,self.simple_order,self.week_words,self.month_words]\n        self.quantity_words = ['once','each','twice','a']\n        self.keywords = ['circular']\n        number_joint = '|'.join(list(self.numbers.keys()))\n        self.entity_patterns = ['(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9 ]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:. ]{1,}(( [0-9])*))|([$,0-9]+( [a-z]+)))',#'(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9. ]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:. ]{1,}(( [0-9])*))|([$,0-9]+( [a-z]+)))',#(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9.]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:. ]{1,}(( [0-9])*))|([$,0-9]+( [a-z]+)))',\n                               '(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9. ]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:. ]{1,}(( [0-9])*))|([$,0-9]+( [a-z]+)))',\n                               # '([A-Za-z0-9]+, ){2,}and ([0-9A-Za-z ]+)'\n                               '([A-Za-z ]+, ){2,}and ([A-Za-z ]+)',\n                                '(— |: )([A-Za-z ]+) (and|or) ([A-Za-z ]+)']#higher participant performance\n            #'((a [0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9.]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*(([a-zA-Z0-9:]{1,}( [0-9])*)|([$,0-9]+( [a-z]+)))'#higher col performance\n        #'(([0-9:$,]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9.]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*[a-zA-Z0-9.]{1,}( [0-9])*'\n            #'(([0-9:]+)|((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9.]{1,})( [0-9])*), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*[a-zA-Z0-9.]{1,}( [0-9])*'\n        #'((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9]{1,})( [0-9])*, ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*[a-zA-Z0-9]{1,}( [0-9])*'\n        self.quantity_pattern = '( |— )(|{number}|[0-9]+)+ ([a-zA-Z]+)[ —.,](({number}|[0-9])+[ ,.])*'.format(number=number_joint)\n        self.range_pattern = '[a-zA-Z ]*({order}|{number}|{week}|([0-9]+))+ (\\([a-z]+\\) )*(through|to) [a-zA-Z ]*({order}|{number}|{week}|([0-9]+.))+'.format(\n            number=number_joint,order='|'.join(list(orders.keys())+list(simple_order.keys())),week='|'.join(list(self.week_words.keys())),month='|'.join(list(self.month_words.keys())))\n        self.number_pattern = '({simple_order}|{order}|{number}|{week}|{month}|([0-9]+))+'.format(number=number_joint,simple_order='|'.join(list(simple_order.keys())),order='|'.join(list(self.orders.keys())),week='|'.join(list(self.week_words.keys())),month='|'.join(list(self.month_words.keys())))\n        #'((a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*([a-zA-Z0-9]{1,}), ){2,}(and|or)*(a|an|the|one|two|three|four|five|six|seven|eight|night|ten|[0-9]+| )*[a-zA-Z0-9]{1,}'\n        # self.predictor_ner = Predictor.from_path(\n        #     \"https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz\",cuda_device=0)\n        # self.predictior_cp = Predictor.from_path(\n        #     \"https://storage.googleapis.com/allennlp-public-models/elmo-constituency-parser-2020.02.10.tar.gz\",cuda_device=0)\n        # self.predictior_dp = Predictor.from_path('https://storage.googleapis.com/allennlp-public-models/biaffine-dependency-parser-ptb-2020.04.06.tar.gz',cuda_device=0)\n        # self.openie_predictor = Predictor.from_path(\n        #     \"https://s3-us-west-2.amazonaws.com/allennlp/models/openie-model.2018-08-20.tar.gz\")\n        # self.srl_predictor = Predictor.from_path(\n        #     \"https://s3-us-west-2.amazonaws.com/allennlp/models/srl-model-2018.05.25.tar.gz\")\n        self.stemm = nltk.PorterStemmer()\n        self.tokenizer = nltk.word_tokenize\n        self.inflect = inflect.engine()\n\n\n    def modify_option(self,options):\n        match_pattern = '([A-Za-z0-9]+, ){1,}([a-zA-Z0-9]*)'\n        modified_options=[]\n        for option in options:\n            all_res = re.finditer(match_pattern,option)\n            for res in all_res:\n                parts = res.group().split(', ')\n                for idx in range(len(parts)):\n                    if 'and' in parts[idx]:\n                        parts[idx] = ' and the {} is'.format(list(self.orders.keys())[idx])\n                    else:\n                        parts[idx] = 'the {} is {}'.format(list(self.orders.keys())[idx],parts[idx])\n                replace_str = ', '.join(parts)\n                option = option.replace(res.group(),replace_str)\n            modified_options.append(option)\n        return modified_options\n\n\n    def find_wspan(self,text,tokens,cspan,start_idx):\n        start = None\n        end = None\n        cand = []\n        for i in range(len(tokens)):\n            if tokens[i] in text:\n                if start:\n                    end+=1\n                else:\n                    start,end = i,i\n            else:\n                if start:\n                    start_dis = abs(cspan[0]-len(' '.join(tokens[:start])))\n                    end_dis = abs(cspan[1]-len(' '.join(tokens[:end+1])))\n                    cand.append((start,end,(start_dis+end_dis)/2))\n                    start,end=None,None\n        if start:\n            start_dis = abs(cspan[0] - len(' '.join(tokens[:start])))\n            end_dis = abs(cspan[1] - len(' '.join(tokens[:end + 1])))\n            cand.append((start, end, (start_dis + end_dis) / 2))\n\n        cand = sorted(cand,key=lambda x:x[2],reverse=False)\n        return (start_idx+cand[0][0],start_idx+cand[0][1]+1)\n\n\n    def extract_entity_pattern(self,text, tokens,sen_start_idx):\n\n        ent_groups = []\n        all_ent = []\n        repeat_group = []\n        for idx,entity_pattern in enumerate(self.entity_patterns):\n            entity_parts = re.finditer(entity_pattern, text)\n            if entity_parts:\n                for entity_part in entity_parts:\n                    tmp = str(entity_part.group()).replace(', ', '#')\n                    # print(tmp)\n                    tmp = str(tmp).replace('and ', '#')\n                    tmp = str(tmp).replace('or ', '#')\n                    tmp = tmp.split('#')\n                    while '' in tmp:\n                        tmp.remove('')\n                    count = 0\n                    # print(tmp)\n                    for widx,item in enumerate(tmp):\n                        if self.exist(item,all_ent):\n                            count+=1\n                        item = item.replace('—','').strip()\n                        if len(item.split(' '))>4:#if length of some word larger than 4,drop this instance\n                            count+=len(tmp)\n                    if count>=(2/3)*len(tmp):#if the number of entities in current group already found larger than 2/3 of the total entities in the group, continue\n                        repeat_group.append({'entities': tmp,\n                                           'span': self.find_wspan(entity_part.group(), tokens, entity_part.span(),\n                                                                   sen_start_idx)})\n                        continue\n                    else:\n                        ent_groups.append({'entities': tmp,\n                                           'span': self.find_wspan(entity_part.group(), tokens, entity_part.span(),\n                                                                   sen_start_idx)})\n\n\n                    all_ent.extend(tmp)\n            # sorted_repeat_group = sorted(repeat_group,key=lambda k:len(k['entities']),reverse=True)\n\n            # if idx>0 and ent_groups:\n\n            if len(ent_groups)>1:\n                break\n\n        return ent_groups\n\n\n    def extract_quantity(self, text, tokens,start_idx):\n        results = re.finditer(self.quantity_pattern,text)\n        re_quantity = []\n        for match in results:\n            re_quantity.append({'text':match.group().strip(' ,.—') ,'span':self.find_wspan(match.group(),tokens, match.span(),start_idx)})\n        range_results = re.finditer(self.range_pattern,text)\n        range_quantity = []\n        for match in range_results:\n            range_quantity.append({'text':match.group().strip(' ,.—') ,'span':self.find_wspan(match.group(),tokens, match.span(),start_idx)})\n        return re_quantity,range_quantity\n\n    def match_number_entity(self,quantity,ent_groups):\n        for qua_idx,qua in enumerate(quantity):\n            qua_pos = qua['span']\n            min_dis, min_idx = 9999,None\n            for gidx,group in enumerate(ent_groups):\n                group_pos = group['span']\n                dis = group_pos[0] - qua_pos[1]\n                if qua_pos[0] in list(range(group_pos[0],group_pos[1])):\n                    dis = 0\n                if (dis>=0 and dis<min_dis):\n                    min_idx = gidx\n                    min_dis = dis\n\n            quantity[qua_idx]['match_entity_group'] = ent_groups[min_idx] if (ent_groups and min_idx!=None) else None\n        return quantity\n\n    def extract_participants(self, leaf_nodes):\n        nouns = []\n        quantity = []\n        numbers = []\n        for idx, node in enumerate(leaf_nodes):\n            #calculate nouns and quantity\n            flag = False\n            if node['nodeType'] in self.entity_tag:\n                #middle of the sequence\n                if idx != 0 and idx != len(leaf_nodes) - 1:\n                    if (leaf_nodes[idx - 1]['word'] in ['—', ',', 'and']) or (\n                            leaf_nodes[idx + 1]['word'] in [',']):\n                        flag = True\n                    elif leaf_nodes[idx-1]['nodeType']=='CD':\n                        quantity.append((leaf_nodes[idx-1]['word'],leaf_nodes[idx]['word'],idx))\n                #start of sequence\n                elif idx == 0:\n                    if (leaf_nodes[idx + 1]['word'] in [',']):\n                        flag = True\n                #end of the sequence\n                elif idx == len(leaf_nodes) - 1:\n                    if (leaf_nodes[idx - 1]['word'] in ['—', ',', 'and']):\n                        flag = True\n                    elif leaf_nodes[idx-1]['nodeType']=='CD':\n                        quantity.append((leaf_nodes[idx-1]['word'],leaf_nodes[idx]['word'],idx))\n                if flag==False:\n                    if node['word'] in list(self.month_words.keys())+list(self.week_words.keys()):\n                        if idx==0:\n                            quantity.append(('null',node['word'],idx))\n                        else:\n                            quantity.append((leaf_nodes[idx - 1]['word'], leaf_nodes[idx]['word'], idx))\n                        flag = True\n                if flag:\n                    nouns.append((node['word'],idx))\n            #if the word is number, find useful sorrounding context\n            if node['nodeType']=='CD' or (node['word'].lower() in self.quantity_words):\n                start=0 if idx==0 else idx-1\n                for j in range(idx,0):\n                    if leaf_nodes[j]['nodeType'] in list(self.entity_tag)+['CD'] or leaf_nodes[j]['word'] in [',','.','—']:\n                        start = j\n                        break\n                for j in range(idx+1,len(leaf_nodes)):\n                    if leaf_nodes[j]['nodeType'] in list(self.entity_tag)+['CD'] or leaf_nodes[j]['word'] in [',','.','—']:\n                        end = j\n                        break\n\n                numbers.append(([leaf['word'] for leaf in leaf_nodes[start:end+1]],node['word'],idx))\n\n        results = {'nouns':nouns, 'quantity':quantity,'numbers':numbers}\n        return results\n\n    def get_noun(self,tree,nps):\n        if isinstance(tree, dict):\n            if \"children\" not in tree:\n                if (tree['nodeType'] in self.entity_tag):\n                    nps.append(tree['word'])\n                # if tree['nodeType'] in [\"NNP\",\"NN\"]:\n                    # print(tree['word'])\n                    # print(tree)\n                    # nps.append(tree)\n\n            elif \"children\" in tree:\n                # cls.get_NP(tree['children'], nps)\n                if (tree['nodeType'] in self.entity_tag):\n                    # print(tree['word'])\n                    # nps.append(tree['word'])\n                    self.get_noun(tree['children'], nps)\n                else:\n                    self.get_noun(tree['children'], nps)\n        elif isinstance(tree, list):\n            for sub_tree in tree:\n                self.get_noun(sub_tree, nps)\n\n        return nps\n\n    def check_contain_num(self,tree):\n        if isinstance(tree, dict):\n            if \"children\" not in tree:\n                if tree['nodeType'] == 'CD':\n                    return True\n                else:\n                    return False\n            else:\n                return self.check_contain_num(tree['children'])\n        elif isinstance(tree, list):\n            ans = False\n            for sub_tree in tree:\n                ans = ans | self.check_contain_num(sub_tree)\n            return ans\n\n    def get_np_has_number(self,tree, nps, subtree):\n        if isinstance(tree, dict):\n            if \"children\" not in tree:\n                if tree['nodeType'] == \"NP\":\n                    # print(tree['word'])\n                    # print(tree)\n                    nps.append(tree['word'])\n            elif \"children\" in tree:\n                if tree['nodeType'] == \"NP\":\n                    # print(tree['word'])\n                    #                 print(tree['word'],check_contain_num(tree))\n                    if self.check_contain_num(tree):\n                        nps.append(tree['word'])\n                        subtree.append(tree)\n\n                #                     get_np_has_number(tree['children'], nps,subtree)\n                else:\n                    self.get_np_has_number(tree['children'], nps, subtree)\n        elif isinstance(tree, list):\n            for sub_tree in tree:\n                self.get_np_has_number(sub_tree, nps, subtree)\n        return nps, subtree\n\n    def combine_cond_keywords(self,keywords):\n        #combine keywords especially for condition extraction\n        for i,group in enumerate(keywords['entity_group']):\n            for j,ent1 in enumerate(group['entities']):\n                ent1 = ent1.strip().replace(', or', '')\n                keywords['entity_group'][i]['entities'][j] = ent1\n                for k,ent2 in enumerate(keywords['entity']):\n                    if ent1 in ent2:\n                        keywords['entity_group'][i]['entities'][j]=ent2\n        return keywords\n\n    def combine_common_keywords(self,keywords):\n        #combine keywords for common noun phrase extraction and entity extration\n        for i,ent2 in enumerate(keywords['entity']):\n            for j,useless_wd in enumerate(self.no_use_single_words):\n                if (useless_wd+' ') in ent2:\n                    keywords['entity'][i] = keywords['entity'][i].strip(useless_wd+' ')\n        for i, ent1 in enumerate(keywords['noun']):\n            for j, ent2 in enumerate(keywords['entity']):\n                if ent1 in ent2:\n                    keywords['noun'].pop(i)\n                    break\n        kws = list(set(keywords['noun']+keywords['entity']))\n        for i,kw in enumerate(kws):\n            if kw in self.no_use_single_words:\n                kws.pop(i)\n            if ',' in kws:\n                tmp = kws[i]\n                kws.pop(i)\n                kws.extend(tmp.split(','))\n        keywords['filtered_keywords'] = kws\n        return keywords\n\n    def extract_question_keywords(self, text, tokens, ent_res):\n        keywords = {'noun': [], 'text':text, 'entity':[]}\n        all_ents = self.extract_entity_allennlp(ent_res['words'], ent_res['tags'])\n        keywords['entity'].extend(all_ents)\n        tree = tokens['hierplane_tree']['root']\n        nps = []\n        nps = self.get_NP(tree,nps)\n        keywords['noun'] = nps\n        return keywords\n\n    def extract_option_keywords(self, text, tokens, ent_res):\n        return self.extract_question_keywords(text,tokens,ent_res)\n\n    def found_key_words_common(self, claim, tokens, ent_res):\n        key_words = {'noun': [], 'text': claim, 'entity':[]}\n        tree = tokens['hierplane_tree']['root']\n        nps, subtrees = [],[]\n        nps, subtrees = self.get_np_has_number(tree,nps,subtrees)\n        key_words['quantity_noun_phrase'] = nps\n        # key_words['quantity_subtree'] = subtrees\n        all_ents = self.extract_entity_allennlp(ent_res['words'], ent_res['tags'])\n        key_words['entity'].extend(all_ents)\n        nps = []\n        tree = tokens['hierplane_tree']['root']\n        nps = self.get_noun(tree, nps)\n        key_words['noun'] = nps\n        return key_words\n\n    def mapnum2int(self,num):\n        # print(num)\n        for d in self.all_num_dict:\n            if num in d.keys():\n                return (d[num],d)\n\n        return int(num),None\n\n    def exist(self,item1, lst):\n        for item2 in lst:\n            if item1.strip() in item2.strip() or item2.strip() in item1.strip():\n                return True\n\n    def extract_columns_from_range(self,quantity,doc):\n\n        nums = re.finditer(self.number_pattern,quantity)\n        all_nums = []\n        num_dict = None\n        start,end=9999,-1\n        print(nums)\n        for num in nums:\n            # print(num)\n            start = min(start, num.span()[0])\n            end = max(end, num.span()[1])\n            num,num_dict = self.mapnum2int(num.group())\n            all_nums.append(num)\n            num_dict = num_dict\n        min_num,max_num = min(all_nums),max(all_nums)\n        columns = []\n        if num_dict:\n            for item in num_dict.items():\n                if item[1]>=min_num and item[1]<=max_num and item[0].lower() not in columns:\n                    columns.append(item[0])\n        else:\n            columns = [str(num) for num in range(min_num,max_num+1)]\n\n        if start<9999 and end!=-1:\n            modified_doc = doc.replace(quantity[start:end],', '.join(columns))\n        else:\n            modified_doc = doc\n        return columns, modified_doc\n\n    def found_key_words_leading_sen(self, claim,tokens, ent_res,sid):\n        #extract entity and quantity especially for two leading sentences for condition extractions\n        #use regex pattern to extract entities and quantity\n        key_words = { 'text': claim, 'quantity_pairs': [], 'entity': []}\n        nps = []\n\n        # tree = tokens['hierplane_tree']['root']\n        # leaf_nodes = self.get_noun(tree, nps)\n        # results = self.extract_participants(leaf_nodes)\n        # key_words['noun'].extend(results['nouns'])#.extend(results['quantity'])\n        # key_words['numbers'] = results['numbers']\n\n        all_ents = self.extract_entity_allennlp(ent_res['words'], ent_res['tags'])\n        key_words['entity'].extend(all_ents)\n\n        ent_groups = self.extract_entity_pattern(claim,tokens['tokens'],sid)\n        key_words['entity_group'] = ent_groups\n\n        # add_keywords = self.combine_cond_keywords(key_words)\n        quantity,range_quantity = self.extract_quantity(claim,tokens['tokens'],sid)\n        # print(claim, '\\n')\n        # print(tokens['tokens'])\n        # print('quantity is:',quantity,'\\n')\n        # print('entity_group is: ',ent_groups,'\\n')\n        quantity = self.match_number_entity(quantity,ent_groups)\n        range_quantity = self.match_number_entity(range_quantity,ent_groups)\n\n        # print('matched quantity is :',quantity)\n        # print('---------------------------------------')\n        key_words['quantity_pairs'] = quantity\n        key_words['range_quantity_pairs'] = range_quantity\n\n\n        return key_words\n\n    def manage_multiple_group(self,ent_groups,words):\n        participants = ent_groups[0]['entities'].copy()\n        start_span = ent_groups[0]['span']\n        columns = []\n        col_flag = False\n        for g in ent_groups[1:]:\n            # print(words[start_span[1]:g['span'][0]+1])\n            if any([item in words[start_span[1]:g['span'][0]+1] for item in ['to','at','on','for']]):\n                columns.extend(g['entities'])\n                col_flag = True\n            elif any([item in words[start_span[1]:g['span'][0]+1] for item in ['and','or','with']]):\n                if col_flag==True:\n                    columns.extend(g['entities'])\n                else:\n                    participants.extend(g['entities'])\n            else:\n                columns.extend(g['entities'])\n                col_flag=True\n            start_span = g['span']\n        if len(columns)==0:\n            columns = ent_groups[-1]['entities']\n        return participants,columns\n\n    def clean_ent(self,ents):\n        no_use_words = ['—',':','.']+[' '+tmp+' ' for tmp in ['a','the','case','bonus','shelf','court']+list(self.numbers.keys()) + self.no_use_single_words]\n        for eidx,ent in enumerate(ents):\n            ents[eidx] = ' '+ents[eidx]\n            for wd in no_use_words:\n                ents[eidx] = ents[eidx].replace(wd,' ')\n            ents[eidx] = ents[eidx].strip()\n        return ents\n\n    def extract_participants_columns(self,ent_groups,range_quantity,words,doc):\n\n        columns = []\n        participants = []\n        modified_doc = doc\n\n        if range_quantity:\n            for rq in range_quantity:\n                column,modified_doc = self.extract_columns_from_range(rq['text'],modified_doc)\n                columns.extend(column)\n            if len(ent_groups)>=2:\n                participants, tmp_columns = self.manage_multiple_group(ent_groups, words)\n                columns.extend(tmp_columns)\n            elif len(ent_groups)==1:\n                participants = ent_groups[0]['entities']\n            else:\n                participants = columns\n        elif len(ent_groups) >= 2:\n            participants, columns = self.manage_multiple_group(ent_groups,words)\n        elif len(ent_groups) == 1:\n            participants = ent_groups[0]['entities']\n            columns = ent_groups[0]['entities']\n        # print(participants)\n        participants = self.clean_ent(participants)\n        columns = self.clean_ent(columns)\n        participants = set(participants)\n        columns = set(columns)\n        same = list(set.intersection(participants,columns))\n        new_columns = [c for c in columns if (c not in same) ]\n        participants = list(participants)\n        if len(new_columns)==0:\n            new_columns = columns\n\n        # print('participants',participants,'\\n')\n        # print('columns',columns,'\\n')\n        # for idx,col in enumerate(columns):\n        #     columns[idx] = list(set(col))\n        return participants,new_columns,modified_doc\n\n    def get_cp_ner_results(self,texts):\n        tokens = self.predictior_cp.predict_batch_json(inputs=[{'sentence':text} for text in texts])\n        dps = self.predictior_dp.predict_batch_json(inputs=[{'sentence':text} for text in texts])\n        ent_res = []\n        for text in texts:\n\n            try:\n                tmp_res = self.predictor_ner.predict(text)\n                ent_res.append(tmp_res)\n            except Exception as e:\n                print(text)\n                ent_res.append({'words':[],'tags':[]})\n        # ent_res = self.predictor_ner.predict_batch_json(inputs=[{'sentence':text} for text in texts])\n        # print(tokens[0].keys())\n        for i in range(len(tokens)):\n            del tokens[i]['class_probabilities']\n        return tokens,ent_res,dps\n    \n    @classmethod\n    def check_contain_upper(cls, password):\n        pattern = re.compile('[A-Z]+')\n        match = pattern.findall(password)\n        if match:\n            return True\n        else:\n            return False\n\n\n    @classmethod\n    def tokenize_sentence(self, sentence):\n        tokens = nltk.word_tokenize(sentence)\n        return tokens\n\n    def normalize_tags(self, tagged):\n        n_tagged = []\n        for t in tagged:\n            if t[1] == \"NP-TL\" or t[1] == \"NP\":\n                n_tagged.append((t[0], \"NNP\"))\n                continue\n            if t[1].endswith(\"-TL\"):\n                n_tagged.append((t[0], t[1][:-3]))\n                continue\n            if t[1].endswith(\"S\"):\n                n_tagged.append((t[0], t[1][:-1]))\n                continue\n            n_tagged.append((t[0], t[1]))\n        return n_tagged\n        # Extract the main topics from the sentence\n\n\n\n    @classmethod\n    def get_NP(cls, tree, nps):\n        if isinstance(tree, dict):\n            if \"children\" not in tree:\n                if tree['nodeType'] in [\"NNP\",\"NN\"]:\n                    # print(tree['word'])\n                    # print(tree)\n                    nps.append(tree['word'])\n            elif \"children\" in tree:\n                if tree['nodeType'] in [\"NNP\",\"NN\"]:\n                    # print(tree['word'])\n                    nps.append(tree['word'])\n                    cls.get_NP(tree['children'], nps)\n                else:\n                    cls.get_NP(tree['children'], nps)\n        elif isinstance(tree, list):\n            for sub_tree in tree:\n                cls.get_NP(sub_tree, nps)\n\n        return nps\n\n\n    @classmethod\n    def get_subjects(cls, tree):\n        subject_words = []\n        subjects = []\n        for subtree in tree['children']:\n            if subtree['nodeType'] == \"VP\" or subtree['nodeType'] == 'S' or subtree['nodeType'] == 'VBZ':\n                subjects.append(' '.join(subject_words))\n                subject_words.append(subtree['word'])\n            else:\n                subject_words.append(subtree['word'])\n        return subjects\n\n\n\n    @classmethod\n    def search_entity_with_tags(cls, tags, words):\n        if ('B-V' in tags):\n            verb_idx = tags.index('B-V')\n        else:\n            return [], []\n        subj, obj = [], []\n        flag = False\n        for idx in range(0, verb_idx):\n            tag = tags[idx]\n            if (tag != 'I-V'):\n                if (tag.find('B-') != -1):\n                    subj.append(words[idx])\n                elif (tag.find('I-') != -1):\n                    if (len(subj) != 0):\n                        subj[-1] += ' %s' % words[idx]\n\n        for idx in range(verb_idx + 1, len(tags)):\n            tag = tags[idx]\n            if (tag != 'I-V'):\n                if (tag.find('B-') != -1):\n                    obj.append(words[idx])\n                elif (tag.find('I-') != -1):\n                    if (len(obj) != 0):\n                        obj[-1] += ' %s' % words[idx]\n\n        return subj, obj\n\n    def analyze_srl_result(self, srl_result):\n        srls, words = srl_result['verbs'], srl_result['words']\n        triples = []\n        for srl in srls:\n            verb, des, tags = srl['verb'], srl['description'], srl['tags']\n            verb = verb\n            subj, obj = self.search_entity_with_tags(tags, words)\n            triples.append({'verb': verb, 'subject': subj, 'object': obj})\n        return triples\n\n    def found_openie_srl(self, texts):\n        openie_results = self.openie_predictor.predict_batch_json(inputs=[{'sentence': text} for text in texts])\n        srl_results = self.srl_predictor.predict_batch_json(inputs=[{'sentence': text} for text in texts])\n        openie_triples = [self.analyze_srl_result(tmp) for tmp in openie_results]\n        srl_triples = [self.analyze_srl_result(tmp) for tmp in srl_results]\n        return openie_results, srl_results, openie_triples, srl_triples\n\n    def infer_important_words(self, words, pos_tags):\n        # obtain pos tag\n        attn_words = []\n\n        def hasNumbers(inputString):\n            return bool(re.search(r'\\d', inputString))\n\n        for idx in range(len(pos_tags)):\n            tag = pos_tags[idx]\n            if (tag in self.pos_useful_tag):\n                attn_words.append(words[idx])\n            elif (hasNumbers(words[idx])):\n                attn_words.append(words[idx])\n\n        # if (len(src_loc) > 0 or len(dest_loc) > 0):\n        #     print(\n        #         'All location candidate is: {}\\n The src_loc is: {} The dest_loc is: {}\\n'.format(all_loc_cdd, src_loc,\n        #                                                                                           dest_loc))\n\n        return attn_words\n    @classmethod\n    def extract_entity_allennlp(cls, words, tags):\n        all_ents = []\n        all_ents_test = []\n        flag = True\n        # for i, tag in enumerate(tags):\n        #     if(tag!='O'):\n        #         all_ents_test.append(words[i])\n        tmp = []\n\n        for i, tag in enumerate(tags):\n            flag = True if (cls.check_contain_upper(words[i])) else False\n            if (tag != 'O' or flag):\n                tmp.append(words[i])\n            if (len(tmp) != 0 and ((tag == 'O' and flag == False) or i == (len(tags) - 1))):\n                all_ents.append(' '.join(tmp))\n                tmp = []\n\n        # assert(' '.join(all_ents_test)==' '.join(all_ents)),'{}, {}, {}, {}'.format(all_ents,all_ents_test,words,tags)\n        return all_ents\n\n    @classmethod\n    def judge_upper(self, text):\n        bigchar = re.findall(r'[A-Z]', text)\n        return (len(bigchar) > 0)\n\n\n\n\n\n",
        "ARM/pipeline/rule_update_table.py": "#https://pypi.org/project/anytree/\r\nfrom anytree import Node, RenderTree, NodeMixin,LevelOrderIter\r\nimport json\r\nimport copy\r\nimport itertools\r\n\r\ndef merge_option_functions(option_functions):\r\n    for id,funcs in enumerate(option_functions):\r\n        args = []\r\n        for j,func in enumerate(funcs):\r\n            if not isinstance(func,TO):\r\n                args.append(func.arg1)\r\n                args.append(func.arg2)\r\n        for j, func in enumerate(funcs):\r\n            if isinstance(func,TO):\r\n                if func.arg1 in args or func.arg2 in args:\r\n                    option_functions[id].pop(j)\r\n    return option_functions\r\n\r\ndef filter_func(kw,sorted_funcs, positions,tokens):\r\n    # In the case: Trapezoid must either be earlier than both Reciprocity and Salammbo or later than both Reciprocity and Salammbo.\r\n    # for previous function, if argument go across a or and multiple functions is not allowed\r\n    # for the last function, if argument all exist and is not the subj of the previous function is not allowed\r\n    prev_subj = []\r\n    prev_obj = []\r\n    prev_so_pair = []\r\n    prev_obj_pos = []\r\n    new_funcs = []\r\n    all_func_type = []\r\n    for i, func in enumerate(sorted_funcs):\r\n        if (type(func), positions[i]) not in all_func_type:\r\n            all_func_type.append((type(func), positions[i]))\r\n    for type_idx, func_type in enumerate(all_func_type):\r\n        for i, func in enumerate(sorted_funcs):\r\n            if (type(func), positions[i]) != func_type:\r\n                continue\r\n            flag = True\r\n            arg1_pos = func.arg1['position']\r\n            arg2_pos = func.arg2['position']\r\n            end_pos = max(list(arg1_pos) + list(arg2_pos))\r\n            if type_idx != len(all_func_type) - 1:\r\n                if any([isinstance(func, tmp) for tmp in [BEFORE, LAST]]):\r\n                    prev_subj.append(func.arg2['participant'])\r\n                    prev_obj.append(func.arg1['participant'])\r\n                    # prev_so_pair.append((func.arg2['participant'],func.arg1['participant']))\r\n                    prev_obj_pos.append(max(func.arg1['position']))\r\n                else:\r\n                    prev_subj.append(func.arg1['participant'])\r\n                    prev_obj.append(func.arg2['participant'])\r\n                    # prev_so_pair.append((func.arg1['participant'], func.arg2['participant']))\r\n                    prev_obj_pos.append(func.arg2['position'])\r\n                for j, tmp_func in enumerate(all_func_type[type_idx+1:]):\r\n                    if (end_pos > max(list(all_func_type[type_idx + j + 1][1]))) \\\r\n                            and (kw in tokens[max(list(positions[i])): max(list(all_func_type[type_idx + j + 1][1]))]) \\\r\n                            and any(\r\n                        [item in range(max(list(positions[i])), max(list(all_func_type[type_idx + j + 1][1]))) for item\r\n                         in prev_obj_pos]):\r\n                        flag = False\r\n                        break\r\n            else:\r\n                if any([isinstance(func, tmp) for tmp in [BEFORE, LAST]]):\r\n                    subj, obj = func.arg2['participant'], func.arg1['participant']\r\n                else:\r\n                    subj, obj = func.arg1['participant'], func.arg2['participant']\r\n                if (obj in prev_subj + prev_obj and subj in prev_obj) :\r\n                    flag = False\r\n            if flag:\r\n                new_funcs.append(sorted_funcs[i])\r\n    # print(new_funcs)\r\n    return new_funcs\r\n\r\ndef merge_funcs_with_and(funcs,tokens,positions):\r\n    if not ('and' in tokens):\r\n        return funcs\r\n    if len(funcs)<2:\r\n        return funcs\r\n    # print(funcs)\r\n    def filter_funcs(sorted_funcs, sorted_positions):\r\n        drop = []\r\n        prev_subj, prev_obj = [],[]\r\n        all_func_type = []\r\n        for i, func in enumerate(sorted_funcs):\r\n            if (type(func), sorted_positions[i]) not in all_func_type:\r\n                all_func_type.append((type(func), sorted_positions[i]))\r\n        for type_idx, func_type in enumerate(all_func_type):\r\n            for i, func in enumerate(sorted_funcs):\r\n                flag = True\r\n                if (type(func), sorted_positions[i]) != func_type:\r\n                    continue\r\n                max_pos = max(list(func.arg1['position'])+list(func.arg2['position']))\r\n                if type_idx!=len(all_func_type)-1:\r\n                    next_pos = min(all_func_type[type_idx+1][1])\r\n                    if max_pos >= next_pos:\r\n                        drop.append(i)\r\n                        flag = False\r\n                if any([isinstance(func, tmp) for tmp in [BEFORE, LAST]]):\r\n                    subj, obj = func.arg2['participant'], func.arg1['participant']\r\n                else:\r\n                    subj, obj = func.arg1['participant'], func.arg2['participant']\r\n                if subj in prev_obj:\r\n                    drop.append(i)\r\n                    flag = False\r\n                if flag:\r\n                    prev_subj.append(subj)\r\n                    prev_obj.append(obj)\r\n            # if any([isinstance(sorted_funcs[-1], tmp) for tmp in [BEFORE, LAST]]):\r\n            #     subj, obj = sorted_funcs[-1].arg2['participant'], sorted_funcs[-1].arg1['participant']\r\n            # else:\r\n            #     subj, obj = sorted_funcs[-1].arg1['participant'], sorted_funcs[-1].arg2['participant']\r\n            # if subj in prev_obj:\r\n            #     drop.append(len(sorted_funcs)-1)\r\n        output_funcs = []\r\n        for i,func in enumerate(sorted_funcs):\r\n            if i not in drop:\r\n                output_funcs.append(func)\r\n        return output_funcs\r\n\r\n    and_pos = [idx for idx in range(len(tokens)) if tokens[idx] == 'and']\r\n    # no_process_funcs = [fun for fun in funcs if (isinstance(fun,OR) or isinstance(fun,IFTHEN))]\r\n    # rest_funcs = [fun for fun in funcs if fun not in no_process_funcs]\r\n    positions = [(i, positions[i]) for i in range(len(positions))]\r\n    sorted_positions = sorted(positions, key=lambda k: max(k[1]))\r\n    sorted_funcs = [funcs[tmp[0]] for tmp in sorted_positions]\r\n    rest_func = []\r\n    for i in range(len(sorted_funcs)):\r\n        if any([isinstance(sorted_funcs[i], tmp) for tmp in [OR, IFTHEN, IFF,AND,UNLESS]]):\r\n            rest_func.append(sorted_funcs[i])\r\n            sorted_funcs.pop(i)\r\n            sorted_positions.pop(i)\r\n    # sorted_funcs = sorted(rest_funcs,key=lambda k:max(k.arg1['position']))\r\n    sorted_positions = [pos[1] for pos in sorted_positions]\r\n\r\n    sorted_funcs = filter_funcs(sorted_funcs, sorted_positions)\r\n    prev_rule_set, after_rule_set = [], []\r\n    new_funcs = []\r\n    for pos in and_pos:\r\n        for i, func in enumerate(sorted_funcs):\r\n            all_arg = [func.arg1, func.arg2]\r\n            end_pos = max([max(arg['position']) for arg in all_arg])\r\n            if end_pos > pos:\r\n                after_rule_set.append(func)\r\n            else:\r\n                prev_rule_set.append(func)\r\n        # print(prev_rule_set,after_rule_set)\r\n        new_funcs.append(\r\n            AND(copy.deepcopy(prev_rule_set), copy.deepcopy(after_rule_set), func.participants_name, func.column_names))\r\n\r\n    # print(new_funcs + rest_func)\r\n    return new_funcs + rest_func\r\ndef merge_funcs_with_neither(funcs,tokens,positions):\r\n    if ('neither' in tokens or 'Neither' in tokens) and 'nor' in tokens:\r\n        all_funcs =[]\r\n        neither_func, nor_func = [],[]\r\n        if 'neither' in tokens:\r\n            neither_pos = tokens.index('neither')\r\n        if 'Neither' in tokens:\r\n            neither_pos = tokens.index('Neither')\r\n        nor_pos = tokens.index('nor')\r\n        neither_part = range(neither_pos,nor_pos+1)\r\n        nor_part = range(nor_pos,len(tokens))\r\n        for i,func in enumerate(funcs):\r\n            min_pos = min(list(positions[i]))\r\n            max_pos = max(list(positions[i]))\r\n            if min_pos in neither_part and max_pos in neither_part:\r\n                neither_func.append(func)\r\n            elif min_pos in nor_part and max_pos in nor_part:\r\n                nor_func.append(func)\r\n        if funcs:\r\n            all_funcs.append(NEITHER(neither_func,nor_func,func.participants_name,func.column_names))\r\n        return all_funcs\r\n    else:\r\n        return funcs\r\ndef merge_funcs_with_unless(funcs,tokens,positions):\r\n    if any([item in ['Unless','unless'] for item in tokens]):\r\n        all_funcs = []\r\n        unless_func,rest_func = [],[]\r\n        if ',' in tokens:\r\n            comma_pos = tokens.index(',')\r\n        else:\r\n            comma_pos = len(tokens)-1\r\n        if 'Unless' in tokens:\r\n            unless_pos = tokens.index('Unless')\r\n            unless_part = (unless_pos,comma_pos+1)\r\n            rest_part = (comma_pos,len(tokens))\r\n        elif 'unless' in tokens:\r\n            unless_pos = tokens.index('unless')\r\n            unless_part = (0,unless_pos)\r\n            rest_part = (comma_pos,len(tokens))\r\n        for i,func in enumerate(funcs):\r\n            min_pos = min(list(positions[i])+list(func.arg2['position'])+list(func.arg1['position']))\r\n            max_pos = max(list(positions[i])+list(func.arg2['position'])+list(func.arg1['position']))\r\n            if min_pos in range(unless_part[0],unless_part[1]) and max_pos in range(unless_part[0],unless_part[1]):\r\n                unless_func.append(func)\r\n            elif min_pos in range(rest_part[0],rest_part[1]) and max_pos in range(rest_part[0],rest_part[1]):\r\n                rest_func.append(func)\r\n        if funcs:\r\n            all_funcs.append(UNLESS(unless_func,rest_func,func.participants_name,func.column_names))\r\n        return all_funcs\r\n    else:\r\n        return funcs\r\n\r\ndef merge_funcs_with_iff(funcs,tokens,ifpos,thenpos,positions):\r\n\r\n    new_func = []\r\n    p_part = list(range(0,ifpos+1))#tokens[:ifpos+1]\r\n    q_part = list(range(thenpos,len(tokens)))#tokens[thenpos:]\r\n    p_func,q_func = [],[]\r\n    sorted_funcs = sorted(funcs, key=lambda k: max(k.arg1['position']))\r\n    pq_flag = [True for i in range(len(funcs))]\r\n    for i,func in enumerate(sorted_funcs):\r\n        pos = positions[i]\r\n        if (min(pos) in p_part or max(pos) in p_part) and (min(func.arg1['position']+func.arg2['position']) in p_part and max(func.arg1['position']+func.arg2['position']) in p_part):\r\n            p_func.append(func)\r\n        elif (min(pos) in q_part or max(pos) in q_part) and (min(func.arg1['position']+func.arg2['position']) in q_part and max(func.arg1['position']+func.arg2['position']) in q_part):\r\n            q_func.append(func)\r\n    if sorted_funcs:\r\n        new_func.append(IFF(p_func,q_func,sorted_funcs[0].participants_name,sorted_funcs[0].column_names))\r\n    return new_func\r\n\r\n\r\ndef merge_funcs_with_or(funcs,tokens,positions):\r\n    if not ('or' in tokens):\r\n        return funcs\r\n    new_funcs = []\r\n    if len(funcs)<2:\r\n        return funcs\r\n    # print(funcs)\r\n\r\n    or_pos = [idx for idx in range(len(tokens)) if tokens[idx]=='or']\r\n    # no_process_funcs = [fun for fun in funcs if (isinstance(fun,OR) or isinstance(fun,IFTHEN))]\r\n    # rest_funcs = [fun for fun in funcs if fun not in no_process_funcs]\r\n    positions = [(i,positions[i]) for i in range(len(positions))]\r\n    sorted_positions = sorted(positions,key=lambda k: max(k[1]))\r\n    sorted_funcs = [funcs[tmp[0]] for tmp in sorted_positions]\r\n    rest_func = []\r\n    for i in range(len(sorted_funcs)):\r\n        if any([isinstance(sorted_funcs[i],tmp) for tmp in [OR,IFTHEN,IFF]]):\r\n            rest_func.append(sorted_funcs[i])\r\n            sorted_funcs.pop(i)\r\n            sorted_positions.pop(i)\r\n    # sorted_funcs = sorted(rest_funcs,key=lambda k:max(k.arg1['position']))\r\n    sorted_positions = [pos[1] for pos in sorted_positions]\r\n    sorted_funcs = filter_func('or',sorted_funcs,sorted_positions,tokens)\r\n    prev_rule_set, after_rule_set = [], []\r\n    new_funcs = []\r\n    for pos in or_pos:\r\n        for i, func in enumerate(sorted_funcs):\r\n            all_arg = [func.arg1, func.arg2]\r\n            end_pos = max([max(arg['position']) for arg in all_arg])\r\n            if end_pos > pos:\r\n                after_rule_set.append(func)\r\n            else:\r\n                prev_rule_set.append(func)\r\n        if (len(after_rule_set)==2 and not prev_rule_set) or (len(prev_rule_set)==2 and not after_rule_set):\r\n            if after_rule_set:\r\n                prev_rule_set = [after_rule_set[0]]\r\n                after_rule_set.pop(0)\r\n            elif prev_rule_set:\r\n                after_rule_set = [prev_rule_set[0]]\r\n                prev_rule_set.pop(0)\r\n        # print(prev_rule_set,after_rule_set)\r\n        new_funcs.append(OR(copy.deepcopy(prev_rule_set), copy.deepcopy(after_rule_set), func.participants_name, func.column_names))\r\n    return new_funcs + rest_func\r\n\r\n\r\n\r\nclass Node(NodeMixin):\r\n    def __init__(self, name, assignments, ents, parent=None, children=None):\r\n        super(Node, self).__init__()\r\n        self.name = name\r\n        self.assignment = copy.deepcopy(assignments)\r\n\r\n        self.ents = ents\r\n        self.parent = parent\r\n        if children:\r\n            self.children = children\r\n    def __repr__(self):\r\n        return '{}'.format(list(set(self.assignment)))\r\n\r\nclass RuleTree():\r\n    def __init__(self,rows,columns,rules,old_assignments,question_type):\r\n        super(RuleTree, self).__init__()\r\n        self.original_assign = old_assignments\r\n        self.rows = rows\r\n        self.columns = columns\r\n        self.rules = rules\r\n        self.root = None\r\n        self.question_type=question_type\r\n\r\n    def obtain_value(self,assignments):\r\n        ents = [set() for i in range(len(assignments))]\r\n        for i,a in enumerate(assignments):\r\n            for item in a:\r\n                ents[i].add(item[0])\r\n                ents[i].add(item[1])\r\n\r\n        return assignments,list(ents)\r\n\r\n    def obtain_root_and_construct_tree(self):\r\n        begin_status, ents = self.obtain_value(self.original_assign)\r\n        self.root = Node('root', [], [])\r\n        children = []\r\n        # print(begin_status)\r\n        for id,(status, ent) in enumerate(zip(begin_status,ents)):\r\n            child = Node(' '.join(ent)+str(id), list(set(status)),\r\n                         list(set(ent)),parent=self.root)\r\n            children.append(child)\r\n        rule_id = 0\r\n        if children:\r\n            for subroot in children:\r\n                self.construct_sub_tree(subroot,rule_id)\r\n        else:\r\n            subroot = Node(' ', [],\r\n                         [],parent=self.root)\r\n            self.construct_sub_tree(subroot, rule_id)\r\n        # print('total number of leaf nodes {}'.format(len(self.obtain_leaf_nodes())))\r\n        # print(RenderTree(self.root))\r\n        final_leaf = []\r\n        each_level_node = [[] for i in range(len(self.rules)+1)]\r\n        # print(RenderTree(self.root))\r\n        for node in LevelOrderIter(self.root):\r\n            each_level_node[node.depth-1].append(node)\r\n            if node.depth == len(self.rules)+1:\r\n                final_leaf.append(node)\r\n\r\n        return final_leaf,each_level_node\r\n        # print(self.obtain_leaf_nodes())\r\n\r\n    def construct_sub_tree(self,root,rule_id):\r\n        if rule_id==len(self.rules):\r\n            return\r\n        rule = self.rules[rule_id]\r\n        # print(rule)\r\n        assignment, new_ents = rule.find_assignment(root.assignment, root.ents, self.question_type)\r\n        # if conflict:\r\n        #     del root\r\n        #     return output\r\n        rule_id = rule_id + 1\r\n        childrens = self.update_nodes(root,assignment, new_ents)\r\n        for child in childrens:\r\n            self.construct_sub_tree(child,rule_id)\r\n\r\n\r\n    def update_nodes(self,root,new_assignment, new_ents):\r\n        previous_assignment = root.assignment\r\n        children = []\r\n        for id,assign in enumerate(new_assignment):\r\n            child = Node(' '.join(root.ents+new_ents)+str(id), list(set(previous_assignment+assign)),\r\n                         list(set(root.ents+new_ents)),parent=root)\r\n            children.append(child)\r\n        return children\r\n\r\n    def obtain_leaf_nodes(self):\r\n        return self.root.leaves\r\n\r\nclass Rule():\r\n    def __init__(self,arg1,arg2,all_pars,all_cols):\r\n        super(Rule, self).__init__()\r\n        self.conditions = []\r\n        self.results = []\r\n        self.participants = []\r\n        self.columns = []\r\n        self.participants_name = all_pars\r\n        self.column_names = all_cols\r\n        self.arg1 = arg1 if arg1 else None\r\n        self.arg2 = arg2 if arg2 else None\r\n        # self.position = position\r\n\r\n\r\n    def __repr__(self):\r\n        output = self.__class__.__name__+ ':\\n'\r\n        if self.arg1 and self.arg2:\r\n            output_dict = {'arguments':[self.arg1['participant'],self.arg2['participant']]}\r\n        else:\r\n            output_dict = {'arguments': [self.arg1, self.arg2]}\r\n\r\n        output += json.dumps(output_dict,indent=4)+'\\n'\r\n        return output\r\n        # return str({\r\n        #     'participants':[self.participants_name[i] for i in self.participants],\r\n        #     'columns':[self.column_names[i] for i in self.columns]\r\n        # })\r\n    def find_ent_related(self,ent,old_assignment):\r\n        ent_assign = []\r\n        non_empty  =[]\r\n        assign_flag = False\r\n        for assign in old_assignment:\r\n            if assign[2]:\r\n                non_empty.append(assign[1])\r\n            if ent in assign:\r\n                ent_assign.append(assign)\r\n                if assign[2]:\r\n                    assign_flag = True#assign flag is used to record whether this entities has been assigned to some space\r\n\r\n        return ent_assign,assign_flag,non_empty\r\n    def generate_new_assign_by_limitation(self,ent,ent_assign,non_empty,old_assignment):\r\n        news = []\r\n        cant_exist = [item[1] for item in ent_assign if not item[2]] + non_empty\r\n        rest_col = [item for item in self.column_names if item not in cant_exist]\r\n        for col in rest_col:\r\n            for assign in old_assignment:\r\n                news.append(assign+[(ent,col,True)])\r\n                for col2 in self.column_names:\r\n                    if col2!=col:\r\n                        news[-1].append((ent,col,False))\r\n        return news\r\n    def find_assignment(self,old_assignment, old_ents,question_type):\r\n        new_pars = []\r\n        new_cols = []\r\n        now_assignments=[]\r\n        for ent in self.participants:\r\n            if ent not in old_ents:\r\n                new_pars.append(ent)\r\n            else:\r\n                ent_assign, assign_flag, non_empty = self.find_ent_related(ent, old_assignment)\r\n                if not now_assignments and not assign_flag:\r\n                    now_assignments = self.generate_new_assign_by_limitation(ent, ent_assign, non_empty, [old_assignment])\r\n                elif now_assignments and not assign_flag:\r\n                    now_assignments = self.generate_new_assign_by_limitation(ent, ent_assign, non_empty,\r\n                                                                             now_assignments)\r\n\r\n        for ent in self.columns:\r\n            if ent not in old_ents:\r\n                new_cols.append(ent)\r\n        new_pars = list(set(new_pars))\r\n        new_cols = list(set(new_cols))\r\n        if not now_assignments:\r\n            new_all_possible_assign = self.generate_possible_assignment(new_pars,[old_assignment],question_type)\r\n        else:\r\n            new_all_possible_assign = self.generate_possible_assignment(new_pars, now_assignments,question_type)\r\n        # print('possible assigment: ',new_all_possible_assign)\r\n        satisfied_assign = self.find_satisfied_assignment(new_all_possible_assign)\r\n        # print('satisfy',satisfied_assign)\r\n        return satisfied_assign,new_pars+new_cols\r\n\r\n    def generate_possible_assignment(self,new_pars,old_assginment,problem_type='ordering'):\r\n        '''\r\n        :param new_pars:\r\n        :param occur: 'once': each participant can occur only in one position, 'multiple': each participant can occur in multiple position\r\n        :return: all possible value of participant regardless of rule\r\n        '''\r\n        all_possible = []\r\n        cache = []\r\n        if not new_pars:\r\n            return old_assginment\r\n        else:\r\n            if problem_type == 'grouping':\r\n                for par in new_pars:\r\n                    # print(cache)\r\n                    tmp = []\r\n                    for col1 in self.column_names:\r\n                        if cache:\r\n                            for item in cache:\r\n                                tmp_item = copy.deepcopy(item)\r\n                                for col2 in self.column_names:\r\n                                    if col1!=col2:\r\n                                        tmp_item.append((par, col2, False))\r\n                                    else:\r\n                                        tmp_item.append((par,  col2,  True))\r\n                                tmp.append(tmp_item)\r\n                        else:\r\n                            one = []\r\n                            for col2 in self.column_names:\r\n                                if col1 != col2:\r\n                                    one.append((par, col2, False))\r\n                                else:\r\n                                    one.append((par, col2, True))\r\n                            tmp.append(one)\r\n                    cache = tmp\r\n                for item in cache:\r\n                    for assign in old_assginment:\r\n                        all_possible.append(assign + item)\r\n            elif problem_type == 'ordering':\r\n                for vv in old_assginment:\r\n                    cache = []\r\n                    exist_col = []\r\n                    for v in vv:\r\n                        if v[2]:\r\n                            exist_col.append(v[1])\r\n                    exist_col = list(set(exist_col))\r\n                    rest_col = [v for v in self.column_names if v not in exist_col]\r\n                    possible_combination = list(itertools.combinations(rest_col, len(new_pars)))\r\n                    for comb in possible_combination:\r\n                        par_permutes = itertools.permutations(new_pars)\r\n                        for permute in par_permutes:\r\n                            tmp = []\r\n                            for pid,par in enumerate(permute):\r\n                                tmp.append((par,comb[pid],True))\r\n                                for col in self.column_names:\r\n                                    if col!=comb[pid]:\r\n                                        tmp.append((par, col, False))\r\n                            cache.append(tmp)\r\n\r\n                    for item in cache:\r\n                        all_possible.append(vv + item)\r\n                        # for assign in old_assginment:\r\n                        #     all_possible.append(assign+item)\r\n            return all_possible\r\n\r\n    def find_satisfied_assignment(self,new_assignments):\r\n        satisfied_assignment = []\r\n        for v in new_assignments:\r\n            if self.satisfy(v):\r\n                satisfied_assignment.append(v)\r\n        return satisfied_assignment\r\n\r\n    def satisfy(self,assignment):\r\n        #may contain multiple conditions and corresponding results\r\n        flags = []\r\n        cond_flag = []\r\n        for id,condition in enumerate(self.conditions):\r\n            flag = True\r\n            for item in condition:\r\n                item = (item['row'], item['column'],item['value'])\r\n                if item not in assignment:\r\n                    flag=False\r\n            cond_flag.append(flag)\r\n            for item in self.results[id]:\r\n                item = (item['row'], item['column'], item['value'])\r\n                if item not in assignment:\r\n                    flag=False\r\n            flags.append(flag)\r\n\r\n        cond_satisfy = any(cond_flag)\r\n        cond_res_flag = any(flags)\r\n        # if self.__class__.__name__ == 'IFTHEN':\r\n        #     return (not cond_satisfy) or cond_res_flag\r\n        # else:\r\n        return cond_res_flag\r\n\r\n    def find_option_assignment(self):\r\n        all_assignments = []\r\n        for i, cond in enumerate(self.conditions):\r\n            all_assignments.append(self.conditions[i]+self.results[i])\r\n        return all_assignments\r\n\r\n\r\n\r\n'''\r\ntmp = {'participant': res.group(),\r\n                           'position': (c2t[min(res.span())], c2t[max(res.span()) - 1]),\r\n                           'type': 'row', 'idx': pidx}\r\n'''\r\ndef append_ent(par_lst,col_lst,arg1,arg2):\r\n    if arg1['type']=='row':\r\n        par_lst.append(arg1['participant'])\r\n    elif arg1['type']=='column':\r\n        col_lst.append(arg1['participant'])\r\n    if arg2['type']=='row':\r\n        par_lst.append(arg2['participant'])\r\n    elif arg2['type']=='column':\r\n        col_lst.append(arg2['participant'])\r\n    par_lst = list(set(par_lst))\r\n    col_lst = list(set(col_lst))\r\n    return par_lst,col_lst\r\n\r\n\r\n\r\nclass TO(Rule):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n        super(TO, self).__init__(arg1,arg2,all_pars,all_cols)\r\n        self.arg1 = arg1\r\n        self.arg2 = arg2\r\n        self.conditions = [[]]\r\n        row_idx = arg1['participant'] if arg1['type'] == 'row' else arg2['participant']\r\n        col_idx = arg1['participant'] if arg1['type'] == 'column' else arg2['participant']\r\n        self.participants,self.columns = append_ent(self.participants,self.columns,arg1,arg2)\r\n        v = False if negation else True\r\n        self.results.append([{'row':row_idx,'column':col_idx,'value':v}])\r\n        # print(self.results)\r\n\r\nclass DIFFERENT(Rule):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n\r\n        super(DIFFERENT, self).__init__(arg1,arg2,all_pars,all_cols)\r\n\r\n        assert(arg1['type']==arg2['type']),'arg1: {}, arg2:{}'.format(arg1,arg2)\r\n        self.participants,self.columns = append_ent(self.participants,self.columns,arg1,arg2)\r\n        if arg1['type'] == 'row': \r\n            for cid,col in enumerate(all_cols):\r\n                for v in [1,-1]:\r\n                        self.conditions.append([{'row':arg1['participant'],'column':col,'value':(v)>0}])\r\n                        self.results.append([{'row': arg2['participant'], 'column': col, 'value':(v)<0 }])\r\n                        self.conditions.append([{'row': arg2['participant'], 'column': col, 'value': (-v)>0}])\r\n                        self.results.append([{'row': arg1['participant'], 'column': col, 'value': (-v)<0}])\r\n        elif arg1['type'] == 'column':\r\n            for rid,row in enumerate(all_pars):\r\n                for v in [1,-1]:\r\n                        self.conditions.append([{'row':row,'column':arg1['participant'],'value':(v)>0}])\r\n                        self.results.append([{'row': row, 'column': arg2['participant'], 'value':(v)<0 }])\r\n                        self.conditions.append([{'row': row, 'column': arg2['participant'], 'value': (-v)>0}])\r\n                        self.results.append([{'row': row, 'column': arg1['participant'], 'value': (-v)<0}])\r\n\r\n\r\n\r\nclass SAME(Rule):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n        super(SAME, self).__init__(arg1,arg2,all_pars,all_cols)\r\n        assert (arg1['type'] == arg2['type']), 'arg1: {}, arg2:{}'.format(arg1, arg2)\r\n        self.participants, self.columns = append_ent(self.participants, self.columns, arg1, arg2)\r\n        if arg1['type'] == 'row':\r\n            for cid, col in enumerate(all_cols):\r\n                for v in [1,-1]:\r\n                    self.conditions.append([{'row': arg1['participant'], 'column': col, 'value': (v)>0}])\r\n                    self.results.append([{'row': arg2['participant'], 'column': col, 'value': (v)>0}])\r\n                    self.conditions.append([{'row': arg2['participant'], 'column': col, 'value': (v)<0}])\r\n                    self.results.append([{'row': arg1['participant'], 'column': col, 'value': (v)<0}])\r\n        elif arg1['type'] == 'column':\r\n            for rid, row in enumerate(all_pars):\r\n                for v in [1,-1]:\r\n                    self.conditions.append([{'row': row, 'column': arg1['participant'], 'value': (v)>0}])\r\n                    self.results.append([{'row': row, 'column': arg2['participant'], 'value': (v)>0}])\r\n                    self.conditions.append([{'row': row, 'column': arg2['participant'], 'value': (v)<0}])\r\n                    self.results.append([{'row': row, 'column': arg1['participant'], 'value': (v)<0}])\r\n\r\nclass NEXT(Rule):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n        super(NEXT, self).__init__(arg1,arg2,all_pars,all_cols)\r\n        # print(arg1,arg2)\r\n        assert (arg1['type'] == arg2['type']), 'arg1: {}, arg2:{}'.format(arg1, arg2)\r\n        self.participants, self.columns = append_ent(self.participants, self.columns, arg1, arg2)\r\n        #the column must be sorted\r\n\r\n    def satisfy(self,assignment):\r\n        arg1_pos, arg2_pos = None, None\r\n        for item in assignment:\r\n            if self.arg1['participant'] in item and item[2]:\r\n                arg1_pos = self.column_names.index(item[1])\r\n            if self.arg2['participant'] in item and item[2]:\r\n                arg2_pos = self.column_names.index(item[1])\r\n        if arg1_pos is not None and arg2_pos is not None:\r\n            return arg2_pos == arg1_pos-1\r\n        elif arg1_pos == 0:\r\n            return False\r\n        elif arg2_pos == len(self.column_names) - 1:\r\n            return False\r\n        else:\r\n            return True\r\n\r\nclass LAST(NEXT):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n        super(LAST, self).__init__(arg2,arg1,negation,all_pars,all_cols)\r\n\r\nclass ADJACENT(Rule):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n        super(ADJACENT, self).__init__(arg1,arg2,all_pars,all_cols)\r\n        # print(arg1,arg2)\r\n        assert (arg1['type'] == arg2['type']), 'arg1: {}, arg2:{}'.format(arg1, arg2)\r\n        self.participants, self.columns = append_ent(self.participants, self.columns, arg1, arg2)\r\n        #the column must be sorted\r\n\r\n    def satisfy(self,assignment):\r\n        arg1_pos, arg2_pos = None, None\r\n        for item in assignment:\r\n            if self.arg1['participant'] in item and item[2]:\r\n                arg1_pos = self.column_names.index(item[1])\r\n            if self.arg2['participant'] in item and item[2]:\r\n                arg2_pos = self.column_names.index(item[1])\r\n        if arg1_pos is not None and arg2_pos is not None:\r\n            return arg2_pos == arg1_pos-1 or arg2_pos == arg1_pos+1\r\n        else:\r\n            return True\r\n\r\n\r\nclass AFTER(Rule):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n        super(AFTER, self).__init__(arg1,arg2,all_pars,all_cols)\r\n        # assert (arg1['type'] == arg2['type']), 'arg1: {}, arg2:{}'.format(arg1, arg2)\r\n        if arg1['type'] == arg2['type']:\r\n            self.process_type = 'same_type'\r\n        else:\r\n            self.process_type = 'different_type'\r\n        self.participants, self.columns = append_ent(self.participants, self.columns, arg1, arg2)\r\n\r\n    def satisfy(self,assignment):\r\n        if self.process_type == 'same_type':\r\n            arg1_pos, arg2_pos = None,None\r\n            for item in assignment:\r\n                if self.arg1['participant'] in item and item[2]:\r\n                    arg1_pos = self.column_names.index(item[1])\r\n                if self.arg2['participant'] in item and item[2]:\r\n                    arg2_pos = self.column_names.index(item[1])\r\n            if arg1_pos is not None and arg2_pos is not None:\r\n                return arg2_pos < arg1_pos\r\n            elif arg1_pos==0:\r\n                return False\r\n            elif arg2_pos==len(self.column_names)-1:\r\n                return False\r\n            else:\r\n                return True\r\n        elif self.process_type=='different_type':\r\n            arg1_pos, arg2_pos = None, None\r\n            for item in assignment:\r\n                if self.arg1['participant'] in item and item[2]:\r\n                    rest_ent = item[1] if item[1] != self.arg1['participant'] else item[0]\r\n                    arg1_pos = self.column_names.index(rest_ent) if self.arg1['type'] == 'row' else self.participants_name.index(rest_ent)\r\n\r\n                if self.arg2['participant'] in item and item[2]:\r\n                    rest_ent = item[1] if item[1] != self.arg2['participant'] else item[0]\r\n                    arg2_pos = self.column_names.index(rest_ent) if self.arg2['type'] == 'row' else self.participants_name.index(rest_ent)\r\n            if arg1_pos is not None and arg2_pos is not None:\r\n                return arg2_pos < arg1_pos\r\n            elif arg1_pos == 0:\r\n                return False\r\n            elif arg2_pos == len(self.column_names) - 1:\r\n                return False\r\n            else:\r\n                return True\r\n\r\nclass BEFORE(AFTER):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n        super(BEFORE, self).__init__(arg2,arg1,negation,all_pars,all_cols)\r\n\r\n\r\n\r\nclass BeforeEqual(Rule):\r\n    def __init__(self,arg1,arg2,negation,all_pars,all_cols):\r\n        super(BeforeEqual, self).__init__(arg1,arg2,all_pars,all_cols)\r\n        # assert (arg1['type'] == arg2['type']), 'arg1: {}, arg2:{}'.format(arg1, arg2)\r\n        if arg1['type'] != arg2['type']:\r\n            self.process_type = 'same_type'\r\n        else:\r\n            self.process_type = 'different_type'\r\n        self.participants, self.columns = append_ent(self.participants, self.columns, arg1, arg2)\r\n\r\n    def satisfy(self,assignment):\r\n        if self.process_type == 'same_type':\r\n            arg1_pos, arg2_pos = None,None\r\n            for item in assignment:\r\n                if self.arg1['participant'] in item and item[2]:\r\n                    arg1_pos = self.column_names.index(item[1])\r\n                if self.arg2['participant'] in item and item[2]:\r\n                    arg2_pos = self.column_names.index(item[1])\r\n            if arg1_pos is not None and arg2_pos is not None:\r\n                return arg2_pos >= arg1_pos\r\n            elif arg2_pos==0:\r\n                return False\r\n            elif arg1_pos==len(self.column_names)-1:\r\n                return False\r\n            else:\r\n                return True\r\n        elif self.process_type=='different_type':\r\n            arg1_pos, arg2_pos = None, None\r\n            for item in assignment:\r\n                if self.arg1['participant'] in item and item[2]:\r\n                    rest_ent = item[1] if item[1] != self.arg1['participant'] else item[0]\r\n                    arg1_pos = self.column_names.index(rest_ent) if self.arg1['type'] == 'row' else self.participants_name.index(rest_ent)\r\n\r\n                if self.arg2['participant'] in item and item[2]:\r\n                    rest_ent = item[1] if item[1] != self.arg2['participant'] else item[0]\r\n                    arg2_pos = self.column_names.index(rest_ent) if self.arg2['type'] == 'row' else self.participants_name.index(rest_ent)\r\n            if arg1_pos is not None and arg2_pos is not None:\r\n                return arg2_pos >= arg1_pos\r\n            elif arg2_pos == 0:\r\n                return False\r\n            elif arg1_pos == len(self.column_names) - 1:\r\n                return False\r\n            else:\r\n                return True\r\n\r\nclass LastNum(Rule):\r\n    def __init__(self, close_ent, num, all_pars, all_cols):\r\n        super(LastNum, self).__init__(None, None, all_pars, all_cols)\r\n        self.ent = close_ent\r\n        self.num = num\r\n        if self.ent['participant'] not in self.participants:\r\n            self.participants.append(self.ent['participant'])\r\n    def satisfy(self,assignment):\r\n        ent_pos = None\r\n        # print(assignment,self.ent)\r\n        for item in assignment:\r\n            if self.ent['participant'] in item and item[2]:\r\n                ent_pos = self.column_names.index(item[1])\r\n        # print(range(len(self.column_names)-self.num,len(self.column_names)))\r\n        # print(self.num)\r\n        if (ent_pos in list(range(len(self.column_names)-self.num,len(self.column_names)))): #or ent_pos is None:\r\n            # print(ent_pos, assignment)\r\n            return True\r\n        else:\r\n            return False\r\n\r\nclass FirstNum(Rule):\r\n    def __init__(self, close_ent, num, all_pars, all_cols):\r\n        super(FirstNum, self).__init__(None, None, all_pars, all_cols)\r\n        self.ent = close_ent\r\n        self.num = num\r\n        if self.ent['participant'] not in self.participants:\r\n            self.participants.append(self.ent['participant'])\r\n    def satisfy(self,assignment):\r\n        ent_pos = None\r\n\r\n        for item in assignment:\r\n            if self.ent['participant'] in item and item[2]:\r\n                ent_pos = self.column_names.index(item[1])\r\n        if (ent_pos in range(0,self.num)):# or ent_pos is None:\r\n            # print(ent_pos,assignment)\r\n            return True\r\n        else:\r\n            return False\r\n\r\n# class BEFORE(NEXT):\r\n#     def __init__(self,arg1,arg2,all_pars,all_cols):\r\n#         super(BEFORE, self).__init__(arg2,arg1,all_pars,all_cols)\r\nclass AND(Rule):\r\n    def __init__(self,prev_rule_set,after_rule_set,all_pars,all_cols):\r\n        super(AND, self).__init__(None,None,all_pars,all_cols)\r\n        self.prev_rule_set = prev_rule_set\r\n        self.after_rule_set = after_rule_set\r\n        for rule in self.prev_rule_set+self.after_rule_set:\r\n            self.participants.extend(rule.participants)\r\n            self.columns.extend(rule.columns)\r\n        self.participants = list(set((self.participants)))\r\n        self.columns = list(set(self.columns))\r\n\r\n    def satisfy(self,assignment):\r\n        count = 0\r\n        prev_satisfy = []\r\n        after_satisfy = []\r\n        for rule in self.prev_rule_set:\r\n            if rule.satisfy(assignment):\r\n                prev_satisfy.append(True)\r\n            else:\r\n                prev_satisfy.append(False)\r\n        for rule in self.after_rule_set:\r\n            if rule.satisfy(assignment):\r\n                after_satisfy.append(True)\r\n            else:\r\n                after_satisfy.append(False)\r\n        if all(prev_satisfy) and all(after_satisfy):\r\n            return True\r\n        else:\r\n            return False\r\nclass OR(Rule):\r\n    def __init__(self,prev_rule_set,after_rule_set,all_pars,all_cols):\r\n        super(OR, self).__init__(None,None,all_pars,all_cols)\r\n        self.prev_rule_set = prev_rule_set\r\n        self.after_rule_set = after_rule_set\r\n        for rule in self.prev_rule_set+self.after_rule_set:\r\n            self.participants.extend(rule.participants)\r\n            self.columns.extend(rule.columns)\r\n        self.participants = list(set((self.participants)))\r\n        self.columns = list(set(self.columns))\r\n\r\n    def satisfy(self,assignment):\r\n        count = 0\r\n        prev_satisfy = []\r\n        after_satisfy = []\r\n        for rule in self.prev_rule_set:\r\n            if rule.satisfy(assignment):\r\n                prev_satisfy.append(True)\r\n            else:\r\n                prev_satisfy.append(False)\r\n        for rule in self.after_rule_set:\r\n            if rule.satisfy(assignment):\r\n                after_satisfy.append(True)\r\n            else:\r\n                after_satisfy.append(False)\r\n        if all(prev_satisfy):\r\n            count+=1\r\n        if all(after_satisfy):\r\n            count+=1\r\n        return count == 1\r\n\r\nclass UNLESS(Rule):\r\n    def __init__(self,unless_rules,rest_rules,all_parts,all_cols):\r\n        super(UNLESS, self).__init__(None,None,all_parts,all_cols)\r\n        self.unless_rule_set = unless_rules\r\n        self.rest_rule_set = rest_rules\r\n        for rule in self.unless_rule_set+self.rest_rule_set:\r\n            self.participants.extend(rule.participants)\r\n            self.columns.extend(rule.columns)\r\n        self.participants = list(set(self.participants))\r\n        self.columns = list(set(self.columns))\r\n\r\n    def satisfy(self,assignment):\r\n        unless_satisfy = []\r\n        res_satisfy = []\r\n        for rule in self.unless_rule_set:\r\n            unless_satisfy.append(rule.satisfy(assignment))\r\n        for rule in self.rest_rule_set:\r\n            res_satisfy.append(rule.satisfy(assignment))\r\n        if all(unless_satisfy):\r\n            return True\r\n        elif (not all(unless_satisfy)) and all(res_satisfy):\r\n            return True\r\n        else:\r\n            return False\r\n\r\n\r\nclass NEITHER(Rule):\r\n    def __init__(self,neither_rules,nor_rules,all_parts,all_cols):\r\n        super(NEITHER, self).__init__(None,None,all_parts,all_cols)\r\n        self.neither_rule_set = neither_rules\r\n        self.nor_rule_set = nor_rules\r\n        for rule in self.neither_rule_set+self.nor_rule_set:\r\n            self.participants.extend(rule.participants)\r\n            self.columns.extend(rule.columns)\r\n        self.participants = list(set(self.participants))\r\n        self.columns = list(set(self.columns))\r\n\r\n    def satisfy(self,assignment):\r\n        neither_satisfy = []\r\n        nor_satisfy = []\r\n        for rule in self.neither_rule_set:\r\n            neither_satisfy.append(rule.satisfy(assignment))\r\n        for rule in self.nor_rule_set:\r\n            nor_satisfy.append(rule.satisfy(assignment))\r\n        if not all(neither_satisfy) and not all(nor_satisfy):\r\n            return True\r\n        else:\r\n            return False\r\nclass IFF(Rule):\r\n    def __init__(self,p_rules,q_rules,all_parts,all_cols):\r\n        super(IFF,self).__init__(None,None,all_parts,all_cols)\r\n        self.p_rule_set = p_rules\r\n        self.q_rule_set = q_rules\r\n        # print(self.if_rule_set+self.then_rule_set)\r\n        for rule in self.p_rule_set+self.q_rule_set:\r\n            self.participants.extend(rule.participants)\r\n            self.columns.extend(rule.columns)\r\n        self.participants = list(set(self.participants))\r\n        self.columns = list(set(self.columns))\r\n\r\n    def satisfy(self,assignment):\r\n        cond_satisfy = []\r\n        res_satisfy = []\r\n        for rule in self.p_rule_set:\r\n            cond_satisfy.append(rule.satisfy(assignment))\r\n        for rule in self.q_rule_set:\r\n            res_satisfy.append(rule.satisfy(assignment))\r\n        flag = all(cond_satisfy) and all(res_satisfy)\r\n        if ((not any(cond_satisfy)) and (not any(res_satisfy))):\r\n            return True\r\n        else:\r\n            return flag\r\n\r\nclass IFTHEN(Rule):\r\n    def __init__(self,if_rules,then_rules,all_parts,all_cols):\r\n        super(IFTHEN,self).__init__(None,None,all_parts,all_cols)\r\n        '''\r\n        complicated:\r\n        if if_rules_set contains 2 rule, and each rule have n,m (cond,res) pair, the condition in if rule set should have n*m conditions\r\n        and then_rules_set contains 2 rule, each rule have p,q (cond,res) pair， the final condition number should be n*m*p*q (cummulatives of all condition+result in ifrule and all condition in then rule)\r\n            have n*m*p*q (cond,res) results pair, each result is the concatenation of result in pair(p_i,q_j) and its repeated n*m times\r\n        '''\r\n        self.if_rule_set = if_rules\r\n        self.then_rule_set = then_rules\r\n        # print(self.if_rule_set+self.then_rule_set)\r\n        for rule in self.if_rule_set+self.then_rule_set:\r\n            self.participants.extend(rule.participants)\r\n            self.columns.extend(rule.columns)\r\n            self.participants = list(set(self.participants))\r\n            self.columns = list(set(self.columns))\r\n\r\n\r\n    def satisfy(self,assignment):\r\n\r\n        cond_satisfy = []\r\n        res_satisfy = []\r\n        for rule in self.if_rule_set:\r\n            cond_satisfy.append(rule.satisfy(assignment))\r\n        for rule in self.then_rule_set:\r\n            res_satisfy.append(rule.satisfy(assignment))\r\n        flag = cond_satisfy and all(cond_satisfy)\r\n        if flag:\r\n            return all(res_satisfy)\r\n        else:\r\n            return True\r\n\r\n",
        "LSTM/main_large.py": "import argparse\nimport logging\nimport os\nimport random\n\nimport numpy as np\nimport torch\nfrom transformers import (\n    WEIGHTS_NAME,\n    AdamW,\n    get_linear_schedule_with_warmup,)\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nfrom torch.utils.data.distributed import DistributedSampler\nfrom tqdm import tqdm, trange\n# from torchtext import data\nfrom torchtext.data import Field\nfrom model import LSATLSTM\nfrom utils_multiple_choice import convert_examples_to_features, processors\n\ntry:\n    from torch.utils.tensorboard import SummaryWriter\nexcept ImportError:\n    from tensorboardX import SummaryWriter\n\nlogger = logging.getLogger(__name__)\n\n\n\ndef init_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        \"--data_dir\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n    )\n    parser.add_argument(\n        \"--model_type\",\n        default=None,\n        type=str,\n        required=True,\n    )\n    parser.add_argument(\n        \"--model_name_or_path\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"Path to pre-trained model or shortcut name selected in the list: \" #+ \", \".join(ALL_MODELS),\n    )\n    parser.add_argument(\n        \"--task_name\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"The name of the task to train\",\n    )\n    parser.add_argument(\n        \"--output_dir\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"The output directory where the model predictions and checkpoints will be written.\",\n    )\n\n    # Other parameters\n    parser.add_argument(\n        \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\"\n    )\n    parser.add_argument(\n        \"--tokenizer_name\",\n        default=\"\",\n        type=str,\n        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n    )\n    parser.add_argument(\n        \"--cache_dir\",\n        default=\"\",\n        type=str,\n        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n    )\n    parser.add_argument(\n        \"--max_seq_length\",\n        default=128,\n        type=int,\n        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n             \"than this will be truncated, sequences shorter will be padded.\",\n    )\n    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n    parser.add_argument(\"--do_test\", action=\"store_true\", help=\"Whether to run test on the test set\")\n    parser.add_argument(\n        \"--evaluate_during_training\", action=\"store_true\", help=\"Run evaluation during training at each logging step.\"\n    )\n    parser.add_argument(\n        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\"\n    )\n\n    parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\")\n    parser.add_argument(\n        \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\"\n    )\n    parser.add_argument(\n        \"--gradient_accumulation_steps\",\n        type=int,\n        default=1,\n        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n    )\n    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight deay if we apply some.\")\n    parser.add_argument('--adam_betas', default='(0.9, 0.999)', type=str, help='betas for Adam optimizer')\n    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n    parser.add_argument(\"--no_clip_grad_norm\", action=\"store_true\", help=\"whether not to clip grad norm\")\n    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n    parser.add_argument(\n        \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\"\n    )\n    parser.add_argument(\n        \"--max_steps\",\n        default=-1,\n        type=int,\n        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n    )\n    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n    parser.add_argument(\"--warmup_proportion\", default=0.0, type=float, help=\"Linear warmup over warmup ratios.\")\n\n    parser.add_argument(\"--logging_steps\", type=int, default=50, help=\"Log every X updates steps.\")\n    parser.add_argument(\"--save_steps\", type=int, default=50, help=\"Save checkpoint every X updates steps.\")\n    parser.add_argument(\n        \"--eval_all_checkpoints\",\n        action=\"store_true\",\n        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n    )\n    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n    parser.add_argument(\n        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\"\n    )\n    parser.add_argument(\n        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\"\n    )\n    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n\n    parser.add_argument(\n        \"--fp16\",\n        action=\"store_true\",\n        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n    )\n    parser.add_argument(\n        \"--fp16_opt_level\",\n        type=str,\n        default=\"O1\",\n        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n             \"See details at https://nvidia.github.io/apex/amp.html\",\n    )\n    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n    parser.add_argument(\"--test_file\", type=str, default=\"\", help=\"file for test\")\n    parser.add_argument(\"--train_file\", type=str, default=\"\", help=\"file for training\")\n    parser.add_argument(\"--dev_file\", type=str, default=\"\", help=\"file for development\")\n    return parser.parse_args()\n\n\ndef set_seed(args):\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    if args.n_gpu > 0:\n        torch.cuda.manual_seed_all(args.seed)\n\n\ndef select_field(features, field):\n    return [[choice[field] for choice in feature.choices_features] for feature in features]\n\n\ndef simple_accuracy(preds, labels):\n    return (preds == labels).mean()\n\n\ndef derive_features_for_model(examples,text_field,processor,args, evaluate=False, test=False, type='ar'):\n    if args.local_rank not in [-1, 0]:\n        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n\n    # Load data features from cache or dataset file\n    if evaluate:\n        cached_mode = \"dev\"+\"_%s\"%type\n    elif test:\n        cached_mode = \"test\"\n        cached_mode = cached_mode + type\n    else:\n        cached_mode = \"train\"+\"_%s\"%type\n    assert not (evaluate and test)\n    cached_features_file = os.path.join(\n        args.data_dir,\n        \"cached_{}_{}_{}_lstm\".format(\n            cached_mode,\n            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n            str(args.max_seq_length),\n        ),\n    )\n\n\n    if os.path.exists(cached_features_file) and not args.overwrite_cache:\n        logger.info(\"Loading features from cached file %s\", cached_features_file)\n        features = torch.load(cached_features_file)\n    else:\n        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n        label_list = processor.get_labels()\n\n        logger.info(\"Training number: %s\", str(len(examples)))\n\n        features = convert_examples_to_features(\n            examples,\n            label_list,\n            args.max_seq_length,\n            text_field\n        )\n        if args.local_rank in [-1, 0]:\n            logger.info(\"Saving features into cached file %s\", cached_features_file)\n            torch.save(features, cached_features_file)\n\n    if args.local_rank == 0:\n        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n\n    # Convert to Tensors and build dataset\n    all_input_ids = torch.tensor([fea.choices_features['input_ids'].numpy() for fea in features], dtype=torch.long)\n    all_input_length = torch.tensor([fea.choices_features['lengths'].numpy() for fea in features], dtype=torch.long)\n    all_label_ids = torch.tensor([f.label for f in features], dtype=torch.long)\n    # print(all_input_ids.size(), all_input_mask.size(), all_segment_ids.size(), all_label_ids.size())\n\n    dataset = TensorDataset(all_input_ids, all_input_length, all_label_ids)\n    return dataset\n\n\n\ndef train(args, train_dataset, val_dataset, model):\n    \"\"\" Train the model \"\"\"\n    if args.local_rank in [-1, 0]:\n        str_list = str(args.output_dir).split('/')\n        tb_log_dir = os.path.join('summaries', str_list[-1])\n        tb_writer = SummaryWriter(tb_log_dir)\n\n    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n    train_sampler = SequentialSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n\n    if args.max_steps > 0:\n        t_total = args.max_steps\n        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n    else:\n        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n\n    # Prepare optimizer and schedule (linear warmup and decay)\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": args.weight_decay,\n        },\n        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n    ]\n    exec('args.adam_betas = ' + args.adam_betas)\n    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, betas=args.adam_betas, eps=args.adam_epsilon)\n    assert not ((args.warmup_steps > 0) and (args.warmup_proportion > 0)), \"--only can set one of --warmup_steps and --warm_ratio \"\n    if args.warmup_proportion > 0:\n        args.warmup_steps = int(t_total * args.warmup_proportion)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n    )\n\n\n    # multi-gpu training (should be after apex fp16 initialization)\n    if args.n_gpu > 1:\n        model = torch.nn.DataParallel(model)\n\n    # Train!\n    logger.info(\"************************* Running training *************************\")\n    logger.info(\"Num examples = %d\", len(train_dataset))\n    logger.info(\"Num Epochs = %d\", args.num_train_epochs)\n    logger.info(\"Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n    logger.info(\n        \"Total train batch size (w. parallel, distributed & accumulation) = %d\",\n        args.train_batch_size\n        * args.gradient_accumulation_steps\n        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n        )\n    # logger.info(\"Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n    logger.info(\"Total optimization steps = %d\", t_total)\n\n    # val_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=True, test=False)\n\n    def evaluate_model(train_preds, train_label_ids, tb_writer, args, model, best_steps, best_dev_acc, val_dataset):\n        train_preds = np.argmax(train_preds, axis=1)\n        train_acc = simple_accuracy(train_preds, train_label_ids)\n        train_preds = None\n        train_label_ids = None\n        results = evaluate(args, model, val_dataset)\n        logger.info(\n            \"dev acc: %s, loss: %s, global steps: %s\",\n            str(results[\"eval_acc\"]),\n            str(results[\"eval_loss\"]),\n            str(global_step),\n        )\n        tb_writer.add_scalar(\"training/acc\", train_acc, global_step)\n        for key, value in results.items():\n            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n        if results[\"eval_acc\"] > best_dev_acc:\n            best_dev_acc = results[\"eval_acc\"]\n            best_steps = global_step\n            logger.info(\"!!!!!!!!!!!!!!!!!!!! achieve BEST dev acc: %s at global step: %s\",\n                        str(best_dev_acc),\n                        str(best_steps)\n                        )\n\n            # if args.do_test:\n            #     results_test, _ = evaluate(args, model, tokenizer, test=True)\n            #     for key, value in results_test.items():\n            #         tb_writer.add_scalar(\"test_{}\".format(key), value, global_step)\n            #     logger.info(\n            #         \"test acc: %s, loss: %s, global steps: %s\",\n            #         str(results_test[\"eval_acc\"]),\n            #         str(results_test[\"eval_loss\"]),\n            #         str(global_step),\n            #     )\n\n            # save best dev acc model\n            # output_dir = os.path.join(args.output_dir, \"checkpoint-best\")\n            output_dir = args.output_dir\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            model_to_save = (\n                model.module if hasattr(model, \"module\") else model\n            )  # Take care of distributed/parallel training\n            logger.info(\"Current local rank %s\", args.local_rank)\n            torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n            logger.info(\"Saving model checkpoint to %s\", output_dir)\n            txt_dir = os.path.join(output_dir, 'best_dev_results.txt')\n            with open(txt_dir, 'w') as f:\n                rs = 'global_steps: {}; dev_acc: {}'.format(global_step, best_dev_acc)\n                f.write(rs)\n                tb_writer.add_text('best_results', rs, global_step)\n\n        logger.info(\"current BEST dev acc: %s at global step: %s\",\n                    str(round(best_dev_acc, 4)),\n                    str(best_steps)\n                    )\n\n        return train_preds, train_label_ids, train_acc, best_steps, best_dev_acc\n\n    # def save_model(args, model, tokenizer):\n    #     output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n    #     if not os.path.exists(output_dir):\n    #         os.makedirs(output_dir)\n    #     model_to_save = (\n    #         model.module if hasattr(model, \"module\") else model\n    #     )  # Take care of distributed/parallel training\n    #     model_to_save.save_pretrained(output_dir)\n    #     tokenizer.save_vocabulary(output_dir)\n    #     tokenizer.save_pretrained(output_dir)\n    #     torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n    #     logger.info(\"Saving model checkpoint to %s\", output_dir)\n\n    global_step = 0\n    tr_loss, logging_loss = 0.0, 0.0\n    best_dev_acc = 0.0\n    best_steps = 0\n    train_preds = None\n    train_label_ids = None\n    model.zero_grad()\n    # train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n    set_seed(args)  # Added here for reproductibility\n    for epoch_index in range(int(args.num_train_epochs)):\n        logger.info('')\n        logger.info('%s Epoch: %d %s', '*'*50, epoch_index, '*'*50)\n        # epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n        for step, batch in enumerate(train_dataloader):\n            model.train()\n            batch = tuple(t.to(args.device) for t in batch)\n            inputs = {\n                \"inputs\": batch[0],\n                'seq_lengths':batch[1],\n                \"labels\": batch[2],\n            }\n            outputs = model(**inputs)\n            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n            logits = outputs[1]\n\n            # print(outputs[2][0].size())\n            # print(outputs[2][1].size())\n\n            ################# work only gpu = 1 ######################\n            if train_preds is None:\n                train_preds = logits.detach().cpu().numpy()\n                train_label_ids = inputs['labels'].detach().cpu().numpy()\n            else:\n                train_preds = np.append(train_preds, logits.detach().cpu().numpy(), axis=0)\n                train_label_ids = np.append(train_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n            ###########################################################\n\n            if args.n_gpu > 1:\n                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n            if args.gradient_accumulation_steps > 1:\n                loss = loss / args.gradient_accumulation_steps\n\n            if args.fp16:\n                with amp.scale_loss(loss, optimizer) as scaled_loss:\n                    scaled_loss.backward()\n                if not args.no_clip_grad_norm:\n                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n            else:\n                loss.backward()\n                if not args.no_clip_grad_norm:\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n\n            tr_loss += loss.item()\n\n            if step % 20 == 0:\n                logger.info(\"********** Iteration %d: current loss: %s\", step, str(round(loss.item(), 4)),)\n\n            if (step + 1) % args.gradient_accumulation_steps == 0:\n                optimizer.step()\n                scheduler.step()  # Update learning rate schedule\n                model.zero_grad()\n                # optimizer.zero_grad()\n                global_step += 1\n\n                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n                    # if (args.local_rank == -1 and args.evaluate_during_training):  # Only evaluate when single GPU otherwise metrics may not average well\n                    if args.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well\n                        train_preds, train_label_ids, train_acc, best_steps, best_dev_acc = evaluate_model(train_preds, train_label_ids, tb_writer, args, model,  best_steps, best_dev_acc, val_dataset)\n                        # tb_writer.add_scalar(\"training/lr\", scheduler.get_lr()[0], global_step)\n                        tb_writer.add_scalar(\"training/lr\", scheduler.get_lr()[0], global_step)\n                        tb_writer.add_scalar(\"training/loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n                        logger.info(\n                            \"Average loss: %s, average acc: %s at global step: %s\",\n                            str((tr_loss - logging_loss) / args.logging_steps),\n                            str(train_acc),\n                            str(global_step),\n                        )\n                        logging_loss = tr_loss\n\n                # if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n                #     save_model(args, model, tokenizer)\n            if args.max_steps > 0 and global_step > args.max_steps:\n                epoch_iterator.close()\n                break\n        if args.max_steps > 0 and global_step > args.max_steps:\n            # train_iterator.close()\n            break\n\n    if args.local_rank in [-1, 0] and train_preds is not None:\n        train_preds, train_label_ids, train_acc, best_steps, best_dev_acc = evaluate_model(train_preds, train_label_ids, tb_writer, args, model, best_steps, best_dev_acc, val_dataset)\n        # save_model(args, model, tokenizer)\n        tb_writer.close()\n\n    return global_step, tr_loss / global_step, best_steps\n\n\ndef evaluate(args, model, val_dataset=None, prefix=\"\", test=False):\n    eval_task_names = (args.task_name,)\n    eval_outputs_dirs = (args.output_dir,)\n\n    results = {}\n    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n        eval_dataset = val_dataset\n\n        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n            os.makedirs(eval_output_dir)\n\n        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n        # Note that DistributedSampler samples randomly\n        eval_sampler = SequentialSampler(eval_dataset)\n        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n\n        # multi-gpu evaluate\n        if args.n_gpu > 1:\n            model = torch.nn.DataParallel(model)\n\n        # Eval!\n        logger.info(\"************************* Running evaluation {} *************************\".format(prefix))\n        logger.info(\"Num examples = %d\", len(eval_dataset))\n        logger.info(\"Batch size = %d\", args.eval_batch_size)\n        eval_loss = 0.0\n        nb_eval_steps = 0\n        preds = None\n        out_label_ids = None\n        model.eval()\n        logger.info(\"Evaluating.................\")\n        # for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n        # for batch in eval_dataloader:\n        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n            # model.eval()\n            batch = tuple(t.to(args.device) for t in batch)\n\n            with torch.no_grad():\n                inputs = {\n                    \"inputs\": batch[0],\n                    'seq_lengths': batch[1],\n                    \"labels\": batch[2],\n                }\n                outputs = model(**inputs)\n                tmp_eval_loss, logits = outputs[:2]\n\n                eval_loss += tmp_eval_loss.mean().item()\n            nb_eval_steps += 1\n            if preds is None:\n                preds = logits.detach().cpu().numpy()\n                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n            else:\n                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n\n        eval_loss = eval_loss / nb_eval_steps\n        preds = np.argmax(preds, axis=1)\n        acc = simple_accuracy(preds, out_label_ids)\n\n        result = {\"eval_acc\": acc, \"eval_loss\": eval_loss}\n        results.update(result)\n\n        # output_eval_file = os.path.join(eval_output_dir, \"is_test_\" + str(test).lower() + \"_eval_results.txt\")\n\n        # with open(output_eval_file, \"w\") as writer:\n        #     logger.info(\"***** Eval results {} *****\".format(str(prefix) + \"----is test:\" + str(test)))\n        #\n        #     # if not test:\n        #     for key in sorted(result.keys()):\n        #         if test:\n        #             logger.info(\"%s = %s\", key, str(result[key]))\n        #         writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n        logger.info(\"***** Eval results {} *****\".format(str(prefix) + \"----is test:\" + str(test)))\n        if test:\n            for key in sorted(result.keys()):\n                logger.info(\"%s = %s\", key, str(round(result[key],4)))\n\n    if test:\n        return results, preds\n    else:\n        return results\n\n\ndef main():\n    args = init_args()\n\n    if (\n        os.path.exists(args.output_dir)\n        and os.listdir(args.output_dir)\n        and args.do_train\n        and not args.overwrite_output_dir\n    ):\n        raise ValueError(\n            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n                args.output_dir\n            )\n        )\n\n    # Setup CUDA, GPU & distributed training\n    if args.local_rank == -1 or args.no_cuda:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n        args.n_gpu = torch.cuda.device_count()\n    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n        torch.distributed.init_process_group(backend=\"nccl\")\n        logger.warning('local_rank: %s, gpu_num: %s', torch.distributed.get_rank(), torch.cuda.device_count(),)\n        args.local_rank = torch.distributed.get_rank()\n        torch.cuda.set_device(args.local_rank)\n        device = torch.device(\"cuda\", args.local_rank)\n        args.n_gpu = 1\n    args.device = device\n\n    # set random seed\n    set_seed(args)\n\n    # Setup logging\n    logging.basicConfig(\n        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n        datefmt=\"%m/%d/%Y %H:%M:%S\",\n        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n    )\n    logger.warning(\n        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n        args.local_rank,\n        device,\n        args.n_gpu,\n        bool(args.local_rank != -1),\n        args.fp16,\n    )\n\n    # logger.info('n_gpu: %s, world_size: %s', args.n_gpu, torch.distributed.get_world_size())\n\n    # Prepare GLUE task\n    args.task_name = args.task_name.lower()\n    if args.task_name not in processors:\n        raise ValueError(\"Task not found: %s\" % (args.task_name))\n    processor = processors[args.task_name]()\n    label_list = processor.get_labels()\n    num_labels = len(label_list)\n\n    # Load pretrained model and tokenizer\n    if args.local_rank not in [-1, 0]:\n        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n\n    args.model_type = args.model_type.lower()\n\n\n\n    # model = model_class\n    text_field = Field(sequential=True, tokenize='basic_english',lower=False,batch_first=True,include_lengths=True,fix_length=args.max_seq_length,use_vocab=True)\n    train_examples, train_texts = processor.get_train_examples(args.data_dir,args.train_file,text_field)\n    dev_examples, dev_texts = processor.get_dev_examples(args.data_dir,args.dev_file,text_field)\n    text_field.build_vocab(train_texts + dev_texts,vectors='glove.840B.300d')\n    train_dataset = derive_features_for_model(train_examples,text_field,processor,args,evaluate=False,type=args.train_file)\n    val_dataset = derive_features_for_model(dev_examples, text_field, processor,args, evaluate=True, type=args.dev_file)\n    cached_vocab_file = os.path.join(\n        args.data_dir,\n        'pretrained_embeddings'\n    )\n\n    model = LSATLSTM(vocab_size=len(text_field.vocab),input_size=300,hidden_size=300,batch_first=True,max_seq_length=args.max_seq_length)\n    if os.path.exists(cached_vocab_file) and not args.overwrite_cache:\n        logger.info(\"Loading embeddings from cached file %s\", cached_vocab_file)\n        embeddings = torch.load(cached_vocab_file)\n    else:\n        logger.info(\"Saving embeddings at file %s\", cached_vocab_file)\n        embeddings = text_field.vocab.vectors\n        torch.save(embeddings, cached_vocab_file)\n\n    if args.local_rank == 0:\n        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n\n    model.to(args.device)\n    model.embedding.weight.data = embeddings.cuda()\n    logger.info(\"Training/evaluation parameters %s\", args)\n    best_steps = 0\n\n    # Training\n    if args.do_train:\n        global_step, tr_loss, best_steps = train(args, train_dataset,val_dataset,model)\n        logger.info(\"global_step = %s, average loss = %s\", global_step, tr_loss)\n\n    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n    \"\"\"\n    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n        # Create output directory if needed\n        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n            os.makedirs(args.output_dir)\n\n        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n        # They can then be reloaded using `from_pretrained()`\n        # model_to_save = (\n        #     model.module if hasattr(model, \"module\") else model\n        # )  # Take care of distributed/parallel training\n        # model_to_save.save_pretrained(args.output_dir)\n        # tokenizer.save_pretrained(args.output_dir)\n\n        # Good practice: save your training arguments together with the trained model\n        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n\n        # Load a trained model and vocabulary that you have fine-tuned\n        model = model_class.from_pretrained(args.output_dir)\n        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n        model.to(args.device)\n    \"\"\"\n\n    # # Evaluation\n    # results = {}\n    # if args.do_eval and args.local_rank in [-1, 0]:\n    #     if not args.do_train:\n    #         args.output_dir = args.model_name_or_path\n    #     checkpoints = [args.output_dir]\n    #     if args.eval_all_checkpoints:\n    #         checkpoints = list(\n    #             os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n    #         )\n    #         logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n    #     logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n    #     for checkpoint in checkpoints:\n    #         global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n    #         prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n    #\n    #         model = model_class.from_pretrained(checkpoint)\n    #         model.to(args.device)\n    #         result = evaluate(args, model, tokenizer, prefix=prefix)\n    #         result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n    #         results.update(result)\n\n    # Test\n    results = {}\n    # test_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True)\n    # test_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_exam')\n\n    # test_dataset_rc = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_rc')\n    # test_dataset_lr = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_lr')\n    '''\n    test_dataset_ar = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='ar')\n\n    if args.do_test and args.local_rank in [-1, 0]:\n        if not args.do_train:\n            checkpoint_dir = args.model_name_or_path\n        if args.evaluate_during_training:\n            checkpoint_dir = os.path.join(args.output_dir)\n        logger.info('load checkpoint_dir: %s', checkpoint_dir)\n        logger.info('current local rank: %s', args.local_rank)\n        if best_steps:\n            logger.info(\"best steps of eval acc is the following checkpoints: %s\", best_steps)\n\n        model = model_class.from_pretrained(checkpoint_dir)\n        model.to(args.device)\n        # result, preds = evaluate(args, model, tokenizer, test_dataset, test=True)\n        result, preds = evaluate(args, model, tokenizer, test_dataset_ar, test=True)\n        # result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n        # results.update(result)\n        np.save(os.path.join(args.output_dir, \"test_preds.npy\" if args.output_dir is not None else \"test_preds.npy\"), preds)\n        # np.save(os.path.join(args.output_dir, \"test_preds_lr.npy\" if args.output_dir is not None else \"test_preds_lr.npy\"), preds)\n\n        # evaluate(args, model, tokenizer, test_dataset_rc, test=True)\n        # evaluate(args, model, tokenizer, test_dataset_lr, test=True)\n        # evaluate(args, model, tokenizer, test_dataset_ar, test=True)\n    '''\n\n    # # Test for each category\n    # results = {}\n    # test_dataset_rc = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_rc')\n    # test_dataset_lr = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_lr')\n    # test_dataset_ar = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_ar')\n    # \n    # if args.do_test and args.local_rank in [-1, 0]:\n    #     if not args.do_train:\n    #         checkpoint_dir = args.model_name_or_path\n    #     if args.evaluate_during_training:\n    #         checkpoint_dir = os.path.join(args.output_dir)\n    #     logger.info('load checkpoint_dir: %s', checkpoint_dir)\n    #     logger.info('current local rank: %s', args.local_rank)\n    #     if best_steps:\n    #         logger.info(\"best steps of eval acc is the following checkpoints: %s\", best_steps)\n    # \n    #     model = model_class.from_pretrained(checkpoint_dir)\n    #     model.to(args.device)\n    #     evaluate(args, model, tokenizer, test_dataset_rc, test=True)\n    #     evaluate(args, model, tokenizer, test_dataset_lr, test=True)\n    #     evaluate(args, model, tokenizer, test_dataset_ar, test=True)\n\n    return results\n\nif __name__ == \"__main__\":\n    main()\n",
        "LSTM/model.py": "import torch\r\nimport torch.nn as nn\r\nimport torch\r\nfrom torch.autograd import Variable\r\nimport copy\r\n# from transformers.modeling_bert import BertLayerNorm\r\nimport torch.nn.functional as F\r\nfrom transformers import RobertaConfig\r\nfrom transformers import PreTrainedModel,RobertaModel#, RobertaPreTrainedModel\r\nfrom allennlp.modules.attention import DotProductAttention\r\nfrom allennlp.nn import util\r\nfrom typing import Dict, Tuple, Sequence,Optional\r\n\r\nclass LSATLSTM(nn.Module):\r\n    def __init__(self,vocab_size,input_size,hidden_size,batch_first=True,max_seq_length=30):\r\n        super(LSATLSTM, self).__init__()\r\n        self.batch_first = batch_first\r\n        self.embedding = nn.Embedding(vocab_size,input_size)\r\n        self.max_seq_length = max_seq_length\r\n        self.rnn = torch.nn.GRU(input_size=input_size,hidden_size=hidden_size,batch_first=batch_first)\r\n        # self.rnn = torch.nn.LSTM(input_size=input_size,hidden_size=hidden_size,batch_first=batch_first)\r\n        self.fc = nn.Linear(hidden_size, 1)\r\n\r\n        # self.rnn = NaiveLSTM(input_sz=input_size,hidden_sz=hidden_size)\r\n        # self.rnn = rnn_util.LayerNormLSTM(input_size=input_size,hidden_size=hidden_size,num_layers=1,\r\n        #                                    dropout=0,bidirectional=False,layer_norm_enabled=True)\r\n    def forward(self,inputs,seq_lengths,labels):#,score):\r\n        # print(inputs.shape,hidden.shape)\r\n        flat_lengths = seq_lengths.view(-1)\r\n        flat_inputs = inputs.view(flat_lengths.size(0),-1)\r\n        num_choices = inputs.size(1)\r\n        embedded_inputs = self.embedding(flat_inputs)\r\n        # flat_inputs = embedded_inputs.view(-1, inputs.size(-1))\r\n\r\n        # print(flat_inputs.shape,flat_lengths.shape)\r\n        packed_inputs = torch.nn.utils.rnn.pack_padded_sequence(embedded_inputs,flat_lengths,batch_first=self.batch_first,enforce_sorted=False)\r\n        # res , (hn,cn) = self.rnn(input=packed_inputs,delta=min_score)\r\n        res, hn = self.rnn(packed_inputs)\r\n        # res, (hn, cn) = self.rnn(packed_inputs)\r\n        padded_res,_ = nn.utils.rnn.pad_packed_sequence(res,batch_first=self.batch_first,total_length=self.max_seq_length)#batch,max_seq_length,hidden\r\n        # padded_gate,_ = nn.utils.rnn.pad_packed_sequence(gates, batch_first=self.batch_first,total_length=self.max_seq_length)\r\n        # hn = torch.cat([hn[0,:,:],hn[1,:,:]],dim=-1)\r\n        logits = self.fc(hn.squeeze(0))\r\n        reshaped_logits = logits.view(-1, num_choices)\r\n        if labels is not None:\r\n            loss_fct = nn.CrossEntropyLoss()\r\n            loss = loss_fct(reshaped_logits, labels)\r\n        return (loss,) + (reshaped_logits,)\r\n        # return hn.squeeze(0),padded_res\r\n        # padded_res, _ = nn.utils.rnn.pad_packed_sequence(res,batch_first=self.batch_first)\r\n\r\n\r\n\r\n\r\n",
        "LSTM/utils_multiple_choice.py": "# coding=utf-8\n# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\" Multiple choice fine-tuning: utilities to work with multiple choice tasks of reading comprehension  \"\"\"\n\n\nimport csv\nimport glob\nimport json\nimport logging\nimport os\nfrom typing import List\n\nimport tqdm\n\nfrom transformers import PreTrainedTokenizer\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass InputExample(object):\n    \"\"\"A single training/test example for multiple choice\"\"\"\n\n    def __init__(self, example_id,contexts, label=None):\n        \"\"\"Constructs a InputExample.\n\n        Args:\n            example_id: Unique id for the example.\n            contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n            question: string. The untokenized text of the second sequence (question).\n            endings: list of str. multiple choice's options. Its length must be equal to contexts' length.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"\n        self.example_id = example_id\n        self.contexts = contexts\n        self.label = label\n\n\nclass InputFeatures(object):\n    def __init__(self, example_id, choices_features, label):\n        self.example_id = example_id\n        self.choices_features = choices_features\n        # self.choices_features = [\n        #     {\"input_ids\": input_ids,'lengths':lengths}\n        #     for input_ids,lengths in choices_features\n        # ]\n        self.label = label\n\n\n\nclass DataProcessor(object):\n    \"\"\"Base class for data converters for multiple choice data sets.\"\"\"\n\n    def get_train_examples(self, data_dir):\n        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n        raise NotImplementedError()\n\n    def get_dev_examples(self, data_dir):\n        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n        raise NotImplementedError()\n\n    def get_test_examples(self, data_dir):\n        \"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"\n        raise NotImplementedError()\n\n    def get_labels(self):\n        \"\"\"Gets the list of labels for this data set.\"\"\"\n        raise NotImplementedError()\n\n\nclass LSATProcessor(DataProcessor):\n    \"\"\"Processor for the LSAT data set.\"\"\"\n\n    def get_train_examples(self, data_dir,type,text_field):\n        \"\"\"See base class.\"\"\"\n        file_name = os.path.join(data_dir, type)\n        logger.info(\"LOOKING AT {} train\".format(file_name))\n        # return self._create_examples(self._read_json(os.path.join(data_dir, \"train.json\")))\n\n        return self._create_examples(self._read_json(file_name),text_field)\n\n    def get_dev_examples(self, data_dir,type,text_field):\n        \"\"\"See base class.\"\"\"\n        file_name = os.path.join(data_dir, type)\n        logger.info(\"LOOKING AT {} dev\".format(file_name))\n        # return self._create_examples(self._read_json(os.path.join(data_dir, \"val.json\")))\n        return self._create_examples(self._read_json(file_name),text_field)\n\n    def get_test_examples(self, data_dir, type, text_field):\n        logger.info(\"LOOKING AT {} test\".format(data_dir))\n        # return self._create_examples(self._read_json(os.path.join(data_dir, \"test.json\")))\n        # return self._create_examples(self._read_json(os.path.join(data_dir, \"test_lr.json\")))\n        return self._create_examples(self._read_json(os.path.join(data_dir, type)),text_field)\n\n    def get_test_examples_specific(self, data_dir, type):\n        logger.info(\"LOOKING AT %s test_%s\", data_dir, type)\n        return self._create_examples(self._read_json(os.path.join(data_dir, \"test_\"+type+\".json\")))\n\n    def get_labels(self):\n        \"\"\"See base class.\"\"\"\n        return [0, 1, 2, 3, 4]\n\n    def _read_json(self, input_file):\n        with open(input_file, \"r\") as f:\n            lines = json.load(f)\n        return lines\n\n    def _create_examples(self, lines, text_field):\n        \"\"\"Creates examples for the training and dev sets.\"\"\"\n        examples = []\n        texts = []\n        for d in lines:\n            context = d['context']\n            question = d['question']\n            answers = d['answers'] #[text_field.preprocess(x) for x in d['answers']]\n            label = d['label']\n            id_string = d['id_string']\n            all_context = [text_field.preprocess(context+' '+question+' '+ans) for ans in answers]\n            if len(answers)==5:\n                examples.append(\n                    InputExample(\n                        example_id = id_string,\n                        contexts = all_context,\n                        # question = text_field.preprocess(question),\n                        # contexts=text_field.preprocess(context),#[context, context, context, context, context],\n                        # endings=[answers[0], answers[1], answers[2], answers[3], answers[4]],\n                        label = label\n                        )\n                    )\n            texts.extend(all_context)\n        return examples,texts\n\nimport re\ndef clean_string(string):\n    return re.sub(r'[^a-zA-Z0-9,.\\'!?]+', ' ', string)\ndef convert_examples_to_features(\n    examples: List[InputExample],\n    label_list: List[str],\n    max_length: int,\n    text_field,\n) -> List[InputFeatures]:\n    \"\"\"\n    Loads a data file into a list of `InputFeatures`\n    \"\"\"\n\n    label_map = {label: i for i, label in enumerate(label_list)}\n\n    features = []\n    for (ex_index, example) in tqdm.tqdm(enumerate(examples), desc=\"convert examples to features\"):\n        if ex_index % 10000 == 0:\n            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n\n        #for ending_idx, (context, question, ending) in enumerate(zip(example.contexts, example.question, example.endings)):\n        padded_contexts, lengths = text_field.pad(example.contexts)\n        # print(len(padded_contexts))\n\n        tmp = tuple([padded_contexts, lengths])\n        input_ids, lengths = text_field.numericalize(tmp)\n        # print(input_ids.shape)\n        # print(len(tmp[0]),len(lengths),text_field.use_vocab,text_field.sequential)\n        choices_features={'input_ids':input_ids,'lengths':lengths}#[(input_ids[i],lengths[i]) for i in range((input_ids.size(0)))]\n        label = label_map[example.label]\n\n        if ex_index < 2:\n            logger.info(\"*** Example ***\")\n            logger.info(\"race_id: {}\".format(example.example_id))\n            for choice_idx, (context) in enumerate(padded_contexts):\n                logger.info(\"choice: {}\".format(choice_idx))\n                logger.info(\"context: {}\".format(context))\n                logger.info(\"input_ids: {}\".format(input_ids[choice_idx,:]))\n                logger.info(\"label: {}\".format(label))\n\n        features.append(InputFeatures(example_id=example.example_id, choices_features=choices_features, label=label))\n\n    return features\n\n\nprocessors = {\"lsat\": LSATProcessor}\n\n",
        "Transformer-based Model/main_large.py": "import argparse\nimport logging\nimport os\nimport random\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nfrom torch.utils.data.distributed import DistributedSampler\nfrom tqdm import tqdm, trange\n\nfrom transformers import (\n    WEIGHTS_NAME,\n    AdamW,\n    BertConfig,\n    BertForMultipleChoice,\n    BertTokenizer,\n    RobertaConfig,\n    RobertaModel,\n    RobertaForMultipleChoice,\n    RobertaTokenizer,\n    XLNetConfig,\n    XLNetForMultipleChoice,\n    XLNetTokenizer,\n    get_linear_schedule_with_warmup,\n)\nfrom utils_multiple_choice import convert_examples_to_features, processors\n\ntry:\n    from torch.utils.tensorboard import SummaryWriter\nexcept ImportError:\n    from tensorboardX import SummaryWriter\n\nlogger = logging.getLogger(__name__)\n\n# ALL_MODELS = sum(\n#     (tuple(conf.pretrained_config_archive_map.keys()) for conf in (BertConfig, XLNetConfig, RobertaConfig)), ()\n# )\n\nMODEL_CLASSES = {\n    \"bert\": (BertConfig, BertForMultipleChoice, BertTokenizer),\n    \"xlnet\": (XLNetConfig, XLNetForMultipleChoice, XLNetTokenizer),\n    \"roberta\": (RobertaConfig, RobertaForMultipleChoice, RobertaTokenizer),\n}\n\n\ndef init_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        \"--data_dir\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n    )\n    parser.add_argument(\n        \"--model_type\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n    )\n    parser.add_argument(\n        \"--model_name_or_path\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"Path to pre-trained model or shortcut name selected in the list: \" #+ \", \".join(ALL_MODELS),\n    )\n    parser.add_argument(\n        \"--task_name\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"The name of the task to train\",\n    )\n    parser.add_argument(\n        \"--output_dir\",\n        default=None,\n        type=str,\n        required=True,\n        help=\"The output directory where the model predictions and checkpoints will be written.\",\n    )\n\n    # Other parameters\n    parser.add_argument(\n        \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\"\n    )\n    parser.add_argument(\n        \"--tokenizer_name\",\n        default=\"\",\n        type=str,\n        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n    )\n    parser.add_argument(\n        \"--cache_dir\",\n        default=\"\",\n        type=str,\n        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n    )\n    parser.add_argument(\n        \"--max_seq_length\",\n        default=128,\n        type=int,\n        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n             \"than this will be truncated, sequences shorter will be padded.\",\n    )\n    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n    parser.add_argument(\"--do_test\", action=\"store_true\", help=\"Whether to run test on the test set\")\n    parser.add_argument(\n        \"--evaluate_during_training\", action=\"store_true\", help=\"Run evaluation during training at each logging step.\"\n    )\n    parser.add_argument(\n        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\"\n    )\n\n    parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\")\n    parser.add_argument(\n        \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\"\n    )\n    parser.add_argument(\n        \"--gradient_accumulation_steps\",\n        type=int,\n        default=1,\n        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n    )\n    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight deay if we apply some.\")\n    parser.add_argument('--adam_betas', default='(0.9, 0.999)', type=str, help='betas for Adam optimizer')\n    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n    parser.add_argument(\"--no_clip_grad_norm\", action=\"store_true\", help=\"whether not to clip grad norm\")\n    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n    parser.add_argument(\n        \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\"\n    )\n    parser.add_argument(\n        \"--max_steps\",\n        default=-1,\n        type=int,\n        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n    )\n    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n    parser.add_argument(\"--warmup_proportion\", default=0.0, type=float, help=\"Linear warmup over warmup ratios.\")\n\n    parser.add_argument(\"--logging_steps\", type=int, default=50, help=\"Log every X updates steps.\")\n    parser.add_argument(\"--save_steps\", type=int, default=50, help=\"Save checkpoint every X updates steps.\")\n    parser.add_argument(\n        \"--eval_all_checkpoints\",\n        action=\"store_true\",\n        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n    )\n    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n    parser.add_argument(\n        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\"\n    )\n    parser.add_argument(\n        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\"\n    )\n    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n\n    parser.add_argument(\n        \"--fp16\",\n        action=\"store_true\",\n        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n    )\n    parser.add_argument(\n        \"--fp16_opt_level\",\n        type=str,\n        default=\"O1\",\n        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n             \"See details at https://nvidia.github.io/apex/amp.html\",\n    )\n    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n\n    return parser.parse_args()\n\n\ndef set_seed(args):\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    if args.n_gpu > 0:\n        torch.cuda.manual_seed_all(args.seed)\n\n\ndef select_field(features, field):\n    return [[choice[field] for choice in feature.choices_features] for feature in features]\n\n\ndef simple_accuracy(preds, labels):\n    return (preds == labels).mean()\n\n\ndef load_and_cache_examples(args, task, tokenizer, evaluate=False, test=False, type='ar'):\n    if args.local_rank not in [-1, 0]:\n        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n\n    processor = processors[task]()\n    # Load data features from cache or dataset file\n    if evaluate:\n        cached_mode = \"dev\"+\"_%s\"%type\n    elif test:\n        cached_mode = \"test\"\n        cached_mode = cached_mode + type\n    else:\n        cached_mode = \"train\"+\"_%s\"%type\n    assert not (evaluate and test)\n    cached_features_file = os.path.join(\n        args.data_dir,\n        \"cached_{}_{}_{}_{}_rm_cq\".format(\n            cached_mode,\n            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n            str(args.max_seq_length),\n            str(task),\n        ),\n    )\n\n    if os.path.exists(cached_features_file) and not args.overwrite_cache:\n        logger.info(\"Loading features from cached file %s\", cached_features_file)\n        features = torch.load(cached_features_file)\n    else:\n        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n        label_list = processor.get_labels()\n        if evaluate:\n            examples = processor.get_dev_examples(args.data_dir,type)\n        elif test:\n            examples = processor.get_test_examples(args.data_dir, type)\n        else:\n            examples = processor.get_train_examples(args.data_dir,type)\n        logger.info(\"Training number: %s\", str(len(examples)))\n        features = convert_examples_to_features(\n            examples,\n            label_list,\n            args.max_seq_length,\n            tokenizer,\n            pad_on_left=bool(args.model_type in [\"xlnet\"]),  # pad on the left for xlnet\n            pad_token_segment_id=4 if args.model_type in [\"xlnet\"] else 0,\n        )\n        if args.local_rank in [-1, 0]:\n            logger.info(\"Saving features into cached file %s\", cached_features_file)\n            torch.save(features, cached_features_file)\n\n    if args.local_rank == 0:\n        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n\n    # Convert to Tensors and build dataset\n    all_input_ids = torch.tensor(select_field(features, \"input_ids\"), dtype=torch.long)\n    all_input_mask = torch.tensor(select_field(features, \"input_mask\"), dtype=torch.long)\n    all_segment_ids = torch.tensor(select_field(features, \"segment_ids\"), dtype=torch.long)\n    all_label_ids = torch.tensor([f.label for f in features], dtype=torch.long)\n    # print(all_input_ids.size(), all_input_mask.size(), all_segment_ids.size(), all_label_ids.size())\n\n    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n    return dataset\n\n\n\ndef train(args, train_dataset, model, tokenizer):\n    \"\"\" Train the model \"\"\"\n    if args.local_rank in [-1, 0]:\n        str_list = str(args.output_dir).split('/')\n        tb_log_dir = os.path.join('summaries', str_list[-1])\n        tb_writer = SummaryWriter(tb_log_dir)\n\n    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n    train_sampler = SequentialSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n\n    if args.max_steps > 0:\n        t_total = args.max_steps\n        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n    else:\n        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n\n    # Prepare optimizer and schedule (linear warmup and decay)\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": args.weight_decay,\n        },\n        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n    ]\n    exec('args.adam_betas = ' + args.adam_betas)\n    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, betas=args.adam_betas, eps=args.adam_epsilon)\n    assert not ((args.warmup_steps > 0) and (args.warmup_proportion > 0)), \"--only can set one of --warmup_steps and --warm_ratio \"\n    if args.warmup_proportion > 0:\n        args.warmup_steps = int(t_total * args.warmup_proportion)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n    )\n\n    if args.fp16:\n        try:\n            from apex import amp\n        except ImportError:\n            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n\n    # multi-gpu training (should be after apex fp16 initialization)\n    if args.n_gpu > 1:\n        model = torch.nn.DataParallel(model)\n\n    # Distributed training (should be after apex fp16 initialization)\n    if args.local_rank != -1:\n        model = torch.nn.parallel.DistributedDataParallel(\n            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n        )\n\n    # Train!\n    logger.info(\"************************* Running training *************************\")\n    logger.info(\"Num examples = %d\", len(train_dataset))\n    logger.info(\"Num Epochs = %d\", args.num_train_epochs)\n    logger.info(\"Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n    logger.info(\n        \"Total train batch size (w. parallel, distributed & accumulation) = %d\",\n        args.train_batch_size\n        * args.gradient_accumulation_steps\n        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n        )\n    # logger.info(\"Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n    logger.info(\"Total optimization steps = %d\", t_total)\n\n    val_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=True, test=False)\n\n    def evaluate_model(train_preds, train_label_ids, tb_writer, args, model, tokenizer, best_steps, best_dev_acc, val_dataset):\n        train_preds = np.argmax(train_preds, axis=1)\n        train_acc = simple_accuracy(train_preds, train_label_ids)\n        train_preds = None\n        train_label_ids = None\n        results = evaluate(args, model, tokenizer, val_dataset)\n        logger.info(\n            \"dev acc: %s, loss: %s, global steps: %s\",\n            str(results[\"eval_acc\"]),\n            str(results[\"eval_loss\"]),\n            str(global_step),\n        )\n        tb_writer.add_scalar(\"training/acc\", train_acc, global_step)\n        for key, value in results.items():\n            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n        if results[\"eval_acc\"] > best_dev_acc:\n            best_dev_acc = results[\"eval_acc\"]\n            best_steps = global_step\n            logger.info(\"!!!!!!!!!!!!!!!!!!!! achieve BEST dev acc: %s at global step: %s\",\n                        str(best_dev_acc),\n                        str(best_steps)\n                        )\n\n            # if args.do_test:\n            #     results_test, _ = evaluate(args, model, tokenizer, test=True)\n            #     for key, value in results_test.items():\n            #         tb_writer.add_scalar(\"test_{}\".format(key), value, global_step)\n            #     logger.info(\n            #         \"test acc: %s, loss: %s, global steps: %s\",\n            #         str(results_test[\"eval_acc\"]),\n            #         str(results_test[\"eval_loss\"]),\n            #         str(global_step),\n            #     )\n\n            # save best dev acc model\n            # output_dir = os.path.join(args.output_dir, \"checkpoint-best\")\n            output_dir = args.output_dir\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            model_to_save = (\n                model.module if hasattr(model, \"module\") else model\n            )  # Take care of distributed/parallel training\n            logger.info(\"Current local rank %s\", args.local_rank)\n            model_to_save.save_pretrained(output_dir)\n            tokenizer.save_vocabulary(output_dir)\n            tokenizer.save_pretrained(output_dir)\n            torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n            logger.info(\"Saving model checkpoint to %s\", output_dir)\n            txt_dir = os.path.join(output_dir, 'best_dev_results.txt')\n            with open(txt_dir, 'w') as f:\n                rs = 'global_steps: {}; dev_acc: {}'.format(global_step, best_dev_acc)\n                f.write(rs)\n                tb_writer.add_text('best_results', rs, global_step)\n\n        logger.info(\"current BEST dev acc: %s at global step: %s\",\n                    str(round(best_dev_acc, 4)),\n                    str(best_steps)\n                    )\n\n        return train_preds, train_label_ids, train_acc, best_steps, best_dev_acc\n\n    # def save_model(args, model, tokenizer):\n    #     output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n    #     if not os.path.exists(output_dir):\n    #         os.makedirs(output_dir)\n    #     model_to_save = (\n    #         model.module if hasattr(model, \"module\") else model\n    #     )  # Take care of distributed/parallel training\n    #     model_to_save.save_pretrained(output_dir)\n    #     tokenizer.save_vocabulary(output_dir)\n    #     tokenizer.save_pretrained(output_dir)\n    #     torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n    #     logger.info(\"Saving model checkpoint to %s\", output_dir)\n\n    global_step = 0\n    tr_loss, logging_loss = 0.0, 0.0\n    best_dev_acc = 0.0\n    best_steps = 0\n    train_preds = None\n    train_label_ids = None\n    model.zero_grad()\n    # train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n    set_seed(args)  # Added here for reproductibility\n    for epoch_index in range(int(args.num_train_epochs)):\n        logger.info('')\n        logger.info('%s Epoch: %d %s', '*'*50, epoch_index, '*'*50)\n        # epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n        for step, batch in enumerate(train_dataloader):\n            model.train()\n            batch = tuple(t.to(args.device) for t in batch)\n            inputs = {\n                \"input_ids\": batch[0],\n                \"attention_mask\": batch[1],\n                \"token_type_ids\": batch[2]\n                if args.model_type in [\"bert\", \"xlnet\"]\n                else None,  # XLM, Roberta don't use segment_ids\n                \"labels\": batch[3],\n            }\n            outputs = model(**inputs)\n            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n            logits = outputs[1]\n\n            # print(outputs[2][0].size())\n            # print(outputs[2][1].size())\n\n            ################# work only gpu = 1 ######################\n            if train_preds is None:\n                train_preds = logits.detach().cpu().numpy()\n                train_label_ids = inputs['labels'].detach().cpu().numpy()\n            else:\n                train_preds = np.append(train_preds, logits.detach().cpu().numpy(), axis=0)\n                train_label_ids = np.append(train_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n            ###########################################################\n\n            if args.n_gpu > 1:\n                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n            if args.gradient_accumulation_steps > 1:\n                loss = loss / args.gradient_accumulation_steps\n\n            if args.fp16:\n                with amp.scale_loss(loss, optimizer) as scaled_loss:\n                    scaled_loss.backward()\n                if not args.no_clip_grad_norm:\n                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n            else:\n                loss.backward()\n                if not args.no_clip_grad_norm:\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n\n            tr_loss += loss.item()\n\n            if step % 20 == 0:\n                logger.info(\"********** Iteration %d: current loss: %s\", step, str(round(loss.item(), 4)),)\n\n            if (step + 1) % args.gradient_accumulation_steps == 0:\n                optimizer.step()\n                scheduler.step()  # Update learning rate schedule\n                model.zero_grad()\n                # optimizer.zero_grad()\n                global_step += 1\n\n                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n                    # if (args.local_rank == -1 and args.evaluate_during_training):  # Only evaluate when single GPU otherwise metrics may not average well\n                    if args.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well\n                        train_preds, train_label_ids, train_acc, best_steps, best_dev_acc = evaluate_model(train_preds, train_label_ids, tb_writer, args, model, tokenizer, best_steps, best_dev_acc, val_dataset)\n                        # tb_writer.add_scalar(\"training/lr\", scheduler.get_lr()[0], global_step)\n                        tb_writer.add_scalar(\"training/lr\", scheduler.get_lr()[0], global_step)\n                        tb_writer.add_scalar(\"training/loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n                        logger.info(\n                            \"Average loss: %s, average acc: %s at global step: %s\",\n                            str((tr_loss - logging_loss) / args.logging_steps),\n                            str(train_acc),\n                            str(global_step),\n                        )\n                        logging_loss = tr_loss\n\n                # if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n                #     save_model(args, model, tokenizer)\n            if args.max_steps > 0 and global_step > args.max_steps:\n                epoch_iterator.close()\n                break\n        if args.max_steps > 0 and global_step > args.max_steps:\n            # train_iterator.close()\n            break\n\n    if args.local_rank in [-1, 0] and train_preds is not None:\n        train_preds, train_label_ids, train_acc, best_steps, best_dev_acc = evaluate_model(train_preds, train_label_ids, tb_writer, args, model, tokenizer, best_steps, best_dev_acc, val_dataset)\n        # save_model(args, model, tokenizer)\n        tb_writer.close()\n\n    return global_step, tr_loss / global_step, best_steps\n\n\ndef evaluate(args, model, tokenizer, val_dataset=None, prefix=\"\", test=False):\n    eval_task_names = (args.task_name,)\n    eval_outputs_dirs = (args.output_dir,)\n\n    results = {}\n    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n        eval_dataset = val_dataset\n\n        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n            os.makedirs(eval_output_dir)\n\n        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n        # Note that DistributedSampler samples randomly\n        eval_sampler = SequentialSampler(eval_dataset)\n        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n\n        # multi-gpu evaluate\n        if args.n_gpu > 1:\n            model = torch.nn.DataParallel(model)\n\n        # Eval!\n        logger.info(\"************************* Running evaluation {} *************************\".format(prefix))\n        logger.info(\"Num examples = %d\", len(eval_dataset))\n        logger.info(\"Batch size = %d\", args.eval_batch_size)\n        eval_loss = 0.0\n        nb_eval_steps = 0\n        preds = None\n        out_label_ids = None\n        model.eval()\n        logger.info(\"Evaluating.................\")\n        # for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n        for batch in eval_dataloader:\n            # model.eval()\n            batch = tuple(t.to(args.device) for t in batch)\n\n            with torch.no_grad():\n                inputs = {\n                    \"input_ids\": batch[0],\n                    \"attention_mask\": batch[1],\n                    \"token_type_ids\": batch[2]\n                    if args.model_type in [\"bert\", \"xlnet\"]\n                    else None,  # XLM don't use segment_ids\n                    \"labels\": batch[3],\n                }\n                outputs = model(**inputs)\n                tmp_eval_loss, logits = outputs[:2]\n\n                eval_loss += tmp_eval_loss.mean().item()\n            nb_eval_steps += 1\n            if preds is None:\n                preds = logits.detach().cpu().numpy()\n                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n            else:\n                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n\n        eval_loss = eval_loss / nb_eval_steps\n        preds = np.argmax(preds, axis=1)\n        acc = simple_accuracy(preds, out_label_ids)\n\n        result = {\"eval_acc\": acc, \"eval_loss\": eval_loss}\n        results.update(result)\n\n        # output_eval_file = os.path.join(eval_output_dir, \"is_test_\" + str(test).lower() + \"_eval_results.txt\")\n\n        # with open(output_eval_file, \"w\") as writer:\n        #     logger.info(\"***** Eval results {} *****\".format(str(prefix) + \"----is test:\" + str(test)))\n        #\n        #     # if not test:\n        #     for key in sorted(result.keys()):\n        #         if test:\n        #             logger.info(\"%s = %s\", key, str(result[key]))\n        #         writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n        logger.info(\"***** Eval results {} *****\".format(str(prefix) + \"----is test:\" + str(test)))\n        if test:\n            for key in sorted(result.keys()):\n                logger.info(\"%s = %s\", key, str(round(result[key],4)))\n\n    if test:\n        return results, preds\n    else:\n        return results\n\n\ndef main():\n    args = init_args()\n\n    if (\n        os.path.exists(args.output_dir)\n        and os.listdir(args.output_dir)\n        and args.do_train\n        and not args.overwrite_output_dir\n    ):\n        raise ValueError(\n            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n                args.output_dir\n            )\n        )\n\n    # Setup CUDA, GPU & distributed training\n    if args.local_rank == -1 or args.no_cuda:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n        args.n_gpu = torch.cuda.device_count()\n    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n        torch.distributed.init_process_group(backend=\"nccl\")\n        logger.warning('local_rank: %s, gpu_num: %s', torch.distributed.get_rank(), torch.cuda.device_count(),)\n        args.local_rank = torch.distributed.get_rank()\n        torch.cuda.set_device(args.local_rank)\n        device = torch.device(\"cuda\", args.local_rank)\n        args.n_gpu = 1\n    args.device = device\n\n    # set random seed\n    set_seed(args)\n\n    # Setup logging\n    logging.basicConfig(\n        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n        datefmt=\"%m/%d/%Y %H:%M:%S\",\n        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n    )\n    logger.warning(\n        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n        args.local_rank,\n        device,\n        args.n_gpu,\n        bool(args.local_rank != -1),\n        args.fp16,\n    )\n\n    # logger.info('n_gpu: %s, world_size: %s', args.n_gpu, torch.distributed.get_world_size())\n\n    # Prepare GLUE task\n    args.task_name = args.task_name.lower()\n    if args.task_name not in processors:\n        raise ValueError(\"Task not found: %s\" % (args.task_name))\n    processor = processors[args.task_name]()\n    label_list = processor.get_labels()\n    num_labels = len(label_list)\n\n    # Load pretrained model and tokenizer\n    if args.local_rank not in [-1, 0]:\n        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n\n    args.model_type = args.model_type.lower()\n    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n\n    config = config_class.from_pretrained(\n        args.config_name if args.config_name else args.model_name_or_path,\n        num_labels=num_labels,\n        finetuning_task=args.task_name,\n        cache_dir=args.cache_dir if args.cache_dir else None,\n        output_hidden_states = True,\n    )\n    tokenizer = tokenizer_class.from_pretrained(\n        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n        do_lower_case=args.do_lower_case,\n        cache_dir=args.cache_dir if args.cache_dir else None,\n    )\n    model = model_class.from_pretrained(\n        args.model_name_or_path,\n        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n        config=config,\n        cache_dir=args.cache_dir if args.cache_dir else None,\n    )\n    # model = model_class\n\n    if args.local_rank == 0:\n        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n\n    model.to(args.device)\n\n    logger.info(\"Training/evaluation parameters %s\", args)\n    best_steps = 0\n\n    # Training\n    if args.do_train:\n        train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)\n\n        global_step, tr_loss, best_steps = train(args, train_dataset, model, tokenizer)\n        logger.info(\"global_step = %s, average loss = %s\", global_step, tr_loss)\n\n    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n    \"\"\"\n    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n        # Create output directory if needed\n        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n            os.makedirs(args.output_dir)\n\n        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n        # They can then be reloaded using `from_pretrained()`\n        # model_to_save = (\n        #     model.module if hasattr(model, \"module\") else model\n        # )  # Take care of distributed/parallel training\n        # model_to_save.save_pretrained(args.output_dir)\n        # tokenizer.save_pretrained(args.output_dir)\n\n        # Good practice: save your training arguments together with the trained model\n        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n\n        # Load a trained model and vocabulary that you have fine-tuned\n        model = model_class.from_pretrained(args.output_dir)\n        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n        model.to(args.device)\n    \"\"\"\n\n    # # Evaluation\n    # results = {}\n    # if args.do_eval and args.local_rank in [-1, 0]:\n    #     if not args.do_train:\n    #         args.output_dir = args.model_name_or_path\n    #     checkpoints = [args.output_dir]\n    #     if args.eval_all_checkpoints:\n    #         checkpoints = list(\n    #             os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n    #         )\n    #         logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n    #     logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n    #     for checkpoint in checkpoints:\n    #         global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n    #         prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n    #\n    #         model = model_class.from_pretrained(checkpoint)\n    #         model.to(args.device)\n    #         result = evaluate(args, model, tokenizer, prefix=prefix)\n    #         result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n    #         results.update(result)\n\n    # Test\n    results = {}\n    # test_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True)\n    # test_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_exam')\n\n    # test_dataset_rc = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_rc')\n    # test_dataset_lr = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_lr')\n    test_dataset_ar = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='ar')\n\n    if args.do_test and args.local_rank in [-1, 0]:\n        if not args.do_train:\n            checkpoint_dir = args.model_name_or_path\n        if args.evaluate_during_training:\n            checkpoint_dir = os.path.join(args.output_dir)\n        logger.info('load checkpoint_dir: %s', checkpoint_dir)\n        logger.info('current local rank: %s', args.local_rank)\n        if best_steps:\n            logger.info(\"best steps of eval acc is the following checkpoints: %s\", best_steps)\n\n        model = model_class.from_pretrained(checkpoint_dir)\n        model.to(args.device)\n        # result, preds = evaluate(args, model, tokenizer, test_dataset, test=True)\n        result, preds = evaluate(args, model, tokenizer, test_dataset_ar, test=True)\n        # result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n        # results.update(result)\n        np.save(os.path.join(args.output_dir, \"test_preds.npy\" if args.output_dir is not None else \"test_preds.npy\"), preds)\n        # np.save(os.path.join(args.output_dir, \"test_preds_lr.npy\" if args.output_dir is not None else \"test_preds_lr.npy\"), preds)\n\n        # evaluate(args, model, tokenizer, test_dataset_rc, test=True)\n        # evaluate(args, model, tokenizer, test_dataset_lr, test=True)\n        # evaluate(args, model, tokenizer, test_dataset_ar, test=True)\n\n\n    # # Test for each category\n    # results = {}\n    # test_dataset_rc = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_rc')\n    # test_dataset_lr = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_lr')\n    # test_dataset_ar = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False, test=True, type='_ar')\n    # \n    # if args.do_test and args.local_rank in [-1, 0]:\n    #     if not args.do_train:\n    #         checkpoint_dir = args.model_name_or_path\n    #     if args.evaluate_during_training:\n    #         checkpoint_dir = os.path.join(args.output_dir)\n    #     logger.info('load checkpoint_dir: %s', checkpoint_dir)\n    #     logger.info('current local rank: %s', args.local_rank)\n    #     if best_steps:\n    #         logger.info(\"best steps of eval acc is the following checkpoints: %s\", best_steps)\n    # \n    #     model = model_class.from_pretrained(checkpoint_dir)\n    #     model.to(args.device)\n    #     evaluate(args, model, tokenizer, test_dataset_rc, test=True)\n    #     evaluate(args, model, tokenizer, test_dataset_lr, test=True)\n    #     evaluate(args, model, tokenizer, test_dataset_ar, test=True)\n\n    return results\n\nif __name__ == \"__main__\":\n    main()\n",
        "Transformer-based Model/utils_multiple_choice.py": "# coding=utf-8\n# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\" Multiple choice fine-tuning: utilities to work with multiple choice tasks of reading comprehension  \"\"\"\n\n\nimport csv\nimport glob\nimport json\nimport logging\nimport os\nfrom typing import List\n\nimport tqdm\n\nfrom transformers import PreTrainedTokenizer\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass InputExample(object):\n    \"\"\"A single training/test example for multiple choice\"\"\"\n\n    def __init__(self, example_id, question, contexts, endings, label=None):\n        \"\"\"Constructs a InputExample.\n\n        Args:\n            example_id: Unique id for the example.\n            contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n            question: string. The untokenized text of the second sequence (question).\n            endings: list of str. multiple choice's options. Its length must be equal to contexts' length.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"\n        self.example_id = example_id\n        self.question = question\n        self.contexts = contexts\n        self.endings = endings\n        self.label = label\n\n\nclass InputFeatures(object):\n    def __init__(self, example_id, choices_features, label):\n        self.example_id = example_id\n        self.choices_features = [\n            {\"input_ids\": input_ids, \"input_mask\": input_mask, \"segment_ids\": segment_ids}\n            for input_ids, input_mask, segment_ids in choices_features\n        ]\n        self.label = label\n\n\nclass DataProcessor(object):\n    \"\"\"Base class for data converters for multiple choice data sets.\"\"\"\n\n    def get_train_examples(self, data_dir):\n        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n        raise NotImplementedError()\n\n    def get_dev_examples(self, data_dir):\n        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n        raise NotImplementedError()\n\n    def get_test_examples(self, data_dir):\n        \"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"\n        raise NotImplementedError()\n\n    def get_labels(self):\n        \"\"\"Gets the list of labels for this data set.\"\"\"\n        raise NotImplementedError()\n\n\nclass LSATProcessor(DataProcessor):\n    \"\"\"Processor for the LSAT data set.\"\"\"\n\n    def get_train_examples(self, data_dir,type=''):\n        \"\"\"See base class.\"\"\"\n        file_name = os.path.join(data_dir, \"train_%s.json\"%type)\n        logger.info(\"LOOKING AT {} train\".format(file_name))\n        # return self._create_examples(self._read_json(os.path.join(data_dir, \"train.json\")))\n\n        return self._create_examples(self._read_json(file_name))\n\n    def get_dev_examples(self, data_dir,type=''):\n        \"\"\"See base class.\"\"\"\n        file_name = os.path.join(data_dir, \"val_%s.json\" % type)\n        logger.info(\"LOOKING AT {} dev\".format(file_name))\n        # return self._create_examples(self._read_json(os.path.join(data_dir, \"val.json\")))\n        return self._create_examples(self._read_json(file_name))\n\n    def get_test_examples(self, data_dir, type=\"\"):\n        logger.info(\"LOOKING AT {} test\".format(data_dir))\n        # return self._create_examples(self._read_json(os.path.join(data_dir, \"test.json\")))\n        # return self._create_examples(self._read_json(os.path.join(data_dir, \"test_lr.json\")))\n        return self._create_examples(self._read_json(os.path.join(data_dir, \"test_\"+ type +\".json\")))\n\n    def get_test_examples_specific(self, data_dir, type):\n        logger.info(\"LOOKING AT %s test_%s\", data_dir, type)\n        return self._create_examples(self._read_json(os.path.join(data_dir, \"test_\"+type+\".json\")))\n\n    def get_labels(self):\n        \"\"\"See base class.\"\"\"\n        return [0, 1, 2, 3, 4]\n\n    def _read_json(self, input_file):\n        with open(input_file, \"r\") as f:\n            lines = json.load(f)\n        return lines\n\n    def _create_examples(self, lines):\n        \"\"\"Creates examples for the training and dev sets.\"\"\"\n        examples = []\n        for d in lines:\n            context = d['context']\n            question = d['question']\n            answers = d['answers']\n            label = d['label']\n            id_string = d['id_string']\n            examples.append(\n                InputExample(\n                    example_id = id_string,\n                    question = question,\n                    contexts=context,#[context, context, context, context, context],\n                    endings=[answers[0], answers[1], answers[2], answers[3], answers[4]],\n                    label = label\n                    )\n                )  \n        return examples\n\nimport re\ndef clean_string(string):\n    return re.sub(r'[^a-zA-Z0-9,.\\'!?]+', ' ', string)\ndef convert_examples_to_features(\n    examples: List[InputExample],\n    label_list: List[str],\n    max_length: int,\n    tokenizer: PreTrainedTokenizer,\n    pad_token_segment_id=0,\n    pad_on_left=False,\n    pad_token=0,\n    mask_padding_with_zero=True,\n) -> List[InputFeatures]:\n    \"\"\"\n    Loads a data file into a list of `InputFeatures`\n    \"\"\"\n\n    label_map = {label: i for i, label in enumerate(label_list)}\n\n    features = []\n    for (ex_index, example) in tqdm.tqdm(enumerate(examples), desc=\"convert examples to features\"):\n        if ex_index % 10000 == 0:\n            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        choices_features = []\n        #for ending_idx, (context, question, ending) in enumerate(zip(example.contexts, example.question, example.endings)):\n        for ending_idx, ending in enumerate(example.endings):\n            # text_a = example.question+ ' '+ending\n            # text_a = example.question\n            text_a = example.contexts\n            text_b = example.question + \" \" + ending\n\n            # text_b = clean_string(' '.join(example.contexts.split()[:100]))\n            # print('text_a is', text_a)\n            # print('text_b is',text_b)\n            # print('-----------------------')\n            # text_a = context\n            # text_b = ending\n\n            # inputs = tokenizer.encode_plus(text_a, text_b, add_special_tokens=True, max_length=max_length,)\n            inputs = tokenizer.encode_plus(text_a, text_b, add_special_tokens=True, max_length=max_length, pad_to_max_length=True, return_attention_mask=True,)\n            # inputs = tokenizer.encode_plus(text_b, add_special_tokens=True, max_length=max_length, pad_to_max_length=True, return_attention_mask=True,)\n            # inputs = tokenizer.encode_plus(text_a, add_special_tokens=True, max_length=max_length,)\n            # inputs = tokenizer(ending, add_special_tokens=True, max_length=max_length)\n            if \"num_truncated_tokens\" in inputs and inputs[\"num_truncated_tokens\"] > 0:\n                logger.info(\n                    \"Attention! you are cropping tokens (swag task is ok). \"\n                    \"If you are training ARC and RACE and you are poping question + options,\"\n                    \"you need to try to use a bigger max seq length!\"\n                )\n\n            input_ids, attention_mask = inputs[\"input_ids\"], inputs['attention_mask']\n            token_type_ids = attention_mask\n            # print(len(input_ids))\n            # print(input_ids)\n            # print(token_type_ids)\n            # print(\"*\"*80)\n\n            # # The mask has 1 for real tokens and 0 for padding tokens. Only real\n            # # tokens are attended to.\n            # attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n            #\n            # # Zero-pad up to the sequence length.\n            # padding_length = max_length - len(input_ids)\n            # if pad_on_left:\n            #     input_ids = ([pad_token] * padding_length) + input_ids\n            #     attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n            #     token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n            # else:\n            #     input_ids = input_ids + ([pad_token] * padding_length)\n            #     attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n            #     token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n\n            assert len(input_ids) == max_length\n            assert len(attention_mask) == max_length\n            assert len(token_type_ids) == max_length\n            choices_features.append((input_ids, attention_mask, token_type_ids))\n\n        # print(tokenizer.sep_token, tokenizer.sep_token_id)\n        # print(tokenizer.pad_token, tokenizer.pad_token_id)\n        # print(tokenizer.bos_token, tokenizer.bos_token_id)\n        # print(tokenizer.eos_token, tokenizer.eos_token_id)\n        # print(tokenizer.unk_token, tokenizer.unk_token_id)\n        # print(tokenizer.cls_token, tokenizer.cls_token_id)\n        # print(tokenizer.mask_token, tokenizer.mask_token_id)\n        # print(tokenizer.additional_special_tokens, tokenizer.additional_special_tokens_ids)\n        # print(tokenizer.SPECIAL_TOKENS_ATTRIBUTES)\n        # return\n\n        label = label_map[example.label]\n\n        # if ex_index < 2:\n        #     logger.info(\"*** Example ***\")\n        #     logger.info(\"race_id: {}\".format(example.example_id))\n        #     for choice_idx, (input_ids, attention_mask, token_type_ids) in enumerate(choices_features):\n        #         logger.info(\"choice: {}\".format(choice_idx))\n        #         logger.info(\"input_ids: {}\".format(\" \".join(map(str, input_ids))))\n        #         logger.info(\"attention_mask: {}\".format(\" \".join(map(str, attention_mask))))\n        #         logger.info(\"token_type_ids: {}\".format(\" \".join(map(str, token_type_ids))))\n        #         logger.info(\"label: {}\".format(label))\n\n        features.append(InputFeatures(example_id=example.example_id, choices_features=choices_features, label=label,))\n\n    return features\n\n\nprocessors = {\"lsat\": LSATProcessor}\n\n"
    }
}