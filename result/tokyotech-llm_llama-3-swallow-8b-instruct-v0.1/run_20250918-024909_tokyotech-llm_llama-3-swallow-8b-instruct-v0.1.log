
======== 1/1 ▶ tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1 ========
📁 Directory to create/use: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1
📁 Output path: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1
1️⃣ HF: True, GH: False
🔎 Candidate rejected: instill-ai/model-llama3-8b-instruct-dvc (score=4, detail={'org_affinity': -6, 'name_hits': 5, 'readme_hits': 4, 'path_hits': 0, 'bad_keywords': 1, 'from_hf_link': 0, 'version_conflict': 0})
✅ Resolved GH repo: meta-llama/llama3 (score=22, detail={'org_affinity': 9, 'name_hits': 2, 'readme_hits': 5, 'path_hits': 2, 'bad_keywords': 10, 'from_hf_link': 1, 'version_conflict': 0})
✅ HF model: tokyotech-llm/llama-3-swallow-8b-instruct-v0.1 (found at priority: 1)
📄 Reports saved/merged (HF): tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_fulltext_huggingface_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.json
✅ JSON file saved: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\huggingface_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.json
📄 Reports merged to: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_fulltext_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.json (HF sources)
✅ Saved group 1 result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\huggingface_filtered_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1_1.json
✅ Saved group 2 result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\huggingface_filtered_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1_2.json
✅ Saved group 3 result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\huggingface_filtered_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1_3.json
✅ Saved group 4 result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\huggingface_filtered_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1_4.json
✅ Saved final merged result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\huggingface_filtered_final_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.json
✅ GH repo: meta-llama/llama3
📄 Reports saved/merged (GH): tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_fulltext_github_meta-llama_llama3.json
ℹ️ Merge skipped: could not determine a single target HF model id.
✅ GitHub JSON file saved: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\github_meta-llama_llama3.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 3, '1-2 (Code)': 3, '1-3 (License)': 6, '1-4 (Paper)': 0}, 'kept': {'1-1 (Weights)': 3, '1-2 (Code)': 3, '1-3 (License)': 5, '1-4 (Paper)': 0}}
✅ Saved group 1 result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\github_filtered_meta-llama_llama3_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 4, '1-6 (Tokenizer)': 3, '2-1 (Hardware)': 0, '2-2 (Software)': 2}, 'kept': {'1-5 (Architecture)': 3, '1-6 (Tokenizer)': 2, '2-1 (Hardware)': 0, '2-2 (Software)': 0}}
✅ Saved group 2 result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\github_filtered_meta-llama_llama3_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 0, '3-1 (Pre-training)': 4, '3-2 (Fine-tuning)': 3, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 0, '3-1 (Pre-training)': 2, '3-2 (Fine-tuning)': 1, '3-3 (Reinforcement Learning)': 0}}
✅ Saved group 3 result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\github_filtered_meta-llama_llama3_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 2}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 2}}
✅ Saved group 4 result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\github_filtered_meta-llama_llama3_4.json
✅ Saved final merged result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\github_filtered_final_meta-llama_llama3.json
🔎 HF tags found arXiv IDs: []
🔄 Simplified query: 'llama 3 swallow 0.1'
🔎 Tavily search: llama 3 swallow 0.1 paper
  → arXiv link found: https://arxiv.org/abs/2407.21783
🔎 Tavily search: llama 3 swallow 0.1 technical report
  → No arXiv link found in results.
🛰️ Tavily candidates: ['2407.21783']
🔬 Verifying 1 Tavily candidate(s) with GPT…
  • Candidate: 2407.21783
    - GPT verdict: ❌ no match (The candidate paper is the official technical report for Meta’s Llama 3 (and specifically Llama 3.1) models, whereas the target model—named 'llama-3-swallow-8b-instruct-v0.1'—is a distinct variant (no)
✅ GPT-verified IDs: []
📦 Final merged arXiv IDs: []
❌ No arXiv ID found/verified for 'tokyotech-llm/llama-3-swallow-8b-instruct-v0.1'.
📄 Reports merged to: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_fulltext_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.json
⚠️ No arXiv/report inputs found for dispatcher; skipping
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 4, '1-2 (Code)': 3, '1-3 (License)': 0, '1-4 (Paper)': 4}, 'kept': {'1-1 (Weights)': 4, '1-2 (Code)': 3, '1-3 (License)': 0, '1-4 (Paper)': 4}}
✅ Saved group 1 : tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_filtered_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 4, '1-6 (Tokenizer)': 3, '2-1 (Hardware)': 2, '2-2 (Software)': 4}, 'kept': {'1-5 (Architecture)': 4, '1-6 (Tokenizer)': 3, '2-1 (Hardware)': 2, '2-2 (Software)': 4}}
✅ Saved group 2 : tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_filtered_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1_2.json
⚠️ Error in group 3: <html>
<head><title>502 Bad Gateway</title></head>
<body>
<center><h1>502 Bad Gateway</h1></center>
<hr><center>cloudflare</center>
</body>
</html>
✅ Saved group 3 : tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_filtered_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 5, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 2, '4-4 (Data Filtering)': 3}, 'kept': {'4-1 (Pre-training Data)': 5, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 2, '4-4 (Data Filtering)': 3}}
✅ Saved group 4 : tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_filtered_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1_4.json
✅ Saved final merged: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_filtered_final_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.json
🧱 Pretrained (base) model found by heuristic: tokyotech-llm/llama-3-swallow-8b-v0.1
📄 Reports saved/merged (HF): tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_fulltext_huggingface_tokyotech-llm_llama-3-swallow-8b-v0.1.json
✅ JSON file saved: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\huggingface_tokyotech-llm_llama-3-swallow-8b-v0.1.json
✅ Saved tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\pretrain_hf_tokyotech-llm_llama-3-swallow-8b-v0.1.json
🔎 Candidate rejected: laboroai/Laboro-ParaCorpus (score=14, detail={'org_affinity': 9, 'name_hits': 0, 'readme_hits': 0, 'path_hits': 0, 'bad_keywords': 0, 'from_hf_link': 1, 'version_conflict': 0})
✅ Resolved GH repo: meta-llama/llama3 (score=22, detail={'org_affinity': 9, 'name_hits': 2, 'readme_hits': 4, 'path_hits': 2, 'bad_keywords': 10, 'from_hf_link': 1, 'version_conflict': 0})
📄 Reports saved/merged (GH): tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\reports_fulltext_github_meta-llama_llama3.json
ℹ️ Merge skipped: could not determine a single target HF model id.
✅ GitHub JSON file saved: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\github_meta-llama_llama3.json
⚠️ GH fetch/dispatch failed: cannot import name 'filter_pretrain_gh' from 'pretrain_github_Dispatcher' (c:\Users\user\Desktop\lab git\lab git\Evaluating-system-based-on-agent\code\pretrain_github_Dispatcher.py)
🔎 HF tags found arXiv IDs: ['2404.17733']
🔄 Simplified query: 'llama 3 swallow 0.1'
🔎 Tavily search: llama 3 swallow 0.1 paper
  → arXiv link found: https://arxiv.org/abs/2407.21783
🔎 Tavily search: llama 3 swallow 0.1 technical report
  → No arXiv link found in results.
🛰️ Tavily candidates: ['2407.21783']
🔬 Verifying 1 Tavily candidate(s) with GPT…
  • Candidate: 2407.21783
    - GPT verdict: ❌ no match (The candidate paper is the technical report for the Llama 3.1 series, while the target model is version v0.1. Under the version rule, the major version numbers must match and the minor version differe)
✅ GPT-verified IDs: []
📦 Final merged arXiv IDs: ['2404.17733']
📄 PDF saved: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\arxiv_2404.17733.pdf
✅ Full paper text saved: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\arxiv_fulltext_tokyotech-llm_llama-3-swallow-8b-v0.1.json
✅ Saved: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\pretrain_arxiv_tokyotech-llm_llama-3-swallow-8b-v0.1.json
✅ Saved pretrain reports: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\pretrain_reports_tokyotech-llm_llama-3-swallow-8b-v0.1.json
📝 Starting openness evaluation...
📝 Saved evaluation result: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\openness_score_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.json
✅ Openness evaluation complete. Result file: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\openness_score_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.json
✅ Saved model ID: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\identified_model.txt
⏳ **Time taken for this model: 2051.97 seconds**
🧾 Log saved to: tokyotech-llm_llama-3-swallow-8b-instruct-v0.1\run_20250918-024909_tokyotech-llm_llama-3-swallow-8b-instruct-v0.1.log
