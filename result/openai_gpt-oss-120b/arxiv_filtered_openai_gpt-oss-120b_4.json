{
  "4-1 (Pre-training Data)": "No statements in the supplied quote set describe the openai/gpt-oss-120b pre-training corpus. Consequently, there is no publicly disclosed information here about data sources, data types, licensing constraints, quantity, geographic or linguistic breakdown, or any other composition details for the pre-training data.",
  "4-2 (Fine-tuning Data)": "Every piece of information we have on fine-tuning for openai/gpt-oss-120b centers on specialized, domain-specific datasets gathered to enhance the model’s performance in safety-critical areas. The quotes explain that gpt-oss-120b was ‘incrementally trained … end-to-end for web browsing’ and then repeatedly fine-tuned on ‘in-domain human expert data relevant to biorisk,’ explicitly intended to improve capabilities tested by OpenAI’s Preparedness benchmarks in biology. A parallel effort applied similar incremental fine-tuning to a cybersecurity-oriented variant; in that case, the added data came from ‘cybersecurity capture the flag challenge environments.’ The same passages emphasise that adversarial fine-tuned versions were compared with both non-fine-tuned baselines and competitor models, showing that ‘an adversarially fine-tuned version gpt-oss-120b’ outperformed DeepSeek R1-0528 though it still trailed OpenAI’s in-house o3 models. Finally, evaluation commentary highlights that ‘gpt-oss variants (both with and without adversarial fine-tuning)’ had browsing enabled when tested, unlike several other models. No quantitative dataset sizes, licensing details, or concrete example excerpts are revealed in the quotes, but they clearly establish the presence of narrowly scoped, expert-curated biorisk and cybersecurity data sets used for iterative, adversarial fine-tuning of gpt-oss-120b.",
  "4-3 (Reinforcement Learning Data)": "The provided quote set contains no references to reinforcement-learning-from-human-feedback (RLHF) or any other reinforcement learning data or procedures for openai/gpt-oss-120b. Therefore, no information is available regarding RL data composition, sourcing, or accessibility.",
  "4-4 (Data Filtering)": "The only filtering detail reported for openai/gpt-oss-120b concerns the removal of hazardous content during the pre-training stage: ‘we filtered out certain harmful data related to Chemical, Biological, Radiological, and Nuclear (CBRN).’ This statement—repeated twice in the provided material—indicates a safety-driven data-cleaning pass aimed at excluding CBRN-related content before the model’s weights were trained. The quotes do not specify the filtering tool, classifier, heuristics, numeric thresholds, or quantitative impact (e.g., percentage removed), nor do they mention any other filtering passes (e.g., deduplication, profanity, copyrighted text) or post-training sanitization. Thus, the sole documented filtering criterion for gpt-oss-120b is the categorical exclusion of CBRN-related data during pre-training as part of OpenAI’s ‘state-of-the-art approaches for safety training.’",
  "4-1 (Pre-training Data)__evidence": [],
  "4-2 (Fine-tuning Data)__evidence": [
    {
      "source": "[sections/Adversarial Training]",
      "quote": "For our adversarially trained biological model, we incrementally trained gpt-oss-120b end-to-end for web browsing, and trained it incrementally with in-domain human expert data relevant to biorisk (for which previous OpenAI models have been the most capable)."
    },
    {
      "source": "[sections/2508.10925]",
      "quote": "• Maximizing capabilities relevant to Preparedness benchmarks in the biological and cyber domains: For our adversarially trained biological model, we incrementally trained gpt-oss-120b end-to-end for web browsing, and trained it incrementally with in-domain human expert data relevant to biorisk (for which previous OpenAI models have been the most capable). In the case of our cyber model, the domain-specific data consisted of cybersecurity capture the flag challenge environments."
    },
    {
      "source": "[sections/5.2.1.1 Long-form Biological Risk Questions]",
      "quote": "All gpt-oss helpful-only variants and competitor models seem to be able to synthesize biorisk-related information across all five steps of the biothreat creation process. We note that the Kimi K2, Qwen 3, and DeepSeek R1 results are without browsing and without adversarial fine-tuning, whereas the OpenAI o3, o4-mini, and gpt-oss variants (both with and without adversarial fine-tuning) are with browsing enabled."
    },
    {
      "source": "[sections/5.2.1.6 Evaluations and Red Teaming by External Safety Experts]",
      "quote": "Their evaluation found that an adversarially fine-tuned version gpt-oss-120b generally performed above a non-fine-tuned version of DeepSeek R1-0528 on these tasks, but remained below our OpenAI o3 models in overall reliability and depth."
    }
  ],
  "4-3 (Reinforcement Learning Data)__evidence": [],
  "4-4 (Data Filtering)__evidence": [
    {
      "source": "[sections/Adversarial Training]",
      "quote": "The gpt-oss models leverage our state-of-art approaches for safety training. During pre-training, we filtered out certain harmful data related to Chemical, Biological, Radiological, and Nuclear (CBRN)."
    },
    {
      "source": "[sections/2508.10925]",
      "quote": "The gpt-oss models leverage our state-of-art approaches for safety training. During pre-training, we filtered out certain harmful data related to Chemical, Biological, Radiological, and Nuclear (CBRN)."
    }
  ]
}