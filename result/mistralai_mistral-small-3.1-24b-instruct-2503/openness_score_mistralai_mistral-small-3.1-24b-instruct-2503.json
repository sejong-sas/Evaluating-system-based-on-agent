{
  "model": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
  "scores": {
    "1-1 Weights": {
      "score": 1,
      "reason": "Weights files present in the repository (e.g., *.safetensors/bin/pt/ckpt)."
    },
    "1-2 Code": {
      "score": 0.0,
      "reason": "No training pipeline files; README mentions are ignored."
    },
    "1-3 License": {
      "score": 1,
      "reason": "Recognized permissive license (e.g., MIT/Apache-2.0/BSD/MPL/CC0/CC-BY) in quotes."
    },
    "1-4 Paper": {
      "score": 0.5,
      "reason": "The model is documented only by an official blog post; this qualifies as Semi-Open, not a full technical report."
    },
    "1-5 Architecture": {
      "score": 1,
      "reason": "Architecture evidence present in extracted quotes."
    },
    "1-6 Tokenizer": {
      "score": 1.0,
      "reason": "Tokenizer files downloadable in repository."
    },
    "2-1 Hardware": {
      "score": 0.0,
      "reason": "Quotes describe deployment hardware (RTX 4090, 55 GB for fp16) but give no information about the hardware used to train the model."
    },
    "2-2 Software": {
      "score": 0.0,
      "reason": "No training-stack details (framework versions, distributed libraries, etc.) are quoted; only inference commands appear."
    },
    "2-3 API": {
      "score": 1.0,
      "reason": "Only third-party or generic API mentions; no official owner-hosted API.  Web search found official API docs: https://openrouter.ai/mistralai/mistral-small-3.1-24b-instruct-2503/api"
    },
    "3-1 Pre-training": {
      "score": 0.0,
      "reason": "No concrete method details in quotes."
    },
    "3-2 Fine-tuning": {
      "score": 0.0,
      "reason": "No concrete method details in quotes."
    },
    "3-3 Reinforcement Learning": {
      "score": 0.0,
      "reason": "No mention of RL or preference-based training. No direct quote evidence; defaulting to Closed by strict rule."
    },
    "4-1 Pre-training Data": {
      "score": 0.0,
      "reason": "No disclosure of pre-training data sources or composition. No direct quote evidence; defaulting to Closed by strict rule."
    },
    "4-2 Fine-tuning Data": {
      "score": 0.0,
      "reason": "No information on the data used for instruction fine-tuning. No direct quote evidence; defaulting to Closed by strict rule."
    },
    "4-3 Reinforcement Learning Data": {
      "score": 0.0,
      "reason": "No RL data is discussed. No direct quote evidence; defaulting to Closed by strict rule."
    },
    "4-4 Data Filtering": {
      "score": 0.0,
      "reason": "No description of data cleaning or filtering steps. No direct quote evidence; defaulting to Closed by strict rule."
    }
  },
  "included_scores": {
    "1-1 Weights": {
      "score": 1,
      "reason": "Weights files present in the repository (e.g., *.safetensors/bin/pt/ckpt)."
    },
    "1-2 Code": {
      "score": 0.0,
      "reason": "No training pipeline files; README mentions are ignored."
    },
    "1-3 License": {
      "score": 1,
      "reason": "Recognized permissive license (e.g., MIT/Apache-2.0/BSD/MPL/CC0/CC-BY) in quotes."
    },
    "1-4 Paper": {
      "score": 0.5,
      "reason": "The model is documented only by an official blog post; this qualifies as Semi-Open, not a full technical report."
    },
    "1-5 Architecture": {
      "score": 1,
      "reason": "Architecture evidence present in extracted quotes."
    },
    "1-6 Tokenizer": {
      "score": 1.0,
      "reason": "Tokenizer files downloadable in repository."
    },
    "2-1 Hardware": {
      "score": 0.0,
      "reason": "Quotes describe deployment hardware (RTX 4090, 55 GB for fp16) but give no information about the hardware used to train the model."
    },
    "2-2 Software": {
      "score": 0.0,
      "reason": "No training-stack details (framework versions, distributed libraries, etc.) are quoted; only inference commands appear."
    },
    "2-3 API": {
      "score": 1.0,
      "reason": "Only third-party or generic API mentions; no official owner-hosted API.  Web search found official API docs: https://openrouter.ai/mistralai/mistral-small-3.1-24b-instruct-2503/api"
    },
    "3-1 Pre-training": {
      "score": 0.0,
      "reason": "No concrete method details in quotes."
    },
    "3-2 Fine-tuning": {
      "score": 0.0,
      "reason": "No concrete method details in quotes."
    },
    "4-1 Pre-training Data": {
      "score": 0.0,
      "reason": "No disclosure of pre-training data sources or composition. No direct quote evidence; defaulting to Closed by strict rule."
    },
    "4-2 Fine-tuning Data": {
      "score": 0.0,
      "reason": "No information on the data used for instruction fine-tuning. No direct quote evidence; defaulting to Closed by strict rule."
    },
    "4-4 Data Filtering": {
      "score": 0.0,
      "reason": "No description of data cleaning or filtering steps. No direct quote evidence; defaulting to Closed by strict rule."
    }
  },
  "final_score_10pt": 3.929,
  "meta": {
    "usage_from_dispatch": {
      "fine_tuning": "used",
      "rl": "not_used"
    },
    "excluded": [
      "3-3 Reinforcement Learning",
      "4-3 Reinforcement Learning Data"
    ],
    "denominator": 14,
    "raw_sum": 5.5,
    "scale": "10/14",
    "code_detection_reason": "No training pipeline files; README mentions are ignored.",
    "pretrain_sources_used": false
  }
}