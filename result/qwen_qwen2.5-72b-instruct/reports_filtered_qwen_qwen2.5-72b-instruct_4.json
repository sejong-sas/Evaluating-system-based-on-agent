{
  "4-1 (Pre-training Data)": "The Qwen2.5 family is reported to be pretrained on “our latest large-scale dataset, encompassing up to 18 trillion tokens,” establishing an extremely large raw-text corpus as its foundation. Within this overarching corpus, several domain-specialised variants are singled out.  Qwen2.5-Coder is said to receive “5.5 trillion tokens of code-related data,” ensuring that even comparatively small code models inherit a massive amount of programming-specific material.  For mathematics, the developers note that, relative to the earlier Qwen2-Math, the newer Qwen2.5-Math is pretrained on “larger-scale … math related data,” and this set explicitly “includes the synthetic data generated by Qwen2-Math,” confirming an internal data-generation loop in which earlier models create additional pretraining material.  Across the family, data scale and linguistic breadth have both grown: the team “collected twice as many pre-training tokens—covering three times more languages,” and an additional comparison highlights that the multilingual coverage supported by the Qwen2.5 pretraining corpus rose from 29 to 119 languages/dialects.  Finally, the authors state that they “employ Qwen2.5 … models to synthesize trillions of text tokens in different formats, including textbooks, question-answering, instructions, and code snippets, covering dozens of domains,” indicating that model-generated synthetic content is deliberately injected back into the training mix to expand both domain and stylistic diversity.",
  "4-2 (Fine-tuning Data)": "",
  "4-3 (Reinforcement Learning Data)": "For reinforcement-learning style optimisation, the documentation mentions a “Model-based Reward with Reference Answer” setup in which “we provide a reference answer for each query and prompt Qwen2.5-72B-Instruct to score the model’s response based on this reference.”  Thus, the RL dataset consists of query–reference-answer pairs, and Qwen2.5-72B-Instruct itself acts as an automatic reward model that evaluates candidate outputs by comparing them to the supplied reference, producing a scalar score used for further optimisation.",
  "4-4 (Data Filtering)": "The filtering pipeline for constructing training or evaluation queries is described in two consecutive steps carried out with the help of Qwen2.5-72B-Instruct.  First, during “the query filtering phase,” the model is tasked with “identify[ing] and remov[ing] queries that are not easily verifiable,” implying an automated check for factual verifiability or answer-ability and subsequent exclusion of those failing the test.  Second, after the unverifiable items have been removed, each remaining query is passed once more to Qwen2.5-72B-Instruct so that it can “annotate each query’s domain … to maintain balanced domain representation across the dataset.”  Although no explicit numeric thresholds are given, the two-stage process—(1) verifiability removal, (2) domain tagging and balancing—constitutes the documented data-cleaning/filtering routine.",
  "4-1 (Pre-training Data)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "In terms of Qwen2.5 , the language models, all models are pretrained on our latest large-scale dataset, encompassing up to 18 trillion tokens."
    },
    {
      "source": "[pdf_text]",
      "quote": "Specifically, Qwen2.5-Coder has been trained on 5.5 trillion tokens of code-related data, enabling even smaller coding-specific models to deliver competitive performance against larger language models on coding evaluation benchmarks."
    },
    {
      "source": "[pdf_text]",
      "quote": "In terms of the math specific language models, we released the first models, Qwen2-Math, last month, and this time, compared to Qwen2-Math, Qwen2.5-Math has been pretrained larger-scale of math related data, including the synthetic data generated by Qwen2-Math."
    },
    {
      "source": "[pdf_text]",
      "quote": "Compared with Qwen2.5 (Yang et al., 2024b), we have significantly expanded the scale and diversity of our training data. Specifically, we collected twice as many pre-training tokens—covering three times more languages."
    },
    {
      "source": "[sections/https://qwenlm.github.io/blog/qwen2.5/]",
      "quote": "In terms of Qwen2.5 , the language models, all models are pretrained on our latest large-scale dataset, encompassing up to 18 trillion tokens."
    },
    {
      "source": "[sections/https://qwenlm.github.io/blog/qwen2.5/]",
      "quote": "Specifically, Qwen2.5-Coder has been trained on 5.5 trillion tokens of code-related data, enabling even smaller coding-specific models to deliver competitive performance against larger language models on coding evaluation benchmarks."
    },
    {
      "source": "[sections/https://qwenlm.github.io/blog/qwen2.5/]",
      "quote": "In terms of the math specific language models, we released the first models, Qwen2-Math, last month, and this time, compared to Qwen2-Math, Qwen2.5-Math has been pretrained larger-scale of math related data, including the synthetic data generated by Qwen2-Math."
    },
    {
      "source": "[pdf_text]",
      "quote": "Compared to its predecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119 languages and dialects, enhancing global accessibility through improved cross-lingual understanding and generation capabilities."
    },
    {
      "source": "[pdf_text]",
      "quote": "Compared with Qwen2.5 (Yang et al., 2024b), we have significantly expanded the scale and diversity of our training data."
    },
    {
      "source": "[pdf_text]",
      "quote": "Compared to the pre-training data used in Qwen2.5, the number of supported languages has been significantly increased from 29 to 119, enhancing the model’s linguistic coverage and cross-lingual capabilities."
    },
    {
      "source": "[pdf_text]",
      "quote": "Besides, we employ Qwen2.5 (Yang et al., 2024b), Qwen2.5-Math (Yang et al., 2024c), and Qwen2.5-Coder (Hui et al., 2024) models to synthesize trillions of text tokens in different formats, including textbooks, question-answering, instructions, and code snippets, covering dozens of domains."
    }
  ],
  "4-2 (Fine-tuning Data)__evidence": [],
  "4-3 (Reinforcement Learning Data)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "Model-based Reward with Reference Answer: In this approach, we provide a reference answer for each query and prompt Qwen2.5-72B-Instruct to score the model’s response based on this reference."
    }
  ],
  "4-4 (Data Filtering)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "In the query filtering phase, we use Qwen2.5-72B-Instruct to identify and remove queries that are not easily verifiable."
    },
    {
      "source": "[pdf_text]",
      "quote": "Additionally, we annotate each query’s domain using Qwen2.5-72B-Instruct to maintain balanced domain representation across the dataset."
    }
  ]
}