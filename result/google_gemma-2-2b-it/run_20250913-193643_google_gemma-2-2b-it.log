
======== 3/3 ▶ google/gemma-2-2b-it ========
📁 Directory to create/use: google_gemma-2-2b-it
📁 Output path: google_gemma-2-2b-it
1️⃣ HF: True, GH: False
🔎 Candidate rejected: huggingface/local-gemma (score=2, detail={'org_affinity': -6, 'name_hits': 1, 'readme_hits': 5, 'path_hits': 2, 'bad_keywords': 9, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: MLConvexAI/Gemma-2-2b-it-finetuning (score=2, detail={'org_affinity': -6, 'name_hits': 4, 'readme_hits': 4, 'path_hits': 3, 'bad_keywords': 6, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: 104-wonohfor/Finetune_LLM_Gemma-2b-it (score=2, detail={'org_affinity': -6, 'name_hits': 3, 'readme_hits': 3, 'path_hits': 3, 'bad_keywords': 8, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: inferless/gemma-2b-it (score=-2, detail={'org_affinity': -6, 'name_hits': 3, 'readme_hits': 3, 'path_hits': 0, 'bad_keywords': 10, 'from_hf_link': 0, 'version_conflict': 0})
✅ Resolved GH repo: google/gemma.cpp (score=17, detail={'org_affinity': 9, 'name_hits': 1, 'readme_hits': 5, 'path_hits': 3, 'bad_keywords': 13, 'from_hf_link': 0, 'version_conflict': 0})
✅ HF model: google/gemma-2-2b-it (found at priority: 1)
📄 Reports saved/merged (HF): google_gemma-2-2b-it\reports_fulltext_huggingface_google_gemma-2-2b-it.json
✅ JSON file saved: google_gemma-2-2b-it\huggingface_google_gemma-2-2b-it.json
📄 Reports merged to: google_gemma-2-2b-it\reports_fulltext_google_gemma-2-2b-it.json (HF sources)
✅ Saved group 1 result: google_gemma-2-2b-it\huggingface_filtered_google_gemma-2-2b-it_1.json
✅ Saved group 2 result: google_gemma-2-2b-it\huggingface_filtered_google_gemma-2-2b-it_2.json
✅ Saved group 3 result: google_gemma-2-2b-it\huggingface_filtered_google_gemma-2-2b-it_3.json
✅ Saved group 4 result: google_gemma-2-2b-it\huggingface_filtered_google_gemma-2-2b-it_4.json
✅ Saved final merged result: google_gemma-2-2b-it\huggingface_filtered_final_google_gemma-2-2b-it.json
✅ GH repo: google/gemma.cpp
📄 Reports saved/merged (GH): google_gemma-2-2b-it\reports_fulltext_github_google_gemma.cpp.json
ℹ️ Merge skipped: could not determine a single target HF model id.
✅ GitHub JSON file saved: google_gemma-2-2b-it\github_google_gemma.cpp.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 5, '1-2 (Code)': 6, '1-3 (License)': 9, '1-4 (Paper)': 3}, 'kept': {'1-1 (Weights)': 3, '1-2 (Code)': 3, '1-3 (License)': 7, '1-4 (Paper)': 0}}
✅ Saved group 1 result: google_gemma-2-2b-it\github_filtered_google_gemma.cpp_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 2, '1-6 (Tokenizer)': 2, '2-1 (Hardware)': 0, '2-2 (Software)': 0}, 'kept': {'1-5 (Architecture)': 1, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}}
✅ Saved group 2 result: google_gemma-2-2b-it\github_filtered_google_gemma.cpp_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 0, '3-1 (Pre-training)': 1, '3-2 (Fine-tuning)': 1, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 0, '3-1 (Pre-training)': 1, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}}
✅ Saved group 3 result: google_gemma-2-2b-it\github_filtered_google_gemma.cpp_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}}
✅ Saved group 4 result: google_gemma-2-2b-it\github_filtered_google_gemma.cpp_4.json
✅ Saved final merged result: google_gemma-2-2b-it\github_filtered_final_google_gemma.cpp.json
🔎 HF tags found arXiv IDs: ['2009.03300', '1905.07830', '1911.11641', '1904.09728', '1905.10044', '1907.10641', '1811.00937', '1809.02789', '1911.01547', '1705.03551', '2107.03374', '2108.07732', '2110.14168', '2009.11462', '2101.11718', '2110.08193', '1804.09301', '2109.07958', '1804.06876', '2103.03874', '2304.06364', '1903.00161', '2206.04615', '2203.09509', '2403.13793']
🔄 Simplified query: 'gemma 2'
🔎 Tavily search: gemma 2 paper
  → arXiv link found: https://arxiv.org/abs/2408.00118
🔎 Tavily search: gemma 2 technical report
  → arXiv link found: https://arxiv.org/html/2408.00118v1
🛰️ Tavily candidates: ['2408.00118']
🔬 Verifying 1 Tavily candidate(s) with GPT…
  • Candidate: 2408.00118
    - GPT verdict: ✅ match (The candidate paper is the official technical report for the Gemma 2 series—including the 2B model (instruction-tuned version 'gemma-2-2b-it')—and since the target model’s major version is 2, the vers)
✅ GPT-verified IDs: ['2408.00118']
📦 Final merged arXiv IDs: ['2009.03300', '1905.07830', '1911.11641', '1904.09728', '1905.10044', '1907.10641', '1811.00937', '1809.02789', '1911.01547', '1705.03551', '2107.03374', '2108.07732', '2110.14168', '2009.11462', '2101.11718', '2110.08193', '1804.09301', '2109.07958', '1804.06876', '2103.03874', '2304.06364', '1903.00161', '2206.04615', '2203.09509', '2403.13793', '2408.00118']
📄 PDF saved: google_gemma-2-2b-it\arxiv_2009.03300.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1905.07830.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1911.11641.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1904.09728.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1905.10044.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1907.10641.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1811.00937.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1809.02789.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1911.01547.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1705.03551.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2107.03374.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2108.07732.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2110.14168.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2009.11462.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2101.11718.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2110.08193.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1804.09301.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2109.07958.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1804.06876.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2103.03874.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2304.06364.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1903.00161.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2206.04615.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2203.09509.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2403.13793.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2408.00118.pdf
✅ Full paper text saved: google_gemma-2-2b-it\arxiv_fulltext_google_gemma-2-2b-it.json
📄 Reports merged to: google_gemma-2-2b-it\reports_fulltext_google_gemma-2-2b-it.json
🔎 Relevance filter: kept 9/26 docs for 'google/gemma-2-2b-it'
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 6, '1-2 (Code)': 0, '1-3 (License)': 1, '1-4 (Paper)': 6}, 'kept': {'1-1 (Weights)': 6, '1-2 (Code)': 0, '1-3 (License)': 1, '1-4 (Paper)': 2}}
✅ Saved group 1 : google_gemma-2-2b-it\arxiv_filtered_google_gemma-2-2b-it_1.json
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 3, '1-6 (Tokenizer)': 3, '2-1 (Hardware)': 2, '2-2 (Software)': 3}, 'kept': {'1-5 (Architecture)': 3, '1-6 (Tokenizer)': 3, '2-1 (Hardware)': 2, '2-2 (Software)': 3}}
✅ Saved group 2 : google_gemma-2-2b-it\arxiv_filtered_google_gemma-2-2b-it_2.json
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 0, '3-1 (Pre-training)': 11, '3-2 (Fine-tuning)': 5, '3-3 (Reinforcement Learning)': 3}, 'kept': {'2-3 (API)': 0, '3-1 (Pre-training)': 11, '3-2 (Fine-tuning)': 4, '3-3 (Reinforcement Learning)': 3}}
✅ Saved group 3 : google_gemma-2-2b-it\arxiv_filtered_google_gemma-2-2b-it_3.json
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 2, '4-2 (Fine-tuning Data)': 3, '4-3 (Reinforcement Learning Data)': 2, '4-4 (Data Filtering)': 4}, 'kept': {'4-1 (Pre-training Data)': 2, '4-2 (Fine-tuning Data)': 3, '4-3 (Reinforcement Learning Data)': 2, '4-4 (Data Filtering)': 4}}
✅ Saved group 4 : google_gemma-2-2b-it\arxiv_filtered_google_gemma-2-2b-it_4.json
✅ Saved final merged: google_gemma-2-2b-it\arxiv_filtered_final_google_gemma-2-2b-it.json
🔎 Relevance filter: kept 4/33 docs for 'google/gemma-2-2b-it'
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 8, '1-2 (Code)': 0, '1-3 (License)': 4, '1-4 (Paper)': 7}, 'kept': {'1-1 (Weights)': 8, '1-2 (Code)': 0, '1-3 (License)': 4, '1-4 (Paper)': 7}}
✅ Saved group 1 : google_gemma-2-2b-it\reports_filtered_google_gemma-2-2b-it_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 5, '1-6 (Tokenizer)': 2, '2-1 (Hardware)': 2, '2-2 (Software)': 2}, 'kept': {'1-5 (Architecture)': 5, '1-6 (Tokenizer)': 2, '2-1 (Hardware)': 2, '2-2 (Software)': 2}}
✅ Saved group 2 : google_gemma-2-2b-it\reports_filtered_google_gemma-2-2b-it_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 0, '3-1 (Pre-training)': 7, '3-2 (Fine-tuning)': 6, '3-3 (Reinforcement Learning)': 3}, 'kept': {'2-3 (API)': 0, '3-1 (Pre-training)': 7, '3-2 (Fine-tuning)': 6, '3-3 (Reinforcement Learning)': 3}}
✅ Saved group 3 : google_gemma-2-2b-it\reports_filtered_google_gemma-2-2b-it_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 3, '4-2 (Fine-tuning Data)': 3, '4-3 (Reinforcement Learning Data)': 3, '4-4 (Data Filtering)': 4}, 'kept': {'4-1 (Pre-training Data)': 3, '4-2 (Fine-tuning Data)': 2, '4-3 (Reinforcement Learning Data)': 2, '4-4 (Data Filtering)': 4}}
✅ Saved group 4 : google_gemma-2-2b-it\reports_filtered_google_gemma-2-2b-it_4.json
✅ Saved final merged: google_gemma-2-2b-it\reports_filtered_final_google_gemma-2-2b-it.json
🧱 Pretrained (base) model found by heuristic: google/gemma-2-2b
📄 Reports saved/merged (HF): google_gemma-2-2b-it\reports_fulltext_huggingface_google_gemma-2-2b.json
✅ JSON file saved: google_gemma-2-2b-it\huggingface_google_gemma-2-2b.json
✅ Saved google_gemma-2-2b-it\pretrain_hf_google_gemma-2-2b.json
🔎 Candidate rejected: huggingface/local-gemma (score=0, detail={'org_affinity': -6, 'name_hits': 1, 'readme_hits': 4, 'path_hits': 1, 'bad_keywords': 9, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: ellie-sleightholm/marqo-google-gemma2 (score=-2, detail={'org_affinity': -6, 'name_hits': 2, 'readme_hits': 3, 'path_hits': 0, 'bad_keywords': 13, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: mustafaaljadery/gemma-2B-10M (score=-4, detail={'org_affinity': -6, 'name_hits': 2, 'readme_hits': 2, 'path_hits': 1, 'bad_keywords': 2, 'from_hf_link': 0, 'version_conflict': -8})
🔎 Candidate rejected: inferless/gemma-2b-it (score=-2, detail={'org_affinity': -6, 'name_hits': 2, 'readme_hits': 2, 'path_hits': 0, 'bad_keywords': 10, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: google-gemini/gemma-cookbook (score=2, detail={'org_affinity': -6, 'name_hits': 1, 'readme_hits': 2, 'path_hits': 4, 'bad_keywords': 8, 'from_hf_link': 0, 'version_conflict': 0})
✅ Resolved GH repo: google/gemma.cpp (score=17, detail={'org_affinity': 9, 'name_hits': 1, 'readme_hits': 4, 'path_hits': 2, 'bad_keywords': 13, 'from_hf_link': 0, 'version_conflict': 0})
📄 Reports saved/merged (GH): google_gemma-2-2b-it\reports_fulltext_github_google_gemma.cpp.json
ℹ️ Merge skipped: could not determine a single target HF model id.
✅ GitHub JSON file saved: google_gemma-2-2b-it\github_google_gemma.cpp.json
⚠️ GH fetch/dispatch failed: cannot import name 'filter_pretrain_gh' from 'pretrain_github_Dispatcher' (c:\Users\user\Desktop\lab git\lab git\Evaluating-system-based-on-agent\code\pretrain_github_Dispatcher.py)
🔎 HF tags found arXiv IDs: ['2009.03300', '1905.07830', '1911.11641', '1904.09728', '1905.10044', '1907.10641', '1811.00937', '1809.02789', '1911.01547', '1705.03551', '2107.03374', '2108.07732', '2110.14168', '2009.11462', '2101.11718', '2110.08193', '1804.09301', '2109.07958', '1804.06876', '2103.03874', '2304.06364', '1903.00161', '2206.04615', '2203.09509', '2403.13793']
🔄 Simplified query: 'gemma 2'
🔎 Tavily search: gemma 2 paper
  → arXiv link found: https://arxiv.org/abs/2408.00118
🔎 Tavily search: gemma 2 technical report
  → arXiv link found: https://arxiv.org/html/2408.00118v1
🛰️ Tavily candidates: ['2408.00118']
🔬 Verifying 1 Tavily candidate(s) with GPT…
  • Candidate: 2408.00118
    - GPT verdict: ✅ match (The candidate paper is the official technical report for Gemma 2 and clearly documents the 2B model variant. Since the target ('google/gemma-2-2b') is a Gemma 2 model, and the paper’s version (Gemma 2)
✅ GPT-verified IDs: ['2408.00118']
📦 Final merged arXiv IDs: ['2009.03300', '1905.07830', '1911.11641', '1904.09728', '1905.10044', '1907.10641', '1811.00937', '1809.02789', '1911.01547', '1705.03551', '2107.03374', '2108.07732', '2110.14168', '2009.11462', '2101.11718', '2110.08193', '1804.09301', '2109.07958', '1804.06876', '2103.03874', '2304.06364', '1903.00161', '2206.04615', '2203.09509', '2403.13793', '2408.00118']
📄 PDF saved: google_gemma-2-2b-it\arxiv_2009.03300.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1905.07830.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1911.11641.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1904.09728.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1905.10044.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1907.10641.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1811.00937.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1809.02789.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1911.01547.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1705.03551.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2107.03374.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2108.07732.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2110.14168.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2009.11462.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2101.11718.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2110.08193.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1804.09301.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2109.07958.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1804.06876.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2103.03874.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2304.06364.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_1903.00161.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2206.04615.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2203.09509.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2403.13793.pdf
📄 PDF saved: google_gemma-2-2b-it\arxiv_2408.00118.pdf
✅ Full paper text saved: google_gemma-2-2b-it\arxiv_fulltext_google_gemma-2-2b.json
✅ Saved: google_gemma-2-2b-it\pretrain_arxiv_google_gemma-2-2b.json
✅ Saved pretrain reports: google_gemma-2-2b-it\pretrain_reports_google_gemma-2-2b.json
📝 Starting openness evaluation...
📝 Saved evaluation result: google_gemma-2-2b-it\openness_score_google_gemma-2-2b-it.json
✅ Openness evaluation complete. Result file: google_gemma-2-2b-it\openness_score_google_gemma-2-2b-it.json
✅ Saved model ID: google_gemma-2-2b-it\identified_model.txt
⏳ **Time taken for this model: 5332.55 seconds**
🧾 Log saved to: google_gemma-2-2b-it\run_20250913-193643_google_gemma-2-2b-it.log
