
======== 1/3 â–¶ meta-llama/Llama-3.3-70B-Instruct ========
ğŸ“ Directory to create/use: meta-llama_llama-3.3-70b-instruct
ğŸ“ Output path: meta-llama_llama-3.3-70b-instruct
1ï¸âƒ£ HF: True, GH: False
âœ… Resolved GH repo: meta-llama/llama3 (score=17, detail={'org_affinity': 9, 'name_hits': 2, 'readme_hits': 4, 'path_hits': 2, 'bad_keywords': 10, 'from_hf_link': 0, 'version_conflict': 0})
âœ… HF model: meta-llama/llama-3.3-70b-instruct (found at priority: 1)
ğŸ“„ Reports saved/merged (HF): meta-llama_llama-3.3-70b-instruct\reports_fulltext_huggingface_meta-llama_llama-3.3-70b-instruct.json
âœ… JSON file saved: meta-llama_llama-3.3-70b-instruct\huggingface_meta-llama_llama-3.3-70b-instruct.json
ğŸ“„ Reports merged to: meta-llama_llama-3.3-70b-instruct\reports_fulltext_meta-llama_llama-3.3-70b-instruct.json (HF sources)
âœ… Saved group 1 result: meta-llama_llama-3.3-70b-instruct\huggingface_filtered_meta-llama_llama-3.3-70b-instruct_1.json
âœ… Saved group 2 result: meta-llama_llama-3.3-70b-instruct\huggingface_filtered_meta-llama_llama-3.3-70b-instruct_2.json
âœ… Saved group 3 result: meta-llama_llama-3.3-70b-instruct\huggingface_filtered_meta-llama_llama-3.3-70b-instruct_3.json
âœ… Saved group 4 result: meta-llama_llama-3.3-70b-instruct\huggingface_filtered_meta-llama_llama-3.3-70b-instruct_4.json
âœ… Saved final merged result: meta-llama_llama-3.3-70b-instruct\huggingface_filtered_final_meta-llama_llama-3.3-70b-instruct.json
âœ… GH repo: meta-llama/llama3
ğŸ“„ Reports saved/merged (GH): meta-llama_llama-3.3-70b-instruct\reports_fulltext_github_meta-llama_llama3.json
â„¹ï¸ Merge skipped: could not determine a single target HF model id.
âœ… GitHub JSON file saved: meta-llama_llama-3.3-70b-instruct\github_meta-llama_llama3.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 3, '1-2 (Code)': 1, '1-3 (License)': 7, '1-4 (Paper)': 1}, 'kept': {'1-1 (Weights)': 3, '1-2 (Code)': 1, '1-3 (License)': 7, '1-4 (Paper)': 1}}
âœ… Saved group 1 result: meta-llama_llama-3.3-70b-instruct\github_filtered_meta-llama_llama3_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 3, '1-6 (Tokenizer)': 2, '2-1 (Hardware)': 0, '2-2 (Software)': 0}, 'kept': {'1-5 (Architecture)': 2, '1-6 (Tokenizer)': 1, '2-1 (Hardware)': 0, '2-2 (Software)': 0}}
âœ… Saved group 2 result: meta-llama_llama-3.3-70b-instruct\github_filtered_meta-llama_llama3_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 0, '3-1 (Pre-training)': 2, '3-2 (Fine-tuning)': 2, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 0, '3-1 (Pre-training)': 1, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}}
âœ… Saved group 3 result: meta-llama_llama-3.3-70b-instruct\github_filtered_meta-llama_llama3_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 2}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 2}}
âœ… Saved group 4 result: meta-llama_llama-3.3-70b-instruct\github_filtered_meta-llama_llama3_4.json
âœ… Saved final merged result: meta-llama_llama-3.3-70b-instruct\github_filtered_final_meta-llama_llama3.json
ğŸ” HF tags found arXiv IDs: ['2204.05149']
ğŸ”„ Simplified query: 'llama 3.3'
ğŸ” Tavily search: llama 3.3 paper
  â†’ arXiv link found: https://arxiv.org/abs/2407.21783
ğŸ” Tavily search: llama 3.3 technical report
  â†’ arXiv link found: https://arxiv.org/abs/2407.21783
ğŸ›°ï¸ Tavily candidates: ['2407.21783']
ğŸ”¬ Verifying 1 Tavily candidate(s) with GPTâ€¦
  â€¢ Candidate: 2407.21783
    - GPT verdict: âœ… match (The paper is the official technical report for Llama 3 models. Although it reports on Llama 3.1, its MAJOR version (3) is the same as that of the target (3.3) and the minor version difference (0.2) is)
âœ… GPT-verified IDs: ['2407.21783']
ğŸ“¦ Final merged arXiv IDs: ['2204.05149', '2407.21783']
ğŸ“„ PDF saved: meta-llama_llama-3.3-70b-instruct\arxiv_2204.05149.pdf
ğŸ“„ PDF saved: meta-llama_llama-3.3-70b-instruct\arxiv_2407.21783.pdf
âœ… Full paper text saved: meta-llama_llama-3.3-70b-instruct\arxiv_fulltext_meta-llama_llama-3.3-70b-instruct.json
ğŸ“„ Reports merged to: meta-llama_llama-3.3-70b-instruct\reports_fulltext_meta-llama_llama-3.3-70b-instruct.json
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
âš ï¸ Error in group 1: Error code: 400 - {'error': {'message': "Invalid prompt: we've limited access to this content for safety reasons. This type of information may be used to benefit or to harm people. We are continuously refining our work in this area, and you can read more about our approach in our blog post (https://openai.com/index/preparing-for-future-ai-capabilities-in-biology) and Model Spec (https://openai.com/index/introducing-the-model-spec).", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_prompt'}}
âœ… Saved group 1 : meta-llama_llama-3.3-70b-instruct\arxiv_filtered_meta-llama_llama-3.3-70b-instruct_1.json
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 17, '1-6 (Tokenizer)': 2, '2-1 (Hardware)': 6, '2-2 (Software)': 6}, 'kept': {'1-5 (Architecture)': 15, '1-6 (Tokenizer)': 2, '2-1 (Hardware)': 6, '2-2 (Software)': 5}}
âœ… Saved group 2 : meta-llama_llama-3.3-70b-instruct\arxiv_filtered_meta-llama_llama-3.3-70b-instruct_2.json
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
âš ï¸ Error in group 3: Error code: 400 - {'error': {'message': "Invalid prompt: we've limited access to this content for safety reasons. This type of information may be used to benefit or to harm people. We are continuously refining our work in this area, and you can read more about our approach in our blog post (https://openai.com/index/preparing-for-future-ai-capabilities-in-biology) and Model Spec (https://openai.com/index/introducing-the-model-spec).", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_prompt'}}
âœ… Saved group 3 : meta-llama_llama-3.3-70b-instruct\arxiv_filtered_meta-llama_llama-3.3-70b-instruct_3.json
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 12, '4-2 (Fine-tuning Data)': 9, '4-3 (Reinforcement Learning Data)': 4, '4-4 (Data Filtering)': 15}, 'kept': {'4-1 (Pre-training Data)': 12, '4-2 (Fine-tuning Data)': 9, '4-3 (Reinforcement Learning Data)': 4, '4-4 (Data Filtering)': 15}}
âœ… Saved group 4 : meta-llama_llama-3.3-70b-instruct\arxiv_filtered_meta-llama_llama-3.3-70b-instruct_4.json
âœ… Saved final merged: meta-llama_llama-3.3-70b-instruct\arxiv_filtered_final_meta-llama_llama-3.3-70b-instruct.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 7, '1-2 (Code)': 5, '1-3 (License)': 0, '1-4 (Paper)': 6}, 'kept': {'1-1 (Weights)': 7, '1-2 (Code)': 5, '1-3 (License)': 0, '1-4 (Paper)': 6}}
âœ… Saved group 1 : meta-llama_llama-3.3-70b-instruct\reports_filtered_meta-llama_llama-3.3-70b-instruct_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 1, '2-1 (Hardware)': 1, '2-2 (Software)': 0}, 'kept': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 1, '2-1 (Hardware)': 1, '2-2 (Software)': 0}}
âœ… Saved group 2 : meta-llama_llama-3.3-70b-instruct\reports_filtered_meta-llama_llama-3.3-70b-instruct_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 4, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 5, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 4, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 5, '3-3 (Reinforcement Learning)': 0}}
âœ… Saved group 3 : meta-llama_llama-3.3-70b-instruct\reports_filtered_meta-llama_llama-3.3-70b-instruct_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}}
âœ… Saved group 4 : meta-llama_llama-3.3-70b-instruct\reports_filtered_meta-llama_llama-3.3-70b-instruct_4.json
âœ… Saved final merged: meta-llama_llama-3.3-70b-instruct\reports_filtered_final_meta-llama_llama-3.3-70b-instruct.json
ğŸ”‘ Hugging Face API says 401/403 â€” model may be private. Set HF_TOKEN in .env if you have access.
ğŸ“ Starting openness evaluation...
ğŸ“ Saved evaluation result: meta-llama_llama-3.3-70b-instruct\openness_score_meta-llama_llama-3.3-70b-instruct.json
âœ… Openness evaluation complete. Result file: meta-llama_llama-3.3-70b-instruct\openness_score_meta-llama_llama-3.3-70b-instruct.json
âœ… Saved model ID: meta-llama_llama-3.3-70b-instruct\identified_model.txt
â³ **Time taken for this model: 3726.91 seconds**
ğŸ§¾ Log saved to: meta-llama_llama-3.3-70b-instruct\run_20250913-180238_meta-llama_llama-3.3-70b-instruct.log
