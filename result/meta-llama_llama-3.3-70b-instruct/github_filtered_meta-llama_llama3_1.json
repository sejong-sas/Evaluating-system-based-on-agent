{
  "1-1 (Weights)": "The project explicitly states that it ‚Äúincludes model weights and starting code for pre-trained and instruction-tuned Llama 3 language models ‚Äî including sizes of 8B to 70B parameters.‚Äù  The official place to obtain them is given in the sentence: ‚ÄúTo download the model weights and tokenizer, please visit the Meta Llama website (https://llama.meta.com/llama-downloads/) and accept our License.‚Äù  In addition to the Meta-hosted download portal, mirrors are provided on Hugging Face: ‚ÄúWe also provide downloads on https://huggingface.co/meta-llama, in both transformers and native `llama3` formats.‚Äù  Collectively, these lines show that anyone who first agrees to the license can fetch full checkpoint files and a tokenizer either from Meta‚Äôs own download page or from the Hugging Face hub, choosing between a standard Transformers serialization or a raw `llama3` format.  No quote indicates any further gate-keeping or approval step beyond accepting the license text.",
  "1-1 (Weights)__evidence": [
    {
      "source": "readme",
      "quote": "This release includes model weights and starting code for pre-trained and instruction-tuned Llama 3 language models ‚Äî including sizes of 8B to 70B parameters."
    },
    {
      "source": "readme",
      "quote": "To download the model weights and tokenizer, please visit the [Meta Llama website](https://llama.meta.com/llama-downloads/) and accept our License."
    },
    {
      "source": "readme",
      "quote": "We also provide downloads on [Hugging Face](https://huggingface.co/meta-llama), in both transformers and native `llama3` formats."
    }
  ],
  "1-2 (Code)": "Code release is limited to inference only.  The sole statement reads: ‚ÄúThis repository is a minimal example of loading Llama 3 models and running inference.‚Äù  Because the quote makes no mention of data-prep, pre-training, fine-tuning, or RL scripts, it confirms that training-time pipelines are not included; users receive just enough code to instantiate the checkpoints and generate text.",
  "1-2 (Code)__evidence": [
    {
      "source": "readme",
      "quote": "This repository is a minimal example of loading Llama 3 models and running inference."
    }
  ],
  "1-3 (License)": "The governing terms are captured in the header line ‚ÄúMETA LLAMA 3 COMMUNITY LICENSE AGREEMENT,‚Äù further dated ‚ÄúMeta Llama 3 Version Release Date: April 18, 2024.‚Äù  Under this agreement, Meta grants ‚Äúa non-exclusive, worldwide, non-transferable and royalty-free limited license ‚Ä¶ to use, reproduce, distribute, copy, create derivative works of, and make modifications to the Llama Materials.‚Äù  Redistribution comes with two obligations: ‚ÄúIf you distribute or make available the Llama Materials ‚Ä¶ you shall (A) provide a copy of this Agreement ‚Ä¶ and (B) prominently display ‚ÄòBuilt with Meta Llama 3‚Äô.‚Äú  A notable restriction appears in the clause: ‚ÄúYou will not use the Llama Materials or any output or results of the Llama Materials to improve any other large language model (excluding Meta Llama 3 or derivative works thereof).‚Äù  Large-scale deployers face an additional gate: ‚ÄúIf ‚Ä¶ the monthly active users ‚Ä¶ is greater than 700 million ‚Ä¶ you must request a license from Meta.‚Äù  The repository footer reinforces that all software artifacts fall under these terms: ‚Äú# This software may be used and distributed in accordance with the terms of the Llama 3 Community License Agreement.‚Äù  No quote mentions any prohibition on commercial use for entities below the 700 million-MAU threshold, so within that limit commercial redistribution and derivative creation are allowed as long as the above conditions are met.",
  "1-3 (License)__evidence": [
    {
      "source": "license_files",
      "quote": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT"
    },
    {
      "source": "license_files",
      "quote": "Meta Llama 3 Version Release Date: April 18, 2024"
    },
    {
      "source": "license_files",
      "quote": "You are granted a non-exclusive, worldwide, non-transferable and royalty-free limited license under Meta‚Äôs intellectual property or other rights owned by Meta embodied in the Llama Materials to use, reproduce, distribute, copy, create derivative works of, and make modifications to the Llama Materials."
    },
    {
      "source": "license_files",
      "quote": "If you distribute or make available the Llama Materials (or any derivative works thereof), or a product or service that uses any of them, including another AI model, you shall (A) provide a copy of this Agreement with any such Llama Materials; and (B) prominently display ‚ÄúBuilt with Meta Llama 3‚Äù on a related website, user interface, blogpost, about page, or product documentation."
    },
    {
      "source": "license_files",
      "quote": "You will not use the Llama Materials or any output or results of the Llama Materials to improve any other large language model (excluding Meta Llama 3 or derivative works thereof)."
    },
    {
      "source": "license_files",
      "quote": "If, on the Meta Llama 3 version release date, the monthly active users of the products or services made available by or for Licensee, or Licensee‚Äôs affiliates, is greater than 700 million monthly active users in the preceding calendar month, you must request a license from Meta, which Meta may grant to you in its sole discretion, and you are not authorized to exercise any of the rights under this Agreement unless or until Meta otherwise expressly grants you such rights."
    },
    {
      "source": "py_files/setup.py",
      "quote": "# This software may be used and distributed in accordance with the terms of the Llama 3 Community License Agreement."
    }
  ],
  "1-4 (Paper)": "There is no formal academic paper cited, but the documentation bundles several first-party resources in a single line: ‚ÄúModels on Hugging Face | Blog | Website | Get Started.‚Äù  These links indicate that technical details, usage guides, and announcements are provided through (1) a Hugging Face model card collection, (2) posts on Meta‚Äôs AI blog, (3) the central Llama website, and (4) a ‚ÄòGet Started‚Äô onboarding page.  The quote does not supply titles, DOIs, or arXiv references, so the public written record currently takes the form of web articles and model cards rather than a peer-reviewed paper.",
  "1-4 (Paper)__evidence": [
    {
      "source": "readme",
      "quote": "ü§ó <a href=\"https://huggingface.co/meta-Llama\"> Models on Hugging Face</a>&nbsp | <a href=\"https://ai.meta.com/blog/\"> Blog</a>&nbsp |  <a href=\"https://llama.meta.com/\">Website</a>&nbsp | <a href=\"https://llama.meta.com/get-started/\">Get Started</a>&nbsp"
    }
  ]
}