{
  "1-1 (Weights)": "The only explicit information given about the tencent/hunyuanimage-2.1 weights is that they are used in an entirely \"frozen\" state during downstream experimentation: “All experiments are conducted using the HunyuanImage 2.1 as the base Text-to-Image model. Its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer.”  This conveys that (a) the authors had access to the pretrained 2.1 parameters, (b) the parameters were not modified or fine-tuned, and (c) the research setup relies on this immutability to highlight the add-on nature of their method.  No sentences indicate that the weights are publicly downloadable, where they are hosted, what authentication or agreements are required, or whether redistribution is allowed; likewise, there is no mention of checkpoints, versioning identifiers, model cards, or hosting platforms.",
  "1-2 (Code)": "The provided quotes contain no sentences that refer to any form of training, fine-tuning, or inference code for tencent/hunyuanimage-2.1.  Consequently, no details are available about the release (or non-release) of data-processing scripts, model configurations, training schedules, evaluation harnesses, or serving pipelines.  In short, the quotes offer zero information on code availability or openness.",
  "1-3 (License)": "There are no sentences in the supplied material that mention a software license, terms of use, redistribution clauses, research-only restrictions, or any other legal framing for the tencent/hunyuanimage-2.1 model.  As such, no licensing information can be summarized from the current quotes.",
  "1-4 (Paper)": "Two sentences serve as the sole evidence of publication-related material.  The first states: “Extensive experiments on the HunyuanImage 2.1 model demonstrate that PromptEnhancer significantly improves image-text alignment across a wide range of semantic and compositional challenges.”  The second elaborates on the scope: “Using HunyuanImage 2.1 as the base T2I model, our method demonstrates its versatility across various domains, including photorealism, digital art, abstract geometry, and multilingual text-in-image generation.”  Together, these lines confirm that a technical work—presumably a paper describing PromptEnhancer—includes a systematic experimental section built upon tencent/hunyuanimage-2.1.  They highlight the model’s role as the fixed baseline, the breadth of evaluation domains, and the claimed empirical gains in image-text alignment.  No bibliographic details (title, authors, venue, DOI, arXiv link, or publication date) are included in the quotes.",
  "1-1 (Weights)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "All experiments are conducted using the HunyuanImage 2.1 as the base Text-to-Image model. Its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer."
    },
    {
      "source": "[sections/Experiments]",
      "quote": "All experiments are conducted using the HunyuanImage 2.1 as the base Text-to-Image model. Its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer."
    }
  ],
  "1-2 (Code)__evidence": [],
  "1-3 (License)__evidence": [],
  "1-4 (Paper)__evidence": [
    {
      "source": "[abstract]",
      "quote": "Extensive experiments on the HunyuanImage 2.1 model demonstrate that PromptEnhancer significantly improves image-text alignment across a wide range of semantic and compositional challenges."
    },
    {
      "source": "[pdf_text]",
      "quote": "Using HunyuanImage 2.1 as the base T2I model, our method demonstrates its versatility across various domains, including photorealism, digital art, abstract geometry, and multilingual text-in-image generation."
    }
  ],
  "1-5 (Architecture)": "",
  "1-6 (Tokenizer)": "",
  "2-1 (Hardware)": "According to the authors, every experiment that leverages the HunyuanImage 2.1 text-to-image model is both trained and executed on exactly eight NVIDIA H800 GPUs. No other accelerator types or GPU counts are mentioned for either training or inference, indicating that the entire computational workload—model fitting, fine-tuning, and subsequent evaluations—relies exclusively on this single 8-GPU H800 setup.",
  "2-2 (Software)": "",
  "1-5 (Architecture)__evidence": [],
  "1-6 (Tokenizer)__evidence": [],
  "2-1 (Hardware)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "All experiments are conducted using the HunyuanImage 2.1 as the base Text-to-Image model. All training and inference are performed on 8 NVIDIA H800 GPUs."
    }
  ],
  "2-2 (Software)__evidence": [],
  "2-3 (API)": "",
  "3-1 (Pre-training)": "",
  "3-2 (Fine-tuning)": "The only disclosed fine-tuning information for tencent/hunyuanimage-2.1 states that every experiment uses “the HunyuanImage 2.1 as the base Text-to-Image model,” and that during those experiments “its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer.”  In other words, rather than updating or adapting the core HunyuanImage 2.1 parameters, the researchers attach an auxiliary component (PromptEnhancer) whose training leaves the underlying 2.1 weights untouched.  This setup is explicitly presented as evidence that HunyuanImage 2.1 can serve as a drop-in, fixed backbone while downstream modules are tuned independently, underscoring a strict “no-weight-updates” policy for the base model in the reported fine-tuning pipeline.",
  "3-3 (Reinforcement Learning)": "",
  "2-3 (API)__evidence": [],
  "3-1 (Pre-training)__evidence": [],
  "3-2 (Fine-tuning)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "All experiments are conducted using the HunyuanImage 2.1 as the base Text-to-Image model. Its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer."
    },
    {
      "source": "[sections/2509.04545]",
      "quote": "All experiments are conducted using the HunyuanImage 2.1 as the base Text-to-Image model. Its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer."
    }
  ],
  "3-3 (Reinforcement Learning)__evidence": [],
  "4-1 (Pre-training Data)": "",
  "4-2 (Fine-tuning Data)": "",
  "4-3 (Reinforcement Learning Data)": "",
  "4-4 (Data Filtering)": "",
  "4-1 (Pre-training Data)__evidence": [],
  "4-2 (Fine-tuning Data)__evidence": [],
  "4-3 (Reinforcement Learning Data)__evidence": [],
  "4-4 (Data Filtering)__evidence": [],
  "__usage": {
    "fine_tuning": "not_used",
    "rl": "unknown"
  }
}