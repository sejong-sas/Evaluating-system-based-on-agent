{
  "1-5 (Architecture)": "HunyuanImage-2.1 is described as a two-stage text-to-image system that can produce native 2 K (2048 × 2048) resolution pictures.  In the first stage—the “Base text-to-image Model”—the system feeds the prompt through two separate text encoders: (1) a multimodal large-language-model (MLLM) encoder that strengthens image–text alignment and (2) a multi-language, character-aware encoder that improves rendering of many written languages.  The visual backbone in this stage is explicitly called a “single- and dual-stream diffusion transformer” carrying 17 billion parameters.  A variational auto-encoder (VAE) with a 32 × compression factor is placed in front of the DiT so that the number of image tokens presented to the diffusion transformer is dramatically reduced.  After an initial image is generated, a second-stage “Refiner Model” is applied; its sole purpose is to sharpen details, raise perceptual quality, and suppress artifacts that survive the first pass.  All of these components together comprise the HunyuanImage-2.1 architecture.",
  "1-5 (Architecture)__evidence": [
    {
      "source": "[readme]",
      "quote": "We present HunyuanImage-2.1, a highly efficient text-to-image model that is capable of generating 2K (2048 × 2048) resolution images."
    },
    {
      "source": "[readme]",
      "quote": "Our architecture consists of two stages:\n1. ​Base text-to-image Model:​​ The first stage is a text-to-image model that utilizes two text encoders: a multimodal large language model (MLLM) to improve image-text alignment, and a multi-language, character-aware encoder to enhance text rendering across various languages. This stage features a single- and dual-stream diffusion transformer with 17 billion parameters.\n2. Refiner Model: The second stage introduces a refiner model that further enhances image quality and clarity, while minimizing artifacts."
    },
    {
      "source": "[readme]",
      "quote": "* Network: A single- and dual-stream diffusion transformer with 17 billion parameters."
    },
    {
      "source": "[readme]",
      "quote": "* A VAE with a 32× compression rate drastically reduces the number of input tokens for the DiT model."
    }
  ],
  "1-6 (Tokenizer)": "The model ships with a bespoke tokenizer declared in code as “class HYTokenizer(PreTrainedTokenizer): \\\"\\\"\\\"hunyuan tokenizer.\\\"\\\"\\\"”.  Its vocabulary is stored in a single file referenced as “hy.tiktoken” via VOCAB_FILES_NAMES = { \"vocab_file\": \"hy.tiktoken\" }.  No other tokenizer implementation or download location is mentioned in the available material.",
  "1-6 (Tokenizer)__evidence": [
    {
      "source": "[py_files/reprompt/tokenization_hy.py]",
      "quote": "class HYTokenizer(PreTrainedTokenizer): \"\"\"hunyuan tokenizer.\"\"\""
    },
    {
      "source": "[py_files/reprompt/tokenization_hy.py]",
      "quote": "VOCAB_FILES_NAMES = {\"vocab_file\": \"hy.tiktoken\"}"
    }
  ],
  "2-1 (Hardware)": "The documentation for HunyuanImage-2.1 lists an NVIDIA GPU with CUDA support as the required accelerator class.  For full-resolution 2048 × 2048 image generation, a board providing at least 24 GB of GPU memory is identified as the current minimum requirement.  No additional cluster size, card model (e.g., H100, A100), or multi-GPU configuration details are disclosed in the supplied quotes.",
  "2-1 (Hardware)__evidence": [
    {
      "source": "[readme]",
      "quote": "**Hardware and OS Requirements:**\n- NVIDIA GPU with CUDA support.\n\n  **Minimum requrement for now:** 24 GB GPU memory for 2048x2048 image generation."
    }
  ],
  "2-2 (Software)": "The installation snippet given for HunyuanImage-2.1 centers on a Python/​pip workflow.  Users are instructed first to “pip install -r requirements.txt,” which implicitly pulls in the model’s full dependency list, and then to explicitly install FlashAttention version 2.7.3 using “pip install flash-attn==2.7.3 --no-build-isolation.”  No other libraries, frameworks, or training flags are shown, so these two commands constitute the entirety of the revealed software setup.",
  "2-2 (Software)__evidence": [
    {
      "source": "[readme]",
      "quote": "2. Install dependencies:\n```bash\npip install -r requirements.txt\npip install flash-attn==2.7.3 --no-build-isolation\n```"
    }
  ]
}