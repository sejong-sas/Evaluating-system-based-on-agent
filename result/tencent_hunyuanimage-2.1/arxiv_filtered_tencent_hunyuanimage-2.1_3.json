{
  "2-3 (API)": "",
  "3-1 (Pre-training)": "",
  "3-2 (Fine-tuning)": "The only disclosed fine-tuning information for tencent/hunyuanimage-2.1 states that every experiment uses “the HunyuanImage 2.1 as the base Text-to-Image model,” and that during those experiments “its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer.”  In other words, rather than updating or adapting the core HunyuanImage 2.1 parameters, the researchers attach an auxiliary component (PromptEnhancer) whose training leaves the underlying 2.1 weights untouched.  This setup is explicitly presented as evidence that HunyuanImage 2.1 can serve as a drop-in, fixed backbone while downstream modules are tuned independently, underscoring a strict “no-weight-updates” policy for the base model in the reported fine-tuning pipeline.",
  "3-3 (Reinforcement Learning)": "",
  "2-3 (API)__evidence": [],
  "3-1 (Pre-training)__evidence": [],
  "3-2 (Fine-tuning)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "All experiments are conducted using the HunyuanImage 2.1 as the base Text-to-Image model. Its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer."
    },
    {
      "source": "[sections/2509.04545]",
      "quote": "All experiments are conducted using the HunyuanImage 2.1 as the base Text-to-Image model. Its weights remain frozen throughout our training process to demonstrate the plug-and-play capability of PromptEnhancer."
    }
  ],
  "3-3 (Reinforcement Learning)__evidence": []
}