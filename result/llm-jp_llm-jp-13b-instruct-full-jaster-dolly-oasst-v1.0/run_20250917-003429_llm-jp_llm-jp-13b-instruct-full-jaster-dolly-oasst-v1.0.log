
======== 3/4 ▶ llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0 ========
📁 Directory to create/use: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0
📁 Output path: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0
1️⃣ HF: True, GH: False
🔎 Candidate rejected: huggingface/tokenizers (score=6, detail={'org_affinity': 9, 'name_hits': 0, 'readme_hits': 0, 'path_hits': 0, 'bad_keywords': 10, 'from_hf_link': 1, 'version_conflict': 0})
🔎 Candidate rejected: pfnet-research/japanese-lm-fin-harness (score=-2, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 3, 'path_hits': 3, 'bad_keywords': 3, 'from_hf_link': 0, 'version_conflict': 0})
✅ Resolved GH repo: llm-jp/llm-jp-eval (score=22, detail={'org_affinity': 9, 'name_hits': 1, 'readme_hits': 3, 'path_hits': 2, 'bad_keywords': 12, 'from_hf_link': 1, 'version_conflict': 0})
✅ HF model: llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0 (found at priority: 1)
📄 Reports saved/merged (HF): llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\reports_fulltext_huggingface_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
✅ JSON file saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\huggingface_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
✅ Saved group 1 result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\huggingface_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_1.json
✅ Saved group 2 result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\huggingface_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_2.json
✅ Saved group 3 result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\huggingface_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_3.json
✅ Saved group 4 result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\huggingface_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_4.json
✅ Saved final merged result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\huggingface_filtered_final_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
✅ GH repo: llm-jp/llm-jp-eval
✅ GitHub JSON file saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\github_llm-jp_llm-jp-eval.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 0, '1-2 (Code)': 1, '1-3 (License)': 3, '1-4 (Paper)': 0}, 'kept': {'1-1 (Weights)': 0, '1-2 (Code)': 1, '1-3 (License)': 3, '1-4 (Paper)': 0}}
✅ Saved group 1 result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\github_filtered_llm-jp_llm-jp-eval_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}, 'kept': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}}
✅ Saved group 2 result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\github_filtered_llm-jp_llm-jp-eval_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 2, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 1, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 1, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 1, '3-3 (Reinforcement Learning)': 0}}
✅ Saved group 3 result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\github_filtered_llm-jp_llm-jp-eval_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 11}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}}
✅ Saved group 4 result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\github_filtered_llm-jp_llm-jp-eval_4.json
✅ Saved final merged result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\github_filtered_final_llm-jp_llm-jp-eval.json
🔎 HF tags found arXiv IDs: []
🔄 Simplified query: 'llm jp full jaster dolly oasst 1.0'
🔎 Tavily search: llm jp full jaster dolly oasst 1.0 paper
  → arXiv link found: https://arxiv.org/html/2407.03963v1
🔎 Tavily search: llm jp full jaster dolly oasst 1.0 technical report
  → arXiv link found: https://arxiv.org/html/2407.03963v1
🛰️ Tavily candidates: ['2407.03963']
🔬 Verifying 1 Tavily candidate(s) with GPT…
  • Candidate: 2407.03963
    - GPT verdict: ✅ match (The paper is the primary technical report for the LLM-jp project and details the release of the 13B model version v1.0 (including instructions with jaster, dolly, and oasst tuning) which exactly match)
✅ GPT-verified IDs: ['2407.03963']
📦 Final merged arXiv IDs: ['2407.03963']
📄 PDF saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_2407.03963.pdf
✅ Full paper text saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_fulltext_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
📄 Reports merged to: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\reports_fulltext_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
🔎 recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 3, '1-2 (Code)': 5, '1-3 (License)': 3, '1-4 (Paper)': 5}, 'kept': {'1-1 (Weights)': 3, '1-2 (Code)': 4, '1-3 (License)': 2, '1-4 (Paper)': 4}}
✅ Saved group 1 : llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_1.json
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
🔎 recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 5, '1-6 (Tokenizer)': 5, '2-1 (Hardware)': 3, '2-2 (Software)': 5}, 'kept': {'1-5 (Architecture)': 5, '1-6 (Tokenizer)': 4, '2-1 (Hardware)': 3, '2-2 (Software)': 3}}
✅ Saved group 2 : llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_2.json
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
🔎 recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 0, '3-1 (Pre-training)': 11, '3-2 (Fine-tuning)': 9, '3-3 (Reinforcement Learning)': 2}, 'kept': {'2-3 (API)': 0, '3-1 (Pre-training)': 10, '3-2 (Fine-tuning)': 7, '3-3 (Reinforcement Learning)': 2}}
✅ Saved group 3 : llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_3.json
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
🔎 recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 8, '4-2 (Fine-tuning Data)': 8, '4-3 (Reinforcement Learning Data)': 1, '4-4 (Data Filtering)': 5}, 'kept': {'4-1 (Pre-training Data)': 4, '4-2 (Fine-tuning Data)': 6, '4-3 (Reinforcement Learning Data)': 1, '4-4 (Data Filtering)': 5}}
✅ Saved group 4 : llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_4.json
✅ Saved final merged: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_filtered_final_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 0, '1-2 (Code)': 0, '1-3 (License)': 0, '1-4 (Paper)': 0}, 'kept': {'1-1 (Weights)': 0, '1-2 (Code)': 0, '1-3 (License)': 0, '1-4 (Paper)': 0}}
✅ Saved group 1 : llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\reports_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}, 'kept': {'1-5 (Architecture)': 0, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}}
✅ Saved group 2 : llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\reports_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 0, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 0, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}}
✅ Saved group 3 : llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\reports_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}}
✅ Saved group 4 : llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\reports_filtered_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0_4.json
✅ Saved final merged: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\reports_filtered_final_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
🔑 Hugging Face API says 401/403 — model may be private. Set HF_TOKEN in .env if you have access.
🧱 Pretrained (base) model found by GPT: llm-jp/llm-jp-13b-v1.0
📄 Reports saved/merged (HF): llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\reports_fulltext_huggingface_llm-jp_llm-jp-13b-v1.0.json
✅ JSON file saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\huggingface_llm-jp_llm-jp-13b-v1.0.json
✅ Saved llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\pretrain_hf_llm-jp_llm-jp-13b-v1.0.json
🔎 Candidate rejected: huggingface/tokenizers (score=6, detail={'org_affinity': 9, 'name_hits': 0, 'readme_hits': 0, 'path_hits': 0, 'bad_keywords': 10, 'from_hf_link': 1, 'version_conflict': 0})
🔎 Candidate rejected: pfnet-research/pfgen-bench (score=-11, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 1, 'path_hits': 0, 'bad_keywords': 10, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: pfnet-research/japanese-lm-fin-harness (score=-2, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 2, 'path_hits': 2, 'bad_keywords': 3, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: CyberAgentAILab/LCTG-Bench (score=-8, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 2, 'path_hits': 0, 'bad_keywords': 8, 'from_hf_link': 0, 'version_conflict': 0})
🔎 Candidate rejected: yuzu-ai/japanese-llm-ranking (score=2, detail={'org_affinity': -6, 'name_hits': 1, 'readme_hits': 0, 'path_hits': 1, 'bad_keywords': 0, 'from_hf_link': 0, 'version_conflict': 0})
✅ Resolved GH repo: llm-jp/llm-jp-eval (score=20, detail={'org_affinity': 9, 'name_hits': 1, 'readme_hits': 2, 'path_hits': 1, 'bad_keywords': 12, 'from_hf_link': 1, 'version_conflict': 0})
✅ GitHub JSON file saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\github_llm-jp_llm-jp-eval.json
⚠️ GH fetch/dispatch failed: cannot import name 'filter_pretrain_gh' from 'pretrain_github_Dispatcher' (c:\Users\user\Desktop\lab git\lab git\Evaluating-system-based-on-agent\code\pretrain_github_Dispatcher.py)
🔎 HF tags found arXiv IDs: []
🔄 Simplified query: 'llm jp 1.0'
🔎 Tavily search: llm jp 1.0 paper
  → arXiv link found: https://arxiv.org/abs/2407.03963
🔎 Tavily search: llm jp 1.0 technical report
  → arXiv link found: https://arxiv.org/abs/2407.03963
🛰️ Tavily candidates: ['2407.03963']
🔬 Verifying 1 Tavily candidate(s) with GPT…
  • Candidate: 2407.03963
    - GPT verdict: ✅ match (The paper explicitly describes the LLM-jp project and its model suite, including the release of LLM-jp-13B v1.0. Since the target model version is v1.0 and the paper details this version (with a major)
✅ GPT-verified IDs: ['2407.03963']
📦 Final merged arXiv IDs: ['2407.03963']
📄 PDF saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_2407.03963.pdf
✅ Full paper text saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\arxiv_fulltext_llm-jp_llm-jp-13b-v1.0.json
✅ Saved: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\pretrain_arxiv_llm-jp_llm-jp-13b-v1.0.json
✅ Saved pretrain reports: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\pretrain_reports_llm-jp_llm-jp-13b-v1.0.json
📝 Starting openness evaluation...
📝 Saved evaluation result: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\openness_score_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
✅ Openness evaluation complete. Result file: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\openness_score_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.json
✅ Saved model ID: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\identified_model.txt
⏳ **Time taken for this model: 2516.03 seconds**
🧾 Log saved to: llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0\run_20250917-003429_llm-jp_llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0.log
