{
  "model": "llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0",
  "scores": {
    "1-2 Code": {
      "score": 0.0,
      "reason": "No training pipeline files; README mentions are ignored."
    },
    "1-3 License": {
      "score": 1.0,
      "reason": "Repository is released under the standard Apache-2.0 licence, which permits use, modification, redistribution and commercial use without additional restrictions."
    },
    "1-4 Paper": {
      "score": 1.0,
      "reason": "A provider-authored technical paper titled “LLM-jp” describing this exact model suite is publicly available."
    },
    "1-5 Architecture": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "1-6 Tokenizer": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "2-1 Hardware": {
      "score": 1.0,
      "reason": "Quotes state the exact hardware used for training: 96 × A100-40 GB GPUs for pre-training and 8 × A100-40 GB GPUs for instruction tuning."
    },
    "2-2 Software": {
      "score": 1.0,
      "reason": "Training stack is explicitly listed: Megatron-DeepSpeed for pre-training; TRL, PEFT, DeepSpeed, PyTorch ≥ 2.0, Transformers ≥ 4.34, Tokenizers ≥ 0.14, Accelerate == 0.23 for fine-tuning."
    },
    "2-3 API": {
      "score": 0.0,
      "reason": "Only generic or non-official mentions; no qualifying official API docs.  No qualifying official API docs via web search."
    },
    "3-1 Pre-training": {
      "score": 0.5,
      "reason": "Method details (10 non-overlapping 27-28 B-token folds, extra 27 B HQ pass, Megatron-DeepSpeed) are given, but not the fully reproducible schedule/objectives."
    },
    "3-2 Fine-tuning": {
      "score": 0.5,
      "reason": "Provides datasets, hardware, libraries, but not the complete set of hyper-parameters or scripts for full reproduction."
    },
    "3-3 Reinforcement Learning": {
      "score": 0.5,
      "reason": "States that Direct Preference Optimisation (DPO) was applied for v1.1, but gives only high-level description without full reproducible detail."
    },
    "4-1 Pre-training Data": {
      "score": 0.5,
      "reason": "Discloses that the corpus mixes Japanese, English and code and gives aggregate token counts, but does not enumerate concrete source datasets or exact proportions."
    },
    "4-2 Fine-tuning Data": {
      "score": 0.5,
      "reason": "Names all instruction datasets (jaster, Dolly-15k, OASST1, etc.) and states availability, but omits sizes and full composition breakdowns."
    },
    "4-3 Reinforcement Learning Data": {
      "score": 0.0,
      "reason": "No quantitative or source information about the preference data used for DPO is provided."
    },
    "4-4 Data Filtering": {
      "score": 0.5,
      "reason": "Mentions deduplication with SimHash, rule-based filters, toxicity filtering and that 27 B tokens survived stricter thresholds, but does not supply full pipeline parameters."
    },
    "1-1 Weights": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    }
  },
  "included_scores": {
    "1-2 Code": {
      "score": 0.0,
      "reason": "No training pipeline files; README mentions are ignored."
    },
    "1-3 License": {
      "score": 1.0,
      "reason": "Repository is released under the standard Apache-2.0 licence, which permits use, modification, redistribution and commercial use without additional restrictions."
    },
    "1-4 Paper": {
      "score": 1.0,
      "reason": "A provider-authored technical paper titled “LLM-jp” describing this exact model suite is publicly available."
    },
    "1-5 Architecture": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "1-6 Tokenizer": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "2-1 Hardware": {
      "score": 1.0,
      "reason": "Quotes state the exact hardware used for training: 96 × A100-40 GB GPUs for pre-training and 8 × A100-40 GB GPUs for instruction tuning."
    },
    "2-2 Software": {
      "score": 1.0,
      "reason": "Training stack is explicitly listed: Megatron-DeepSpeed for pre-training; TRL, PEFT, DeepSpeed, PyTorch ≥ 2.0, Transformers ≥ 4.34, Tokenizers ≥ 0.14, Accelerate == 0.23 for fine-tuning."
    },
    "2-3 API": {
      "score": 0.0,
      "reason": "Only generic or non-official mentions; no qualifying official API docs.  No qualifying official API docs via web search."
    },
    "3-1 Pre-training": {
      "score": 0.5,
      "reason": "Method details (10 non-overlapping 27-28 B-token folds, extra 27 B HQ pass, Megatron-DeepSpeed) are given, but not the fully reproducible schedule/objectives."
    },
    "3-2 Fine-tuning": {
      "score": 0.5,
      "reason": "Provides datasets, hardware, libraries, but not the complete set of hyper-parameters or scripts for full reproduction."
    },
    "3-3 Reinforcement Learning": {
      "score": 0.5,
      "reason": "States that Direct Preference Optimisation (DPO) was applied for v1.1, but gives only high-level description without full reproducible detail."
    },
    "4-1 Pre-training Data": {
      "score": 0.5,
      "reason": "Discloses that the corpus mixes Japanese, English and code and gives aggregate token counts, but does not enumerate concrete source datasets or exact proportions."
    },
    "4-2 Fine-tuning Data": {
      "score": 0.5,
      "reason": "Names all instruction datasets (jaster, Dolly-15k, OASST1, etc.) and states availability, but omits sizes and full composition breakdowns."
    },
    "4-3 Reinforcement Learning Data": {
      "score": 0.0,
      "reason": "No quantitative or source information about the preference data used for DPO is provided."
    },
    "4-4 Data Filtering": {
      "score": 0.5,
      "reason": "Mentions deduplication with SimHash, rule-based filters, toxicity filtering and that 27 B tokens survived stricter thresholds, but does not supply full pipeline parameters."
    },
    "1-1 Weights": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    }
  },
  "final_score_10pt": 6.25,
  "meta": {
    "usage_from_dispatch": {
      "fine_tuning": "used",
      "rl": "used"
    },
    "excluded": [],
    "denominator": 16,
    "raw_sum": 10.0,
    "scale": "10/16",
    "code_detection_reason": "No training pipeline files; README mentions are ignored.",
    "pretrain_sources_used": true
  }
}