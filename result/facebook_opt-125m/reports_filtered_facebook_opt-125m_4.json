{
  "4-1 (Pre-training Data)": "The OPT-175B pre-training corpus was assembled as a deliberately broad union of five large-scale text collections. Concretely, the mixture re-uses the three component datasets originally adopted for RoBERTa, augments them with a selected subset of the Pile, and adds the Pushshift.io Reddit dump that had previously been processed for Roller et al. Together these sources were chosen both for their topical breadth and for their ready availability. The same curated mixture was used for training the full family of OPT models. Post-training evaluation raised the possibility that ConvAI2 conversation data may have been unintentionally present in the pre-training or validation split, because the unsupervised OPT-175B model displayed performance on ConvAI2 comparable to the task-specific BlenderBot 1, suggesting potential corpus leakage.",
  "4-2 (Fine-tuning Data)": "",
  "4-3 (Reinforcement Learning Data)": "",
  "4-4 (Data Filtering)": "",
  "4-1 (Pre-training Data)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "The pre-training data for training the OPT-175B model was created by a union of five datasets, including three datasets used by RoBERTa (Liu et al., 2019b), a subset of the Pile (Gao et al., 2021a), along with the Pushshift.io Reddit dataset that was developed in (Baumgartner et al., 2020) and processed in (Roller et al., 2021)."
    },
    {
      "source": "[pdf_text]",
      "quote": "Yes, this dataset was used to pre-train the OPT models."
    },
    {
      "source": "[pdf_text]",
      "quote": "Training data for OPT-175B was selected based on a combination of breadth and availability."
    },
    {
      "source": "[pdf_text]",
      "quote": "We were somewhat surprised that the evaluations of the unsupervised OPT-175B model were as competitive as BlenderBot 1 on the ConvAI2 dataset. This may indicate leakage of the ConvAI2 dataset into the general pre-training corpus or even into the validation data as evaluated in Table 2."
    }
  ],
  "4-2 (Fine-tuning Data)__evidence": [],
  "4-3 (Reinforcement Learning Data)__evidence": [],
  "4-4 (Data Filtering)__evidence": []
}