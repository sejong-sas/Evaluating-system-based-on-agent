{
  "1-5 (Architecture)": "The QwQ-32B model is presented as a 32 billion parameter architecture, explicitly emphasizing its design by comparing its performance with that of a much larger model that boasts 671 billion parameters (with 37 billion activated). The details include numerical specifications such as '32B', '64', '40 / 8', and a configuration notation '128K / 8K', along with an Apache 2.0 license marker. These quotes provide a glimpse into both the scale and some of the underlying configuration parameters of the model, underscoring its efficiency and competitive performance despite a relatively smaller parameter count compared to giants in the field.",
  "1-6 (Tokenizer)": "The tokenizer for QwQ-32B is directly associated with the model and is accessible via the Hugging Face ecosystem. The implementation uses transformers’ AutoTokenizer and AutoModelForCausalLM, where the model is identified by the name 'Qwen/QwQ-32B'. The configuration details shared include a link to a tokenizer configuration file that outlines key tokenization settings, such as the use of '<|im_end|>' as the end-of-sequence token and a suggested update indicating that the pad token should ideally be '<|vision_pad|>' during finetuning. These details confirm a carefully maintained tokenization process tailored for the model.",
  "2-1 (Hardware)": "",
  "2-2 (Software)": "",
  "1-5 (Architecture)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "We are excited to introduce QwQ-32B, a model with 32 billion parameters that achieves performance comparable to DeepSeek-R1, which boasts 671 billion parameters (with 37 billion activated)."
    },
    {
      "source": "[pdf_text]",
      "quote": "32B\n64\n40 / 8\nNo\n128K / 8K\nApache 2.0"
    },
    {
      "source": "[sections/https://qwenlm.github.io/blog/qwq-32b/]",
      "quote": "We are excited to introduce QwQ-32B, a model with 32 billion parameters that achieves performance comparable to DeepSeek-R1, which boasts 671 billion parameters (with 37 billion activated)."
    }
  ],
  "1-6 (Tokenizer)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "from transformers import AutoModelForCausalLM , AutoTokenizer model_name = \"Qwen/QwQ-32B\" model = AutoModelForCausalLM . from_pretrained ( model_name , torch_dtype = \"auto\" , device_map = \"auto\" ) tokenizer = AutoTokenizer . from_pretrained ( model_name )"
    },
    {
      "source": "[pdf_text]",
      "quote": "We updated it in: https://huggingface.co/unsloth/QwQ-32B/blob/main/tokenizer_config.json Copy \"eos_token\": \"<|im_end|>\", \"pad_token\": \"<|endoftext|>\""
    },
    {
      "source": "[sections/https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-effectively]",
      "quote": "✏️ Tokenizer Bug Fixes We found a few issues as well specifically impacting finetuning! The EOS token is correct, but the PAD token should probably rather be \"<|vision_pad|>\" We updated it in: https://huggingface.co/unsloth/QwQ-32B/blob/main/tokenizer_config.json"
    }
  ],
  "2-1 (Hardware)__evidence": [],
  "2-2 (Software)__evidence": []
}