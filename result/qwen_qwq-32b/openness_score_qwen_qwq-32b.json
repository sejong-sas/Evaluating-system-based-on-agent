{
  "model": "Qwen/QwQ-32B",
  "scores": {
    "1-1 Weights": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "1-2 Code": {
      "score": 0.0,
      "reason": "No training pipeline files; README mentions are ignored."
    },
    "1-3 License": {
      "score": 1.0,
      "reason": "Distributed under Apache-2.0 (quotes explicitly show “license: apache-2.0” and LICENSE file). The license permits use, modification, redistribution, and commercial use."
    },
    "1-4 Paper": {
      "score": 0.5,
      "reason": "The provider hosts an official blog/technical write-up on its own domain (qwenlm.github.io) but no formal paper or tech report dedicated to QwQ-32B."
    },
    "1-5 Architecture": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "1-6 Tokenizer": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "2-1 Hardware": {
      "score": 0.0,
      "reason": "No quoted information about the type or amount of hardware used for training."
    },
    "2-2 Software": {
      "score": 0.0,
      "reason": "Only the base framework (‘transformers’) is mentioned; no detailed training-stack components or versions are disclosed."
    },
    "2-3 API": {
      "score": 0.0,
      "reason": "Only generic or non-official mentions; no qualifying official API docs.  No qualifying official API docs via web search."
    },
    "3-1 Pre-training": {
      "score": 0.0,
      "reason": "Pre-training is acknowledged but no reproducible methodological details are given."
    },
    "3-2 Fine-tuning": {
      "score": 0.0,
      "reason": "Supervised fine-tuning is mentioned without any concrete methodological information."
    },
    "3-3 Reinforcement Learning": {
      "score": 0.0,
      "reason": "Reinforcement learning is stated as part of post-training, but no algorithmic or procedural details are disclosed."
    },
    "4-1 Pre-training Data": {
      "score": 0.5,
      "reason": "No source, size, or composition details of the pre-training corpus are provided in the quotes. Adjusted to Semi-Open: quotes indicate partial disclosure."
    },
    "4-2 Fine-tuning Data": {
      "score": 0.0,
      "reason": "No information on datasets or sizes used for supervised fine-tuning."
    },
    "4-3 Reinforcement Learning Data": {
      "score": 0.0,
      "reason": "No disclosure of preference or reward data used during RL."
    },
    "4-4 Data Filtering": {
      "score": 0.0,
      "reason": "No statements about filtering or cleaning procedures. No direct quote evidence; defaulting to Closed by strict rule."
    }
  },
  "included_scores": {
    "1-1 Weights": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "1-2 Code": {
      "score": 0.0,
      "reason": "No training pipeline files; README mentions are ignored."
    },
    "1-3 License": {
      "score": 1.0,
      "reason": "Distributed under Apache-2.0 (quotes explicitly show “license: apache-2.0” and LICENSE file). The license permits use, modification, redistribution, and commercial use."
    },
    "1-4 Paper": {
      "score": 0.5,
      "reason": "The provider hosts an official blog/technical write-up on its own domain (qwenlm.github.io) but no formal paper or tech report dedicated to QwQ-32B."
    },
    "1-5 Architecture": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "1-6 Tokenizer": {
      "score": 1.0,
      "reason": "Hugging Face presence detected; forced Open per FORCE_HF_CORE_OPEN."
    },
    "2-1 Hardware": {
      "score": 0.0,
      "reason": "No quoted information about the type or amount of hardware used for training."
    },
    "2-2 Software": {
      "score": 0.0,
      "reason": "Only the base framework (‘transformers’) is mentioned; no detailed training-stack components or versions are disclosed."
    },
    "2-3 API": {
      "score": 0.0,
      "reason": "Only generic or non-official mentions; no qualifying official API docs.  No qualifying official API docs via web search."
    },
    "3-1 Pre-training": {
      "score": 0.0,
      "reason": "Pre-training is acknowledged but no reproducible methodological details are given."
    },
    "3-2 Fine-tuning": {
      "score": 0.0,
      "reason": "Supervised fine-tuning is mentioned without any concrete methodological information."
    },
    "3-3 Reinforcement Learning": {
      "score": 0.0,
      "reason": "Reinforcement learning is stated as part of post-training, but no algorithmic or procedural details are disclosed."
    },
    "4-1 Pre-training Data": {
      "score": 0.5,
      "reason": "No source, size, or composition details of the pre-training corpus are provided in the quotes. Adjusted to Semi-Open: quotes indicate partial disclosure."
    },
    "4-2 Fine-tuning Data": {
      "score": 0.0,
      "reason": "No information on datasets or sizes used for supervised fine-tuning."
    },
    "4-3 Reinforcement Learning Data": {
      "score": 0.0,
      "reason": "No disclosure of preference or reward data used during RL."
    },
    "4-4 Data Filtering": {
      "score": 0.0,
      "reason": "No statements about filtering or cleaning procedures. No direct quote evidence; defaulting to Closed by strict rule."
    }
  },
  "final_score_10pt": 3.125,
  "meta": {
    "usage_from_dispatch": {
      "fine_tuning": "used",
      "rl": "used"
    },
    "excluded": [],
    "denominator": 16,
    "raw_sum": 5.0,
    "scale": "10/16",
    "code_detection_reason": "No training pipeline files; README mentions are ignored.",
    "pretrain_sources_used": false
  }
}