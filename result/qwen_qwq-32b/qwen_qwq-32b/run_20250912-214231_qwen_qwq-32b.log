
======== 1/1 â–¶ Qwen/QwQ-32B ========
ğŸ“ Directory to create/use: qwen_qwq-32b
ğŸ“ Output path: qwen_qwq-32b
1ï¸âƒ£ HF: True, GH: False
ğŸ” Candidate rejected: inferless/qwq-32b-preview (score=-10, detail={'org_affinity': -6, 'name_hits': 2, 'readme_hits': 2, 'path_hits': 0, 'bad_keywords': 7, 'from_hf_link': 0, 'version_conflict': -8})
ğŸ” Candidate rejected: vllm-project/vllm-ascend (score=-14, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 0, 'path_hits': 0, 'bad_keywords': 11, 'from_hf_link': 0, 'version_conflict': 0})
ğŸ” Candidate rejected: vllm-project/vllm (score=-14, detail={'org_affinity': -6, 'name_hits': 0, 'readme_hits': 0, 'path_hits': 0, 'bad_keywords': 14, 'from_hf_link': 0, 'version_conflict': 0})
âœ… Resolved GH repo: QwenLM/QwQ (score=13, detail={'org_affinity': 9, 'name_hits': 1, 'readme_hits': 4, 'path_hits': 0, 'bad_keywords': 19, 'from_hf_link': 0, 'version_conflict': 0})
âœ… HF model: qwen/qwq-32b (found at priority: 1)
ğŸ“„ Reports saved/merged (HF): qwen_qwq-32b\reports_fulltext_huggingface_qwen_qwq-32b.json
âœ… JSON file saved: qwen_qwq-32b\huggingface_qwen_qwq-32b.json
ğŸ“„ Reports merged to: qwen_qwq-32b\reports_fulltext_qwen_qwq-32b.json (HF sources)
âœ… Saved group 1 result: qwen_qwq-32b\huggingface_filtered_qwen_qwq-32b_1.json
âœ… Saved group 2 result: qwen_qwq-32b\huggingface_filtered_qwen_qwq-32b_2.json
âœ… Saved group 3 result: qwen_qwq-32b\huggingface_filtered_qwen_qwq-32b_3.json
âœ… Saved group 4 result: qwen_qwq-32b\huggingface_filtered_qwen_qwq-32b_4.json
âœ… Saved final merged result: qwen_qwq-32b\huggingface_filtered_final_qwen_qwq-32b.json
âœ… GH repo: QwenLM/QwQ
ğŸ“„ Reports saved/merged (GH): qwen_qwq-32b\reports_fulltext_github_qwenlm_qwq.json
â„¹ï¸ Merge skipped: could not determine a single target HF model id.
âœ… GitHub JSON file saved: qwen_qwq-32b\github_QwenLM_QwQ.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 4, '1-2 (Code)': 2, '1-3 (License)': 8, '1-4 (Paper)': 3}, 'kept': {'1-1 (Weights)': 4, '1-2 (Code)': 1, '1-3 (License)': 5, '1-4 (Paper)': 3}}
âœ… Saved group 1 result: qwen_qwq-32b\github_filtered_QwenLM_QwQ_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 1, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}, 'kept': {'1-5 (Architecture)': 1, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}}
âœ… Saved group 2 result: qwen_qwq-32b\github_filtered_QwenLM_QwQ_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 4, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 1}, 'kept': {'2-3 (API)': 4, '3-1 (Pre-training)': 0, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 1}}
âœ… Saved group 3 result: qwen_qwq-32b\github_filtered_QwenLM_QwQ_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 7}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 1}}
âœ… Saved group 4 result: qwen_qwq-32b\github_filtered_QwenLM_QwQ_4.json
âœ… Saved final merged result: qwen_qwq-32b\github_filtered_final_QwenLM_QwQ.json
ğŸ” HF tags found arXiv IDs: ['2309.00071', '2412.15115']
ğŸ”„ Simplified query: 'qwq'
ğŸ” Tavily search: qwq paper
  â†’ arXiv link found: https://arxiv.org/abs/2505.09388
ğŸ” Tavily search: qwq technical report
  â†’ arXiv link found: https://arxiv.org/abs/2505.09388
ğŸ›°ï¸ Tavily candidates: ['2505.09388']
ğŸ”¬ Verifying 1 Tavily candidate(s) with GPTâ€¦
  â€¢ Candidate: 2505.09388
    - GPT verdict: âŒ no match (The candidate paper is the Qwen3 Technical Report covering the Qwen3 series (including a 32B dense variant) and, while it mentions dedicated reasoning models like QwQâ€32B in passing, it is not present)
âœ… GPT-verified IDs: []
ğŸ“¦ Final merged arXiv IDs: ['2309.00071', '2412.15115']
ğŸ“„ PDF saved: qwen_qwq-32b\arxiv_2309.00071.pdf
ğŸ“„ PDF saved: qwen_qwq-32b\arxiv_2412.15115.pdf
âœ… Full paper text saved: qwen_qwq-32b\arxiv_fulltext_qwen_qwq-32b.json
ğŸ“„ Reports merged to: qwen_qwq-32b\reports_fulltext_qwen_qwq-32b.json
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
ğŸ” recall keys: ['1-1 (Weights)', '1-2 (Code)', '1-3 (License)', '1-4 (Paper)']
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 2, '1-2 (Code)': 0, '1-3 (License)': 2, '1-4 (Paper)': 4}, 'kept': {'1-1 (Weights)': 2, '1-2 (Code)': 0, '1-3 (License)': 2, '1-4 (Paper)': 2}}
âœ… Saved group 1 : qwen_qwq-32b\arxiv_filtered_qwen_qwq-32b_1.json
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
ğŸ” recall keys: ['1-5 (Architecture)', '1-6 (Tokenizer)', '2-1 (Hardware)', '2-2 (Software)']
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 6, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}, 'kept': {'1-5 (Architecture)': 6, '1-6 (Tokenizer)': 0, '2-1 (Hardware)': 0, '2-2 (Software)': 0}}
âœ… Saved group 2 : qwen_qwq-32b\arxiv_filtered_qwen_qwq-32b_2.json
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
ğŸ” recall keys: ['2-3 (API)', '3-1 (Pre-training)', '3-2 (Fine-tuning)', '3-3 (Reinforcement Learning)']
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 0, '3-1 (Pre-training)': 2, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}, 'kept': {'2-3 (API)': 0, '3-1 (Pre-training)': 2, '3-2 (Fine-tuning)': 0, '3-3 (Reinforcement Learning)': 0}}
âœ… Saved group 3 : qwen_qwq-32b\arxiv_filtered_qwen_qwq-32b_3.json
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
ğŸ” recall keys: ['4-1 (Pre-training Data)', '4-2 (Fine-tuning Data)', '4-3 (Reinforcement Learning Data)', '4-4 (Data Filtering)']
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}, 'kept': {'4-1 (Pre-training Data)': 0, '4-2 (Fine-tuning Data)': 0, '4-3 (Reinforcement Learning Data)': 0, '4-4 (Data Filtering)': 0}}
âœ… Saved group 4 : qwen_qwq-32b\arxiv_filtered_qwen_qwq-32b_4.json
âœ… Saved final merged: qwen_qwq-32b\arxiv_filtered_final_qwen_qwq-32b.json
evidence counts before/after model-guard: {'raw': {'1-1 (Weights)': 11, '1-2 (Code)': 0, '1-3 (License)': 5, '1-4 (Paper)': 7}, 'kept': {'1-1 (Weights)': 11, '1-2 (Code)': 0, '1-3 (License)': 5, '1-4 (Paper)': 7}}
âœ… Saved group 1 : qwen_qwq-32b\reports_filtered_qwen_qwq-32b_1.json
evidence counts before/after model-guard: {'raw': {'1-5 (Architecture)': 6, '1-6 (Tokenizer)': 4, '2-1 (Hardware)': 0, '2-2 (Software)': 1}, 'kept': {'1-5 (Architecture)': 6, '1-6 (Tokenizer)': 4, '2-1 (Hardware)': 0, '2-2 (Software)': 1}}
âœ… Saved group 2 : qwen_qwq-32b\reports_filtered_qwen_qwq-32b_2.json
evidence counts before/after model-guard: {'raw': {'2-3 (API)': 3, '3-1 (Pre-training)': 2, '3-2 (Fine-tuning)': 1, '3-3 (Reinforcement Learning)': 2}, 'kept': {'2-3 (API)': 3, '3-1 (Pre-training)': 2, '3-2 (Fine-tuning)': 1, '3-3 (Reinforcement Learning)': 2}}
âœ… Saved group 3 : qwen_qwq-32b\reports_filtered_qwen_qwq-32b_3.json
evidence counts before/after model-guard: {'raw': {'4-1 (Pre-training Data)': 2, '4-2 (Fine-tuning Data)': 1, '4-3 (Reinforcement Learning Data)': 1, '4-4 (Data Filtering)': 0}, 'kept': {'4-1 (Pre-training Data)': 2, '4-2 (Fine-tuning Data)': 1, '4-3 (Reinforcement Learning Data)': 1, '4-4 (Data Filtering)': 0}}
âœ… Saved group 4 : qwen_qwq-32b\reports_filtered_qwen_qwq-32b_4.json
âœ… Saved final merged: qwen_qwq-32b\reports_filtered_final_qwen_qwq-32b.json
ğŸ§± Pretrained (base) model found by heuristic: Qwen/Qwen2.5-32B
ğŸ“„ Reports saved/merged (HF): qwen_qwq-32b\reports_fulltext_huggingface_qwen_qwen2.5-32b.json
âœ… JSON file saved: qwen_qwq-32b\huggingface_Qwen_Qwen2.5-32B.json
âœ… Saved qwen_qwq-32b\pretrain_hf_qwen_qwen2.5-32b.json
ğŸ” Candidate rejected: inferless/qwen2.5-coder-32b-instruct (score=-2, detail={'org_affinity': -6, 'name_hits': 3, 'readme_hits': 3, 'path_hits': 0, 'bad_keywords': 8, 'from_hf_link': 0, 'version_conflict': 0})
ğŸ” Candidate rejected: TheRealFREDP3D/Ollama-Colab-qwen2.5-coder-32b (score=2, detail={'org_affinity': -6, 'name_hits': 3, 'readme_hits': 3, 'path_hits': 3, 'bad_keywords': 10, 'from_hf_link': 0, 'version_conflict': 0})
âœ… Resolved GH repo: QwenLM/Qwen2.5 (score=22, detail={'org_affinity': 9, 'name_hits': 2, 'readme_hits': 3, 'path_hits': 2, 'bad_keywords': 20, 'from_hf_link': 1, 'version_conflict': 0})
ğŸ“„ Reports saved/merged (GH): qwen_qwq-32b\reports_fulltext_github_qwenlm_qwen2.5.json
â„¹ï¸ Merge skipped: could not determine a single target HF model id.
âœ… GitHub JSON file saved: qwen_qwq-32b\github_QwenLM_Qwen2.5.json
âš ï¸ GH fetch/dispatch failed: cannot import name 'filter_pretrain_gh' from 'pretrain_github_Dispatcher' (c:\Users\user\Desktop\lab git\lab git\Evaluating-system-based-on-agent\code\pretrain_github_Dispatcher.py)
ğŸ” HF tags found arXiv IDs: ['2407.10671']
ğŸ”„ Simplified query: 'Qwen2.5'
ğŸ” Tavily search: Qwen2.5 paper
  â†’ arXiv link found: https://arxiv.org/abs/2502.13923
ğŸ” Tavily search: Qwen2.5 technical report
  â†’ arXiv link found: https://arxiv.org/abs/2412.15115
ğŸ›°ï¸ Tavily candidates: ['2412.15115', '2502.13923']
ğŸ”¬ Verifying 2 Tavily candidate(s) with GPTâ€¦
  â€¢ Candidate: 2412.15115
    - GPT verdict: âœ… match (The paper is the Qwen2.5 Technical Report, and it details the Qwen2.5 series, including models of various sizes such as the 32B variant. Since the target model is Qwen2.5-32B and the report is for ver)
  â€¢ Candidate: 2502.13923
    - GPT verdict: âŒ no match (The candidate paper is the technical report for the Qwen2.5-VL series, a vision-language variant, and does not cover the Qwen2.5-32B model. Although both share the major version number 2.5, the paperâ€™)
âœ… GPT-verified IDs: ['2412.15115']
ğŸ“¦ Final merged arXiv IDs: ['2407.10671', '2412.15115']
ğŸ“„ PDF saved: qwen_qwq-32b\arxiv_2407.10671.pdf
ğŸ“„ PDF saved: qwen_qwq-32b\arxiv_2412.15115.pdf
âœ… Full paper text saved: qwen_qwq-32b\arxiv_fulltext_qwen_qwen2.5-32b.json
âœ… Saved: qwen_qwq-32b\pretrain_arxiv_qwen_qwen2.5-32b.json
âœ… Saved pretrain reports: qwen_qwq-32b\pretrain_reports_qwen_qwen2.5-32b.json
ğŸ“ Starting openness evaluation...
ğŸ“ Saved evaluation result: qwen_qwq-32b\openness_score_qwen_qwq-32b.json
âœ… Openness evaluation complete. Result file: qwen_qwq-32b\openness_score_qwen_qwq-32b.json
âœ… Saved model ID: qwen_qwq-32b\identified_model.txt
â³ **Time taken for this model: 3459.99 seconds**
ğŸ§¾ Log saved to: qwen_qwq-32b\run_20250912-214231_qwen_qwq-32b.log
