{
  "1-1 (Weights)": "The quotation ‚Äú**This repo contains the QwQ 32B model**‚Äù confirms that the weight files for the 32-billion-parameter QwQ variant are stored directly in the current repository. A second sentence, ‚ÄúYou can try our [demo](https://huggingface.co/spaces/Qwen/QwQ-32B-Demo) or access QwQ models via [QwenChat](https://chat.qwen.ai),‚Äù shows two additional public access paths: a Hugging Face Space demo and the QwenChat web interface. These statements together indicate that the QwQ-32B weights are publicly hosted in the repo and can also be reached through online inference endpoints; no further restrictions on download or usage are mentioned in the provided text.",
  "1-1 (Weights)__evidence": [
    {
      "source": "[readme]",
      "quote": "**This repo contains the QwQ 32B model**, which has the following features:"
    },
    {
      "source": "[readme]",
      "quote": "You can try our [demo](https://huggingface.co/spaces/Qwen/QwQ-32B-Demo) or access QwQ models via [QwenChat](https://chat.qwen.ai)."
    }
  ],
  "1-2 (Code)": "The sentence ‚ÄúQwQ is based on Qwen2.5, whose code has been in the latest Hugging face `transformers`.‚Äù establishes that implementation support for QwQ-32B already exists in the public `transformers` library. The follow-up line, ‚ÄúFor more details, please refer to our [blog] ‚Ä¶ [GitHub] ‚Ä¶ and [Documentation] ‚Ä¶,‚Äù points to a public blog post, the Qwen2.5 GitHub repository, and Read-the-Docs pages as further sources. These quotes collectively show that open-source code relevant to QwQ-32B is available, although the excerpts do not specify whether the released code covers only inference or also pre-training, fine-tuning, or RL stages.",
  "1-2 (Code)__evidence": [
    {
      "source": "[readme]",
      "quote": "QwQ is based on Qwen2.5, whose code has been in the latest Hugging face `transformers`."
    },
    {
      "source": "[readme]",
      "quote": "For more details, please refer to our [blog](https://qwenlm.github.io/blog/qwq-32b/), [GitHub](https://github.com/QwenLM/Qwen2.5), and [Documentation](https://qwen.readthedocs.io/en/latest/)."
    }
  ],
  "1-3 (License)": "Licensing information is repeated several times: ‚Äúlicense: apache-2.0,‚Äù ‚Äú[readme] ‚Ä¶ license: apache-2.0 ‚Ä¶ license_link: https://huggingface.co/Qwen/QWQ-32B/blob/main/LICENSE,‚Äù and the explicit notice ‚ÄúLicensed under the Apache License, Version 2.0 (the \\\"License\\\"); you may not use this file except in compliance with the License.‚Äù A further confirmation line states ‚ÄúLICENSE file present: LICENSE.‚Äù These sentences together make clear that QwQ-32B is distributed under the Apache License, Version 2.0, and that users must follow that license‚Äôs terms, as emphasized by the quoted restriction clause.",
  "1-3 (License)__evidence": [
    {
      "source": "[readme]",
      "quote": "license: apache-2.0"
    },
    {
      "source": "[license_file]",
      "quote": "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License."
    },
    {
      "source": "[readme]",
      "quote": "[readme]\n---\nlicense: apache-2.0\nlicense_link: https://huggingface.co/Qwen/QWQ-32B/blob/main/LICENSE\nlanguage:\n- en\npipeline_tag: text-generation\nbase_model: Qwen/Qwen2.5-32B\ntags:\n- chat\nlibr"
    },
    {
      "source": "[files]",
      "quote": "LICENSE file present: LICENSE"
    }
  ],
  "1-4 (Paper)": "Two quotations describe written resources for the model. First: ‚ÄúDetailed evaluation results are reported in this [üìë blog](https://qwenlm.github.io/blog/qwq-32b/).‚Äù Second is the full BibTeX entry:\n‚Äú@misc{qwq32b,\n    title = {QwQ-32B: Embracing the Power of Reinforcement Learning},\n    url = {https://qwenlm.github.io/blog/qwq-32b/},\n    author = {Qwen Team},\n    month = {March},\n    year = {2025}\n}‚Äù.\nThese excerpts indicate that the primary official write-up is a publicly available technical blog post, which includes evaluation details and is intended to be cited using the supplied BibTeX metadata (title, author, month, year, and URL).",
  "1-4 (Paper)__evidence": [
    {
      "source": "[readme]",
      "quote": "Detailed evaluation results are reported in this [üìë blog](https://qwenlm.github.io/blog/qwq-32b/)."
    },
    {
      "source": "[readme]",
      "quote": "@misc{qwq32b,\n    title = {QwQ-32B: Embracing the Power of Reinforcement Learning},\n    url = {https://qwenlm.github.io/blog/qwq-32b/},\n    author = {Qwen Team},\n    month = {March},\n    year = {2025}\n}"
    }
  ]
}