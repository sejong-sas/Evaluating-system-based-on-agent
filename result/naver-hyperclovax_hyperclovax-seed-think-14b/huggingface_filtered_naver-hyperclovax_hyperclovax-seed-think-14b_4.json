{
  "4-1 (Pre-training Data)": "",
  "4-1 (Pre-training Data)__evidence": [],
  "4-2 (Fine-tuning Data)": "",
  "4-2 (Fine-tuning Data)__evidence": [],
  "4-3 (Reinforcement Learning Data)": "For the hyperclovax-seed-think-14b line, the material explicitly states that reinforcement-learning work is carried out only after cost-saving model-compression steps in which low-importance parameters are pruned and knowledge is distilled from a larger teacher into the smaller student.  Once the compressed version is in place, HyperCLOVA X Think applies what it calls “the latest RL recipe” in a carefully sequenced four-stage programme:  (1) Supervised Fine-Tuning (SFT) is first used to create a strong instruction-following baseline; (2) Reinforcement Learning with Verifiable Rewards (RLVR) then introduces reward signals that can be automatically validated; (3) a dedicated Length-Controllability (LC) phase follows, targeting improvements in the length and structure of the model’s reasoning paths; and (4) the process concludes with a joint optimisation that merges Reinforcement Learning from Human Feedback (RLHF) and RLVR in the same training loop.  The quotation does not specify the exact datasets, their provenance, licences, or public availability; it focuses entirely on the multi-stage methodological design just described.",
  "4-3 (Reinforcement Learning Data)__evidence": [
    {
      "source": "[readme]",
      "quote": "By pruning low-importance parameters and distilling knowledge from a large model into a smaller one, training costs have been significantly reduced. On top of this, [the latest RL recipe validated in HyperCLOVA X Think](https://arxiv.org/pdf/2506.22403) is applied in a multi-stage process: (1) Supervised Fine-Tuning (SFT), (2) Reinforcement Learning with Verifiable Rewards (RLVR), (3) Length Controllability (LC) for reasoning path optimization, and (4) a joint training of Reinforcement Learning from Human Feedback (RLHF) and RLVR."
    }
  ],
  "4-4 (Data Filtering)": "",
  "4-4 (Data Filtering)__evidence": []
}