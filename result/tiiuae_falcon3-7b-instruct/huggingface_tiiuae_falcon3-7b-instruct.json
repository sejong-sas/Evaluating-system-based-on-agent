{
    "model_id": "tiiuae/falcon3-7b-instruct",
    "files": [
        ".gitattributes",
        "README.md",
        "config.json",
        "generation_config.json",
        "model-00001-of-00004.safetensors",
        "model-00002-of-00004.safetensors",
        "model-00003-of-00004.safetensors",
        "model-00004-of-00004.safetensors",
        "model.safetensors.index.json",
        "special_tokens_map.json",
        "tokenizer.json",
        "tokenizer_config.json"
    ],
    "readme": "---\nlanguage:\n- en\n- fr\n- es\n- pt\ntags:\n- falcon3\nbase_model: tiiuae/Falcon3-7B-Base\nlicense: other\nlicense_name: falcon-llm-license\nlicense_link: https://falconllm.tii.ae/falcon-terms-and-conditions.html\nlibrary_name: transformers\n---\n\n<div align=\"center\">\n    <img src=\"https://huggingface.co/datasets/tiiuae/documentation-images/resolve/main/general/falco3-logo.png\" alt=\"drawing\" width=\"500\"/>\n</div>\n\n# Falcon3-7B-Instruct\n\n**Falcon3** family of Open Foundation Models is a set of pretrained and instruct LLMs ranging from 1B to 10B.\n\nThis repository contains the **Falcon3-7B-Instruct**. It achieves state of art results (at the time of release) on reasoning, language understanding, instruction following, code and mathematics tasks.\nFalcon3-7B-Instruct supports 4 languages (english, french, spanish, portuguese) and a context length up to 32K.\n\n## Model Details\n- Architecture\n  - Transformer based causal decoder only architecture\n  - 28 decoder blocks\n  - Grouped query attention (GQA) for faster inference: 12 query heads and 4 key value heads\n  - Wider head dimension: 256\n  - High RoPE value to support long context understanding: 1000042\n  - Uses SwiGLU and RMSNorm\n  - 32K context length\n  - 131K vocab size\n- Pretrained on 14 Teratokens of datasets comprising of web, code, STEM, high quality and mutlilingual data using 1024 H100 GPU chips\n- Postrained on 1.2 million samples of STEM, conversations, code, safety and function call data\n- Supports EN, FR, ES, PT\n- Developed by [Technology Innovation Institute](https://www.tii.ae)\n- License: TII Falcon-LLM License 2.0\n- Model Release Date: December 2024\n\n\n## Getting started\n\n<details>\n<summary> Click to expand </summary>\n\n```python\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"tiiuae/Falcon3-7B-Instruct\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nprompt = \"How many hours in one day?\"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful friendly assistant Falcon3 from TII, try to follow instructions as much as possible.\"},\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=1024\n)\ngenerated_ids = [\n    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n]\n\nresponse = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\nprint(response)\n```\n\n</details>\n\n<br>\n\n## Benchmarks\nWe report the official HuggingFace leaderboard normalized evaluations [Open LLM Leaderboard Evaluation Results](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard) in the following table.\n<table border=\"1\" style=\"width: 100%; text-align: center; border-collapse: collapse;\">\n    <colgroup>\n        <col style=\"width: 10%;\">\n        <col style=\"width: 7%;\">\n        <col style=\"width: 7%;\">\n        <col style=\"background-color: rgba(80, 15, 213, 0.5); width: 7%;\">\n    </colgroup>\n    <thead>\n        <tr>\n            <th>Benchmark</th>\n            <th>Llama-3.1-8B-Instruct</th>\n            <th>Qwen2.5-7B-Instruct</th>\n            <th>Falcon3-7B-Instruct</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>IFEval</td>\n            <td><b>78.56</b></td>\n            <td>75.85</td>\n            <td>76.12</td>\n        </tr>\n        <tr>\n            <td>BBH (3-shot)</td>\n            <td>29.89</td>\n            <td>34.89</td>\n            <td><b>37.92</b></td>\n        </tr>\n        <tr>\n            <td>MATH Lvl-5 (4-shot)</td>\n            <td>19.34</td>\n            <td>0.00</td>\n            <td><b>31.87</b></td>\n        </tr>              \n        <tr>\n            <td>GPQA (0-shot)</td>\n            <td>2.35</td>\n            <td>5.48</td>\n            <td><b>8.05</b></td>\n        </tr>\n        <tr>\n            <td>MUSR (0-shot)</td>\n            <td>8.41</td>\n            <td>8.45</td>\n            <td><b>21.17</b></td>\n        </tr>\n        <tr>\n            <td>MMLU-PRO (5-shot)</td>\n            <td>30.68</td>\n            <td><b>36.52</b></td>\n            <td>34.30</td>\n        </tr>        \n    </tbody>\n</table>\n\nAlso, we report in the following table our internal pipeline benchmarks.\n - We use [lm-evaluation harness](https://github.com/EleutherAI/lm-evaluation-harness).\n - We report **raw scores** obtained by applying chat template and fewshot_as_multiturn.\n - We use same batch-size across all models.\n\n<table border=\"1\" style=\"width: 100%; text-align: center; border-collapse: collapse;\">\n    <colgroup>\n        <col style=\"width: 10%;\">\n        <col style=\"width: 10%;\">\n        <col style=\"width: 7%;\">\n        <col style=\"width: 7%;\">\n        <col style=\"background-color: rgba(80, 15, 213, 0.5); width: 7%;\">\n    </colgroup>\n    <thead>\n        <tr>\n            <th>Category</th>\n            <th>Benchmark</th>\n            <th>Llama-3.1-8B-Instruct</th>\n            <th>Qwen2.5-7B-Instruct</th>\n            <th>Falcon3-7B-Instruct</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td rowspan=\"3\">General</td>\n            <td>MMLU (5-shot)</td>\n            <td>68.2</td>\n            <td><b>73.5</b></td>\n            <td>70.5</td>\n        </tr>\n        <tr>\n            <td>MMLU-PRO (5-shot)</td>\n            <td>36.4</td>\n            <td><b>43.1</b></td>\n            <td>40.7</td>\n        </tr>\n        <tr>\n            <td>IFEval</td>\n            <td><b>78.8</b></td>\n            <td>74.7</td>\n            <td>76.5</td>\n        </tr>\n        <tr>\n            <td rowspan=\"3\">Math</td>\n            <td>GSM8K (5-shot)</td>\n            <td><b>82.6</b></td>\n            <td>72.0</td>\n            <td>81.4</td>\n        </tr>\n        <tr>\n            <td>GSM8K (8-shot, COT)</td>\n            <td><b>85.4</b></td>\n            <td>76.6</td>\n            <td>79.7</td>\n        </tr>\n        <tr>\n            <td>MATH Lvl-5 (4-shot)</td>\n            <td>15.4</td>\n            <td>-</td>\n            <td><b>29.4</b></td>\n        </tr>\n        <tr>\n            <td rowspan=\"5\">Reasoning</td>\n            <td>Arc Challenge (25-shot)</td>\n            <td>58.6</td>\n            <td>57.8</td>\n            <td><b>62.6</b></td>\n        </tr>\n        <tr>\n            <td>GPQA (0-shot)</td>\n            <td><b>33.5</b></td>\n            <td>32</td>\n            <td>31.9</td>\n        </tr>\n        <tr>\n            <td>GPQA (0-shot, COT)</td>\n            <td>9.6</td>\n            <td>13.8</td>\n            <td><b>22.3</b></td>\n        </tr>\n        <tr>\n            <td>MUSR (0-shot)</td>\n            <td>38.6</td>\n            <td>41</td>\n            <td><b>46.4</b></td>\n        </tr>\n        <tr>\n            <td>BBH (3-shot)</td>\n            <td>48.6</td>\n            <td><b>54.1</b></td>\n            <td>52.4</td>\n        </tr>\n        <tr>\n            <td rowspan=\"4\">CommonSense Understanding</td>\n            <td>PIQA (0-shot)</td>\n            <td><b>78.9</b></td>\n            <td>73.7</td>\n            <td>78.8</td>\n        </tr>\n        <tr>\n            <td>SciQ (0-shot)</td>\n            <td>80.2</td>\n            <td>50.9</td>\n            <td><b>94.7</b></td>\n        </tr>\n        <tr>\n            <td>Winogrande (0-shot)</td>\n            <td>-</td>\n            <td>-</td>\n            <td>70.4</td>\n        </tr>\n        <tr>\n            <td>OpenbookQA (0-shot)</td>\n            <td><b>46.2</b></td>\n            <td>42.4</td>\n            <td>45.8</td>\n        </tr>\n        <tr>\n            <td rowspan=\"2\">Instructions following</td>\n            <td>MT-Bench (avg)</td>\n            <td>7.9</td>\n            <td><b>8.5</b></td>\n            <td>8.4</td>\n        </tr>\n        <tr>\n            <td>Alpaca (WC)</td>\n            <td>26.6</td>\n            <td><b>31.5</b></td>\n            <td>26.1</td>\n        </tr>\n        <tr>\n            <td>Tool use</td>\n            <td>BFCL AST (avg)</td>\n            <td>90.6</td>\n            <td><b>91.4</b></td>\n            <td>89.5</td>\n        </tr>\n    </tbody>\n</table>\n\n## Useful links\n- View our [release blogpost](https://huggingface.co/blog/falcon3).\n- Feel free to join [our discord server](https://discord.gg/fwXpMyGc) if you have any questions or to interact with our researchers and developers.\n\n## Technical Report\nComing soon....\n\n## Citation\nIf Falcon3 family were helpful to your work, feel free to give us a cite.\n\n```\n@misc{Falcon3,\n    title = {The Falcon 3 family of Open Models},\n    author = {TII Team},\n    month = {December},\n    year = {2024}\n}\n```\n",
    "config": "{\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 11,\n  \"eos_token_id\": 11,\n  \"head_dim\": 256,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"intermediate_size\": 23040,\n  \"max_position_embeddings\": 32768,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 4,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000042,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 131072\n}\n",
    "generation_config": "{\n  \"_from_model_config\": true,\n  \"bos_token_id\": 11,\n  \"eos_token_id\": 11,\n  \"transformers_version\": \"4.46.1\"\n}\n",
    "license_file": "",
    "py_files": {}
}