{
  "2-3 (API)": "The provided materials explicitly note two public-facing access points for DeepSeek-V3. First, \"You can chat with DeepSeek-V3 on DeepSeek's official website: [chat.deepseek.com](https://chat.deepseek.com/sign_in)\", which confirms the existence of an interactive chat front-end. Second, the developers state, \"We also provide OpenAI-Compatible API at DeepSeek Platform: [platform.deepseek.com](https://platform.deepseek.com/)\", establishing that an openly accessible, OpenAI-style REST API is available through the DeepSeek Platform. Together, these sentences document both a browser-based chat interface and an API endpoint that claims compatibility with the OpenAI specification.",
  "2-3 (API)__evidence": [
    {
      "source": "[readme]",
      "quote": "You can chat with DeepSeek-V3 on DeepSeek's official website: [chat.deepseek.com](https://chat.deepseek.com/sign_in)"
    },
    {
      "source": "[readme]",
      "quote": "We also provide OpenAI-Compatible API at DeepSeek Platform: [platform.deepseek.com](https://platform.deepseek.com/)"
    }
  ],
  "3-1 (Pre-training)": "\"We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities.\"  In addition to the massive token count, the authors highlight the efficiency of the run: \"At an economical cost of only 2.664M H800 GPU hours, we complete the pre-training of DeepSeek-V3 on 14.8T tokens, producing the currently strongest open-source base model.\"  These two statements collectively establish (i) the scale of the corpus (14.8 T tokens), (ii) the hardware budget (2.664 M H800 GPU-hours), and (iii) the claim of state-of-the-art strength among open-source base models, all of which characterize the core pre-training effort for DeepSeek-V3.",
  "3-1 (Pre-training)__evidence": [
    {
      "source": "[readme]",
      "quote": "We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities."
    },
    {
      "source": "[readme]",
      "quote": "At an economical cost of only 2.664M H800 GPU hours, we complete the pre-training of DeepSeek-V3 on 14.8T tokens, producing the currently strongest open-source base model."
    }
  ],
  "3-2 (Fine-tuning)": "Fine-tuning is described as a two-step process layered on top of the large-scale pre-training. First, the authors note that after pre-training on \"14.8 trillion diverse and high-quality tokens\" the model undergoes \"Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities.\"  Second, they articulate a specific technique aimed at reasoning: \"We introduce an innovative methodology to distill reasoning capabilities from the long-Chain-of-Thought (CoT) model, specifically from one of the DeepSeek R1 series models, into standard LLMs, particularly DeepSeek-V3.\"  Together these quotations indicate (a) the existence of a supervised fine-tuning phase, (b) an additional RL-based phase, and (c) a specialized knowledge-distillation pipeline that transfers long CoT reasoning from DeepSeek R1 to DeepSeek-V3.",
  "3-2 (Fine-tuning)__evidence": [
    {
      "source": "[readme]",
      "quote": "We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities."
    },
    {
      "source": "[readme]",
      "quote": "We introduce an innovative methodology to distill reasoning capabilities from the long-Chain-of-Thought (CoT) model, specifically from one of the DeepSeek R1 series models, into standard LLMs, particularly DeepSeek-V3."
    }
  ],
  "3-3 (Reinforcement Learning)": "Reinforcement learning is explicitly listed as a core component of the post-pre-training workflow: \"We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities.\"  This sentence confirms that, after supervised fine-tuning, an RL stage (implicitly RLHF or a related paradigm) is used to further improve DeepSeek-V3.",
  "3-3 (Reinforcement Learning)__evidence": [
    {
      "source": "[readme]",
      "quote": "We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities."
    }
  ]
}