{
  "model_id": "bigscience/bloom",
  "full_texts": [
    {
      "arxiv_id": "https://arxiv.org/abs/2211.02001",
      "full_text": " [2211.02001] Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2211.02001 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Machine Learning arXiv:2211.02001 (cs) [Submitted on 3 Nov 2022] Title: Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model Authors: Alexandra Sasha Luccioni , Sylvain Viguier , Anne-Laure Ligozat View a PDF of the paper titled Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model, by Alexandra Sasha Luccioni and 2 other authors View PDF Abstract: Progress in machine learning (ML) comes with a cost to the environment, given that training ML models requires significant computational resources, energy and materials. In the present article, we aim to quantify the carbon footprint of BLOOM, a 176-billion parameter language model, across its life cycle. We estimate that BLOOM&#39;s final training emitted approximately 24.7 tonnes of~\\carboneq~if we consider only the dynamic power consumption, and 50.5 tonnes if we account for all processes ranging from equipment manufacturing to energy-based operational consumption. We also study the energy requirements and carbon emissions of its deployment for inference via an API endpoint receiving user queries in real-time. We conclude with a discussion regarding the difficulty of precisely estimating the carbon footprint of ML models and future research directions that can contribute towards improving carbon emissions reporting. Subjects: Machine Learning (cs.LG) Cite as: arXiv:2211.02001 [cs.LG] &nbsp; (or arXiv:2211.02001v1 [cs.LG] for this version) &nbsp; https://doi.org/10.48550/arXiv.2211.02001 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Alexandra Sasha Luccioni [ view email ] [v1] Thu, 3 Nov 2022 17:13:48 UTC (271 KB) Full-text links: Access Paper: View a PDF of the paper titled Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model, by Alexandra Sasha Luccioni and 2 other authors View PDF TeX Source Other Formats view license Current browse context: cs.LG &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2022-11 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar 2 blog links ( what is this? ) export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack "
    },
    {
      "arxiv_id": "https://arxiv.org/abs/2211.05100",
      "full_text": " [2211.05100] BLOOM: A 176B-Parameter Open-Access Multilingual Language Model Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate &gt; cs &gt; arXiv:2211.05100 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2211.05100 (cs) [Submitted on 9 Nov 2022 ( v1 ), last revised 27 Jun 2023 (this version, v4)] Title: BLOOM: A 176B-Parameter Open-Access Multilingual Language Model Authors: BigScience Workshop : Teven Le Scao , Angela Fan , Christopher Akiki , Ellie Pavlick , Suzana Ilić , Daniel Hesslow , Roman Castagné , Alexandra Sasha Luccioni , François Yvon , Matthias Gallé , Jonathan Tow , Alexander M. Rush , Stella Biderman , Albert Webson , Pawan Sasanka Ammanamanchi , Thomas Wang , Benoît Sagot , Niklas Muennighoff , Albert Villanova del Moral , Olatunji Ruwase , Rachel Bawden , Stas Bekman , Angelina McMillan-Major , Iz Beltagy , Huu Nguyen , Lucile Saulnier , Samson Tan , Pedro Ortiz Suarez , Victor Sanh , Hugo Laurençon , Yacine Jernite , Julien Launay , Margaret Mitchell , Colin Raffel , Aaron Gokaslan , Adi Simhi , Aitor Soroa , Alham Fikri Aji , Amit Alfassy , Anna Rogers , Ariel Kreisberg Nitzav , Canwen Xu , Chenghao Mou , Chris Emezue , Christopher Klamm , Colin Leong , Daniel van Strien , David Ifeoluwa Adelani , Dragomir Radev , Eduardo González Ponferrada , Efrat Levkovizh , Ethan Kim , Eyal Bar Natan , Francesco De Toni , Gérard Dupont , Germán Kruszewski , Giada Pistilli , Hady Elsahar , Hamza Benyamina , Hieu Tran , Ian Yu , Idris Abdulmumin , Isaac Johnson , Itziar Gonzalez-Dios , Javier de la Rosa , Jenny Chim , Jesse Dodge , Jian Zhu , Jonathan Chang , Jörg Frohberg , Joseph Tobing , Joydeep Bhattacharjee , Khalid Almubarak , Kimbo Chen , Kyle Lo , Leandro Von Werra , Leon Weber , Long Phan , Loubna Ben allal , Ludovic Tanguy , Manan Dey , Manuel Romero Muñoz , Maraim Masoud , María Grandury , Mario Šaško , Max Huang , Maximin Coavoux , Mayank Singh , Mike Tian-Jian Jiang , Minh Chien Vu , Mohammad A. Jauhar , Mustafa Ghaleb , Nishant Subramani , Nora Kassner , Nurulaqilla Khamis , Olivier Nguyen , Omar Espejel , Ona de Gibert , Paulo Villegas , Peter Henderson , Pierre Colombo , Priscilla Amuok , Quentin Lhoest , Rheza Harliman , Rishi Bommasani , Roberto Luis López , Rui Ribeiro , Salomey Osei , Sampo Pyysalo , Sebastian Nagel , Shamik Bose , Shamsuddeen Hassan Muhammad , Shanya Sharma , Shayne Longpre , Somaieh Nikpoor , Stanislav Silberberg , Suhas Pai , Sydney Zink , Tiago Timponi Torrent , Timo Schick , Tristan Thrush , Valentin Danchev , Vassilina Nikoulina , Veronika Laippala , Violette Lepercq , Vrinda Prabhu , Zaid Alyafeai , Zeerak Talat , Arun Raja , Benjamin Heinzerling , Chenglei Si , Davut Emre Taşar , Elizabeth Salesky , Sabrina J. Mielke , Wilson Y. Lee , Abheesht Sharma , Andrea Santilli , Antoine Chaffin , Arnaud Stiegler , Debajyoti Datta , Eliza Szczechla , Gunjan Chhablani , Han Wang , Harshit Pandey , Hendrik Strobelt , Jason Alan Fries , Jos Rozen , Leo Gao , Lintang Sutawika , M Saiful Bari , Maged S. Al-shaibani , Matteo Manica , Nihal Nayak , Ryan Teehan , Samuel Albanie , Sheng Shen , Srulik Ben-David , Stephen H. Bach , Taewoon Kim , Tali Bers , Thibault Fevry , Trishala Neeraj , Urmish Thakker , Vikas Raunak , Xiangru Tang , Zheng-Xin Yong , Zhiqing Sun , Shaked Brody , Yallow Uri , Hadar Tojarieh , Adam Roberts , Hyung Won Chung , Jaesung Tae , Jason Phang , Ofir Press , Conglong Li , Deepak Narayanan , Hatim Bourfoune , Jared Casper , Jeff Rasley , Max Ryabinin , Mayank Mishra , Minjia Zhang , Mohammad Shoeybi , Myriam Peyrounette , Nicolas Patry , Nouamane Tazi , Omar Sanseviero , Patrick von Platen , Pierre Cornette , Pierre François Lavallée , Rémi Lacroix , Samyam Rajbhandari , Sanchit Gandhi , Shaden Smith , Stéphane Requena , Suraj Patil , Tim Dettmers , Ahmed Baruwa , Amanpreet Singh , Anastasia Cheveleva , Anne-Laure Ligozat , Arjun Subramonian , Aurélie Névéol , Charles Lovering , Dan Garrette , Deepak Tunuguntla , Ehud Reiter , Ekaterina Taktasheva , Ekaterina Voloshina , Eli Bogdanov , Genta Indra Winata , Hailey Schoelkopf , Jan-Christoph Kalo , Jekaterina Novikova , Jessica Zosa Forde , Jordan Clive , Jungo Kasai , Ken Kawamura , Liam Hazan , Marine Carpuat , Miruna Clinciu , Najoung Kim , Newton Cheng , Oleg Serikov , Omer Antverg , Oskar van der Wal , Rui Zhang , Ruochen Zhang , Sebastian Gehrmann , Shachar Mirkin , Shani Pais , Tatiana Shavrina , Thomas Scialom , Tian Yun , Tomasz Limisiewicz , Verena Rieser , Vitaly Protasov , Vladislav Mikhailov , Yada Pruksachatkun , Yonatan Belinkov , Zachary Bamberger , Zdeněk Kasner , Alice Rueda , Amanda Pestana , Amir Feizpour , Ammar Khan , Amy Faranak , Ana Santos , Anthony Hevia , Antigona Unldreaj , Arash Aghagol , Arezoo Abdollahi , Aycha Tammour , Azadeh HajiHosseini , Bahareh Behroozi , Benjamin Ajibade , Bharat Saxena , Carlos Muñoz Ferrandis , Daniel McDuff , Danish Contractor , David Lansky , Davis David , Douwe Kiela , Duong A. Nguyen , Edward Tan , Emi Baylor , Ezinwanne Ozoani , Fatima Mirza , Frankline Ononiwu , Habib Rezanejad , Hessie Jones , Indrani Bhattacharya , Irene Solaiman , Irina Sedenko , Isar Nejadgholi , Jesse Passmore , Josh Seltzer , Julio Bonis Sanz , Livia Dutra , Mairon Samagaio , Maraim Elbadri , Margot Mieskes , Marissa Gerchick , Martha Akinlolu , Michael McKenna , Mike Qiu , Muhammed Ghauri , Mykola Burynok , Nafis Abrar , Nazneen Rajani , Nour Elkott , Nour Fahmy , Olanrewaju Samuel , Ran An , Rasmus Kromann , Ryan Hao , Samira Alizadeh , Sarmad Shubber , Silas Wang , Sourav Roy , Sylvain Viguier , Thanh Le , Tobi Oyebade , Trieu Le , Yoyo Yang , Zach Nguyen , Abhinav Ramesh Kashyap , Alfredo Palasciano , Alison Callahan , Anima Shukla , Antonio Miranda-Escalada , Ayush Singh , Benjamin Beilharz , Bo Wang , Caio Brito , Chenxi Zhou , Chirag Jain , Chuxin Xu , Clémentine Fourrier , Daniel León Periñán , Daniel Molano , Dian Yu , Enrique Manjavacas , Fabio Barth , Florian Fuhrimann , Gabriel Altay , Giyaseddin Bayrak , Gully Burns , Helena U. Vrabec , Imane Bello , Ishani Dash , Jihyun Kang , John Giorgi , Jonas Golde , Jose David Posada , Karthik Rangasai Sivaraman , Lokesh Bulchandani , Lu Liu , Luisa Shinzato , Madeleine Hahn de Bykhovetz , Maiko Takeuchi , Marc Pàmies , Maria A Castillo , Marianna Nezhurina , Mario Sänger , Matthias Samwald , Michael Cullan , Michael Weinberg , Michiel De Wolf , Mina Mihaljcic , Minna Liu , Moritz Freidank , Myungsun Kang , Natasha Seelam , Nathan Dahlberg , Nicholas Michio Broad , Nikolaus Muellner , Pascale Fung , Patrick Haller , Ramya Chandrasekhar , Renata Eisenberg , Robert Martin , Rodrigo Canalli , Rosaline Su , Ruisi Su , Samuel Cahyawijaya , Samuele Garda , Shlok S Deshmukh , Shubhanshu Mishra , Sid Kiblawi , Simon Ott , Sinee Sang-aroonsiri , Srishti Kumar , Stefan Schweter , Sushil Bharati , Tanmay Laud , Théo Gigant , Tomoya Kainuma , Wojciech Kusa , Yanis Labrak , Yash Shailesh Bajaj , Yash Venkatraman , Yifan Xu , Yingxin Xu , Yu Xu , Zhe Tan , Zhongli Xie , Zifan Ye , Mathilde Bras , Younes Belkada , Thomas Wolf et al. (293 additional authors not shown) &nbsp;You must enable JavaScript to view entire author list. View a PDF of the paper titled BLOOM: A 176B-Parameter Open-Access Multilingual Language Model, by BigScience Workshop: Teven Le Scao and 391 other authors View PDF Abstract: Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License. Subjects: Computation and Language (cs.CL) Cite as: arXiv:2211.05100 [cs.CL] &nbsp; (or arXiv:2211.05100v4 [cs.CL] for this version) &nbsp; https://doi.org/10.48550/arXiv.2211.05100 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Teven Le Scao [ view email ] [v1] Wed, 9 Nov 2022 18:48:09 UTC (7,578 KB) [v2] Sun, 11 Dec 2022 01:09:36 UTC (3,789 KB) [v3] Mon, 13 Mar 2023 15:55:30 UTC (3,908 KB) [v4] Tue, 27 Jun 2023 09:57:58 UTC (3,909 KB) Full-text links: Access Paper: View a PDF of the paper titled BLOOM: A 176B-Parameter Open-Access Multilingual Language Model, by BigScience Workshop: Teven Le Scao and 391 other authors View PDF TeX Source Other Formats view license Current browse context: cs.CL &lt;&nbsp;prev &nbsp; | &nbsp; next&nbsp;&gt; new | recent | 2022-11 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar 1 blog link ( what is this? ) a export BibTeX citation Loading... BibTeX formatted citation &times; loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) About Help contact arXiv Click here to contact arXiv Contact subscribe to arXiv mailings Click here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack "
    },
    {
      "arxiv_id": "https://bigscience.huggingface.co/blog/the-bigscience-rail-license",
      "full_text": " The BigScience RAIL License The BigScience RAIL License # Danish Contractor (BigScience Model Governance WG) Carlos MuÃ±oz Ferrandis (BigScience Legal & Ethical WG, Model Governance WG) Please access the license here . Disclaimer: Neither this post nor the license are intended to be legal advice from any of the authors. BigScience is an ongoing collaborative open science initiative, where a large number of researchers from all over the world work together to train a large language model. Everything happens completely in the open, anyone can participate, and all research artifacts are shared with the entire research community. Consequently, BigScience would like to ensure free worldwide access to its Large Language Models (\"LLMs\") by taking a multicultural and responsible approach to the development and release of these artifacts. We feel that there is a balance to be struck between maximizing access and use of LLMs on the one hand, and mitigating the risks associated with use of these powerful models, on the other hand, which could bring about harm and a negative impact on society. The fact that a software license is deemed \"open\" ( e.g. under an \"open source\" license ) does not inherently mean that the use of the licensed material is going to be responsible. Whereas the principles of 'openness' and 'responsible use' may lead to friction, they are not mutually exclusive, and we strive for a balanced approach to their interaction. Being conscious about LLMs' capabilities and promoting responsible development and use of the latter, we designed a Responsible AI License (\"RAIL\") for the use (in the broadest sense of the word) of the model. Such a license effectively imposes behavioral-use terms on the use of the model. The concept of a Responsible AI License emerged from a community initiative to empower developers to place restrictions on the use of their AI technology through end user and source code license agreements. To design the license for the BigScience set of BLOOM models, we reviewed existing work documenting the potential harms of Large Language Models (\"LLMs\"), also consulted with BigScience Working Groups for the Model Cards and Ethical Charter (see here a work-in-progress version of the BigScience BLOOM model card), and asked them how work from BigScience could be used inappropriately. We also reviewed publicly available AI ethics guidelines, including the Montreal Declaration for Responsible AI, IBM's Principles of Trust and Transparency, and the European Commission's Ethics Guidelines for Trustworthy AI. Other relevant AI licensing work, such as the Montreal Data License initiative, were also taken into account. Large language models have many capabilities, they are of course applicable to classical language uses such as text generation, summarization or translation, and they are being successfully applied in almost all aspects of our lives. But unforeseeable new uses may appear in the future since they can generalize to new tasks without needing additional data. However, legitimate concerns about the impact of this technology on society and our planet are being raised, including the need for AI fairness, transparency, explainability and robustness, as well as addressing issues related to privacy, accountability, addiction, manipulation, and misuse. Most of these concerns can be addressed only via a multi-dimensional approach, where technical tools are complemented by educational and training initiatives, governance frameworks, diversity policies, and multi-stakeholder engagements. That is what BigScience is also about. Nonetheless, even when an LLM is built with the adoption of solid governance frameworks and best practices, there is still the risk of harmful use. For example, a large language model could be used to create fallacious information or to mislead a child (or even an adult) to think that they are not interacting with an AI system, but a human expert. In addition to ethical considerations, certain uses of an AI system may be inappropriate due to the limitations of the technology being released. In such situations, while the use-case by itself may not be considered intrinsically \"unethical\", the application of the technology, due to its design or limitations, may be inappropriate for certain settings including well intentioned high-risk applications. More tellingly, the AI model could be used on data inputs that are very different from the training/testing data, which could lead to unpredictable and undesirable behavior in terms of accuracy, fairness, and robustness. Governing bodies worldwide are beginning to propose and implement policies and laws that regulate AI related products and services. For example, the Government of Maine now prohibits government use of facial recognition except in specifically outlined situations. Boston, San Francisco, Portland, and other cities have passed similar bans. Also, in April 2021, the European Commission published the Proposal for an European Union (\"EU\") \"AI Act\" , a legislative project for a future AI regulation that may define the entire regulatory infrastructure for AI products and services, at the intersection between fostering innovation and protecting the public interest and fundamental rights. The proposal for the AI Act covers both hard (e.g., high-risk AI systems) and soft (e.g., codes of conduct) law approaches, and sets new legal instruments aiming at fostering a controlled development of AI systems in the EU - e.g. \"AI regulatory sandboxes\". Complementary to ongoing policy initiatives and concerns, our approach to adopt a RAIL license is a step in this growing demand for more concrete actions on AI misuse. The figure below presents a high-level overview of the types of initiatives emerging from the AI community to enable trustworthy AI systems. The goal of our approach to licensing is to support AI researchers who may be concerned about the possible inappropriate use of their models and would still like to share their work for advancing science. As a result, we opted to design an open and permissive license that also includes use-based restrictions. Although, the Apache 2.0 license was applicable to resources used to develop the Model , the licensing conditions have been modified for the access and distribution of the Model . This has been done to further BigScience's aims of promoting not just open-access to its artifacts, but also a responsible use of these artifacts. We include some FAQs to help answer some questions that we often faced during the development of our license. Frequently Asked Questions # What are we licensing? The license covers the BigScience BLOOM models, any checkpoints released during the training, and any source code, scripts and/or documentation necessary to define, run, load, benchmark and evaluate the LLM (what we call \"Complementary Material\"). Is this an open source license? This is not an open source license according to the Open Source Initiative definition, because it has some restrictions on the use of the model. That said, it does not impose any restrictions on reuse, distribution, commercialization, adaptation as long as the model is not being applied towards use-cases that have been restricted. Can a BigScience BLOOM model be combined with an open source project? Combining the model with an existing open source project would be considered creating a Derivative of the model as per the license. Thus, the RAIL license's provision governing the use-based restrictions will have to be an enforceable component of subsequent licensing - or any other legal agreement - conditions when re-licensing the model or a derivative of the model. In effect, this means that you will not be able to re-license a BigScience BLOOM model strictly under existing open-source licenses - as defined by the Open Source Initiative . However, please consult a lawyer to ascertain the best option for licensing your work that is based on the BigScience BLOOM models. Why should BigScience decide what is appropriate or not regarding the use of the model? As creators of the model, we believe we have some responsibility to think about how our work is used. We believe we should do as much as we can to prevent possible harms from our work, especially if there are possible use cases that are incompatible or inappropriate with model performance as well as with the Ethical Charter adopted by the BigScience community. Do \"Use-based restrictions\" apply to all the licensed artifacts? No, use-based restrictions only apply to the use of the BigScience BLOOM models, including downstream use of the weights, fine-tuning and task adaptation, but not to the rest of the material, including the source code. This is because the source code already exists under open source terms, and restraining its use would be both inefficient and incongruent, especially since someone could easily circumvent the use-based restrictions by getting the source code from an alternate source. What about subsequent versions of the Model, do use-based restrictions apply to them? Yes. The RAIL license has been designed to be applicable for downstream licensing terms of any derivative versions of any of the BigScience BLOOM models offered and/or released by a downstream user. In other words, the analogy could be made to the so-called \"copyleft\" clause of the GPL-family licenses, meaning that the use of any Derivatives of the Model (as defined in the license) should be governed by the same use-based restrictions. Can you give me an example? Imagine a company wants to use a BigScience BLOOM model in order to develop a version for a commercial chatbot. The company accesses the model, modifies it, and finetunes it to be the technical backbone of the chatbot app. Firstly, these actions will be governed by the RAIL license. Secondly and worth to note, according to the terms defined in our RAIL License this is considered a Derivative of the Model. Thus, the use of the chatbot will be governed by the use-based restrictions defined in the RAIL license, and accordingly, when commercializing the new version of the Model by means of a commercial license (or any other type of legal agreement), the latter will have to integrate these use-based restrictions as part of the subsequent license. Does the license cover every harmful use case? No. We recognize that the list of use-based restrictions do not conceivably represent âeverythingâ one could possibly do with our work. We focus on use cases which could be feasible for the model at this time. This license is a start by us at exploring how such RAIL licenses could be used to mitigate harm and we hope that these first set of provisions can evolve into more comprehensive provisions over time with community engagement. I have questions on whether my use of the BigScience BLOOM model fits into one of the use restrictions: Imagine you are using a BigScience BLOOM model in your research project and you plan to publish your results - e.g. a modified version of the LLM and its related scientific discussion in an academic paper or a blog. The use âas isâ is not prohibited if there is no purposed harm - e.g. use limited to publishing results in an academic research paper or sharing results in a blog. Thus, this should be fine, as long as it is not used to enable the applications that could violate the use restrictions. Further, note that the license requires that you, as the user of the LLM, have to include the use-based restrictions as provisions in any license (or similar legal agreement) that you adopt for hosting, sharing or releasing your work based on a BigScience BLOOM model or its checkpoints. Nonetheless, we are conscious that the concept of \"harm\" is not as straightforward, even more so from a legal perspective. Consequently, we have drafted our use case restrictions informed by the opinion of technical experts, experimental and empirical results on AI fairness evaluation, and ongoing legislative proposals, such as the AI Act, and more precisely articles 5, 6 and Annex III. If you are confused or unsure, you can always reach out to the BigScience community (email below), we will be happy to help you out. What if I want to use it for a use case that should no longer be restricted because I have fixed a problem or a limitation of the model? Please contact BigScience (emails below) to review the use case and the changes made by you. The BigScience BLOOM model at sight will need to be relicensed to you separately to permit that use case, if approved. Is it possible for the licensor to remotely restrict the use of the model? If so, what does it mean? The model by itself does not have any built-in mechanism for it to be restricted. However, if the model is hosted via an API, restricting access remotely can be possible as the API access key can be revoked. We hope the BigScience RAIL License can help stimulate further ideas over how general-purpose LLMs might best be licensed to discourage misuse. This license is not perfect and we hope that the AI and open source communities will give us feedback to improve it. Sharing and collaborative development have been central to the rapid progress in the field of AI, this must continue and we hope a RAIL license such as this one can help create a balance between equal access to science and responsible use. License authorship: Carlos MuÃ±oz Ferrandis, Danish Contractor, Huu Nguyen, David Lansky License Acknowledgments: Somaieh Nikpoor, Aaron Gokaslan, Margaret Mitchell, Yacine Jernite, Imane Bello, Giada Pistilli, Suzana IIiÄ, Thomas Wolf, Stella Biderman, Victor Sahn, Matthias GallÃ©, Anna Rogers, Maraim Elbadri, Kenneth Heafield. Blog Acknowledgments: Francesca Rossi, Margaret Mitchell, Yacine Jernite, Suzana IIiÄ, Daniel McDuff License contact: Carlos MuÃ±oz Ferrandis (carlosmunozferrandis@gmail.com) Danish Contractor (danishcontractor@outlook.com) "
    }
  ]
}