{
  "1-1 (Weights)": "The available statements indicate that the parameters for lgai-exaone/exaone-deep-32b are distributed without gate-keeping to anyone conducting research. One sentence explicitly states that “All EXAONE Deep models are openly available for research purposes and can be downloaded from https://huggingface.co/LGAI-EXAONE,” which confirms both openness (no application process or approval step is mentioned) and the hosting location (the ‘LGAI-EXAONE’ organisation page on Hugging Face). A second citation, “[8] LG AI Research. EXAONE-3.5-32B-Instruct … 2025,” shows that a concrete 32-billion-parameter checkpoint (the ‘EXAONE-3.5-32B-Instruct’ variant) is already published under the same namespace. Together these lines substantiate that (i) the deep 32 B weights exist, (ii) they reside on Hugging Face, (iii) the intended audience is ‘research’, and (iv) no paywall or private request mechanism is mentioned. No quote mentions any geographic or user-type exclusions, rate limits, or embargoes, so none can be asserted here.",
  "1-2 (Code)": "No excerpt references source code, scripts, configuration files, or repositories for pre-training, fine-tuning, or any other stage of the lgai-exaone/exaone-deep-32b training pipeline. Because the quote collection is silent, we cannot confirm the release of either full training code or inference-only examples. The safest conclusion from the provided material is that there is no public training code disclosed for the EXAONE Deep 32 B model.",
  "1-3 (License)": "Three sentences give the only licensing details. First, “Section B in the Appendix provides license information for using the EXAONE Deep models,” indicating that formal terms are bundled with the technical documentation. The next sentence names those terms: “EXAONE AI Model License Agreement 1.1 - NC,” where the “NC” tag signals a non-commercial clause. The final line tells users that by downloading or otherwise using the model they automatically accept the agreement. From these points we can infer: (a) Right of use – granted, but confined to the scope allowed by the NC licence (commercial exploitation is therefore disallowed). (b) Modification – not explicitly mentioned in the citations, so its permissibility is unknown. (c) Redistribution – likewise not referenced, leaving uncertainty about whether sharing derivatives or the raw weights is allowed. (d) Commercial use – implicitly prohibited by the “NC” designation. No wording about patent, warranty, or attribution obligations appears in the supplied material, nor any reference to a standard open-source licence (e.g., Apache-2.0).",
  "1-4 (Paper)": "Two sources establish the written record for the model family. A standalone title, “EXAONE Deep: Reasoning Enhanced Language Models,” signals a dedicated document that presumably focuses on the Deep series (which includes the 32 B checkpoint). A second reference, repeated twice, cites the arXiv preprint “EXAONE 3.5: Series of Large Language Models for Real-world Use Cases” (arXiv:2412.04862, 2024). The repeated listing implies that this 3.5-series paper is the principal technical report and likely covers model architecture, training corpus, evaluation, and deployment notes for derivatives such as exaone-deep-32b. No DOI, journal venue, or blog post is supplied beyond these citations, and no presentation slides or tutorials are mentioned.",
  "1-1 (Weights)__evidence": [
    {
      "source": "[abstract]",
      "quote": "All EXAONE Deep models are openly available for research purposes and can be downloaded from https://huggingface.co/LGAI-EXAONE."
    },
    {
      "source": "[sections/References]",
      "quote": "[8] LG AI Research. EXAONE-3.5-32B-Instruct. https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-32B-Instruct, 2025."
    }
  ],
  "1-2 (Code)__evidence": [],
  "1-3 (License)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "Section B in the Appendix provides license information for using the EXAONE Deep models."
    },
    {
      "source": "[pdf_text]",
      "quote": "EXAONE AI Model License Agreement 1.1 - NC This License Agreement (“Agreement”) is entered into between you (“Licensee”) and LG Management Development Institute Co., Ltd. (“Licensor”), governing the use of the EXAONE AI Model (“Model”)."
    },
    {
      "source": "[pdf_text]",
      "quote": "By downloading, installing, or using the EXAONE AI Model, the Licensee acknowledges that it has read, understood, and agrees to be bound by the terms and conditions of this Agreement."
    }
  ],
  "1-4 (Paper)__evidence": [
    {
      "source": "[title]",
      "quote": "EXAONE Deep: Reasoning Enhanced Language Models"
    },
    {
      "source": "[pdf_text References]",
      "quote": "[6] LG AI Research. EXAONE 3.5: Series of Large Language Models for Real-world Use Cases. https://arxiv.org/abs/2412.04862, 2024."
    },
    {
      "source": "[sections/References]",
      "quote": "[6] LG AI Research. EXAONE 3.5: Series of Large Language Models for Real-world Use Cases. https://arxiv.org/abs/2412.04862, 2024."
    }
  ],
  "1-5 (Architecture)": "The provided excerpts do not contain any sentences that describe architectural characteristics of lgai-exaone/exaone-deep-32b. No information is given about layer counts, hidden sizes, attention heads, parameter totals, or other structural design choices.",
  "1-6 (Tokenizer)": "None of the quoted material mentions a tokenizer for lgai-exaone/exaone-deep-32b. There is no reference to the tokenizer’s name, vocabulary size, file format, or availability for download.",
  "2-1 (Hardware)": "The only hardware detail explicitly stated is that “the EXAONE Deep models are trained using NVIDIA H100 GPU clusters provided by Google Cloud Platform.” Beyond confirming the use of H100 accelerators hosted on GCP, the quotes supply no further data—such as GPU counts, node topology, or total compute hours—for lgai-exaone/exaone-deep-32b.",
  "2-2 (Software)": "Two sentences describe the training software stack for lgai-exaone/exaone-deep-32b. First, “We utilize SimPER [19] as the training algorithm for DPO and our designed GRPO [15] variant for Online RL,” establishing that SimPER is employed during the DPO phase and a custom GRPO variant during online reinforcement learning. Second, training is said to run on “NVIDIA H100 GPU clusters provided by Google Cloud Platform and NVIDIA NeMo Framework,” indicating that the NVIDIA NeMo framework supplies the primary distributed-training environment. No additional frameworks, libraries, version numbers, or configuration flags are disclosed in the provided quotes.",
  "1-5 (Architecture)__evidence": [],
  "1-6 (Tokenizer)__evidence": [],
  "2-1 (Hardware)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "In terms of training compute, the EXAONE Deep models are trained using NVIDIA H100 GPU clusters provided by Google Cloud Platform and NVIDIA NeMo Framework."
    }
  ],
  "2-2 (Software)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "This structured approach enables EXAONE Deep to engage in robust reasoning and deliver well-founded answers to a given query. We utilize SimPER [19] as the training algorithm for DPO and our designed GRPO [15] variant for Online RL."
    },
    {
      "source": "[pdf_text]",
      "quote": "In terms of training compute, the EXAONE Deep models are trained using NVIDIA H100 GPU clusters provided by Google Cloud Platform and NVIDIA NeMo Framework."
    }
  ],
  "2-3 (API)": "",
  "3-1 (Pre-training)": "The quotes indicate that the EXAONE Deep family, which includes the 32 B variant, is pretrained on NVIDIA H100 GPU clusters hosted on Google Cloud Platform and orchestrated through the NVIDIA NeMo framework. The authors note that the overall compute consumed for both the initial pre-training run and for later reasoning-oriented stages is tabulated in their Table 1. Architecturally, the EXAONE Deep line is initialized from the EXAONE 3.5 Instruct base models, which are themselves instruction-tuned systems already capable of following prompts; these Instruct checkpoints therefore serve as the foundational weights upon which further Deep training is performed.",
  "3-2 (Fine-tuning)": "LG AI Research presents three parameter scales—EXAONE Deep 2.4 B, 7.8 B and 32 B—that are explicitly described as fine-tuned descendants of the EXAONE 3.5 series and are ‘specifically optimized for reasoning tasks.’ To reach this goal, the team prepares supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) datasets in a deliberately templated format (see their Figure 3). This templated SFT+DPO regimen is stated to be the key mechanism for boosting the reasoning capability of the EXAONE Deep models, including the 32 B variant.",
  "3-3 (Reinforcement Learning)": "",
  "2-3 (API)__evidence": [],
  "3-1 (Pre-training)__evidence": [
    {
      "source": "[sections/Modeling]",
      "quote": "In terms of training compute, the EXAONE Deep models are trained using NVIDIA H100 GPU clusters provided by Google Cloud Platform and NVIDIA NeMo Framework. The amount of computation used for pretraining of base models and fine-tuning of enhancing reasoning is presented in Table 1."
    },
    {
      "source": "[sections/Modeling]",
      "quote": "The base models of EXAONE Deep are EXAONE 3.5 Instruct models [7, 8, 9], which are instruction-tuned models possessing instruction-following capabilities."
    }
  ],
  "3-2 (Fine-tuning)__evidence": [
    {
      "source": "[sections/Introduction]",
      "quote": "LG AI Research is introducing a new model lineup called EXAONE Deep 2.4B, 7.8B, and 32B. These models are fine-tuned versions of the EXAONE 3.5 series [6], specifically optimized for reasoning tasks."
    },
    {
      "source": "[sections/Modeling]",
      "quote": "To enhance the reasoning abilities of EXAONE Deep, we structured SFT and DPO data in a templated format as illustrated in Figure 3."
    }
  ],
  "3-3 (Reinforcement Learning)__evidence": [],
  "4-1 (Pre-training Data)": "",
  "4-2 (Fine-tuning Data)": "The lgai-exaone/exaone-deep-32b model is described as a fine-tuned descendant of the “EXAONE 3.5 series,” with the explicit goal of improving its performance on reasoning-oriented tasks. According to the available quote, the developers approached this objective through three well-known and widely adopted fine-tuning strategies: (1) Supervised Fine-Tuning (SFT), (2) Direct Preference Optimization (DPO), and (3) Online Reinforcement Learning (Online RL). No additional details on the size, source, or exact composition of the fine-tuning datasets are provided in the quoted material, but the statement makes clear that all three techniques were used in a concerted way to adapt the base EXAONE model line to the reasoning domain.",
  "4-3 (Reinforcement Learning Data)": "For the lgai-exaone/exaone-deep-32b model, the only information disclosed about reinforcement learning data is that Online Reinforcement Learning (Online RL) constituted one of the three main methods—alongside Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO)—applied during development. The quote stresses that these models stem from the EXAONE 3.5 series and have been further optimized for reasoning tasks, but it does not reveal any specifics about the RL dataset’s origin, scale, public availability, or creation process beyond the fact that Online RL was indeed part of the refinement pipeline.",
  "4-4 (Data Filtering)": "",
  "4-1 (Pre-training Data)__evidence": [],
  "4-2 (Fine-tuning Data)__evidence": [
    {
      "source": "[sections/Introduction]",
      "quote": "These models are fine-tuned versions of the EXAONE 3.5 series [6], specifically optimized for reasoning tasks. We have trained these models using three prominent techniques widely employed for fine-tuning: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Online Reinforcement Learning (Online RL)."
    }
  ],
  "4-3 (Reinforcement Learning Data)__evidence": [
    {
      "source": "[sections/Introduction]",
      "quote": "These models are fine-tuned versions of the EXAONE 3.5 series [6], specifically optimized for reasoning tasks. We have trained these models using three prominent techniques widely employed for fine-tuning: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Online Reinforcement Learning (Online RL)."
    }
  ],
  "4-4 (Data Filtering)__evidence": [],
  "__usage": {
    "fine_tuning": "used",
    "rl": "used"
  }
}