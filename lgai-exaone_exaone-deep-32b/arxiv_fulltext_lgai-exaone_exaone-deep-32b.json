{
  "model_id": "lgai-exaone/exaone-deep-32b",
  "full_texts": [
    {
      "arxiv_id": "2503.12524",
      "full_text": "EXAONE Deep: Reasoning Enhanced Language Models\nLG AI Research∗\nAbstract\nWe present EXAONE Deep series, which exhibits superior capabilities in various reasoning tasks,\nincluding math and coding benchmarks. We train our models mainly on the reasoning-specialized\ndataset that incorporates long streams of thought processes. Evaluation results show that our smaller\nmodels, EXAONE Deep 2.4B and 7.8B, outperform other models of comparable size, while the\nlargest model, EXAONE Deep 32B, demonstrates competitive performance against leading open-\nweight models. All EXAONE Deep models are openly available for research purposes and can be\ndownloaded from https://huggingface.co/LGAI-EXAONE.\nAIME 2024\nAIME 2025\nGPQA Diamond\nLiveCodeBench\nCSAT Math 2025\n50\n60\n70\n80\n90\n100\n72.1\n65.8\n66.1\n59.5\n94.5\n72.6\n55.2\n62.1\n57.2\n84.1\n79.5\n67.1\n63.3\n63.4\n94.4\n70.0\n53.9\n65.2\n57.5\n88.8\n79.8\n66.8\n71.5\n65.9\n89.9\n90.0\n80.0\n83.3\n73.3\n86.7\n76.7\n86.7\n66.7\n86.7\n80.0\nEXAONE-Deep-32B\nDeepSeek-R1-Qwen-32B\nQwQ-32B\nDeepSeek-R1-Llama-70B\nDeepSeek-R1 (671B)\nAIME 2024\nAIME 2025\nGPQA Diamond\nLiveCodeBench\nCSAT Math 2025\n0\n20\n40\n60\n80\n100\n70.0\n59.6\n62.6\n55.2\n89.9\n55.5\n38.5\n49.1\n37.6\n79.7\n50.4\n33.6\n49.0\n39.6\n74.1\n63.6\n54.8\n60.0\n53.8\n84.4\n52.5\n47.9\n54.3\n46.6\n79.2\n28.9\n23.9\n33.8\n16.9\n65.6\n83.3\n76.7\n83.3\n56.7\n80.0\n53.3\n80.0\n66.7\n76.7\n73.3\n52.7\n36.7\nEXAONE-Deep-7.8B\nDeepSeek-R1-Qwen-7B\nDeepSeek-R1-Llama-8B\nOpenAI-o1-mini\nEXAONE-Deep-2.4B\nDeepSeek-R1-Qwen-1.5B\nFigure 1: Overall performance comparison. EXAONE Deep 32B model demonstrates competitive performance com-\npared to leading open-weight reasoning models such as QwQ-32B and DeepSeek-R1. It also outperforms both\nDeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Llama-70B. The lightly colored regions in AIME 2024 and\n2025 show the performance of majority vote (consensus).\n∗The complete list of authors who contributed to this work can be found in Appendix A.\narXiv:2503.12524v2  [cs.CL]  19 Mar 2025\n\n1\nIntroduction\nRecently, there has been a growing trend in research to enhance reasoning performance by adjusting computing resources\nduring the testing phase [16]. In response to this trend, LG AI Research is introducing a new model lineup called\nEXAONE Deep 2.4B, 7.8B, and 32B. These models are fine-tuned versions of the EXAONE 3.5 series [6], specifically\noptimized for reasoning tasks. We have trained these models using three prominent techniques widely employed for\nfine-tuning: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Online Reinforcement Learning\n(Online RL).\nThe performance evaluation of the models indicates that, for the 2.4B variant, it demonstrates superior performance\ncompared to DeepSeek-R1-Distill-Qwen-1.5B [2]. For the 7.8B variant, it outperforms not only open-weight models of\ncomparable scale such as DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B [2] but also a proprietary\nreasoning model OpenAI o1-mini [12]. In the case of the 32B model, its performance is competitive to that of\nthe leading open-weight reasoning models such as QwQ-32B [13] and DeepSeek-R1 [2], and is superior to that of\nDeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Llama-70B [2] as illustrated in Figure 1.\nThoughts become words, words become deeds, deeds become habits, habits become character,\nand character becomes destiny. Therefore watch the <thought>s of your mind with the sleepless\neye of your mind.\n- TRYON EDWARDS\n2\nModeling\n2.1\nData\nTo enhance the reasoning capabilities of language models, we have utilized 1.6M instances for SFT, 20K instances\nof preference data for DPO, and an additional 10K instances for Online RL. The SFT dataset contains approximately\n12B tokens, with its length distribution illustrated in Figure 2. The dataset is designed to guide models in performing\nreasoning through an extended chain-of-thought (CoT) process, as illustrated in Figure 3.\n0\n10000\n20000\nToken Count\n0\n20000\n40000\n60000\n80000\nFrequency\nOverall\nscience\ncode\nmath\nothers\n0\n10000\n20000\nToken Count\n0\n10000\n20000\n30000\nMath\n0\n10000\n20000\nToken Count\n0\n10000\n20000\n30000\nCode\n0\n10000\n20000\nToken Count\n0\n5000\n10000\n15000\n20000\n25000\nScience\n0\n10000\n20000\nToken Count\n0\n2500\n5000\n7500\n10000\n12500\nOthers\nFigure 2: Distribution of token counts of the SFT dataset. Data points in the Code domain are notably longer on average,\nwhereas those in the Others domain tend to be shorter.\n2.2\nTraining\nThe base models of EXAONE Deep are EXAONE 3.5 Instruct models [7, 8, 9], which are instruction-tuned models\npossessing instruction-following capabilities. To enhance the reasoning abilities of EXAONE Deep, we structured SFT\nand DPO data in a templated format as illustrated in Figure 3. Each training instance consists of a structured thought\nprocess followed by a final answer that synthesizes the reasoning steps into a coherent and precise response. Specifically,\nthe EXAONE 3.5 Instruct models are trained to engage in reasoning within the <thought> and </thought> tags,\nperforming step-by-step logical progression along with reflection, self-checking, and correction. The final answer,\ngenerated after reasoning, is designed to be self-contained, summarizing the key insights derived from the thought\nprocess in a clear and concise manner. This structured approach enables EXAONE Deep to engage in robust reasoning\nand deliver well-founded answers to a given query. We utilize SimPER [19] as the training algorithm for DPO and our\ndesigned GRPO [15] variant for Online RL.\nIn terms of training compute, the EXAONE Deep models are trained using NVIDIA H100 GPU clusters provided\nby Google Cloud Platform and NVIDIA NeMo Framework. The amount of computation used for pretraining of base\nmodels and fine-tuning of enhancing reasoning is presented in Table 1.\n2\n\nSFT Dataset Example\nQuery: Given the complex numbers u, v, and w such that uv = 12+16i, vw = 20−15i, and wu = −30+40i,\nfind real numbers p and q such that u + v + w = p + qi. Determine the value of p2 + q2.\nResponse:\n<thought>\nOkay, so I need to find real numbers p and q such that u+v +w = p+qi, and then compute p2 +q2. The given\ninformation is the products of the complex numbers: uv = 12 + 16i, vw = 20 −15i, and wu = −30 + 40i.\nHmm, complex numbers can sometimes be tricky because of their real and imaginary parts, but maybe I can\nfind expressions for u, v, w individually?\nLet me think. If I have three equations involving the products of pairs of these complex numbers,\nmaybe I can multiply all three equations together? Let’s see: uv × vw × wu = (uvw)2. So (uvw)2 =\n(12 + 16i)(20 −15i)(−30 + 40i). If I compute that product, I can then take the square root to find uvw. But\ntaking the square root of a complex number might give multiple values, but since we’re dealing with complex\nnumbers u, v, w, maybe we can choose a principal root or something. Wait, but maybe there’s a better way.\nAlternatively, if I can express each variable in terms of another. For example, from uv = 12 + 16i, maybe\nu = (12+16i)/v. Similarly, from vw = 20−15i, w = (20−15i)/v. Then from wu = −30+40i, substituting\nthe expressions for u and w in terms of v, we get [(20 −15i)/v] × [(12 + 16i)/v] = −30 + 40i. That simplifies\nto (20−15i)(12+16i)/(v2) = −30+40i. Then solving for v2, we get v2 = (20−15i)(12+16i)/(−30+40i).\nThen once we find v2, we can take square roots to find v, and subsequently find u and w.\n... (thought process continues)\n</thought>\nFor each v, we compute u and w:\nCase 1: v = 9−13i\n5\n• u = −2 + 6i\n• w = 15+5i\n2\nCase 2: v = −9+13i\n5\n• u = 2 −6i\n• w = −15−5i\n2\nSumming u, v, and w in both cases:\nCase 1: u + v + w = 73\n10 + 59\n10i\nCase 2: u + v + w = −73\n10 −59\n10i\nIn both cases, p2 + q2 is:\n\u001273\n10\n\u00132\n+\n\u001259\n10\n\u00132\n= 732 + 592\n100\n= 5329 + 3481\n100\n= 8810\n100 = 881\n10\nThus, the value of p2 + q2 is:\n881\n10\nFigure 3: An example of SFT dataset. The dataset is specifically designed to facilitate models in conducting reasoning\ntasks through an extended chain-of-thought methodology.\n3\n\nModel size\nPretraining\nFine-tuning\nTotal\n32B\n1.25 × 1024\n7.04 × 1021\n1.26 × 1024\n7.8B\n4.21 × 1023\n1.71 × 1021\n4.23 × 1023\n2.4B\n9.36 × 1022\n5.27 × 1020\n9.41 × 1022\nTable 1: Amount of computation (FLOPs) for model training.\n3\nEvaluation\n3.1\nBenchmarks\nWe evaluate models on MATH-500 [10], American Invitational Mathematics Examination (AIME) 2024 and 2025 [11],\nthe mathematics sections of South Korea’s College Scholastic Ability Test (CSAT) 2025 [5], GPQA Diamond [14],\nLiveCodeBench (24.08-25.02) [4], MMLU [3], and MMLU-Pro [18].\nIn the case of CSAT, which includes textual problems and supplementary graphical information, the graphical content\nis excluded when evaluating the performance. Since most of this graphical information is also available in textual\ndescriptions, its impact on results is considered minimal. In addition, students can choose from three elective subjects\n— calculus, statistics, and geometry — in the mathematics section. The final score is calculated as the average of the\nscores obtained in these three elective subjects.\n3.2\nBaselines\nWe have conducted comprehensive evaluations against strong baseline such as DeepSeek-R1 as well as comparable-scale\nbaselines such as QwQ-32B, DeepSeek-R1-Distill-Qwen-32B, 7B, 1.5B, DeepSeek-R1-Distill-Llama-70B, 8B, and\nOpenAI o1-mini (2024-09-12).\n3.3\nEvaluation Setup\nFollowing the setup described in the DeepSeek-R1 technical report [2], the maximum length of model generations is set\nto 32K tokens. Additionally, since the lengthy outputs of the reasoning models can vary greatly, as noted in the report,\nwe adopt the pass@k metric [1] to ensure the reliability of model performances. Specifically, we generate k responses\nfor each test case using a sampling temperature of 0.6 and a top-p value of 0.951, and calculate pass@1 as followed:\npass@1 = 1\nk\nk\nX\ni=1\npi,\n(1)\nwhere pi denotes the correctness of the i-th response. We also report cons@k [2] where the model generates k answers\nand the final answer is the one generated the most frequently [17].\nThe evaluation prompts used for assessing EXAONE Deep models are shown in Figure 4, 5, and 6. For the CSAT\nbenchmark, both prompts are employed, as it includes short-answer and multiple-choice questions. For baseline models,\nwe report scores from official reports if available; otherwise, we measure performance ourselves. Specifically, for\nmultiple-choice question answering types, we adopt prompts from OpenAI simple-evals framework2. When evaluating\nshort-answer questions, we utilize the MATH-500 prompt from simple-evals for OpenAI o-series models, but use the\nsame prompt with ours (Figure 4) for others, as it aligns with their recommended prompt.\n3.4\nExperimental Results\nThe performance comparison between EXAONE Deep and baseline models is conducted across four categories:\nmathematics, science, coding, and general knowledge. The evaluation results for the mathematics category are presented\nin Table 2, while those for the other categories are given in Table 3.\n1For QwQ-32B, we additionally applied the recommended top-k = 40 during evaluation. For OpenAI o1-mini, we were unable\nto adjust sampling parameters to our desired settings; thus, we used temperature = 1 and top-p = 1.\n2https://github.com/openai/simple-evals\n4\n\nPrompt for Short-Answer Questions\n{{question}}\nPlease reason step by step, and put your final answer within \\boxed{}.\nFigure 4: Prompt for evaluating models on short-answer questions. We apply the prompt to the MATH-500, AIME\n2024/2025, and CSAT 2025 benchmarks.\nPrompt for Multiple-Choice Questions\nQuestion : {{question}}\nOptions :\nA) {{option A}}\nB) {{option B}}\n...\nPlease reason step by step, and you should write the correct option alphabet within \\boxed{}.\nFigure 5: Prompt used for evaluating EXAONE Deep models on multiple-choice questions. We apply the prompt to the\nCSAT 2025, GPQA Diamond, MMLU, and MMLU-Pro benchmarks. The number of options is adjusted for each test\ncase.\nPrompt for Code Generation\nYou will be given a question (problem specification) and will generate a correct Python program that matches\nthe specification and passes all tests. You should first think about the step-by-step reasoning process and then\nprovide the code.\nQuestion: {{question}}\nFigure 6: Prompt used for evaluating EXAONE Deep models on code generation. We apply the prompt to the\nLiveCodeBench Code Generation task.\nWe find that the EXAONE Deep 32B model exhibits competitive performance, rivaling leading open-weight reasoning\nmodels such as DeepSeek-R1 and QwQ-32B. Notably, it outperforms the distilled versions of DeepSeek-R1, including\nDeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Llama-70B.\nFurthermore, the EXAONE Deep 7.8B model demonstrates superior performance compared to models of similar\nscale such as DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B. It also outperforms the proprietary\nreasoning model: OpenAI o1-mini.\nRegarding the EXAONE Deep 2.4B, it outperforms the DeepSeek-R1-Distill-Qwen-1.5B. Our experimental results\nhighlight the EXAONE Deep models demonstrate enhanced reasoning capabilities across different model sizes.\n4\nLimitations\nThe EXAONE Deep models introduced in this document are specifically fine-tuned to excel at reasoning tasks. Though\ntheir base models are instruction-fine-tuned and generally capable of following instructions, for addressing a wider\nrange of real-world use cases, we strongly recommend utilizing the EXAONE 3.5 Instruct models [7, 8, 9], which are\noptimized for practical application scenarios.\n5\n\nModel\nMATH-500\n(pass@1)\nAIME 2024\n(pass@1)\nAIME 2024\n(cons@64)\nAIME 2025\n(pass@1)\nAIME 2025\n(cons@64)\nCSAT 2025\n(pass@1)\nEXAONE Deep 32B\n95.7\n72.1\n90.0\n65.8\n80.0\n94.5\nDeepSeek-R1-Distill-Qwen-32B\n94.3*\n72.6*\n83.3*\n55.2\n73.3\n84.1\nQwQ-32B\n95.5\n79.5*\n86.7\n67.1\n76.7\n94.4\nDeepSeek-R1-Distill-Llama-70B\n94.5*\n70.0*\n86.7*\n53.9\n66.7\n88.8\nDeepSeek-R1 (671B)\n97.3*\n79.8*\n86.7\n66.8\n80.0\n89.9\nEXAONE Deep 7.8B\n94.8\n70.0\n83.3\n59.6\n76.7\n89.9\nDeepSeek-R1-Distill-Qwen-7B\n92.8*\n55.5*\n83.3*\n38.5\n56.7\n79.7\nDeepSeek-R1-Distill-Llama-8B\n89.1*\n50.4*\n80.0*\n33.6\n53.3\n74.1\nOpenAI o1-mini\n90.0*\n63.6*\n80.0*\n54.8\n66.7\n84.4\nEXAONE Deep 2.4B\n92.3\n52.5\n76.7\n47.9\n73.3\n79.2\nDeepSeek-R1-Distill-Qwen-1.5B\n83.9*\n28.9*\n52.7*\n23.9\n36.7\n65.6\nTable 2: Comparison between EXAONE Deep and baseline models in the Mathematics category. The asterisk (*)\nindicates figures that have been officially reported. When calculating pass@1 score, we set k in Equation 1 as 8 for\nMATH-500, 16 for CSAT 2025, and 64 for AIME 2024 and 2025. For AIME 2024 and 2025, we also report cons@64.\nFor CSAT 2025, the individual scores for the elective subjects can be found in Table 4 within Appendix C. Bold scores\nindicate the best performance, and underlined scores mean the second best.\nModel\nGPQA Diamond\n(pass@1)\nLiveCodeBench\n(pass@1)\nMMLU\n(accuracy)\nMMLU-Pro\n(accuracy)\nEXAONE Deep 32B\n66.1\n59.5\n83.0\n74.0\nDeepSeek-R1-Distill-Qwen-32B\n62.1*\n57.2*\n83.6\n77.2\nQwQ-32B\n63.3\n63.4*\n87.4\n79.1\nDeepSeek-R1-Distill-Llama-70B\n65.2*\n57.5*\n89.1\n79.4\nDeepSeek-R1 (671B)\n71.5*\n65.9*\n90.8*\n84.0\nEXAONE Deep 7.8B\n62.6\n55.2\n75.0\n65.7\nDeepSeek-R1-Distill-Qwen-7B\n49.1*\n37.6*\n57.7\n59.3\nDeepSeek-R1-Distill-Llama-8B\n49.0*\n39.6*\n74.4\n60.6\nOpenAI o1-mini\n60.0*\n53.8*\n85.2*\n80.3\nEXAONE Deep 2.4B\n54.3\n46.6\n65.8\n56.4\nDeepSeek-R1-Distill-Qwen-1.5B\n33.8*\n16.9*\n33.8\n39.3\nTable 3: Comparison between EXAONE Deep and baseline models in the Science (GPQA Diamond), Coding\n(LiveCodeBench), and General (MMLU and MMLU-Pro) categories. The asterisk (*) indicates figures that have been\nofficially reported. When calculating pass@1 score, we set k in Equation 1 as 6 for LiveCodeBench and 16 for GPQA\nDiamond. Bold scores indicate the best performance, and underlined scores mean the second best.\n5\nDeployment\nSection B in the Appendix provides license information for using the EXAONE Deep models. Understanding the\nlicense information is essential for the legal utilization of the language model.\n6\nConclusion\nIn this document, we presented three specialized reasoning models: EXAONE Deep 2.4B, 7.8B, and 32B. Despite\nthe emergence of various methodologies aimed at improving reasoning capabilities, we have chosen to rely on well-\nestablished approaches such as SFT, DPO, and Online RL, achieving superior or competitive performance relative\nto models of comparable scale. Our results highlight the effectiveness and practicality of these proven techniques in\nadvancing reasoning performance. At present, these models are primarily engaged in problem-solving in domains\nwhere clear answers are available, such as mathematics, science, and coding. Looking ahead, we aim to extend their\ncapabilities into areas where answers are less clear or yet to be discovered, thereby broadening their impact and utility.\n6\n\nOur models are available to everyone for research purposes, and we welcome your feedback to help us improve the\nmodels. If you have any feedback or are interested in exploring commercial opportunities with our models, please reach\nout to contact_us@lgresearch.ai.\n7\n\nA\nContributors\nAll authors are listed in alphabetical order by last name.\nCore Contributors\nEunbi Choi, Kibong Choi, Seokhee Hong, Junwon Hwang, Hyojin Jeon, Hyunjik Jo, Joonkee Kim,\nSeonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Haeju Lee, Jinsik Lee, Kyungmin Lee,\nSangha Park, Heuiyeen Yeen, Hyeongu Yun\nContributors\nKyunghoon Bae, Stanley Jungkyu Choi, Yemuk Choi, Kijeong Jeon, Gerrard Jeongwon Jo, Jiyeon Jung,\nHyosang Kim, Youchul Kim, Edward Hwayoung Lee, Honglak Lee, Yongmin Park, Sihoon Yang, Sihyuk Yi\n8\n\nB\nModel License\nEXAONE AI Model License Agreement 1.1 - NC\nThis License Agreement (“Agreement”) is entered into between you (“Licensee”) and LG Management De-\nvelopment Institute Co., Ltd. (“Licensor”), governing the use of the EXAONE AI Model (“Model”). By downloading,\ninstalling, copying, or using the Model, you agree to comply with and be bound by the terms of this Agreement. If you\ndo not agree to all the terms, you must not download, install, copy, or use the Model. This Agreement constitutes a\nbinding legal agreement between the Licensee and Licensor.\n1. Definitions\n1.1 Model: The artificial intelligence model provided by Licensor, which includes any software, algorithms,\nmachine learning models, or related components supplied by Licensor. This definition extends to encompass all updates,\nenhancements, improvements, bug fixes, patches, or other modifications that may be provided by Licensor from time to\ntime, whether automatically or manually implemented.\n1.2 Derivatives: Any modifications, alterations, enhancements, improvements, adaptations, or derivative works of\nthe Model created by Licensee or any third party. This includes changes made to the Model’s architecture, parame-\nters, data processing methods, or any other aspect of the Model that results in a modification of its functionality or output.\n1.3 Output: Any data, results, content, predictions, analyses, insights, or other materials generated by the\nModel or Derivatives, regardless of whether they are in their original form or have been further processed or modified\nby the Licensee. This includes, but is not limited to, textual or numerical produced directly or indirectly through the use\nof the Model.\n1.4 Licensor: LG Management Development Institute Co., Ltd., the owner, developer, and provider of the\nEXAONE AI Model. The Licensor holds all rights, title, and interest in the Model and is responsible for granting\nlicenses to use the Model under the terms specified in this Agreement.\n1.5 Licensee: The individual, organization, corporation, academic institution, government agency, or other\nentity using or intending to use the Model under the terms and conditions of this Agreement. The Licensee is responsible\nfor ensuring compliance with the Agreement by all authorized users who access or utilize the Model on behalf of the\nLicensee.\n2. License Grant\n2.1 Grant of License: Subject to the terms and conditions outlined in this Agreement, the Licensor hereby\ngrants the Licensee a limited, non-exclusive, non-transferable, worldwide, and revocable license to:\na. Access, download, install, and use the Model solely for research purposes. This includes evaluation, test-\ning, academic research, experimentation, and participation in competitions, provided that such participation is in a\nnon-commercial context. Notwithstanding Section 3.1, the Licensee may only provide the Model or Derivatives for a\ncompetition if no commercial license is granted to the competition organizer or any third party.\nb. Publicly disclose research results and findings derived from the use of the Model or Derivatives, including\npublishing papers or presentations.\nc. Modify the Model and create Derivatives based on the Model, provided that such modifications and Derivatives are\nused exclusively for research purposes. The Licensee may conduct experiments, perform analyses, and apply custom\nmodifications to the Model to explore its capabilities and performance under various scenarios. If the Model is modified,\nthe modified Model must include “EXAONE” at the beginning of its name.\nd. Distribute the Model and Derivatives in each case with a copy of this Agreement.\n2.2 Scope of License: The license granted herein does not authorize the Licensee to use the Model for any\npurpose not explicitly permitted under this Agreement. Any use beyond the scope of this license, including any com-\nmercial application or external distribution, is strictly prohibited unless explicitly agreed upon in writing by the Licensor.\n9\n\n3. Restrictions\n3.1 Commercial Use: The Licensee is expressly prohibited from using the Model, Derivatives, or Output for\nany commercial purposes, including but not limited to, developing or deploying products, services, or applications\nthat generate revenue, whether directly or indirectly. Any commercial exploitation of the Model or its derivatives\nrequires a separate commercial license agreement with the Licensor. Furthermore, the Licensee shall not use the Model,\nDerivatives or Output to develop or improve other models.\n3.2 Reverse Engineering: The Licensee shall not decompile, disassemble, reverse engineer, or attempt to\nderive the source code, underlying ideas, algorithms, or structure of the Model, except to the extent that such activities\nare expressly permitted by applicable law. Any attempt to bypass or circumvent technological protection measures\napplied to the Model is strictly prohibited.\n3.3 Unlawful Use: The Licensee shall not use the Model and Derivatives for any illegal, fraudulent, or unau-\nthorized activities, nor for any purpose that violates applicable laws or regulations. This includes but is not limited to\nthe creation, distribution, or dissemination of malicious, deceptive, or unlawful content.\n3.4 Ethical Use: The Licensee shall ensure that the Model or Derivatives is used in an ethical and responsi-\nble manner, adhering to the following guidelines:\na. The Model and Derivatives shall not be used to generate, propagate, or amplify false, misleading, or harm-\nful information, including fake news, misinformation, or disinformation.\nb. The Model and Derivatives shall not be employed to create, distribute, or promote content that is discrimi-\nnatory, harassing, defamatory, abusive, or otherwise offensive to individuals or groups based on race, gender, sexual\norientation, religion, nationality, or other protected characteristics.\nc. The Model and Derivatives shall not infringe on the rights of others, including intellectual property rights,\nprivacy rights, or any other rights recognized by law. The Licensee shall obtain all necessary permissions and consents\nbefore using the Model and Derivatives in a manner that may impact the rights of third parties.\nd. The Model and Derivatives shall not be used in a way that causes harm, whether physical, mental, emo-\ntional, or financial, to individuals, organizations, or communities. The Licensee shall take all reasonable measures to\nprevent misuse or abuse of the Model and Derivatives that could result in harm or injury.\n4. Ownership\n4.1 Intellectual Property: All rights, title, and interest in and to the Model, including any modifications,\nDerivatives, and associated documentation, are and shall remain the exclusive property of the Licensor. The Licensee\nacknowledges that this Agreement does not transfer any ownership rights to the Licensee. All trademarks, service\nmarks, and logos associated with the Model are the property of the Licensor.\n4.2 Output: All rights, title, and interest in and to the Output generated by the Model and Derivatives whether in its\noriginal form or modified, are and shall remain the exclusive property of the Licensor. Licensee may use, modify, and\ndistribute the Output and its derivatives for research purpose. The Licensee shall not claim ownership of the Output\nexcept as expressly provided in this Agreement. The Licensee may use the Output solely for the purposes permitted\nunder this Agreement and shall not exploit the Output for unauthorized or commercial purposes.\n4.3 Attribution: In any publication or presentation of results obtained using the Model, the Licensee shall\nprovide appropriate attribution to the Licensor, citing the Model’s name and version, along with any relevant\ndocumentation or references specified by the Licensor.\n10\n\n5. No Warranty\n5.1 “As-Is” Basis: The Model, Derivatives, and Output are provided on an “as-is” and “as-available” basis,\nwithout any warranties or representations of any kind, whether express, implied, or statutory. The Licensor\ndisclaims all warranties, including but not limited to, implied warranties of merchantability, fitness for a partic-\nular purpose, accuracy, reliability, non-infringement, or any warranty arising from the course of dealing or usage of trade.\n5.2 Performance and Reliability: The Licensor does not warrant or guarantee that the Model, Derivatives\nor Output will meet the Licensee’s requirements, that the operation of the Model, Derivatives or Output will be\nuninterrupted or error-free, or that defects in the Model will be corrected. The Licensee acknowledges that the use of\nthe Model, Derivatives or Output is at its own risk and that the Model, Derivatives or Output may contain bugs, errors,\nor other limitations.\n5.3 No Endorsement: The Licensor does not endorse, approve, or certify any results, conclusions, or recom-\nmendations derived from the use of the Model. The Licensee is solely responsible for evaluating the accuracy, reliability,\nand suitability of the Model for its intended purposes.\n6. Limitation of Liability\n6.1 No Liability for Damages: To the fullest extent permitted by applicable law, in no event shall the Licen-\nsor be liable for any special, incidental, indirect, consequential, exemplary, or punitive damages, including but not\nlimited to, damages for loss of business profits, business interruption, loss of business information, loss of data, or\nany other pecuniary or non-pecuniary loss arising out of or in connection with the use or inability to use the Model,\nDerivatives or any Output, even if the Licensor has been advised of the possibility of such damages.\n6.2 Indemnification: The Licensee agrees to indemnify, defend, and hold harmless the Licensor, its affili-\nates, officers, directors, employees, and agents from and against any claims, liabilities, damages, losses, costs, or\nexpenses (including reasonable attorneys’ fees) arising out of or related to the Licensee’s use of the Model, any\nDerivatives, or any Output, including any violation of this Agreement or applicable laws.\n7. Termination\n7.1 Termination by Licensor: The Licensor reserves the right to terminate this Agreement and revoke the\nLicensee’s rights to use the Model at any time, with or without cause, and without prior notice if the Licensee breaches\nany of the terms or conditions of this Agreement. Termination shall be effective immediately upon notice.\n7.2 Effect of Termination: Upon termination of this Agreement, the Licensee must immediately cease all\nuse of the Model, Derivatives, and Output and destroy all copies of the Model, Derivatives, and Output in its possession\nor control, including any backup or archival copies. The Licensee shall certify in writing to the Licensor that such\ndestruction has been completed.\n7.3 Survival: The provisions of this Agreement that by their nature should survive termination, including\nbut not limited to, Sections 4 (Ownership), 5 (No Warranty), 6 (Limitation of Liability), and this Section 7 (Termination),\nshall continue to apply after termination.\n8. Governing Law\n8.1 Governing Law: This Agreement shall be governed by and construed in accordance with the laws of\nthe Republic of Korea, without regard to its conflict of laws principles.\n8.2 Arbitration: Any disputes, controversies, or claims arising out of or relating to this Agreement, includ-\ning its existence, validity, interpretation, performance, breach, or termination, shall be referred to and finally resolved\nby arbitration administered by the Korean Commercial Arbitration Board (KCAB) in accordance with the International\nArbitration Rules of the Korean Commercial Arbitration Board in force at the time of the commencement of the\narbitration. The seat of arbitration shall be Seoul, Republic of Korea. The tribunal shall consist of one arbitrator. The\nlanguage of the arbitration shall be English.\n11\n\n9. Alterations\n9.1 Modifications: The Licensor reserves the right to modify or amend this Agreement at any time, in its\nsole discretion. Any modifications will be effective upon posting the updated Agreement on the Licensor’s website or\nthrough other means of communication. The Licensee is responsible for reviewing the Agreement periodically for\nchanges. Continued use of the Model after any modifications have been made constitutes acceptance of the revised\nAgreement.\n9.2 Entire Agreement: This Agreement constitutes the entire agreement between the Licensee and Licensor\nconcerning the subject matter hereof and supersedes all prior or contemporaneous oral or written agreements,\nrepresentations, or understandings. Any terms or conditions of any purchase order or other document submitted by\nthe Licensee in connection with the Model that are in addition to, different from, or inconsistent with the terms and\nconditions of this Agreement are not binding on the Licensor and are void.\nBy downloading, installing, or using the EXAONE AI Model, the Licensee acknowledges that it has read,\nunderstood, and agrees to be bound by the terms and conditions of this Agreement.\n12\n\nC\nEvaluation Details\nModel\nCSAT 2025\nCalculus\n(pass@1)\nCSAT 2025\nStatistics\n(pass@1)\nCSAT 2025\nGeometry\n(pass@1)\nEXAONE Deep 32B\n95.1\n95.0\n93.5\nQwQ-32B\n94.5\n95.5\n93.3\nDeepSeek-R1 (671B)\n89.4\n90.8\n89.6\nDeepSeek-R1-Distill-Llama-70B\n88.1\n90.3\n88.1\nDeepSeek-R1-Distill-Qwen-32B\n84.3\n84.4\n83.5\nEXAONE Deep 7.8B\n89.5\n91.8\n88.5\nOpenAI o1-mini\n82.8\n85.9\n84.6\nDeepSeek-R1-Distill-Qwen-7B\n75.6\n83.8\n79.6\nDeepSeek-R1-Distill-Llama-8B\n70.6\n79.0\n72.6\nEXAONE Deep 2.4B\n74.4\n82.4\n80.8\nDeepSeek-R1-Distill-Qwen-1.5B\n64.4\n67.6\n64.6\nTable 4: Comparison of EXAONE Deep with baseline models in the individual scores for the elective subjects at the\nCSAT 2025 benchmark. Bold scores indicate the best performance, and underlined scores mean the second best.\n13\n\nReferences\n[1] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri\nEdwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael\nPetrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,\nAlethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such,\nDave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William\nSaunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\nRadford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario\nAmodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating Large Language Models Trained\non Code. https://arxiv.org/abs/2107.03374, 2021.\n[2] DeepSeek-AI. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. https:\n//arxiv.org/abs/2501.12948, 2025.\n[3] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.\nMeasuring Massive Multitask Language Understanding. https://arxiv.org/abs/2009.03300, 2021.\n[4] Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama,\nKoushik Sen, and Ion Stoica. LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language\nModels for Code. https://arxiv.org/abs/2403.07974, 2024.\n[5] Korea Institute for Curriculum and Evaluation. College Scholastic Ability Test. https://www.suneung.re.kr,\n2025.\n[6] LG AI Research. EXAONE 3.5: Series of Large Language Models for Real-world Use Cases. https://arxiv.\norg/abs/2412.04862, 2024.\n[7] LG AI Research. EXAONE-3.5-2.4B-Instruct. https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.\n4B-Instruct, 2025.\n[8] LG AI Research.\nEXAONE-3.5-32B-Instruct.\nhttps://huggingface.co/LGAI-EXAONE/EXAONE-3.\n5-32B-Instruct, 2025.\n[9] LG AI Research. EXAONE-3.5-7.8B-Instruct. https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-7.\n8B-Instruct, 2025.\n[10] Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John\nSchulman, Ilya Sutskever, and Karl Cobbe. Let’s Verify Step by Step. https://arxiv.org/abs/2305.20050,\n2023.\n[11] Mathematical Association of America. American Invitational Mathematics Examination. https://maa.org,\n2025.\n[12] OpenAI. OpenAI o1 System Card. https://cdn.openai.com/o1-system-card-20241205.pdf, 2024.\n[13] Qwen Team. QwQ-32B: Embracing the Power of Reinforcement Learning. https://qwenlm.github.io/\nblog/qwq-32b, 2025.\n[14] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian\nMichael, and Samuel R. Bowman. GPQA: A Graduate-Level Google-Proof Q&A Benchmark. https://arxiv.\norg/abs/2311.12022, 2023.\n[15] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang,\nY. K. Li, Y. Wu, and Daya Guo. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language\nModels. https://arxiv.org/abs/2402.03300, 2024.\n[16] Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling LLM Test-Time Compute Optimally can be\nMore Effective than Scaling Model Parameters. https://arxiv.org/abs/2408.03314, 2024.\n[17] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny\nZhou. Self-Consistency Improves Chain of Thought Reasoning in Language Models. https://arxiv.org/\nabs/2203.11171, 2023.\n14\n\n[18] Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran\nArulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, and\nWenhu Chen. MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark.\nhttps://arxiv.org/abs/2406.01574, 2024.\n[19] Teng Xiao, Yige Yuan, Zhengyu Chen, Mingxiao Li, Shangsong Liang, Zhaochun Ren, and Vasant G Honavar.\nSimPER: A Minimalist Approach to Preference Alignment without Hyperparameters. https://arxiv.org/\nabs/2502.00883, 2025.\n15\n"
    }
  ]
}