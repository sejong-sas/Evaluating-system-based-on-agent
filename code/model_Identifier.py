import json
import re
import requests
import os
from urllib.parse import urlparse
from dotenv import load_dotenv
from openai import OpenAI
from Huggingface_Fatcher import huggingface_fetcher
from github_Fatcher import github_fetcher
from arxiv_Fetcher import arxiv_fetcher_from_model
# from openness_Evaluator import evaluate_openness  # í‰ê°€ ëª¨ë“ˆ ìž„í¬íŠ¸
from github_Dispatcher import filter_github_features
from arxiv_Dispatcher import filter_arxiv_features
from huggingface_Dispatcher import filter_hf_features
from openness_Evaluator import evaluate_openness_from_files
from inference import run_inference

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
dotenv_path = os.path.join(os.getcwd(), '.env')
load_dotenv(dotenv_path)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1. ìž…ë ¥ íŒŒì‹±: URL ë˜ëŠ” org/model
def extract_model_info(input_str: str) -> dict:
    platform = None
    organization = model = None
    if input_str.startswith("http"):
        parsed = urlparse(input_str)
        domain = parsed.netloc.lower()
        segments = parsed.path.strip("/").split("/")
        if len(segments) >= 2:
            organization = segments[0]
            model = segments[1].split("?")[0].split("#")[0].replace(".git", "")
            if "huggingface" in domain:
                platform = "huggingface"
            elif "github" in domain:
                platform = "github"
    else:
        parts = input_str.strip().split("/")
        if len(parts) == 2:
            organization, model = parts
            platform = "unknown"
    if not organization or not model:
        raise ValueError("ì˜¬ë°”ë¥¸ ìž…ë ¥ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. 'org/model' ë˜ëŠ” URLì„ ìž…ë ¥í•˜ì„¸ìš”.")
    full_id = f"{organization}/{model}"
    hf_id = full_id.lower()
    return {"platform": platform, "organization": organization,
            "model": model, "full_id": full_id, "hf_id": hf_id}

# 2. ì¡´ìž¬ ì—¬ë¶€ í…ŒìŠ¤íŠ¸
def test_hf_model_exists(model_id: str) -> bool:
    resp = requests.get(f"https://huggingface.co/api/models/{model_id}")
    return resp.status_code == 200

def test_github_repo_exists(repo: str) -> bool:
    resp = requests.get(f"https://api.github.com/repos/{repo}")
    return resp.status_code == 200

# 3. ë§í¬ íŒŒì‹± í—¬í¼
def extract_repo_from_url(url: str) -> str:
    parsed = urlparse(url)
    parts = parsed.path.strip("/").split("/")
    if len(parts) >= 2:
        repo = parts[1].split("?")[0].split("#")[0].replace(".git", "")
        return f"{parts[0]}/{repo}"
    return ""

# 4. HF íŽ˜ì´ì§€ â†’ GitHub (fallback: raw README)
def find_github_in_huggingface(model_id: str) -> str:
    try:
        card = requests.get(f"https://huggingface.co/api/models/{model_id}?full=true").json().get("cardData", {})
        for field in ["repository", "homepage"]:
            url = card.get("links", {}).get(field, "")
            if "github.com" in url:
                return extract_repo_from_url(url)
        content = card.get("content", "")
        all_links = re.findall(r"https://github\.com/[\w\-]+/[\w\-\.]+", content)
        for link in all_links:
            if "github.com" in link:
                return extract_repo_from_url(link)
    except:
        pass
    for branch in ["main", "master"]:
        raw_url = f"https://huggingface.co/{model_id}/raw/{branch}/README.md"
        try:
            r = requests.get(raw_url)
            if r.status_code == 200:
                m2 = re.search(r"github\.com/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                if m2:
                    return m2.group(1)
        except:
            pass
    return None

# 5. GitHub íŽ˜ì´ì§€ â†’ HF (fallback: raw README and HTML)
def find_huggingface_in_github(repo: str) -> str:
    for fname in ["README.md", "README.en.md", "model_card.md"]:
        for branch in ["main", "master"]:
            raw_url = f"https://raw.githubusercontent.com/{repo}/{branch}/{fname}"
            try:
                r = requests.get(raw_url)
                if r.status_code == 200:
                    m = re.search(r"https?://huggingface\.co/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                    if m:
                        candidate = m.group(1).lower()
                        if not candidate.startswith('collections/'):
                            return candidate
                    m2 = re.search(r"huggingface\.co/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                    if m2:
                        candidate = m2.group(1).lower()
                        if not candidate.startswith('collections/'):
                            return candidate
                    m_md = re.search(r"\\[.*?\\]\\((https?://huggingface\.co/[\w\-/\.]+)\\)", r.text, re.IGNORECASE)
                    if m_md:
                        candidate = extract_model_info(m_md.group(1))["hf_id"]
                        if not candidate.startswith('collections/'):
                            return candidate
                    m_html = re.search(r'<a\\s+href="https?://huggingface\.co/([\w\-/\.]+)"', r.text, re.IGNORECASE)
                    if m_html:
                        candidate = m_html.group(1).lower()
                        if not candidate.startswith('collections/'):
                            return candidate
            except:
                pass
    try:
        html = requests.get(f"https://github.com/{repo}").text
        m3 = re.findall(r"https://huggingface\.co/[\w\-]+/[\w\-\.]+", html, re.IGNORECASE)
        for link in m3:
            if 'href' in html[html.find(link)-20:html.find(link)]:
                candidate = extract_model_info(link)["hf_id"]
                if not candidate.startswith('collections/'):
                    return candidate
    except:
        pass
    return None

# 7. ë©”ì¸ ë¡œì§
def run_all_fetchers(user_input: str):
    info = extract_model_info(user_input)
    hf_id = gh_id = None
    found_rank_hf = found_rank_gh = None
    full = info['full_id']
    hf_cand = info['hf_id']

    hf_ok = test_hf_model_exists(hf_cand)
    gh_ok = test_github_repo_exists(full)
    print(f"1ï¸âƒ£ HF: {hf_ok}, GH: {gh_ok}")

    if hf_ok:
        hf_id = hf_cand
        found_rank_hf = 1
    if gh_ok:
        gh_id = full
        found_rank_gh = 1

    if hf_ok and not gh_id:
        gh_link = find_github_in_huggingface(hf_cand)
        print(f"ðŸ” 2ìˆœìœ„ HFâ†’GH link: {gh_link}")
        if gh_link and test_github_repo_exists(gh_link):
            gh_id = gh_link
            found_rank_gh = 2
    if gh_ok and not hf_id:
        hf_link = find_huggingface_in_github(full)
        print(f"ðŸ” 2ìˆœìœ„ GHâ†’HF link: {hf_link}")
        if hf_link and test_hf_model_exists(hf_link):
            hf_id = hf_link
            found_rank_hf = 2

    if hf_ok and not gh_id:
        guess_gh = gpt_guess_github_from_huggingface(hf_cand)
        print(f"â³ 3ìˆœìœ„ GPT HFâ†’GH guess: {guess_gh}")
        if guess_gh and test_github_repo_exists(guess_gh):
            gh_id = guess_gh
            found_rank_gh = 3
    if gh_ok and not hf_id:
        guess_hf = gpt_guess_huggingface_from_github(full)
        print(f"â³ 3ìˆœìœ„ GPT GHâ†’HF guess: {guess_hf}")
        if guess_hf and test_hf_model_exists(guess_hf):
            hf_id = guess_hf
            found_rank_hf = 3

    if hf_id:
        rank_hf = found_rank_hf or 'ì—†ìŒ'
        print(f"âœ… HF model: {hf_id} (ë°œê²¬: {rank_hf}ìˆœìœ„)")
        huggingface_fetcher(hf_id, save_to_file=True)
        arxiv_fetcher_from_model(hf_id, save_to_file=True)
        try:
            hf_filtered = filter_hf_features(hf_id)
        except FileNotFoundError:
            gh_filtered = {}
            print("âš ï¸ Huggingfacw JSON íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•Šì•„ í•„í„°ë§ ìƒëžµ")
        try:
            ax_filtered = filter_arxiv_features(hf_id)
        except FileNotFoundError:
            ax_filtered = {}
            print("âš ï¸ arxiv JSON íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•Šì•„ í•„í„°ë§ ìƒëžµ")
    else:
        print("âš ï¸ HF ì •ë³´ ì—†ìŒ")

    if gh_id:
        rank_gh = found_rank_gh or 'ì—†ìŒ'
        print(f"âœ… GH repo: {gh_id} (ë°œê²¬: {rank_gh}ìˆœìœ„)")
        github_fetcher(gh_id, branch="main", save_to_file=True)
        try:
            gh_filtered = filter_github_features(gh_id)
        except FileNotFoundError:
            gh_filtered = {}
            print("âš ï¸ GitHub JSON íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•Šì•„ í•„í„°ë§ ìƒëžµ")
    else:
        print("âš ï¸ GH ì •ë³´ ì—†ìŒ")

      # 9. Openness í‰ê°€ ìˆ˜í–‰
    
    try:
        print("ðŸ“ ê°œë°©ì„± í‰ê°€ ì‹œìž‘...")
        eval_res = evaluate_openness_from_files(full)
        print(f"âœ… ê°œë°©ì„± í‰ê°€ ì™„ë£Œ. ê²°ê³¼ íŒŒì¼: openness_score_{full.replace('/', '_')}.json")
    except Exception as e:
        print("âš ï¸ ê°œë°©ì„± í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)



if __name__ == "__main__":
    user_input = input("ðŸŒ HF/GH URL ë˜ëŠ” org/model: ").strip()
    run_all_fetchers(user_input)

    info = extract_model_info(user_input)
    hf_id = info['hf_id']

    if test_hf_model_exists(hf_id):
        with open("identified_model.txt", "w", encoding="utf-8") as f:
            f.write(hf_id)
        print(f"âœ… ëª¨ë¸ ID ì €ìž¥ ì™„ë£Œ: {hf_id}")

        # âœ… ë°”ë¡œ ì¶”ë¡ ê¹Œì§€ ì‹¤í–‰
        prompt = input("ðŸ“ í”„ë¡¬í”„íŠ¸ë¥¼ ìž…ë ¥í•˜ì„¸ìš”: ")
        run_inference(hf_id, prompt)