# model_Identifier.py

import os
<<<<<<< HEAD
=======
import re
import json
import requests
>>>>>>> origin/main
from pathlib import Path
from urllib.parse import urlparse

from dotenv import load_dotenv
from openai import OpenAI

from huggingface_Fetcher import huggingface_fetcher
from github_Fetcher import github_fetcher
from arxiv_Fetcher import arxiv_fetcher_from_model

from github_Dispatcher import filter_github_features
from arxiv_Dispatcher import filter_arxiv_features
from huggingface_Dispatcher import filter_hf_features

from openness_Evaluator import evaluate_openness_from_files
from inference import run_inference

<<<<<<< HEAD

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
dotenv_path = os.path.join(os.getcwd(), '.env')
=======
# ========= í™˜ê²½ì„¤ì • =========
dotenv_path = os.path.join(os.getcwd(), ".env")
>>>>>>> origin/main
load_dotenv(dotenv_path)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ========= ê³µí†µ ìœ í‹¸ =========
def extract_model_info(input_str: str) -> dict:
    """HF/GH URL ë˜ëŠ” 'org/model'ì„ ë°›ì•„ íŒŒì‹±."""
    platform = None
    organization = model = None

    if input_str.startswith("http"):
        parsed = urlparse(input_str)
        domain = parsed.netloc.lower()
        segments = parsed.path.strip("/").split("/")
        if len(segments) >= 2:
            organization = segments[0]
            model = (
                segments[1].split("?")[0]
                .split("#")[0]
                .replace(".git", "")
            )
            if "huggingface" in domain:
                platform = "huggingface"
            elif "github" in domain:
                platform = "github"
    else:
        parts = input_str.strip().split("/")
        if len(parts) == 2:
            organization, model = parts
            platform = "unknown"

    if not organization or not model:
        raise ValueError("ì˜¬ë°”ë¥¸ ì…ë ¥ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. 'org/model' ë˜ëŠ” URLì„ ì…ë ¥í•˜ì„¸ìš”.")

    full_id = f"{organization}/{model}"
    hf_id = full_id.lower()
    return {
        "platform": platform,
        "organization": organization,
        "model": model,
        "full_id": full_id,
        "hf_id": hf_id,
    }

def test_hf_model_exists(model_id: str) -> bool:
    resp = requests.get(f"https://huggingface.co/api/models/{model_id}")
    return resp.status_code == 200

def test_github_repo_exists(repo: str) -> bool:
    resp = requests.get(f"https://api.github.com/repos/{repo}")
    return resp.status_code == 200

def extract_repo_from_url(url: str) -> str:
    parsed = urlparse(url)
    parts = parsed.path.strip("/").split("/")
    if len(parts) >= 2:
        repo = parts[1].split("?")[0].split("#")[0].replace(".git", "")
        return f"{parts[0]}/{repo}"
    return ""

def find_github_in_huggingface(model_id: str) -> str | None:
    """HF ëª¨ë¸ ì¹´ë“œ/READMEì—ì„œ GH repoë¥¼ ì°¾ì•„ëƒ„."""
    try:
        card = requests.get(
            f"https://huggingface.co/api/models/{model_id}?full=true"
        ).json().get("cardData", {})
        # 1) ë§í¬ í•„ë“œ
        for field in ["repository", "homepage"]:
            url = card.get("links", {}).get(field, "")
            if "github.com" in url:
                return extract_repo_from_url(url)
        # 2) ì¹´ë“œ ë³¸ë¬¸
        content = card.get("content", "")
        all_links = re.findall(r"https://github\.com/[\w\-]+/[\w\-\.]+", content)
        for link in all_links:
            if "github.com" in link:
                return extract_repo_from_url(link)
    except Exception:
        pass

    # 3) raw README
    for branch in ["main", "master"]:
        raw_url = f"https://huggingface.co/{model_id}/raw/{branch}/README.md"
        try:
            r = requests.get(raw_url)
            if r.status_code == 200:
                m2 = re.search(r"github\.com/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                if m2:
                    return m2.group(1)
        except Exception:
            pass
    return None

def find_huggingface_in_github(repo: str) -> str | None:
    """GH README/í˜ì´ì§€ì—ì„œ HF ëª¨ë¸ IDë¥¼ ì°¾ì•„ëƒ„."""
    for fname in ["README.md"]:
        for branch in ["main", "master"]:
            raw_url = f"https://raw.githubusercontent.com/{repo}/{branch}/{fname}"
            try:
                r = requests.get(raw_url)
                if r.status_code == 200:
                    m = re.search(r"https?://huggingface\.co/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                    if m:
                        candidate = m.group(1).lower()
                        if not candidate.startswith("collections/"):
                            return candidate

                    m2 = re.search(r"huggingface\.co/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                    if m2:
                        candidate = m2.group(1).lower()
                        if not candidate.startswith("collections/"):
                            return candidate

                    m_md = re.search(r"\[.*?\]\((https?://huggingface\.co/[\w\-/\.]+)\)", r.text, re.IGNORECASE)
                    if m_md:
                        candidate = extract_model_info(m_md.group(1))["hf_id"]
                        if not candidate.startswith("collections/"):
                            return candidate

                    m_html = re.search(r'<a\s+href="https?://huggingface\.co/([\w\-/\.]+)"', r.text, re.IGNORECASE)
                    if m_html:
                        candidate = m_html.group(1).lower()
                        if not candidate.startswith("collections/"):
                            return candidate
            except Exception:
                pass

    try:
        html = requests.get(f"https://github.com/{repo}").text
        m3 = re.findall(r"https://huggingface\.co/[\w\-]+/[\w\-\.]+", html, re.IGNORECASE)
        for link in m3:
            if 'href' in html[html.find(link)-20:html.find(link)]:
                candidate = extract_model_info(link)["hf_id"]
                if not candidate.startswith("collections/"):
                    return candidate
    except Exception:
        pass
    return None

def gpt_guess_github_from_huggingface(hf_id: str) -> str | None:
    prompt = f"""
Hugging Faceì— ë“±ë¡ëœ ëª¨ë¸ '{hf_id}'ì˜ ì›ë³¸ ì½”ë“œê°€ ì €ì¥ëœ GitHub ì €ì¥ì†Œë¥¼ ì¶”ì •í•˜ì„¸ìš”.
- 'organization/repo' **í•œ ì¤„ë§Œ** ì¶œë ¥(ë§í¬/ì„¤ëª… X)
- ëª¨ë…¸ë¦¬í¬ë³´ë‹¤ ëª¨ë¸ ì „ìš© ì €ì¥ì†Œ ìš°ì„ 
- Distillì´ë©´ ë¶€ëª¨ ëª¨ë¸ ì €ì¥ì†Œ ê³ ë ¤
- ì˜ˆ: facebookresearch/llama
"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        guess = resp.choices[0].message.content.strip()
        if "/" in guess:
            return guess
    except Exception as e:
        print("âš ï¸ GPT HFâ†’GH ì¶”ì • ì¤‘ ì˜¤ë¥˜:", e)
    return None

def gpt_guess_huggingface_from_github(gh_id: str) -> str | None:
    prompt = f"""
GitHub ì €ì¥ì†Œ '{gh_id}'ì™€ ì—°ê²°ëœ Hugging Face ëª¨ë¸ IDë¥¼ ì¶”ì •í•˜ì„¸ìš”.
- organization/model **í•œ ì¤„ë§Œ** ì¶œë ¥
- ì˜ˆ: facebookresearch/llama
"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        guess = resp.choices[0].message.content.strip().lower()
        if "/" in guess:
            return guess
    except Exception as e:
        print("âš ï¸ GPT GHâ†’HF ì¶”ì • ì¤‘ ì˜¤ë¥˜:", e)
    return None

<<<<<<< HEAD
def run_all_fetchers(user_input: str):
    outdir = make_model_dir(user_input)
    print(f"ğŸ“ ì¶œë ¥ ê²½ë¡œ: {outdir}")
=======
def make_model_dir(user_input: str) -> Path:
    """ëª¨ë¸ë³„ ì„œë¸Œë””ë ‰í† ë¦¬ ìƒì„±(ì•ˆì „í•œ í´ë”ëª…)."""
>>>>>>> origin/main
    info = extract_model_info(user_input)
    base = info["hf_id"]  # ex) 'bigscience/bloomz-560m'
    safe = re.sub(r'[<>:"/\\|?*\s]+', "_", base).lower()  # ì•ˆì „í•œ í´ë”ëª…
    path = Path(safe)
    path.mkdir(parents=True, exist_ok=True)
    return path

# ========= ë©”ì¸ íŒŒì´í”„ë¼ì¸ =========
def run_all_fetchers(user_input: str):
    outdir = make_model_dir(user_input)
    print(f"ğŸ“ ì¶œë ¥ ê²½ë¡œ: {outdir}")

    info = extract_model_info(user_input)
    full = info["full_id"]
    hf_cand = info["hf_id"]

    hf_id = None
    gh_id = None
    found_rank_hf = None
    found_rank_gh = None
    data = None  # HF README ë³´ê´€

    hf_ok = test_hf_model_exists(hf_cand)
    gh_ok = test_github_repo_exists(full)
    print(f"1ï¸âƒ£ HF: {hf_ok}, GH: {gh_ok}")

    if hf_ok:
        hf_id = hf_cand
        found_rank_hf = 1
    if gh_ok:
        gh_id = full
        found_rank_gh = 1

    if hf_ok and not gh_id:
        gh_link = find_github_in_huggingface(hf_cand)
        print(f"ğŸ” 2ìˆœìœ„ HFâ†’GH link: {gh_link}")
        if gh_link and test_github_repo_exists(gh_link):
            gh_id = gh_link
            found_rank_gh = 2

    if gh_ok and not hf_id:
        hf_link = find_huggingface_in_github(full)
        print(f"ğŸ” 2ìˆœìœ„ GHâ†’HF link: {hf_link}")
        if hf_link and test_hf_model_exists(hf_link):
            hf_id = hf_link
            found_rank_hf = 2

    if hf_ok and not gh_id:
        guess_gh = gpt_guess_github_from_huggingface(hf_cand)
        print(f"â³ 3ìˆœìœ„ GPT HFâ†’GH guess: {guess_gh}")
        if guess_gh and test_github_repo_exists(guess_gh):
            gh_id = guess_gh
            found_rank_gh = 3
            print("âš ï¸ GPT ì¶”ì • ê²°ê³¼ â€” ì‹¤ì œ í¬í•¨ ëª¨ë¸ í™•ì¸ í•„ìš”")

    if gh_ok and not hf_id:
        guess_hf = gpt_guess_huggingface_from_github(full)
        print(f"â³ 3ìˆœìœ„ GPT GHâ†’HF guess: {guess_hf}")
        if guess_hf and test_hf_model_exists(guess_hf):
            hf_id = guess_hf
            found_rank_hf = 3
<<<<<<< HEAD
            print("âš ï¸ GPT ì¶”ì • ê²°ê³¼ì…ë‹ˆë‹¤. ëª¨ë¸ IDê°€ ì •í™•í•œì§€ ê²€í†  í•„ìš”")
    
    
=======
            print("âš ï¸ GPT ì¶”ì • ê²°ê³¼ â€” ëª¨ë¸ ID ì •í™•ì„± í™•ì¸ í•„ìš”")

    # ---- Hugging Face ì¸¡ ìˆ˜ì§‘/í•„í„° ----
>>>>>>> origin/main
    if hf_id:
        rank_hf = found_rank_hf or "ì—†ìŒ"
        print(f"âœ… HF model: {hf_id} (ë°œê²¬: {rank_hf}ìˆœìœ„)")
        data = huggingface_fetcher(hf_id, save_to_file=True, output_dir=outdir)
        arxiv_fetcher_from_model(hf_id, save_to_file=True, output_dir=outdir)
        try:
<<<<<<< HEAD
            hf_filtered = filter_hf_features(hf_id, output_dir=outdir)
=======
            _ = filter_hf_features(hf_id, output_dir=outdir)
>>>>>>> origin/main
        except FileNotFoundError:
            print("âš ï¸ HuggingFace JSON íŒŒì¼ì´ ì—†ì–´ í•„í„°ë§ ìƒëµ")
        try:
<<<<<<< HEAD
            ax_filtered = filter_arxiv_features(hf_id, output_dir=outdir)
=======
            _ = filter_arxiv_features(hf_id, output_dir=outdir)
>>>>>>> origin/main
        except FileNotFoundError:
            print("âš ï¸ arXiv JSON íŒŒì¼ì´ ì—†ì–´ í•„í„°ë§ ìƒëµ")
    else:
        print("âš ï¸ HuggingFace ì •ë³´ ì—†ìŒ")
<<<<<<< HEAD
=======

    # ---- GitHub ì¸¡ ìˆ˜ì§‘/í•„í„° ----
>>>>>>> origin/main
    if gh_id:
        rank_gh = found_rank_gh or "ì—†ìŒ"
        print(f"âœ… GH repo: {gh_id} (ë°œê²¬: {rank_gh}ìˆœìœ„)")
        try:
            github_fetcher(gh_id, branch="main", save_to_file=True, output_dir=outdir)
        except requests.exceptions.HTTPError:
            print("âš ï¸ main ë¸Œëœì¹˜ ì‹¤íŒ¨, masterë¡œ ì¬ì‹œë„...")
            try:
                github_fetcher(gh_id, branch="master", save_to_file=True, output_dir=outdir)
            except Exception as e:
                print("âŒ master ë¸Œëœì¹˜ë„ ì‹¤íŒ¨:", e)
        try:
<<<<<<< HEAD
            gh_filtered = filter_github_features(gh_id, output_dir=outdir)
=======
            _ = filter_github_features(gh_id, output_dir=outdir)
>>>>>>> origin/main
        except FileNotFoundError:
            print("âš ï¸ GitHub JSON íŒŒì¼ì´ ì—†ì–´ í•„í„°ë§ ìƒëµ")
    else:
        print("âš ï¸ GitHub ì •ë³´ ì—†ìŒ")

<<<<<<< HEAD
    run_inference(data.get("readme"))
    
# 8. Openness í‰ê°€ ìˆ˜í–‰
    try:
        print("ğŸ“ ê°œë°©ì„± í‰ê°€ ì‹œì‘...")
        eval_res = evaluate_openness_from_files(full, base_dir=str(outdir))
        base = full.replace("/", "_")
        outfile = Path(outdir) / f"openness_score_{base}.json"
        print(f"âœ… ê°œë°©ì„± í‰ê°€ ì™„ë£Œ.  ê²°ê³¼ íŒŒì¼: {outfile}")
    except Exception as e:
        print("âš ï¸ ê°œë°©ì„± í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)

    # README ê¸°ë°˜ ì¶”ë¡ ì€ dataê°€ ìˆì„ ë•Œë§Œ
    if 'data' in locals() and isinstance(data, dict) and data.get("readme"):
        run_inference(data.get("readme"))


def make_model_dir(user_input: str) -> Path:
    info = extract_model_info(user_input)        # ìœ„ì— ì´ë¯¸ ìˆëŠ” í•¨ìˆ˜
    base = info["hf_id"]                         # ex) 'bigscience/bloomz-560m'
    # í´ë”ëª…ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€ê²½: ìŠ¬ë˜ì‹œ/ê³µë°±/ê¸ˆì§€ë¬¸ì -> _
    safe = re.sub(r'[<>:"/\\|?*\s]+', "_", base) # ex) 'bigscience_bloomz-560m'
    path = Path(safe)
    path.mkdir(parents=True, exist_ok=True)      # ìƒìœ„ í´ë”ê¹Œì§€ ìƒì„±, ìˆìœ¼ë©´ ê·¸ëƒ¥ í†µê³¼
    return path

if __name__ == "__main__":
    user_input = input("ğŸŒ HF/GH URL ë˜ëŠ” org/model: ").strip()
    model_dir = make_model_dir(user_input)
    print(f"ğŸ“ ìƒì„±/ì‚¬ìš©í•  í´ë”: {model_dir}") 
    run_all_fetchers(user_input)

    info = extract_model_info(user_input)
    hf_id = info['hf_id']

    if test_hf_model_exists(hf_id):
        with open("identified_model.txt", "w", encoding="utf-8") as f:
            f.write(hf_id)
        print(f"âœ… ëª¨ë¸ ID ì €ì¥ ì™„ë£Œ: {hf_id}")

    #     # âœ… ë°”ë¡œ ì¶”ë¡ ê¹Œì§€ ì‹¤í–‰
    #     prompt = input("ğŸ“ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    #     run_inference(hf_id, prompt)
=======
    # ---- README ê¸°ë°˜ ê°„ë‹¨ ì¶”ë¡ (ì„ íƒ) ----
    if isinstance(data, dict) and data.get("readme"):
        run_inference(data["readme"])

    # ---- ê°œë°©ì„± í‰ê°€ ----
    try:
        print("ğŸ“ ê°œë°©ì„± í‰ê°€ ì‹œì‘...")
        try:
            _ = evaluate_openness_from_files(full, base_dir=str(outdir))
        except TypeError:
            _ = evaluate_openness_from_files(full)
        base_name = full.replace("/", "_")
        print(f"âœ… ê°œë°©ì„± í‰ê°€ ì™„ë£Œ. ê²°ê³¼ íŒŒì¼: {outdir / Path(f'openness_score_{base_name}.json')}")
    except Exception as e:
        print("âš ï¸ ê°œë°©ì„± í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)

# ========= ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ =========
if __name__ == "__main__":
    user_input = input("ğŸŒ HF/GH URL ë˜ëŠ” org/model: ").strip()
    model_dir = make_model_dir(user_input)
    print(f"ğŸ“ ìƒì„±/ì‚¬ìš©í•  í´ë”: {model_dir}")
    run_all_fetchers(user_input)
>>>>>>> origin/main
