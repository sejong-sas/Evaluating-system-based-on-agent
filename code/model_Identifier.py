import json
import re
import requests
import os
from urllib.parse import urlparse
from dotenv import load_dotenv
from openai import OpenAI
from huggingface_Fetcher import huggingface_fetcher
from github_Fetcher import github_fetcher
from arxiv_Fetcher import arxiv_fetcher_from_model
# from openness_Evaluator import evaluate_openness  # í‰ê°€ ëª¨ë“ˆ ì„í¬íŠ¸
from github_Dispatcher import filter_github_features
from arxiv_Dispatcher import filter_arxiv_features
from huggingface_Dispatcher import filter_hf_features
from openness_Evaluator import evaluate_openness_from_files
from inference import run_inference

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
dotenv_path = os.path.join(os.getcwd(), '.env')
load_dotenv(dotenv_path)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1. ì…ë ¥ íŒŒì‹±: URL ë˜ëŠ” org/model
def extract_model_info(input_str: str) -> dict:
    platform = None
    organization = model = None
    if input_str.startswith("http"):
        parsed = urlparse(input_str)
        domain = parsed.netloc.lower()
        segments = parsed.path.strip("/").split("/")
        if len(segments) >= 2:
            organization = segments[0]
            model = segments[1].split("?")[0].split("#")[0].replace(".git", "")
            if "huggingface" in domain:
                platform = "huggingface"
            elif "github" in domain:
                platform = "github"
    else:
        parts = input_str.strip().split("/")
        if len(parts) == 2:
            organization, model = parts
            platform = "unknown"
    if not organization or not model:
        raise ValueError("ì˜¬ë°”ë¥¸ ì…ë ¥ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. 'org/model' ë˜ëŠ” URLì„ ì…ë ¥í•˜ì„¸ìš”.")
    full_id = f"{organization}/{model}"
    hf_id = full_id.lower()
    return {"platform": platform, "organization": organization,
            "model": model, "full_id": full_id, "hf_id": hf_id}

# 2. ì¡´ì¬ ì—¬ë¶€ í…ŒìŠ¤íŠ¸
def test_hf_model_exists(model_id: str) -> bool:
    resp = requests.get(f"https://huggingface.co/api/models/{model_id}")
    return resp.status_code == 200

def test_github_repo_exists(repo: str) -> bool:
    resp = requests.get(f"https://api.github.com/repos/{repo}")
    return resp.status_code == 200

# 3. ë§í¬ íŒŒì‹± í—¬í¼
def extract_repo_from_url(url: str) -> str:
    parsed = urlparse(url)
    parts = parsed.path.strip("/").split("/")
    if len(parts) >= 2:
        repo = parts[1].split("?")[0].split("#")[0].replace(".git", "")
        return f"{parts[0]}/{repo}"
    return ""

# 4. HF í˜ì´ì§€ â†’ GitHub (fallback: raw README)
def find_github_in_huggingface(model_id: str) -> str:
    try:
        card = requests.get(f"https://huggingface.co/api/models/{model_id}?full=true").json().get("cardData", {})
        for field in ["repository", "homepage"]:
            url = card.get("links", {}).get(field, "")
            if "github.com" in url:
                return extract_repo_from_url(url)
        content = card.get("content", "")
        all_links = re.findall(r"https://github\.com/[\w\-]+/[\w\-\.]+", content)
        for link in all_links:
            if "github.com" in link:
                return extract_repo_from_url(link)
    except:
        pass
    for branch in ["main", "master"]:
        raw_url = f"https://huggingface.co/{model_id}/raw/{branch}/README.md"
        try:
            r = requests.get(raw_url)
            if r.status_code == 200:
                m2 = re.search(r"github\.com/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                if m2:
                    return m2.group(1)
        except:
            pass
    return None

# 5. GitHub í˜ì´ì§€ â†’ HF (fallback: raw README and HTML) ,,,, "README.en.md", "model_card.md"###################
def find_huggingface_in_github(repo: str) -> str:
    for fname in ["README.md"]:
        for branch in ["main", "master"]:
            raw_url = f"https://raw.githubusercontent.com/{repo}/{branch}/{fname}"
            try:
                r = requests.get(raw_url)
                if r.status_code == 200:
                    m = re.search(r"https?://huggingface\.co/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                    if m:
                        candidate = m.group(1).lower()
                        if not candidate.startswith('collections/'):
                            return candidate
                    m2 = re.search(r"huggingface\.co/([\w\-]+/[\w\-\.]+)", r.text, re.IGNORECASE)
                    if m2:
                        candidate = m2.group(1).lower()
                        if not candidate.startswith('collections/'):
                            return candidate
                    m_md = re.search(r"\\[.*?\\]\\((https?://huggingface\.co/[\w\-/\.]+)\\)", r.text, re.IGNORECASE)
                    if m_md:
                        candidate = extract_model_info(m_md.group(1))["hf_id"]
                        if not candidate.startswith('collections/'):
                            return candidate
                    m_html = re.search(r'<a\\s+href="https?://huggingface\.co/([\w\-/\.]+)"', r.text, re.IGNORECASE)
                    if m_html:
                        candidate = m_html.group(1).lower()
                        if not candidate.startswith('collections/'):
                            return candidate
            except:
                pass
    try:
        html = requests.get(f"https://github.com/{repo}").text
        m3 = re.findall(r"https://huggingface\.co/[\w\-]+/[\w\-\.]+", html, re.IGNORECASE)
        for link in m3:
            if 'href' in html[html.find(link)-20:html.find(link)]:
                candidate = extract_model_info(link)["hf_id"]
                if not candidate.startswith('collections/'):
                    return candidate
    except:
        pass
    return None
def gpt_guess_github_from_huggingface(hf_id: str) -> str:
    prompt = f"""
Hugging Faceì— ë“±ë¡ëœ ëª¨ë¸ '{hf_id}'ì— ëŒ€í•´, ì´ ëª¨ë¸ì˜ ì›ë³¸ ì½”ë“œê°€ ì €ì¥ëœ GitHub ì €ì¥ì†Œë¥¼ ì¶”ì •í•˜ì„¸ìš”.

ğŸŸ¢ ì§€ì¼œì•¼ í•  ê·œì¹™:
1. 'organization/repo' í˜•ì‹ìœ¼ë¡œ **ì •í™•í•œ GitHub ê²½ë¡œë§Œ** ë°˜í™˜í•˜ì„¸ìš” (ë§í¬ X, ì„¤ëª… X).
2. 'google-research/google-research'ì²˜ëŸ¼ ë„ˆë¬´ ì¼ë°˜ì ì¸ ëª¨ë…¸ë¦¬í¬ì§€í„°ë¦¬ëŠ” í”¼í•˜ê³ , ëª¨ë¸ ë‹¨ìœ„ ì €ì¥ì†Œê°€ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ìš°ì„  ì¶”ì •í•˜ì„¸ìš”.
3. distill ëª¨ë¸ì¸ ê²½ìš° ë¶€ëª¨ ëª¨ë¸ì„ ì°¾ì•„ì£¼ì„¸ìš”.
4. í•´ë‹¹ ëª¨ë¸ì˜ ì´ë¦„, êµ¬ì¡°, ë…¼ë¬¸, tokenizer, ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬(PyTorch, JAX, T5 ë“±)ë¥¼ ì°¸ê³ í•´ì„œ ì •í™•í•œ repoë¥¼ ì¶”ì •í•˜ì„¸ìš”.
5. ê²°ê³¼ëŠ” **ë”± í•œ ì¤„**, ì˜ˆ: `facebookresearch/llama`

ğŸ”´ ì¶œë ¥ì—ëŠ” ë¶€ê°€ ì„¤ëª… ì—†ì´ GitHub ì €ì¥ì†Œ ê²½ë¡œë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        guess = response.choices[0].message.content.strip()
        if "/" in guess:
            return guess
    except Exception as e:
        print("âš ï¸ GPT HFâ†’GH ì¶”ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
    return None

def gpt_guess_huggingface_from_github(gh_id: str) -> str:
    prompt = f"""
Hugging Faceì— ë“±ë¡ëœ ëª¨ë¸ '{gh_id}'ì˜ ì›ë³¸ ì½”ë“œê°€ ì €ì¥ëœ Hugging Face ëª¨ë¸ IDë¥¼ ì¶”ì •í•´ì£¼ì„¸ìš”.
- ì •í™•í•œ organization/repository ê²½ë¡œë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
- ëª¨ë¸ ì´ë¦„ì´ë‚˜ ê´€ë ¨ ë…¼ë¬¸ì—ì„œ ìœ ë˜ëœ GitHub ì €ì¥ì†Œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì •í•˜ì„¸ìš”.
- ì˜ˆì‹œ ì¶œë ¥: facebookresearch/llama
- 'google-research/google-research'ì²˜ëŸ¼ ê´‘ë²”ìœ„í•œ ëª¨ë…¸ë¦¬í¬ì§€í„°ë¦¬ëŠ” í”¼í•˜ê³ , í•´ë‹¹ ëª¨ë¸ì„ ìœ„í•œ ë³„ë„ ì €ì¥ì†Œê°€ ìˆë‹¤ë©´ ê·¸ìª½ì„ ìš°ì„  ê³ ë ¤í•˜ì„¸ìš”.
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        guess = response.choices[0].message.content.strip().lower()
        if "/" in guess:
            return guess
    except Exception as e:
        print("âš ï¸ GPT GHâ†’HF ì¶”ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
    return None

def run_all_fetchers(user_input: str):
    info = extract_model_info(user_input)
    hf_id = gh_id = None
    found_rank_hf = found_rank_gh = None
    full = info['full_id']
    hf_cand = info['hf_id']

    hf_ok = test_hf_model_exists(hf_cand)
    gh_ok = test_github_repo_exists(full)
    print(f"1ï¸âƒ£ HF: {hf_ok}, GH: {gh_ok}")

    if hf_ok:
        hf_id = hf_cand
        found_rank_hf = 1
    if gh_ok:
        gh_id = full
        found_rank_gh = 1

    if hf_ok and not gh_id:
        gh_link = find_github_in_huggingface(hf_cand)
        print(f"ğŸ” 2ìˆœìœ„ HFâ†’GH link: {gh_link}")
        if gh_link and test_github_repo_exists(gh_link):
            gh_id = gh_link
            found_rank_gh = 2

    if gh_ok and not hf_id:
        hf_link = find_huggingface_in_github(full)
        print(f"ğŸ” 2ìˆœìœ„ GHâ†’HF link: {hf_link}")
        if hf_link and test_hf_model_exists(hf_link):
            hf_id = hf_link
            found_rank_hf = 2

    if hf_ok and not gh_id:
        guess_gh = gpt_guess_github_from_huggingface(hf_cand)
        print(f"â³ 3ìˆœìœ„ GPT HFâ†’GH guess: {guess_gh}")
        if guess_gh and test_github_repo_exists(guess_gh):
            gh_id = guess_gh
            found_rank_gh = 3
            print("âš ï¸ GPT ì¶”ì • ê²°ê³¼ì…ë‹ˆë‹¤. ì €ì¥ì†Œê°€ ì‹¤ì œë¡œ í•´ë‹¹ ëª¨ë¸ì„ í¬í•¨í•˜ëŠ”ì§€ ê²€í†  í•„ìš”")

    if gh_ok and not hf_id:
        guess_hf = gpt_guess_huggingface_from_github(full)
        print(f"â³ 3ìˆœìœ„ GPT GHâ†’HF guess: {guess_hf}")
        if guess_hf and test_hf_model_exists(guess_hf):
            hf_id = guess_hf
            found_rank_hf = 3
            print("âš ï¸ GPT ì¶”ì • ê²°ê³¼ì…ë‹ˆë‹¤. ëª¨ë¸ IDê°€ ì •í™•í•œì§€ ê²€í†  í•„ìš”")

    if hf_id:
        rank_hf = found_rank_hf or 'ì—†ìŒ'
        print(f"âœ… HF model: {hf_id} (ë°œê²¬: {rank_hf}ìˆœìœ„)")
        data = huggingface_fetcher(hf_id, save_to_file=True)
        arxiv_fetcher_from_model(hf_id, save_to_file=True)
        try:
            hf_filtered = filter_hf_features(hf_id)
        except FileNotFoundError:
            hf_filtered = {}
            print("âš ï¸ HuggingFace JSON íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ í•„í„°ë§ ìƒëµ")
        try:
            ax_filtered = filter_arxiv_features(hf_id)
        except FileNotFoundError:
            ax_filtered = {}
            print("âš ï¸ arXiv JSON íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ í•„í„°ë§ ìƒëµ")
    else:
        print("âš ï¸ HuggingFace ì •ë³´ ì—†ìŒ")

    if gh_id:
        rank_gh = found_rank_gh or 'ì—†ìŒ'
        print(f"âœ… GH repo: {gh_id} (ë°œê²¬: {rank_gh}ìˆœìœ„)")

        try:
            github_fetcher(gh_id, branch="main", save_to_file=True)
        except requests.exceptions.HTTPError:
            print("âš ï¸ main ë¸Œëœì¹˜ ì ‘ê·¼ ì‹¤íŒ¨, master ë¸Œëœì¹˜ë¡œ ì¬ì‹œë„...")
            try:
                github_fetcher(gh_id, branch="master", save_to_file=True)
            except Exception as e:
                print("âŒ master ë¸Œëœì¹˜ë„ ì‹¤íŒ¨:", e)

        try:
            gh_filtered = filter_github_features(gh_id)
        except FileNotFoundError:
            gh_filtered = {}
            print("âš ï¸ GitHub JSON íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ í•„í„°ë§ ìƒëµ")
    else:
        print("âš ï¸ GitHub ì •ë³´ ì—†ìŒ")
    run_inference(data.get("readme"))
    
# 8. Openness í‰ê°€ ìˆ˜í–‰
    
    try:
        print("ğŸ“ ê°œë°©ì„± í‰ê°€ ì‹œì‘...")
        eval_res = evaluate_openness_from_files(full)
        print(f"âœ… ê°œë°©ì„± í‰ê°€ ì™„ë£Œ. ê²°ê³¼ íŒŒì¼: openness_score_{full.replace('/', '_')}.json")
    except Exception as e:
        print("âš ï¸ ê°œë°©ì„± í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)

    run_inference(data.get("readme"))

if __name__ == "__main__":
    user_input = input("ğŸŒ HF/GH URL ë˜ëŠ” org/model: ").strip()
    run_all_fetchers(user_input)

    info = extract_model_info(user_input)
    hf_id = info['hf_id']

    # if test_hf_model_exists(hf_id):
    #     with open("identified_model.txt", "w", encoding="utf-8") as f:
    #         f.write(hf_id)
    #     print(f"âœ… ëª¨ë¸ ID ì €ì¥ ì™„ë£Œ: {hf_id}")

    #     # âœ… ë°”ë¡œ ì¶”ë¡ ê¹Œì§€ ì‹¤í–‰
    #     prompt = input("ğŸ“ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    #     run_inference(hf_id, prompt)