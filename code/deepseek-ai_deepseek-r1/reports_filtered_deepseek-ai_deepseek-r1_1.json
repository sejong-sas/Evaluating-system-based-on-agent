{
  "1-1 (Weights)": "The provided quotes for DeepSeek-R1 detail that the model weights are publicly open-sourced to support the research community. Specifically, they mention that both DeepSeek-R1 and its variant DeepSeek-R1-Zero are available, alongside six additional dense models with sizes of 1.5B, 7B, 8B, 14B, 32B, and 70B. These dense models have been distilled from DeepSeek-R1 based on frameworks like Qwen and Llama. This information emphasizes the commitment to openness and accessibility, allowing researchers to download and experiment with multiple versions derived from DeepSeek-R1.",
  "1-2 (Code)": "No information regarding the public availability of training or inference code for DeepSeek-R1 was provided. There is no mention of whether the training pipeline, data preparation, configurations, or other related scripts are open-sourced.",
  "1-3 (License)": "There is no information provided about the licensing details for DeepSeek-R1. No explicit details regarding rights of use, modification, redistribution, or any restrictions such as non-commercial or research-only use were mentioned.",
  "1-4 (Paper)": "The quotes clearly reference an official paper titled 'DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning'. The documentation indicates that a PDF version of the paper is available, and that the paper was authored by DeepSeek-AI along with 199 other contributors. The repeated mention of this paper underlines its significance in explaining the theoretical foundations and experimental methodologies behind DeepSeek-R1, particularly in leveraging reinforcement learning to enhance reasoning capabilities in large language models.",
  "1-1 (Weights)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama."
    },
    {
      "source": "[abstract]",
      "quote": "To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama."
    },
    {
      "source": "[sections/2501.12948]",
      "quote": "To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama."
    }
  ],
  "1-2 (Code)__evidence": [],
  "1-3 (License)__evidence": [],
  "1-4 (Paper)__evidence": [
    {
      "source": "[pdf_text]",
      "quote": "View a PDF of the paper titled DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, by DeepSeek-AI and 199 other authors"
    },
    {
      "source": "[title]",
      "quote": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
    },
    {
      "source": "[sections/2501.12948]",
      "quote": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
    }
  ]
}