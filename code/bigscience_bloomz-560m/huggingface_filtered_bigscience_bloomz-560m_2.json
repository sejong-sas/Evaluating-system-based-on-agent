{
  "1-5 (아키텍처 Architecture)": "모델 아키텍처는 bloom-560m과 동일한 구조를 가지며, config.json 파일 참조를 통해 세부 구성을 확인할 수 있다. 이 구성에는 하이퍼파라미터 설정이 포함되어 있으며, 특히 'n_layer' 값이 24로 명시되어 있어 모델의 레이어 수를 구체적으로 나타낸다.",
  "1-5 (아키텍처 Architecture)__evidence": [
    {
      "source": "readme",
      "quote": "- **Architecture:** Same as [bloom-560m](https://huggingface.co/bigscience/bloom-560m), also refer to the `config.json` file"
    },
    {
      "source": "config",
      "quote": "\"n_layer\": 24"
    }
  ],
  "1-6 (토크나이저 Tokenizer)": "토크나이저는 pretrained checkpoint에서 AutoTokenizer를 통해 로드되며, tokenizer.json 파일에 토크나이저의 세부 구조와 관련 정보가 포함되어 있다. 이를 통해 사용된 토크나이저의 이름, 구조, 그리고 다운로드 가능 여부를 확인할 수 있다.",
  "1-6 (토크나이저 Tokenizer)__evidence": [
    {
      "source": "readme",
      "quote": "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
    },
    {
      "source": "files",
      "quote": "tokenizer.json"
    }
  ],
  "2-1 (하드웨어 Hardware)": "훈련에는 AMD CPUs가 사용되어, 각 노드마다 512GB의 메모리를 갖추고 있다. 또한, 64개의 A100 80GB GPU가 8개의 GPU가 포함된 8개의 노드에 분산 배치되어 있으며, 각 노드는 NVLink 4 연결과 4 OmniPath 링크를 통해 상호 연결되어 있어 계산 자원의 규모와 성능을 극대화한다.",
  "2-1 (하드웨어 Hardware)__evidence": [
    {
      "source": "readme",
      "quote": "- **CPUs:** AMD CPUs with 512GB memory per node"
    },
    {
      "source": "readme",
      "quote": "- **GPUs:** 64 A100 80GB GPUs with 8 GPUs per node (8 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links"
    }
  ],
  "2-2 (소프트웨어 Software)": "훈련에는 Megatron-DeepSpeed를 통한 오케스트레이션이 채택되어 있으며, 이는 대규모 분산 훈련을 효율적으로 관리한다. 그 외에도 PyTorch(버전 1.11, CUDA-11.5 사용)가 신경망 구축 및 학습에 활용되어, 최신 소프트웨어 도구들과 버전이 결합되어 안정적인 실험 환경을 제공한다.",
  "2-2 (소프트웨어 Software)__evidence": [
    {
      "source": "readme",
      "quote": "- **Orchestration:** [Megatron-DeepSpeed](https://github.com/bigscience-workshop/Megatron-DeepSpeed)"
    },
    {
      "source": "readme",
      "quote": "- **Neural networks:** [PyTorch](https://github.com/pytorch/pytorch) (pytorch-1.11 w/ CUDA-11.5)"
    }
  ]
}