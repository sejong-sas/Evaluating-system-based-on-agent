{
  "1-1 (가중치 Weights)": "제공된 인용문에 따르면, 모델의 가중치는 사전 학습된 체크포인트 형태로 공개되어 있으며, 다운로드 링크를 통해 접근할 수 있습니다. 체크포인트는 모델이 PP=12, TP=4, DP=4의 설정으로 구성되어 있음을 명시하고 있습니다. 또한, 사용자가 모델의 형태를 변경하거나 재구성하려는 경우를 대비하여 별도의 'universal checkpoint'도 제공되고 있어, 두 가지 유형의 가중치 파일이 존재하며 각각의 목적에 따라 활용할 수 있음을 알 수 있습니다.",
  "1-2 (코드 Code)": "코드 관련 인용문에서는 훈련 및 추론을 위한 코드가 GitHub 레포지토리에서 제공되고 있음을 설명하고 있습니다. 구체적으로, 't0loading' 브랜치를 클론하여 필요한 환경을 구축하는 방법이 명시되어 있으며, 제공된 setup guide를 통해 필요한 패키지와 설정이 구성됩니다. 또한, 'create_xp3x.py'라는 스크립트 파일이 포함되어 있어, 이 파일 역시 코드의 구성 요소 중 하나로 사용자의 작업 환경에서 중요한 역할을 할 것으로 보입니다.",
  "1-3 (라이선스 License)": "라이선스 관련 인용문은 코드와 모델이 Apache License Version 2.0 (2004년 1월 버전)에 따라 배포되고 있음을 명확히 하고 있습니다. 또한, 'LICENSE.md' 파일을 통해 라이선스의 구체적인 조건과 사용자에게 부여되는 권한이 상세히 명시되어 있음을 알 수 있습니다. 이는 오픈 소스 소프트웨어의 투명한 배포 및 사용 조건을 충실히 반영하는 조치입니다.",
  "1-4 (논문 Paper)": "논문 관련 인용문에서는 이 저장소가 BLOOMZ, mT0, 그리고 xP3 모델의 구성 요소들을 포함하는 전반적인 개요를 제공하며, 이는 'Crosslingual Generalization through Multitask Finetuning'이라는 제목의 논문과 연계되어 있습니다. 논문 링크를 통해 해당 연구의 세부 내용을 확인할 수 있을 뿐 아니라, 'plotstables/XMTF_ACL2023_POSTER.pdf' 파일을 통해 추가적인 시각적 자료나 연구 결과를 제공하고 있어, 전체 프로젝트의 이론적 배경 및 구체적 구현 내용을 이해하는 데 도움이 될 수 있습니다.",
  "1-1 (가중치 Weights)__evidence": [
    {
      "source": "readme",
      "quote": "Download the pretrained model [checkpoint](https://huggingface.co/bigscience/bloom-optimizer-states), which is of shape PP=12, TP=4, DP=4. If you'd like to reshape the model you will also need to download [the universal checkpoint](https://huggingface.co/bigscience/bloom-optimizer-states/tree/global_step95000_universal)."
    }
  ],
  "1-2 (코드 Code)__evidence": [
    {
      "source": "readme",
      "quote": "Setup the training code: `git clone -b t0loading https://github.com/bigscience-workshop/Megatron-DeepSpeed` & follow its [setup guide](https://github.com/bigscience-workshop/Megatron-DeepSpeed/tree/t0loading#get-started-fast) to create an environment with necessary packages."
    },
    {
      "source": "files",
      "quote": "create_xp3x.py"
    }
  ],
  "1-3 (라이선스 License)__evidence": [
    {
      "source": "license_files",
      "quote": "Apache License\n                           Version 2.0, January 2004"
    },
    {
      "source": "files",
      "quote": "LICENSE.md"
    }
  ],
  "1-4 (논문 Paper)__evidence": [
    {
      "source": "readme",
      "quote": "This repository provides an overview of all components used for the creation of BLOOMZ & mT0 and xP3 introduced in the paper [Crosslingual Generalization through Multitask Finetuning](https://arxiv.org/abs/2211.01786)."
    },
    {
      "source": "files",
      "quote": "plotstables/XMTF_ACL2023_POSTER.pdf"
    }
  ]
}