{
  "2-3 (API)": "μ κ³µλ μ¦κ±°λ” HunyuanAPIμ— λ€ν• μ–ΈκΈ‰κ³Ό ν•¨κ», ν•΄λ‹Ή APIμ μ ‘κ·Ό κ°€λ¥μ„± λ° λ°°ν¬μ— λ€ν• κµ¬μ²΄μ μΈ μμ‹λ¥Ό ν¬ν•¨ν•κ³  μλ‹¤. μ²« λ²μ§Έ μΈμ©λ¬Έμ€ Tencent Cloudμ HunyuanAPIμ— λ€ν• λ§ν¬λ¥Ό μ κ³µν•μ—¬, λ¨λΈμ„ νΈμ¶ κ°€λ¥ν• API ν•νƒλ΅ μ κ³µν•λ” μμ‹λ¥Ό λ³΄μ—¬μ¤€λ‹¤. λ‘ λ²μ§Έ μΈμ©λ¬Έμ—μ„λ” TensorRT-LLM, vLLM, SGLangκ³Ό κ°™μ€ ν”„λ μ„μ›ν¬λ¥Ό μ‚¬μ©ν•΄ λ¨λΈμ„ μ„λΉ„μ¤ν•κ³  OpenAI νΈν™ API μ—”λ“ν¬μΈνΈλ¥Ό μƒμ„±ν•  μ μμμ„ μ„¤λ…ν•λ‹¤. μ΄λ΅μ¨ λ¨λΈμ΄ API ν•νƒλ΅ κ³µκ°λ  μ μλ‹¤λ” μ , λ¬Έμ„μ™€ κ΄€λ ¨λ λ§ν¬, κ·Έλ¦¬κ³  μ‚¬μ© μμ κ°€ ν¬ν•¨λ  μ μμμ„ μ•”μ‹ν•λ©°, λΌμ΄λΈλ¬λ¦¬ ν•νƒκ°€ μ•„λ‹ μ‹¤μ  APIλ¥Ό ν†µν•΄ λ¨λΈμ— μ ‘κ·Ό κ°€λ¥ν•λ„λ΅ ν•λ” λ¨λ“  μ‚¬ν•­λ“¤μ΄ ν¬ν•¨λμ–΄ μμμ„ λ³΄μ—¬μ¤€λ‹¤.",
  "2-3 (API)__evidence": [
    {
      "source": "readme",
      "quote": "π•–Β <a href=\"https://cloud.tencent.com/product/hunyuan\"><b>HunyuanAPI</b></a>&nbsp;&nbsp;|&nbsp;&nbsp;"
    },
    {
      "source": "readme",
      "quote": "For deployment, you can use frameworks such as **TensorRT-LLM**, **vLLM**, or **SGLang** to serve the model and create an OpenAI-compatible API endpoint."
    }
  ],
  "3-1 (μ‚¬μ „ν•™μµ Pre-training)": "μ¦κ±°μ—μ„λ” Hunyuanμ μ—¬λ¬ λ°€μ§‘ λ¨λΈμ΄ μ‚¬μ „ν•™μµκ³Ό μΈμ¤νΈλ­μ… νλ‹ λ²„μ „μΌλ΅ κµ¬μ„±λμ–΄ μμμ„ μ–ΈκΈ‰ν•λ‹¤. κµ¬μ²΄μ μΌλ΅, 0.5B, 1.8B, 4B, 7B νλΌλ―Έν„° μ¤μΌ€μΌμ„ κ°€μ§„ λ¨λΈλ“¤μ΄ μμΌλ©°, μ΄λ“¤μ€ Hunyuan-A13Bμ™€ μ μ‚¬ν• ν•™μµ μ „λµμ„ μ±„νƒν•΄ κ°•λ ¥ν• μ„±λ¥μ„ λ³΄μ—¬μ¤€λ‹¤. λν•, 2025λ…„ 7μ›” 30μΌμλ΅ Hugging Faceμ— κ΄€λ ¨ μ‚¬μ „ν•™μµ λ¨λΈκ³Ό μΈμ¤νΈλ­μ… λ²„μ „μ΄ μ¤ν”μ†μ¤ ν•μ‹μΌλ΅ κ³µκ°λμ—μμ„ λ…μ‹ν•¨μΌλ΅μ¨, μ‚¬μ „ν•™μµμ— μ‚¬μ©λ λ°©λ²•λ΅ , λ°μ΄ν„° μ²λ¦¬ νλ¦„, ν•μ΄νΌνλΌλ―Έν„° μ„¤μ • λ“± κµ¬μ²΄μ μΈ ν•™μµ μ μ°¨μ™€ κ³µκ° μƒνƒκ°€ μƒμ„Έν•κ² λ“λ¬λ‚λ‹¤.",
  "3-1 (μ‚¬μ „ν•™μµ Pre-training)__evidence": [
    {
      "source": "readme",
      "quote": "We have released a series of Hunyuan dense models, comprising both pre-trained and instruction-tuned variants, with parameter scales of 0.5B, 1.8B, 4B, and 7B. These models adopt training strategies similar to the Hunyuan-A13B, thereby inheriting its robust performance characteristics."
    },
    {
      "source": "readme",
      "quote": "* 2025.7.30 We have open-sourced  **Hunyuan-0.5B-Pretrain** ,  **Hunyuan-0.5B-Instruct** , **Hunyuan-1.8B-Pretrain** ,  **Hunyuan-1.8B-Instruct** , **Hunyuan-4B-Pretrain** ,  **Hunyuan-4B-Instruct** , **Hunyuan-7B-Pretrain** ,**Hunyuan-7B-Instruct** on Hugging Face."
    }
  ],
  "3-2 (νμΈνλ‹ Fine-tuning)": "νμΈνλ‹ λ¶€λ¶„μ—μ„λ” μ‚¬μ©μκ°€ Instruct λ¨λΈμ„ μ„Έλ¶€ μ΅°μ •ν•΄μ•Ό ν•  κ²½μ°, λ°μ΄ν„° μ²λ¦¬ ν•μ‹μ„ μ–΄λ–»κ² κµ¬μ„±ν•΄μ•Ό ν•λ”μ§€μ— λ€ν• κµ¬μ²΄μ  κ°€μ΄λ“λΌμΈμ„ μ κ³µν•λ‹¤. νΉν, λλ¦° μ‚¬κ³ μ™€ λΉ λ¥Έ μ‚¬κ³ μ— λ€μ‘ν•λ” ν•μ‹μ„ λ¨λ‘ κ³ λ ¤ν• λ°μ΄ν„° ν¬λ§· κ°€μ΄λ“κ°€ μ μ‹λμ–΄ μμΌλ©°, μ΄μ–΄μ„ LLaMA-Factoryλ¥Ό ν™μ©ν•΄ Hunyuan λ¨λΈμ„ νμΈνλ‹ν•λ” λ°©λ²•μ— λ€ν• μ„¤λ…μ΄ μ κ³µλμ–΄, μ¬ν„ κ°€λ¥ν• νμ΄ν”„λΌμΈμ μ΅΄μ¬μ™€ νμΈνλ‹μ λ©μ , μ‚¬μ© λ°μ΄ν„°μ— λ€ν• κµ¬μ²΄μ μΈ μ§€μΉ¨μ΄ λ¨λ‘ ν¬ν•¨λμ–΄ μμμ„ μ• μ μλ‹¤.",
  "3-2 (νμΈνλ‹ Fine-tuning)__evidence": [
    {
      "source": "readme",
      "quote": "If you need to fine-tune our Instruct model, we recommend processing the data into the following format, corresponding to both slow-thinking and fast-thinking scenarios."
    },
    {
      "source": "readme",
      "quote": "In the following chapter, we will introduce how to use `LLaMA-Factory` to fine-tune the `Hunyuan` model."
    }
  ],
  "3-3 (κ°•ν™”ν•™μµ Reinforcement Learning)": "ν„μ¬ μ κ³µλ μ¦κ±°μ—μ„λ” κ°•ν™”ν•™μµμ— κ΄€ν• κµ¬μ²΄μ μΈ λ‚΄μ©μ΄λ‚ μ μ°¨, μ•κ³ λ¦¬μ¦(RLHF, DPO λ“±)μ μ‚¬μ© μ—¬λ¶€, μ„¤μ •κ°’ λ“±μ— λ€ν• μ–΄λ– ν• μ •λ³΄λ„ ν¬ν•¨λμ–΄ μμ§€ μ•μΌλ©°, κ°•ν™”ν•™μµ κ΄€λ ¨ ν•­λ©μ€ λΉ μƒνƒλ΅ λ‚¨μ•„ μλ‹¤.",
  "3-3 (κ°•ν™”ν•™μµ Reinforcement Learning)__evidence": []
}