# openness_Evaluator.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â€¢ Hugging Face ëª¨ë¸ ì¡´ì¬ ì‹œ ìë™ 1ì : 1-1, 1-5, 1-6
# â€¢ ë‚˜ë¨¸ì§€ 13ê°œ í•­ëª©ì€ GPT í‰ê°€
# â€¢ í›ˆë ¨ ë°©ë²•ë¡ (3-1~3-3)ì€ arxiv_Dispatcher JSONì„ ìµœìš°ì„  ì°¸ê³ 
# â€¢ GPT ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ê°•ì œ: {"scores": {...}, "total_score": ...}
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import os, json
from typing import Dict, Any
from dotenv import load_dotenv
from openai import OpenAI
from pathlib import Path

load_dotenv()
_API_KEY = os.getenv("OPENAI_API_KEY")
if not _API_KEY:
    raise RuntimeError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
client = OpenAI(api_key=_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‰ê°€ ê¸°ì¤€ ì „ë¬¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CRITERIA_TEXT = """
## 1. ëª¨ë¸ ê¸°ë³¸ ê°œë°©ì„± (Model Basic Openness) - 6ê°œ í•­ëª©
### 1-1. ê°€ì¤‘ì¹˜ (Weights) - ë§Œì•½ í—ˆê¹…í˜ì´ìŠ¤ì— ëª¨ë¸ì´ ì˜¬ë¼ì™€ ìˆë‹¤ë©´ ë¬´ì¡°ê±´ Open
- Open(1ì ): ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ í—ˆê°€ ì—†ì´ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥
- Semi-Open(0.5ì ): í—ˆê°€ë¥¼ ë°›ì€ í›„ ëª¨ë¸ ê°€ì¤‘ì¹˜ ì´ìš© ê°€ëŠ¥
- Closed(0ì ): ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ê³µê°œë˜ì§€ ì•Šì•„ ì‚¬ìš© ë¶ˆê°€
### 1-2. ì½”ë“œ (Code) - ë§Œì•½ í—ˆê¹…í˜ì´ìŠ¤ì— .py íŒŒì¼ì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ Open
- Open(1ì ): ëª¨ë¸ í›ˆë ¨ ë° êµ¬í˜„ì— ì‚¬ìš©ëœ ì „ì²´ ì½”ë“œê°€ ê³µê°œ
- Semi-Open(0.5ì ): ëª¨ë¸ í›ˆë ¨ ë° êµ¬í˜„ ì½”ë“œì˜ ì¼ë¶€ë§Œ ê³µê°œ
- Closed(0ì ): í›ˆë ¨ ë° êµ¬í˜„ ì½”ë“œê°€ ê³µê°œë˜ì§€ ì•ŠìŒ
### 1-3. ë¼ì´ì„ ìŠ¤ (License)
- Open(1ì ): ì‚¬ìš©, ìˆ˜ì •, ì¬ë°°í¬, ìƒì—…ì  ì´ìš©ì— ì œí•œ ì—†ìŒ (MIT, Apache ë“±)
- Semi-Open(0.5ì ): ì‚¬ìš©, ìˆ˜ì •, ì¬ë°°í¬, ìƒì—…ì  ì´ìš© ì¤‘ 1ê°œ ì´ìƒ ì œí•œ
- Closed(0ì ): 3ê°œ ì´ìƒ ì œí•œ ì¡´ì¬í•˜ê±°ë‚˜ í•´ë‹¹ ë¼ì´ì„ ìŠ¤ ì—†ìŒ
### 1-4. ë…¼ë¬¸ (Paper)
- Open(1ì ): ê³µì‹ ë…¼ë¬¸ ë˜ëŠ” ê¸°ìˆ  ë³´ê³ ì„œ ì¡´ì¬
- Semi-Open(0.5ì ): ì›¹ì‚¬ì´íŠ¸ ë˜ëŠ” ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì¡´ì¬
- Closed(0ì ): ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ
### 1-5. ì•„í‚¤í…ì²˜ (Architecture) - ë§Œì•½ í—ˆê¹…í˜ì´ìŠ¤ì— ëª¨ë¸ì´ ì˜¬ë¼ì™€ ìˆë‹¤ë©´ ë¬´ì¡°ê±´ Open
- Open(1ì ): ëª¨ë¸ êµ¬ì¡°ì™€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ì™„ì „íˆ ê³µê°œ
- Semi-Open(0.5ì ): ëª¨ë¸ êµ¬ì¡°ë§Œ ê³µê°œ
- Closed(0ì ): ëª¨ë¸ êµ¬ì¡° ì •ë³´ ë¯¸ê³µê°œ
### 1-6. í† í¬ë‚˜ì´ì € (Tokenizer) - ë§Œì•½ í—ˆê¹…í˜ì´ìŠ¤ì— ëª¨ë¸ì´ ì˜¬ë¼ì™€ ìˆë‹¤ë©´ ë¬´ì¡°ê±´ Open
- Open(1ì ): ì‚¬ìš©ëœ í† í¬ë‚˜ì´ì €ê°€ ëª…ì‹œì ìœ¼ë¡œ ê³µê°œ
- Semi-Open(0.5ì ): ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ í† í¬ë‚˜ì´ì € ì¡´ì¬
- Closed(0ì ): í† í¬ë‚˜ì´ì € ì •ë³´ ë¯¸ê³µê°œ

## 2. ì ‘ê·¼ì„± ë° ì¬í˜„ì„± (Accessibility and Reproducibility) - 3ê°œ í•­ëª©
### 2-1. í•˜ë“œì›¨ì–´ (Hardware)
- Open(1ì ): í›ˆë ¨ í•˜ë“œì›¨ì–´ ì¢…ë¥˜Â·ìˆ˜ëŸ‰ ì™„ì „ ê³µê°œ
- Semi-Open(0.5ì ): í•˜ë“œì›¨ì–´ ì¢…ë¥˜ë§Œ ê³µê°œ
- Closed(0ì ): í•˜ë“œì›¨ì–´ ì •ë³´ ë¯¸ê³µê°œ
### 2-2. ì†Œí”„íŠ¸ì›¨ì–´ (Software)
- Open(1ì ): í›ˆë ¨ì— í•„ìš”í•œ ì†Œí”„íŠ¸ì›¨ì–´ ì‚¬ì–‘ ì™„ì „ ê³µê°œ
- Semi-Open(0.5ì ): ì¼ë¶€ë§Œ ê³µê°œ
- Closed(0ì ): ì •ë³´ ë¯¸ê³µê°œ
### 2-3. API
- Open(1ì ): ê³µê°œ API ì¡´ì¬
- Semi-Open(0.5ì ): í–¥í›„ ê³µê°œ ì˜ˆì •
- Closed(0ì ): API ì—†ìŒ

## 3. í›ˆë ¨ ë°©ë²•ë¡  ê°œë°©ì„± (Training Methodology Openness) - 3ê°œ í•­ëª©
### 3-1. ì‚¬ì „í•™ìŠµ (Pre-training)
- Open(1ì ): ì¬í˜„ ê°€ëŠ¥ ìˆ˜ì¤€ì˜ ìƒì„¸ ê³µê°œ
- Semi-Open(0.5ì ): ì¼ë¶€ ë°©ë²•ë§Œ ì–¸ê¸‰
- Closed(0ì ): ë°©ë²• ë¯¸ê³µê°œ
### 3-2. íŒŒì¸íŠœë‹ (Fine-tuning)
- Open(1ì ): ë°©ë²•ë¡  ì™„ì „ ê³µê°œ
- Semi-Open(0.5ì ): ì¼ë¶€ ê³µê°œ
- Closed(0ì ): ë¯¸ê³µê°œ/N/A
### 3-3. ê°•í™”í•™ìŠµ (Reinforcement Learning)
- Open(1ì ): RLHF, DPO ë“± ìƒì„¸ ê³µê°œ
- Semi-Open(0.5ì ): ì¼ë¶€ ê³µê°œ
- Closed(0ì ): ë¯¸ê³µê°œ/N/A

## 4. ë°ì´í„° ê°œë°©ì„± (Data Openness) - 4ê°œ í•­ëª©
### 4-1. ì‚¬ì „í•™ìŠµ ë°ì´í„° (Pre-training Data)
- Open(1ì ): ìˆ˜ëŸ‰Â·ì¶œì²˜ ì™„ì „ ê³µê°œ
- Semi-Open(0.5ì ): ì¢…ë¥˜ë§Œ ê³µê°œ
- Closed(0ì ): ë¯¸ê³µê°œ
### 4-2. íŒŒì¸íŠœë‹ ë°ì´í„° (Fine-tuning Data)
- Open(1ì ): ë°ì´í„° ì™„ì „ ê³µê°œ
- Semi-Open(0.5ì ): ì¼ë¶€ ê³µê°œ
- Closed(0ì ): ë¯¸ê³µê°œ/N/A
### 4-3. ê°•í™”í•™ìŠµ ë°ì´í„° (Reinforcement Learning Data)
- Open(1ì ): ë°ì´í„° ì™„ì „ ê³µê°œ
- Semi-Open(0.5ì ): ì¼ë¶€ ê³µê°œ
- Closed(0ì ): ë¯¸ê³µê°œ/N/A
### 4-4. ë°ì´í„° í•„í„°ë§ (Data Filtering)
- Open(1ì ): í•„í„°ë§ ë°©ë²•ë¡ Â·ë‚´ìš© ì™„ì „ ê³µê°œ
- Semi-Open(0.5ì ): ì¼ë¶€ ê³µê°œ
- Closed(0ì ): ë¯¸ê³µê°œ
""".strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GPT ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EVALUATION_PROMPT = f"""
{CRITERIA_TEXT}

â—ï¸í›ˆë ¨ ë°©ë²•ë¡  ê°œë°©ì„±(3-1 ~ 3-3)ì€ arxiv_Dispatcherê°€ ë§Œë“  JSON(ë…¼ë¬¸ ì •ë³´)ì„ **ê°€ì¥ ìš°ì„ ** ì°¸ê³ í•˜ì„¸ìš”.
HuggingFaceÂ·GitHub ì •ë³´ëŠ” ë³´ì¡° ì°¸ê³ ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.

ë˜í•œ Hugging Faceì— ëª¨ë¸ì´ ì¡´ì¬í•˜ë¯€ë¡œ **ë‹¤ìŒ ì„¸ í•­ëª©ì€ ì´ë¯¸ Open(1ì )** ì…ë‹ˆë‹¤.
  â€¢ 1-1 Weights â€¢ 1-5 Architecture â€¢ 1-6 Tokenizer
â†’ ì´ ì„¸ í•­ëª©ì€ scoresì— ë„£ì§€ ë§ˆì„¸ìš”.

ë°˜ë“œì‹œ ì•„ë˜ ìŠ¤í‚¤ë§ˆì²˜ëŸ¼ ë‹¨ì¼ JSON ë¸”ë¡ì„ ë°˜í™˜í•˜ì‹­ì‹œì˜¤:

{{
  "scores": {{
    "1-2 ì½”ë“œ": {{ "score": 1,   "reason": "..." }},
    ...
  }},
  "total_score": 12.5
}}
ë‹¤ë¥¸ ì£¼ì„Â·ë°±í‹±Â·ë¶ˆí•„ìš” í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.
""".strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìë™ 1ì  í•­ëª© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AUTO_OPEN_LABELS = {
    "1-1 ê°€ì¤‘ì¹˜":   "í—ˆê¹…í˜ì´ìŠ¤ì— ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³µê°œ",
    "1-5 ì•„í‚¤í…ì²˜": "í—ˆê¹…í˜ì´ìŠ¤ ì¹´ë“œì— ì•„í‚¤í…ì²˜ ì •ë³´ ê³µê°œ",
    "1-6 í† í¬ë‚˜ì´ì €": "í—ˆê¹…í˜ì´ìŠ¤ ì¹´ë“œ/configì— í† í¬ë‚˜ì´ì € ì •ë³´ ê³µê°œ",
}

def _auto_scores(hf_json: Dict[str, Any]) -> Dict[str, Dict]:
    return {lbl: {"score": 1, "reason": reason}
            for lbl, reason in AUTO_OPEN_LABELS.items()} if hf_json else {}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GPT í‰ê°€ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _gpt_evaluate(model: str,
                  hf: Dict, gh: Dict, ax: Dict) -> Dict[str, Dict]:
    payload = {
        "model": model,
        "data": {"huggingface": hf, "github": gh, "arxiv": ax}
    }
    rsp = client.chat.completions.create(
        model="o3-mini",
        reasoning_effort="medium",
        response_format={"type":"json_object"},
        messages=[
            {"role":"system","content":EVALUATION_PROMPT},
            {"role":"user",  "content":json.dumps(payload, ensure_ascii=False)}
        ]
    )
    raw = json.loads(rsp.choices[0].message.content.strip())
    scores_dict = raw.get("scores", raw)      # ìœ ì—° íŒŒì‹±
    out = {}
    for k, v in scores_dict.items():
        if isinstance(v, dict):
            out[k] = {"score": v.get("score", 0), "reason": v.get("reason","")}
        elif isinstance(v, (int, float)):
            out[k] = {"score": v, "reason": ""}
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ í‰ê°€ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def evaluate_openness(model_name: str,
                      hf_json=None, gh_json=None, arxiv_json=None) -> Dict:
    hf, gh, ax = hf_json or {}, gh_json or {}, arxiv_json or {}

    scores = _gpt_evaluate(model_name, hf, gh, ax)
    scores.update(_auto_scores(hf))           # ìë™ 1ì  í•­ëª© ì¶”ê°€/ë®ì–´ì“°ê¸°

    total = sum(v["score"] for v in scores.values())
    return {"model": model_name, "scores": scores, "total_score": total}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íŒŒì¼ ë¡œë” & CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load(p):
    if os.path.exists(p) and os.path.getsize(p):
        try:
            return json.load(open(p,encoding="utf-8"))
        except json.JSONDecodeError:
            print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨:", p)
    return {}

def evaluate_openness_from_files(model_name: str, base_dir: str | Path = "."):
    base = model_name.replace("/", "_").lower()
    base_dir = Path(base_dir)

    # í´ë” ìš°ì„ , ì—†ìœ¼ë©´ ë£¨íŠ¸ í´ë°±
    def _load_from_base(filename: str):
        p = base_dir / filename
        if p.exists() and p.stat().st_size:
            try:
                return json.load(open(p, encoding="utf-8"))
            except json.JSONDecodeError:
                print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨:", p)
        # ë£¨íŠ¸ í´ë°±
        if os.path.exists(filename) and os.path.getsize(filename):
            try:
                return json.load(open(filename, encoding="utf-8"))
            except json.JSONDecodeError:
                print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨:", filename)
        return {}

    hf = _load_from_base(f"huggingface_filtered_final_{base}.json")
    gh = _load_from_base(f"github_filtered_final_{base}.json")
    ax = _load_from_base(f"arxiv_filtered_final_{base}.json")

    res = evaluate_openness(model_name, hf, gh, ax)
    out = base_dir / f"openness_score_{base}.json"
    json.dump(res, open(out, "w", encoding="utf-8"), ensure_ascii=False, indent=2)
    print("ğŸ“ í‰ê°€ ê²°ê³¼ ì €ì¥:", out)
    return res


if __name__ == "__main__":
    evaluate_openness_from_files("bigscience/bloomz-560m")
