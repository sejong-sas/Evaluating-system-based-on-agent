{
  "1-5 (아키텍처 Architecture)": "인용문에 따르면, 모델의 아키텍처는 Bloom-560m과 동일하며, 자세한 구조와 하이퍼파라미터는 config.json 파일에 명시되어 있다. 특히 'n_layer': 24 라는 표현을 통해 레이어 수 등 중요한 파라미터가 설정되어 있음을 알 수 있다.",
  "1-5 (아키텍처 Architecture)__evidence": [
    {
      "source": "readme",
      "quote": "- **Architecture:** Same as [bloom-560m](https://huggingface.co/bigscience/bloom-560m), also refer to the `config.json` file"
    },
    {
      "source": "config",
      "quote": "\"n_layer\": 24,"
    }
  ],
  "1-6 (토크나이저 Tokenizer)": "제공된 증거에서는 토크나이저가 AutoTokenizer.from_pretrained(checkpoint)를 사용하여 불러오고 있음을 나타내며, 이로 인해 어떤 특정 체크포인트에서 토크나이저의 이름, 구조 및 다운로드 가능 여부 등 자세한 정보가 관리되고 있음을 보여준다.",
  "1-6 (토크나이저 Tokenizer)__evidence": [
    {
      "source": "readme",
      "quote": "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
    }
  ],
  "2-1 (하드웨어 Hardware)": "하드웨어 구성은 두 가지 주요 부문을 포함한다. 첫째, 각 노드에는 512GB 메모리를 갖춘 AMD CPU가 사용되고 있으며, 둘째, 64개의 A100 80GB GPU가 총 8개의 노드에서 8개씩 배치되어 NVLink 4 inter-gpu 연결과 4 OmniPath 링크를 통해 고속 데이터 전송 및 동기화가 이루어지는 구조를 갖추고 있다.",
  "2-1 (하드웨어 Hardware)__evidence": [
    {
      "source": "readme",
      "quote": "- **CPUs:** AMD CPUs with 512GB memory per node"
    },
    {
      "source": "readme",
      "quote": "- **GPUs:** 64 A100 80GB GPUs with 8 GPUs per node (8 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links"
    }
  ],
  "2-2 (소프트웨어 Software)": "훈련 소프트웨어로는 Megatron-DeepSpeed가 오케스트레이션 역할을 하며, DeepSpeed를 통해 최적화 및 병렬 처리가 수행된다. 신경망 구성은 PyTorch (pytorch-1.11 w/ CUDA-11.5)를 사용하여 구현되었고, 조건에 따라 FP16 연산을 위해 NVIDIA의 apex가 활용될 수 있음을 증거에서 확인할 수 있다.",
  "2-2 (소프트웨어 Software)__evidence": [
    {
      "source": "readme",
      "quote": "- **Orchestration:** [Megatron-DeepSpeed](https://github.com/bigscience-workshop/Megatron-DeepSpeed)"
    },
    {
      "source": "readme",
      "quote": "- **Optimizer & parallelism:** [DeepSpeed](https://github.com/microsoft/DeepSpeed)"
    },
    {
      "source": "readme",
      "quote": "- **Neural networks:** [PyTorch](https://github.com/pytorch/pytorch) (pytorch-1.11 w/ CUDA-11.5)"
    },
    {
      "source": "readme",
      "quote": "- **FP16 if applicable:** [apex](https://github.com/NVIDIA/apex)"
    }
  ]
}